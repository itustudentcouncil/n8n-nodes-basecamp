// Code generated by protoc-gen-ts_proto. DO NOT EDIT.
// versions:
//   protoc-gen-ts_proto  v2.2.0
//   protoc               unknown
// source: google/cloud/aiplatform/v1beta1/vertex_rag_data.proto

/* eslint-disable */
import { BinaryReader, BinaryWriter } from "@bufbuild/protobuf/wire";
import Long from "long";
import { Timestamp } from "../../../protobuf/timestamp.js";
import { ApiAuth } from "./api_auth.js";
import {
  BigQueryDestination,
  DirectUploadSource,
  GcsDestination,
  GcsSource,
  GoogleDriveSource,
  JiraSource,
  SharePointSources,
  SlackSource,
} from "./io.js";

export const protobufPackage = "google.cloud.aiplatform.v1beta1";

/** Config for the embedding model to use for RAG. */
export interface RagEmbeddingModelConfig {
  /**
   * The Vertex AI Prediction Endpoint that either refers to a publisher model
   * or an endpoint that is hosting a 1P fine-tuned text embedding model.
   * Endpoints hosting non-1P fine-tuned text embedding models are
   * currently not supported.
   * This is used for dense vector search.
   */
  vertexPredictionEndpoint?:
    | RagEmbeddingModelConfig_VertexPredictionEndpoint
    | undefined;
  /** Configuration for hybrid search. */
  hybridSearchConfig?: RagEmbeddingModelConfig_HybridSearchConfig | undefined;
}

/** Config representing a model hosted on Vertex Prediction Endpoint. */
export interface RagEmbeddingModelConfig_VertexPredictionEndpoint {
  /**
   * Required. The endpoint resource name.
   * Format:
   * `projects/{project}/locations/{location}/publishers/{publisher}/models/{model}`
   * or
   * `projects/{project}/locations/{location}/endpoints/{endpoint}`
   */
  endpoint: string;
  /**
   * Output only. The resource name of the model that is deployed on the
   * endpoint. Present only when the endpoint is not a publisher model.
   * Pattern:
   * `projects/{project}/locations/{location}/models/{model}`
   */
  model: string;
  /**
   * Output only. Version ID of the model that is deployed on the endpoint.
   * Present only when the endpoint is not a publisher model.
   */
  modelVersionId: string;
}

/** Configuration for sparse emebdding generation. */
export interface RagEmbeddingModelConfig_SparseEmbeddingConfig {
  /** Use BM25 scoring algorithm. */
  bm25?: RagEmbeddingModelConfig_SparseEmbeddingConfig_Bm25 | undefined;
}

/** Message for BM25 parameters. */
export interface RagEmbeddingModelConfig_SparseEmbeddingConfig_Bm25 {
  /** Optional. Use multilingual tokenizer if set to true. */
  multilingual: boolean;
  /**
   * Optional. The parameter to control term frequency saturation. It
   * determines the scaling between the matching term frequency and final
   * score. k1 is in the range of [1.2, 3]. The default value is 1.2.
   */
  k1?:
    | number
    | undefined;
  /**
   * Optional. The parameter to control document length normalization. It
   * determines how much the document length affects the final score. b is
   * in the range of [0, 1]. The default value is 0.75.
   */
  b?: number | undefined;
}

/** Config for hybrid search. */
export interface RagEmbeddingModelConfig_HybridSearchConfig {
  /**
   * Optional. The configuration for sparse embedding generation. This field
   * is optional the default behavior depends on the vector database choice on
   * the RagCorpus.
   */
  sparseEmbeddingConfig:
    | RagEmbeddingModelConfig_SparseEmbeddingConfig
    | undefined;
  /**
   * Required. The Vertex AI Prediction Endpoint that hosts the embedding
   * model for dense embedding generations.
   */
  denseEmbeddingModelPredictionEndpoint: RagEmbeddingModelConfig_VertexPredictionEndpoint | undefined;
}

/** Config for the Vector DB to use for RAG. */
export interface RagVectorDbConfig {
  /** The config for the RAG-managed Vector DB. */
  ragManagedDb?:
    | RagVectorDbConfig_RagManagedDb
    | undefined;
  /** The config for the Weaviate. */
  weaviate?:
    | RagVectorDbConfig_Weaviate
    | undefined;
  /** The config for the Pinecone. */
  pinecone?:
    | RagVectorDbConfig_Pinecone
    | undefined;
  /** The config for the Vertex Feature Store. */
  vertexFeatureStore?:
    | RagVectorDbConfig_VertexFeatureStore
    | undefined;
  /** The config for the Vertex Vector Search. */
  vertexVectorSearch?:
    | RagVectorDbConfig_VertexVectorSearch
    | undefined;
  /** Authentication config for the chosen Vector DB. */
  apiAuth: ApiAuth | undefined;
}

/** The config for the default RAG-managed Vector DB. */
export interface RagVectorDbConfig_RagManagedDb {
}

/** The config for the Weaviate. */
export interface RagVectorDbConfig_Weaviate {
  /**
   * Weaviate DB instance HTTP endpoint. e.g. 34.56.78.90:8080
   * Vertex RAG only supports HTTP connection to Weaviate.
   * This value cannot be changed after it's set.
   */
  httpEndpoint: string;
  /**
   * The corresponding collection this corpus maps to.
   * This value cannot be changed after it's set.
   */
  collectionName: string;
}

/** The config for the Pinecone. */
export interface RagVectorDbConfig_Pinecone {
  /**
   * Pinecone index name.
   * This value cannot be changed after it's set.
   */
  indexName: string;
}

/** The config for the Vertex Feature Store. */
export interface RagVectorDbConfig_VertexFeatureStore {
  /**
   * The resource name of the FeatureView.
   * Format:
   * `projects/{project}/locations/{location}/featureOnlineStores/{feature_online_store}/featureViews/{feature_view}`
   */
  featureViewResourceName: string;
}

/** The config for the Vertex Vector Search. */
export interface RagVectorDbConfig_VertexVectorSearch {
  /**
   * The resource name of the Index Endpoint.
   * Format:
   * `projects/{project}/locations/{location}/indexEndpoints/{index_endpoint}`
   */
  indexEndpoint: string;
  /**
   * The resource name of the Index.
   * Format:
   * `projects/{project}/locations/{location}/indexes/{index}`
   */
  index: string;
}

/** RagFile status. */
export interface FileStatus {
  /** Output only. RagFile state. */
  state: FileStatus_State;
  /** Output only. Only when the `state` field is ERROR. */
  errorStatus: string;
}

/** RagFile state. */
export enum FileStatus_State {
  /** STATE_UNSPECIFIED - RagFile state is unspecified. */
  STATE_UNSPECIFIED = 0,
  /** ACTIVE - RagFile resource has been created and indexed successfully. */
  ACTIVE = 1,
  /**
   * ERROR - RagFile resource is in a problematic state.
   * See `error_message` field for details.
   */
  ERROR = 2,
  UNRECOGNIZED = -1,
}

export function fileStatus_StateFromJSON(object: any): FileStatus_State {
  switch (object) {
    case 0:
    case "STATE_UNSPECIFIED":
      return FileStatus_State.STATE_UNSPECIFIED;
    case 1:
    case "ACTIVE":
      return FileStatus_State.ACTIVE;
    case 2:
    case "ERROR":
      return FileStatus_State.ERROR;
    case -1:
    case "UNRECOGNIZED":
    default:
      return FileStatus_State.UNRECOGNIZED;
  }
}

export function fileStatus_StateToJSON(object: FileStatus_State): string {
  switch (object) {
    case FileStatus_State.STATE_UNSPECIFIED:
      return "STATE_UNSPECIFIED";
    case FileStatus_State.ACTIVE:
      return "ACTIVE";
    case FileStatus_State.ERROR:
      return "ERROR";
    case FileStatus_State.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/** RagCorpus status. */
export interface CorpusStatus {
  /** Output only. RagCorpus life state. */
  state: CorpusStatus_State;
  /** Output only. Only when the `state` field is ERROR. */
  errorStatus: string;
}

/** RagCorpus life state. */
export enum CorpusStatus_State {
  /** UNKNOWN - This state is not supposed to happen. */
  UNKNOWN = 0,
  /** INITIALIZED - RagCorpus resource entry is initialized, but hasn't done validation. */
  INITIALIZED = 1,
  /** ACTIVE - RagCorpus is provisioned successfully and is ready to serve. */
  ACTIVE = 2,
  /**
   * ERROR - RagCorpus is in a problematic situation.
   * See `error_message` field for details.
   */
  ERROR = 3,
  UNRECOGNIZED = -1,
}

export function corpusStatus_StateFromJSON(object: any): CorpusStatus_State {
  switch (object) {
    case 0:
    case "UNKNOWN":
      return CorpusStatus_State.UNKNOWN;
    case 1:
    case "INITIALIZED":
      return CorpusStatus_State.INITIALIZED;
    case 2:
    case "ACTIVE":
      return CorpusStatus_State.ACTIVE;
    case 3:
    case "ERROR":
      return CorpusStatus_State.ERROR;
    case -1:
    case "UNRECOGNIZED":
    default:
      return CorpusStatus_State.UNRECOGNIZED;
  }
}

export function corpusStatus_StateToJSON(object: CorpusStatus_State): string {
  switch (object) {
    case CorpusStatus_State.UNKNOWN:
      return "UNKNOWN";
    case CorpusStatus_State.INITIALIZED:
      return "INITIALIZED";
    case CorpusStatus_State.ACTIVE:
      return "ACTIVE";
    case CorpusStatus_State.ERROR:
      return "ERROR";
    case CorpusStatus_State.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/**
 * A RagCorpus is a RagFile container and a project can have multiple
 * RagCorpora.
 */
export interface RagCorpus {
  /** Output only. The resource name of the RagCorpus. */
  name: string;
  /**
   * Required. The display name of the RagCorpus.
   * The name can be up to 128 characters long and can consist of any UTF-8
   * characters.
   */
  displayName: string;
  /** Optional. The description of the RagCorpus. */
  description: string;
  /** Optional. Immutable. The embedding model config of the RagCorpus. */
  ragEmbeddingModelConfig:
    | RagEmbeddingModelConfig
    | undefined;
  /** Optional. Immutable. The Vector DB config of the RagCorpus. */
  ragVectorDbConfig:
    | RagVectorDbConfig
    | undefined;
  /** Output only. Timestamp when this RagCorpus was created. */
  createTime:
    | Date
    | undefined;
  /** Output only. Timestamp when this RagCorpus was last updated. */
  updateTime:
    | Date
    | undefined;
  /** Output only. RagCorpus state. */
  corpusStatus: CorpusStatus | undefined;
}

/** A RagFile contains user data for chunking, embedding and indexing. */
export interface RagFile {
  /**
   * Output only. Google Cloud Storage location of the RagFile.
   * It does not support wildcards in the Cloud Storage uri for now.
   */
  gcsSource?:
    | GcsSource
    | undefined;
  /**
   * Output only. Google Drive location. Supports importing individual files
   * as well as Google Drive folders.
   */
  googleDriveSource?:
    | GoogleDriveSource
    | undefined;
  /**
   * Output only. The RagFile is encapsulated and uploaded in the
   * UploadRagFile request.
   */
  directUploadSource?:
    | DirectUploadSource
    | undefined;
  /** The RagFile is imported from a Slack channel. */
  slackSource?:
    | SlackSource
    | undefined;
  /** The RagFile is imported from a Jira query. */
  jiraSource?:
    | JiraSource
    | undefined;
  /** The RagFile is imported from a SharePoint source. */
  sharePointSources?:
    | SharePointSources
    | undefined;
  /** Output only. The resource name of the RagFile. */
  name: string;
  /**
   * Required. The display name of the RagFile.
   * The name can be up to 128 characters long and can consist of any UTF-8
   * characters.
   */
  displayName: string;
  /** Optional. The description of the RagFile. */
  description: string;
  /** Output only. The size of the RagFile in bytes. */
  sizeBytes: Long;
  /** Output only. The type of the RagFile. */
  ragFileType: RagFile_RagFileType;
  /** Output only. Timestamp when this RagFile was created. */
  createTime:
    | Date
    | undefined;
  /** Output only. Timestamp when this RagFile was last updated. */
  updateTime:
    | Date
    | undefined;
  /** Output only. State of the RagFile. */
  fileStatus: FileStatus | undefined;
}

/** The type of the RagFile. */
export enum RagFile_RagFileType {
  /** RAG_FILE_TYPE_UNSPECIFIED - RagFile type is unspecified. */
  RAG_FILE_TYPE_UNSPECIFIED = 0,
  /** RAG_FILE_TYPE_TXT - RagFile type is TXT. */
  RAG_FILE_TYPE_TXT = 1,
  /** RAG_FILE_TYPE_PDF - RagFile type is PDF. */
  RAG_FILE_TYPE_PDF = 2,
  UNRECOGNIZED = -1,
}

export function ragFile_RagFileTypeFromJSON(object: any): RagFile_RagFileType {
  switch (object) {
    case 0:
    case "RAG_FILE_TYPE_UNSPECIFIED":
      return RagFile_RagFileType.RAG_FILE_TYPE_UNSPECIFIED;
    case 1:
    case "RAG_FILE_TYPE_TXT":
      return RagFile_RagFileType.RAG_FILE_TYPE_TXT;
    case 2:
    case "RAG_FILE_TYPE_PDF":
      return RagFile_RagFileType.RAG_FILE_TYPE_PDF;
    case -1:
    case "UNRECOGNIZED":
    default:
      return RagFile_RagFileType.UNRECOGNIZED;
  }
}

export function ragFile_RagFileTypeToJSON(object: RagFile_RagFileType): string {
  switch (object) {
    case RagFile_RagFileType.RAG_FILE_TYPE_UNSPECIFIED:
      return "RAG_FILE_TYPE_UNSPECIFIED";
    case RagFile_RagFileType.RAG_FILE_TYPE_TXT:
      return "RAG_FILE_TYPE_TXT";
    case RagFile_RagFileType.RAG_FILE_TYPE_PDF:
      return "RAG_FILE_TYPE_PDF";
    case RagFile_RagFileType.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/** Specifies the size and overlap of chunks for RagFiles. */
export interface RagFileChunkingConfig {
  /** The size of the chunks. */
  chunkSize: number;
  /** The overlap between chunks. */
  chunkOverlap: number;
}

/** Specifies the parsing config for RagFiles. */
export interface RagFileParsingConfig {
  /** Whether to use advanced PDF parsing. */
  useAdvancedPdfParsing: boolean;
}

/** Config for uploading RagFile. */
export interface UploadRagFileConfig {
  /** Specifies the size and overlap of chunks after uploading RagFile. */
  ragFileChunkingConfig: RagFileChunkingConfig | undefined;
}

/** Config for importing RagFiles. */
export interface ImportRagFilesConfig {
  /**
   * Google Cloud Storage location. Supports importing individual files as
   * well as entire Google Cloud Storage directories. Sample formats:
   * - `gs://bucket_name/my_directory/object_name/my_file.txt`
   * - `gs://bucket_name/my_directory`
   */
  gcsSource?:
    | GcsSource
    | undefined;
  /**
   * Google Drive location. Supports importing individual files as
   * well as Google Drive folders.
   */
  googleDriveSource?:
    | GoogleDriveSource
    | undefined;
  /** Slack channels with their corresponding access tokens. */
  slackSource?:
    | SlackSource
    | undefined;
  /** Jira queries with their corresponding authentication. */
  jiraSource?:
    | JiraSource
    | undefined;
  /** SharePoint sources. */
  sharePointSources?:
    | SharePointSources
    | undefined;
  /** The Cloud Storage path to write partial failures to. */
  partialFailureGcsSink?:
    | GcsDestination
    | undefined;
  /**
   * The BigQuery destination to write partial failures to. It should be a
   * bigquery table resource name (e.g.
   * "bq://projectId.bqDatasetId.bqTableId"). If the dataset id does not
   * exist, it will be created. If the table does not exist, it will be
   * created with the expected schema. If the table exists, the schema will be
   * validated and data will be added to this existing table.
   */
  partialFailureBigquerySink?:
    | BigQueryDestination
    | undefined;
  /** Specifies the size and overlap of chunks after importing RagFiles. */
  ragFileChunkingConfig:
    | RagFileChunkingConfig
    | undefined;
  /** Specifies the parsing config for RagFiles. */
  ragFileParsingConfig:
    | RagFileParsingConfig
    | undefined;
  /**
   * Optional. The max number of queries per minute that this job is allowed to
   * make to the embedding model specified on the corpus. This value is specific
   * to this job and not shared across other import jobs. Consult the Quotas
   * page on the project to set an appropriate value here.
   * If unspecified, a default value of 1,000 QPM would be used.
   */
  maxEmbeddingRequestsPerMin: number;
}

function createBaseRagEmbeddingModelConfig(): RagEmbeddingModelConfig {
  return { vertexPredictionEndpoint: undefined, hybridSearchConfig: undefined };
}

export const RagEmbeddingModelConfig: MessageFns<RagEmbeddingModelConfig> = {
  encode(message: RagEmbeddingModelConfig, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.vertexPredictionEndpoint !== undefined) {
      RagEmbeddingModelConfig_VertexPredictionEndpoint.encode(
        message.vertexPredictionEndpoint,
        writer.uint32(10).fork(),
      ).join();
    }
    if (message.hybridSearchConfig !== undefined) {
      RagEmbeddingModelConfig_HybridSearchConfig.encode(message.hybridSearchConfig, writer.uint32(18).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): RagEmbeddingModelConfig {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseRagEmbeddingModelConfig();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.vertexPredictionEndpoint = RagEmbeddingModelConfig_VertexPredictionEndpoint.decode(
            reader,
            reader.uint32(),
          );
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.hybridSearchConfig = RagEmbeddingModelConfig_HybridSearchConfig.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): RagEmbeddingModelConfig {
    return {
      vertexPredictionEndpoint: isSet(object.vertexPredictionEndpoint)
        ? RagEmbeddingModelConfig_VertexPredictionEndpoint.fromJSON(object.vertexPredictionEndpoint)
        : undefined,
      hybridSearchConfig: isSet(object.hybridSearchConfig)
        ? RagEmbeddingModelConfig_HybridSearchConfig.fromJSON(object.hybridSearchConfig)
        : undefined,
    };
  },

  toJSON(message: RagEmbeddingModelConfig): unknown {
    const obj: any = {};
    if (message.vertexPredictionEndpoint !== undefined) {
      obj.vertexPredictionEndpoint = RagEmbeddingModelConfig_VertexPredictionEndpoint.toJSON(
        message.vertexPredictionEndpoint,
      );
    }
    if (message.hybridSearchConfig !== undefined) {
      obj.hybridSearchConfig = RagEmbeddingModelConfig_HybridSearchConfig.toJSON(message.hybridSearchConfig);
    }
    return obj;
  },

  create(base?: DeepPartial<RagEmbeddingModelConfig>): RagEmbeddingModelConfig {
    return RagEmbeddingModelConfig.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<RagEmbeddingModelConfig>): RagEmbeddingModelConfig {
    const message = createBaseRagEmbeddingModelConfig();
    message.vertexPredictionEndpoint =
      (object.vertexPredictionEndpoint !== undefined && object.vertexPredictionEndpoint !== null)
        ? RagEmbeddingModelConfig_VertexPredictionEndpoint.fromPartial(object.vertexPredictionEndpoint)
        : undefined;
    message.hybridSearchConfig = (object.hybridSearchConfig !== undefined && object.hybridSearchConfig !== null)
      ? RagEmbeddingModelConfig_HybridSearchConfig.fromPartial(object.hybridSearchConfig)
      : undefined;
    return message;
  },
};

function createBaseRagEmbeddingModelConfig_VertexPredictionEndpoint(): RagEmbeddingModelConfig_VertexPredictionEndpoint {
  return { endpoint: "", model: "", modelVersionId: "" };
}

export const RagEmbeddingModelConfig_VertexPredictionEndpoint: MessageFns<
  RagEmbeddingModelConfig_VertexPredictionEndpoint
> = {
  encode(
    message: RagEmbeddingModelConfig_VertexPredictionEndpoint,
    writer: BinaryWriter = new BinaryWriter(),
  ): BinaryWriter {
    if (message.endpoint !== "") {
      writer.uint32(10).string(message.endpoint);
    }
    if (message.model !== "") {
      writer.uint32(18).string(message.model);
    }
    if (message.modelVersionId !== "") {
      writer.uint32(26).string(message.modelVersionId);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): RagEmbeddingModelConfig_VertexPredictionEndpoint {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseRagEmbeddingModelConfig_VertexPredictionEndpoint();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.endpoint = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.model = reader.string();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.modelVersionId = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): RagEmbeddingModelConfig_VertexPredictionEndpoint {
    return {
      endpoint: isSet(object.endpoint) ? globalThis.String(object.endpoint) : "",
      model: isSet(object.model) ? globalThis.String(object.model) : "",
      modelVersionId: isSet(object.modelVersionId) ? globalThis.String(object.modelVersionId) : "",
    };
  },

  toJSON(message: RagEmbeddingModelConfig_VertexPredictionEndpoint): unknown {
    const obj: any = {};
    if (message.endpoint !== "") {
      obj.endpoint = message.endpoint;
    }
    if (message.model !== "") {
      obj.model = message.model;
    }
    if (message.modelVersionId !== "") {
      obj.modelVersionId = message.modelVersionId;
    }
    return obj;
  },

  create(
    base?: DeepPartial<RagEmbeddingModelConfig_VertexPredictionEndpoint>,
  ): RagEmbeddingModelConfig_VertexPredictionEndpoint {
    return RagEmbeddingModelConfig_VertexPredictionEndpoint.fromPartial(base ?? {});
  },
  fromPartial(
    object: DeepPartial<RagEmbeddingModelConfig_VertexPredictionEndpoint>,
  ): RagEmbeddingModelConfig_VertexPredictionEndpoint {
    const message = createBaseRagEmbeddingModelConfig_VertexPredictionEndpoint();
    message.endpoint = object.endpoint ?? "";
    message.model = object.model ?? "";
    message.modelVersionId = object.modelVersionId ?? "";
    return message;
  },
};

function createBaseRagEmbeddingModelConfig_SparseEmbeddingConfig(): RagEmbeddingModelConfig_SparseEmbeddingConfig {
  return { bm25: undefined };
}

export const RagEmbeddingModelConfig_SparseEmbeddingConfig: MessageFns<RagEmbeddingModelConfig_SparseEmbeddingConfig> =
  {
    encode(
      message: RagEmbeddingModelConfig_SparseEmbeddingConfig,
      writer: BinaryWriter = new BinaryWriter(),
    ): BinaryWriter {
      if (message.bm25 !== undefined) {
        RagEmbeddingModelConfig_SparseEmbeddingConfig_Bm25.encode(message.bm25, writer.uint32(10).fork()).join();
      }
      return writer;
    },

    decode(input: BinaryReader | Uint8Array, length?: number): RagEmbeddingModelConfig_SparseEmbeddingConfig {
      const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
      let end = length === undefined ? reader.len : reader.pos + length;
      const message = createBaseRagEmbeddingModelConfig_SparseEmbeddingConfig();
      while (reader.pos < end) {
        const tag = reader.uint32();
        switch (tag >>> 3) {
          case 1:
            if (tag !== 10) {
              break;
            }

            message.bm25 = RagEmbeddingModelConfig_SparseEmbeddingConfig_Bm25.decode(reader, reader.uint32());
            continue;
        }
        if ((tag & 7) === 4 || tag === 0) {
          break;
        }
        reader.skip(tag & 7);
      }
      return message;
    },

    fromJSON(object: any): RagEmbeddingModelConfig_SparseEmbeddingConfig {
      return {
        bm25: isSet(object.bm25) ? RagEmbeddingModelConfig_SparseEmbeddingConfig_Bm25.fromJSON(object.bm25) : undefined,
      };
    },

    toJSON(message: RagEmbeddingModelConfig_SparseEmbeddingConfig): unknown {
      const obj: any = {};
      if (message.bm25 !== undefined) {
        obj.bm25 = RagEmbeddingModelConfig_SparseEmbeddingConfig_Bm25.toJSON(message.bm25);
      }
      return obj;
    },

    create(
      base?: DeepPartial<RagEmbeddingModelConfig_SparseEmbeddingConfig>,
    ): RagEmbeddingModelConfig_SparseEmbeddingConfig {
      return RagEmbeddingModelConfig_SparseEmbeddingConfig.fromPartial(base ?? {});
    },
    fromPartial(
      object: DeepPartial<RagEmbeddingModelConfig_SparseEmbeddingConfig>,
    ): RagEmbeddingModelConfig_SparseEmbeddingConfig {
      const message = createBaseRagEmbeddingModelConfig_SparseEmbeddingConfig();
      message.bm25 = (object.bm25 !== undefined && object.bm25 !== null)
        ? RagEmbeddingModelConfig_SparseEmbeddingConfig_Bm25.fromPartial(object.bm25)
        : undefined;
      return message;
    },
  };

function createBaseRagEmbeddingModelConfig_SparseEmbeddingConfig_Bm25(): RagEmbeddingModelConfig_SparseEmbeddingConfig_Bm25 {
  return { multilingual: false, k1: undefined, b: undefined };
}

export const RagEmbeddingModelConfig_SparseEmbeddingConfig_Bm25: MessageFns<
  RagEmbeddingModelConfig_SparseEmbeddingConfig_Bm25
> = {
  encode(
    message: RagEmbeddingModelConfig_SparseEmbeddingConfig_Bm25,
    writer: BinaryWriter = new BinaryWriter(),
  ): BinaryWriter {
    if (message.multilingual !== false) {
      writer.uint32(8).bool(message.multilingual);
    }
    if (message.k1 !== undefined) {
      writer.uint32(21).float(message.k1);
    }
    if (message.b !== undefined) {
      writer.uint32(29).float(message.b);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): RagEmbeddingModelConfig_SparseEmbeddingConfig_Bm25 {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseRagEmbeddingModelConfig_SparseEmbeddingConfig_Bm25();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 8) {
            break;
          }

          message.multilingual = reader.bool();
          continue;
        case 2:
          if (tag !== 21) {
            break;
          }

          message.k1 = reader.float();
          continue;
        case 3:
          if (tag !== 29) {
            break;
          }

          message.b = reader.float();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): RagEmbeddingModelConfig_SparseEmbeddingConfig_Bm25 {
    return {
      multilingual: isSet(object.multilingual) ? globalThis.Boolean(object.multilingual) : false,
      k1: isSet(object.k1) ? globalThis.Number(object.k1) : undefined,
      b: isSet(object.b) ? globalThis.Number(object.b) : undefined,
    };
  },

  toJSON(message: RagEmbeddingModelConfig_SparseEmbeddingConfig_Bm25): unknown {
    const obj: any = {};
    if (message.multilingual !== false) {
      obj.multilingual = message.multilingual;
    }
    if (message.k1 !== undefined) {
      obj.k1 = message.k1;
    }
    if (message.b !== undefined) {
      obj.b = message.b;
    }
    return obj;
  },

  create(
    base?: DeepPartial<RagEmbeddingModelConfig_SparseEmbeddingConfig_Bm25>,
  ): RagEmbeddingModelConfig_SparseEmbeddingConfig_Bm25 {
    return RagEmbeddingModelConfig_SparseEmbeddingConfig_Bm25.fromPartial(base ?? {});
  },
  fromPartial(
    object: DeepPartial<RagEmbeddingModelConfig_SparseEmbeddingConfig_Bm25>,
  ): RagEmbeddingModelConfig_SparseEmbeddingConfig_Bm25 {
    const message = createBaseRagEmbeddingModelConfig_SparseEmbeddingConfig_Bm25();
    message.multilingual = object.multilingual ?? false;
    message.k1 = object.k1 ?? undefined;
    message.b = object.b ?? undefined;
    return message;
  },
};

function createBaseRagEmbeddingModelConfig_HybridSearchConfig(): RagEmbeddingModelConfig_HybridSearchConfig {
  return { sparseEmbeddingConfig: undefined, denseEmbeddingModelPredictionEndpoint: undefined };
}

export const RagEmbeddingModelConfig_HybridSearchConfig: MessageFns<RagEmbeddingModelConfig_HybridSearchConfig> = {
  encode(message: RagEmbeddingModelConfig_HybridSearchConfig, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.sparseEmbeddingConfig !== undefined) {
      RagEmbeddingModelConfig_SparseEmbeddingConfig.encode(message.sparseEmbeddingConfig, writer.uint32(10).fork())
        .join();
    }
    if (message.denseEmbeddingModelPredictionEndpoint !== undefined) {
      RagEmbeddingModelConfig_VertexPredictionEndpoint.encode(
        message.denseEmbeddingModelPredictionEndpoint,
        writer.uint32(18).fork(),
      ).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): RagEmbeddingModelConfig_HybridSearchConfig {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseRagEmbeddingModelConfig_HybridSearchConfig();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.sparseEmbeddingConfig = RagEmbeddingModelConfig_SparseEmbeddingConfig.decode(reader, reader.uint32());
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.denseEmbeddingModelPredictionEndpoint = RagEmbeddingModelConfig_VertexPredictionEndpoint.decode(
            reader,
            reader.uint32(),
          );
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): RagEmbeddingModelConfig_HybridSearchConfig {
    return {
      sparseEmbeddingConfig: isSet(object.sparseEmbeddingConfig)
        ? RagEmbeddingModelConfig_SparseEmbeddingConfig.fromJSON(object.sparseEmbeddingConfig)
        : undefined,
      denseEmbeddingModelPredictionEndpoint: isSet(object.denseEmbeddingModelPredictionEndpoint)
        ? RagEmbeddingModelConfig_VertexPredictionEndpoint.fromJSON(object.denseEmbeddingModelPredictionEndpoint)
        : undefined,
    };
  },

  toJSON(message: RagEmbeddingModelConfig_HybridSearchConfig): unknown {
    const obj: any = {};
    if (message.sparseEmbeddingConfig !== undefined) {
      obj.sparseEmbeddingConfig = RagEmbeddingModelConfig_SparseEmbeddingConfig.toJSON(message.sparseEmbeddingConfig);
    }
    if (message.denseEmbeddingModelPredictionEndpoint !== undefined) {
      obj.denseEmbeddingModelPredictionEndpoint = RagEmbeddingModelConfig_VertexPredictionEndpoint.toJSON(
        message.denseEmbeddingModelPredictionEndpoint,
      );
    }
    return obj;
  },

  create(base?: DeepPartial<RagEmbeddingModelConfig_HybridSearchConfig>): RagEmbeddingModelConfig_HybridSearchConfig {
    return RagEmbeddingModelConfig_HybridSearchConfig.fromPartial(base ?? {});
  },
  fromPartial(
    object: DeepPartial<RagEmbeddingModelConfig_HybridSearchConfig>,
  ): RagEmbeddingModelConfig_HybridSearchConfig {
    const message = createBaseRagEmbeddingModelConfig_HybridSearchConfig();
    message.sparseEmbeddingConfig =
      (object.sparseEmbeddingConfig !== undefined && object.sparseEmbeddingConfig !== null)
        ? RagEmbeddingModelConfig_SparseEmbeddingConfig.fromPartial(object.sparseEmbeddingConfig)
        : undefined;
    message.denseEmbeddingModelPredictionEndpoint =
      (object.denseEmbeddingModelPredictionEndpoint !== undefined &&
          object.denseEmbeddingModelPredictionEndpoint !== null)
        ? RagEmbeddingModelConfig_VertexPredictionEndpoint.fromPartial(object.denseEmbeddingModelPredictionEndpoint)
        : undefined;
    return message;
  },
};

function createBaseRagVectorDbConfig(): RagVectorDbConfig {
  return {
    ragManagedDb: undefined,
    weaviate: undefined,
    pinecone: undefined,
    vertexFeatureStore: undefined,
    vertexVectorSearch: undefined,
    apiAuth: undefined,
  };
}

export const RagVectorDbConfig: MessageFns<RagVectorDbConfig> = {
  encode(message: RagVectorDbConfig, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.ragManagedDb !== undefined) {
      RagVectorDbConfig_RagManagedDb.encode(message.ragManagedDb, writer.uint32(10).fork()).join();
    }
    if (message.weaviate !== undefined) {
      RagVectorDbConfig_Weaviate.encode(message.weaviate, writer.uint32(18).fork()).join();
    }
    if (message.pinecone !== undefined) {
      RagVectorDbConfig_Pinecone.encode(message.pinecone, writer.uint32(26).fork()).join();
    }
    if (message.vertexFeatureStore !== undefined) {
      RagVectorDbConfig_VertexFeatureStore.encode(message.vertexFeatureStore, writer.uint32(34).fork()).join();
    }
    if (message.vertexVectorSearch !== undefined) {
      RagVectorDbConfig_VertexVectorSearch.encode(message.vertexVectorSearch, writer.uint32(50).fork()).join();
    }
    if (message.apiAuth !== undefined) {
      ApiAuth.encode(message.apiAuth, writer.uint32(42).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): RagVectorDbConfig {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseRagVectorDbConfig();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.ragManagedDb = RagVectorDbConfig_RagManagedDb.decode(reader, reader.uint32());
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.weaviate = RagVectorDbConfig_Weaviate.decode(reader, reader.uint32());
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.pinecone = RagVectorDbConfig_Pinecone.decode(reader, reader.uint32());
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.vertexFeatureStore = RagVectorDbConfig_VertexFeatureStore.decode(reader, reader.uint32());
          continue;
        case 6:
          if (tag !== 50) {
            break;
          }

          message.vertexVectorSearch = RagVectorDbConfig_VertexVectorSearch.decode(reader, reader.uint32());
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.apiAuth = ApiAuth.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): RagVectorDbConfig {
    return {
      ragManagedDb: isSet(object.ragManagedDb)
        ? RagVectorDbConfig_RagManagedDb.fromJSON(object.ragManagedDb)
        : undefined,
      weaviate: isSet(object.weaviate) ? RagVectorDbConfig_Weaviate.fromJSON(object.weaviate) : undefined,
      pinecone: isSet(object.pinecone) ? RagVectorDbConfig_Pinecone.fromJSON(object.pinecone) : undefined,
      vertexFeatureStore: isSet(object.vertexFeatureStore)
        ? RagVectorDbConfig_VertexFeatureStore.fromJSON(object.vertexFeatureStore)
        : undefined,
      vertexVectorSearch: isSet(object.vertexVectorSearch)
        ? RagVectorDbConfig_VertexVectorSearch.fromJSON(object.vertexVectorSearch)
        : undefined,
      apiAuth: isSet(object.apiAuth) ? ApiAuth.fromJSON(object.apiAuth) : undefined,
    };
  },

  toJSON(message: RagVectorDbConfig): unknown {
    const obj: any = {};
    if (message.ragManagedDb !== undefined) {
      obj.ragManagedDb = RagVectorDbConfig_RagManagedDb.toJSON(message.ragManagedDb);
    }
    if (message.weaviate !== undefined) {
      obj.weaviate = RagVectorDbConfig_Weaviate.toJSON(message.weaviate);
    }
    if (message.pinecone !== undefined) {
      obj.pinecone = RagVectorDbConfig_Pinecone.toJSON(message.pinecone);
    }
    if (message.vertexFeatureStore !== undefined) {
      obj.vertexFeatureStore = RagVectorDbConfig_VertexFeatureStore.toJSON(message.vertexFeatureStore);
    }
    if (message.vertexVectorSearch !== undefined) {
      obj.vertexVectorSearch = RagVectorDbConfig_VertexVectorSearch.toJSON(message.vertexVectorSearch);
    }
    if (message.apiAuth !== undefined) {
      obj.apiAuth = ApiAuth.toJSON(message.apiAuth);
    }
    return obj;
  },

  create(base?: DeepPartial<RagVectorDbConfig>): RagVectorDbConfig {
    return RagVectorDbConfig.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<RagVectorDbConfig>): RagVectorDbConfig {
    const message = createBaseRagVectorDbConfig();
    message.ragManagedDb = (object.ragManagedDb !== undefined && object.ragManagedDb !== null)
      ? RagVectorDbConfig_RagManagedDb.fromPartial(object.ragManagedDb)
      : undefined;
    message.weaviate = (object.weaviate !== undefined && object.weaviate !== null)
      ? RagVectorDbConfig_Weaviate.fromPartial(object.weaviate)
      : undefined;
    message.pinecone = (object.pinecone !== undefined && object.pinecone !== null)
      ? RagVectorDbConfig_Pinecone.fromPartial(object.pinecone)
      : undefined;
    message.vertexFeatureStore = (object.vertexFeatureStore !== undefined && object.vertexFeatureStore !== null)
      ? RagVectorDbConfig_VertexFeatureStore.fromPartial(object.vertexFeatureStore)
      : undefined;
    message.vertexVectorSearch = (object.vertexVectorSearch !== undefined && object.vertexVectorSearch !== null)
      ? RagVectorDbConfig_VertexVectorSearch.fromPartial(object.vertexVectorSearch)
      : undefined;
    message.apiAuth = (object.apiAuth !== undefined && object.apiAuth !== null)
      ? ApiAuth.fromPartial(object.apiAuth)
      : undefined;
    return message;
  },
};

function createBaseRagVectorDbConfig_RagManagedDb(): RagVectorDbConfig_RagManagedDb {
  return {};
}

export const RagVectorDbConfig_RagManagedDb: MessageFns<RagVectorDbConfig_RagManagedDb> = {
  encode(_: RagVectorDbConfig_RagManagedDb, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): RagVectorDbConfig_RagManagedDb {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseRagVectorDbConfig_RagManagedDb();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(_: any): RagVectorDbConfig_RagManagedDb {
    return {};
  },

  toJSON(_: RagVectorDbConfig_RagManagedDb): unknown {
    const obj: any = {};
    return obj;
  },

  create(base?: DeepPartial<RagVectorDbConfig_RagManagedDb>): RagVectorDbConfig_RagManagedDb {
    return RagVectorDbConfig_RagManagedDb.fromPartial(base ?? {});
  },
  fromPartial(_: DeepPartial<RagVectorDbConfig_RagManagedDb>): RagVectorDbConfig_RagManagedDb {
    const message = createBaseRagVectorDbConfig_RagManagedDb();
    return message;
  },
};

function createBaseRagVectorDbConfig_Weaviate(): RagVectorDbConfig_Weaviate {
  return { httpEndpoint: "", collectionName: "" };
}

export const RagVectorDbConfig_Weaviate: MessageFns<RagVectorDbConfig_Weaviate> = {
  encode(message: RagVectorDbConfig_Weaviate, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.httpEndpoint !== "") {
      writer.uint32(10).string(message.httpEndpoint);
    }
    if (message.collectionName !== "") {
      writer.uint32(18).string(message.collectionName);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): RagVectorDbConfig_Weaviate {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseRagVectorDbConfig_Weaviate();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.httpEndpoint = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.collectionName = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): RagVectorDbConfig_Weaviate {
    return {
      httpEndpoint: isSet(object.httpEndpoint) ? globalThis.String(object.httpEndpoint) : "",
      collectionName: isSet(object.collectionName) ? globalThis.String(object.collectionName) : "",
    };
  },

  toJSON(message: RagVectorDbConfig_Weaviate): unknown {
    const obj: any = {};
    if (message.httpEndpoint !== "") {
      obj.httpEndpoint = message.httpEndpoint;
    }
    if (message.collectionName !== "") {
      obj.collectionName = message.collectionName;
    }
    return obj;
  },

  create(base?: DeepPartial<RagVectorDbConfig_Weaviate>): RagVectorDbConfig_Weaviate {
    return RagVectorDbConfig_Weaviate.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<RagVectorDbConfig_Weaviate>): RagVectorDbConfig_Weaviate {
    const message = createBaseRagVectorDbConfig_Weaviate();
    message.httpEndpoint = object.httpEndpoint ?? "";
    message.collectionName = object.collectionName ?? "";
    return message;
  },
};

function createBaseRagVectorDbConfig_Pinecone(): RagVectorDbConfig_Pinecone {
  return { indexName: "" };
}

export const RagVectorDbConfig_Pinecone: MessageFns<RagVectorDbConfig_Pinecone> = {
  encode(message: RagVectorDbConfig_Pinecone, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.indexName !== "") {
      writer.uint32(10).string(message.indexName);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): RagVectorDbConfig_Pinecone {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseRagVectorDbConfig_Pinecone();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.indexName = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): RagVectorDbConfig_Pinecone {
    return { indexName: isSet(object.indexName) ? globalThis.String(object.indexName) : "" };
  },

  toJSON(message: RagVectorDbConfig_Pinecone): unknown {
    const obj: any = {};
    if (message.indexName !== "") {
      obj.indexName = message.indexName;
    }
    return obj;
  },

  create(base?: DeepPartial<RagVectorDbConfig_Pinecone>): RagVectorDbConfig_Pinecone {
    return RagVectorDbConfig_Pinecone.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<RagVectorDbConfig_Pinecone>): RagVectorDbConfig_Pinecone {
    const message = createBaseRagVectorDbConfig_Pinecone();
    message.indexName = object.indexName ?? "";
    return message;
  },
};

function createBaseRagVectorDbConfig_VertexFeatureStore(): RagVectorDbConfig_VertexFeatureStore {
  return { featureViewResourceName: "" };
}

export const RagVectorDbConfig_VertexFeatureStore: MessageFns<RagVectorDbConfig_VertexFeatureStore> = {
  encode(message: RagVectorDbConfig_VertexFeatureStore, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.featureViewResourceName !== "") {
      writer.uint32(10).string(message.featureViewResourceName);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): RagVectorDbConfig_VertexFeatureStore {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseRagVectorDbConfig_VertexFeatureStore();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.featureViewResourceName = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): RagVectorDbConfig_VertexFeatureStore {
    return {
      featureViewResourceName: isSet(object.featureViewResourceName)
        ? globalThis.String(object.featureViewResourceName)
        : "",
    };
  },

  toJSON(message: RagVectorDbConfig_VertexFeatureStore): unknown {
    const obj: any = {};
    if (message.featureViewResourceName !== "") {
      obj.featureViewResourceName = message.featureViewResourceName;
    }
    return obj;
  },

  create(base?: DeepPartial<RagVectorDbConfig_VertexFeatureStore>): RagVectorDbConfig_VertexFeatureStore {
    return RagVectorDbConfig_VertexFeatureStore.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<RagVectorDbConfig_VertexFeatureStore>): RagVectorDbConfig_VertexFeatureStore {
    const message = createBaseRagVectorDbConfig_VertexFeatureStore();
    message.featureViewResourceName = object.featureViewResourceName ?? "";
    return message;
  },
};

function createBaseRagVectorDbConfig_VertexVectorSearch(): RagVectorDbConfig_VertexVectorSearch {
  return { indexEndpoint: "", index: "" };
}

export const RagVectorDbConfig_VertexVectorSearch: MessageFns<RagVectorDbConfig_VertexVectorSearch> = {
  encode(message: RagVectorDbConfig_VertexVectorSearch, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.indexEndpoint !== "") {
      writer.uint32(10).string(message.indexEndpoint);
    }
    if (message.index !== "") {
      writer.uint32(18).string(message.index);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): RagVectorDbConfig_VertexVectorSearch {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseRagVectorDbConfig_VertexVectorSearch();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.indexEndpoint = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.index = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): RagVectorDbConfig_VertexVectorSearch {
    return {
      indexEndpoint: isSet(object.indexEndpoint) ? globalThis.String(object.indexEndpoint) : "",
      index: isSet(object.index) ? globalThis.String(object.index) : "",
    };
  },

  toJSON(message: RagVectorDbConfig_VertexVectorSearch): unknown {
    const obj: any = {};
    if (message.indexEndpoint !== "") {
      obj.indexEndpoint = message.indexEndpoint;
    }
    if (message.index !== "") {
      obj.index = message.index;
    }
    return obj;
  },

  create(base?: DeepPartial<RagVectorDbConfig_VertexVectorSearch>): RagVectorDbConfig_VertexVectorSearch {
    return RagVectorDbConfig_VertexVectorSearch.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<RagVectorDbConfig_VertexVectorSearch>): RagVectorDbConfig_VertexVectorSearch {
    const message = createBaseRagVectorDbConfig_VertexVectorSearch();
    message.indexEndpoint = object.indexEndpoint ?? "";
    message.index = object.index ?? "";
    return message;
  },
};

function createBaseFileStatus(): FileStatus {
  return { state: 0, errorStatus: "" };
}

export const FileStatus: MessageFns<FileStatus> = {
  encode(message: FileStatus, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.state !== 0) {
      writer.uint32(8).int32(message.state);
    }
    if (message.errorStatus !== "") {
      writer.uint32(18).string(message.errorStatus);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): FileStatus {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseFileStatus();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 8) {
            break;
          }

          message.state = reader.int32() as any;
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.errorStatus = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): FileStatus {
    return {
      state: isSet(object.state) ? fileStatus_StateFromJSON(object.state) : 0,
      errorStatus: isSet(object.errorStatus) ? globalThis.String(object.errorStatus) : "",
    };
  },

  toJSON(message: FileStatus): unknown {
    const obj: any = {};
    if (message.state !== 0) {
      obj.state = fileStatus_StateToJSON(message.state);
    }
    if (message.errorStatus !== "") {
      obj.errorStatus = message.errorStatus;
    }
    return obj;
  },

  create(base?: DeepPartial<FileStatus>): FileStatus {
    return FileStatus.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<FileStatus>): FileStatus {
    const message = createBaseFileStatus();
    message.state = object.state ?? 0;
    message.errorStatus = object.errorStatus ?? "";
    return message;
  },
};

function createBaseCorpusStatus(): CorpusStatus {
  return { state: 0, errorStatus: "" };
}

export const CorpusStatus: MessageFns<CorpusStatus> = {
  encode(message: CorpusStatus, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.state !== 0) {
      writer.uint32(8).int32(message.state);
    }
    if (message.errorStatus !== "") {
      writer.uint32(18).string(message.errorStatus);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): CorpusStatus {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseCorpusStatus();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 8) {
            break;
          }

          message.state = reader.int32() as any;
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.errorStatus = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): CorpusStatus {
    return {
      state: isSet(object.state) ? corpusStatus_StateFromJSON(object.state) : 0,
      errorStatus: isSet(object.errorStatus) ? globalThis.String(object.errorStatus) : "",
    };
  },

  toJSON(message: CorpusStatus): unknown {
    const obj: any = {};
    if (message.state !== 0) {
      obj.state = corpusStatus_StateToJSON(message.state);
    }
    if (message.errorStatus !== "") {
      obj.errorStatus = message.errorStatus;
    }
    return obj;
  },

  create(base?: DeepPartial<CorpusStatus>): CorpusStatus {
    return CorpusStatus.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<CorpusStatus>): CorpusStatus {
    const message = createBaseCorpusStatus();
    message.state = object.state ?? 0;
    message.errorStatus = object.errorStatus ?? "";
    return message;
  },
};

function createBaseRagCorpus(): RagCorpus {
  return {
    name: "",
    displayName: "",
    description: "",
    ragEmbeddingModelConfig: undefined,
    ragVectorDbConfig: undefined,
    createTime: undefined,
    updateTime: undefined,
    corpusStatus: undefined,
  };
}

export const RagCorpus: MessageFns<RagCorpus> = {
  encode(message: RagCorpus, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    if (message.displayName !== "") {
      writer.uint32(18).string(message.displayName);
    }
    if (message.description !== "") {
      writer.uint32(26).string(message.description);
    }
    if (message.ragEmbeddingModelConfig !== undefined) {
      RagEmbeddingModelConfig.encode(message.ragEmbeddingModelConfig, writer.uint32(50).fork()).join();
    }
    if (message.ragVectorDbConfig !== undefined) {
      RagVectorDbConfig.encode(message.ragVectorDbConfig, writer.uint32(58).fork()).join();
    }
    if (message.createTime !== undefined) {
      Timestamp.encode(toTimestamp(message.createTime), writer.uint32(34).fork()).join();
    }
    if (message.updateTime !== undefined) {
      Timestamp.encode(toTimestamp(message.updateTime), writer.uint32(42).fork()).join();
    }
    if (message.corpusStatus !== undefined) {
      CorpusStatus.encode(message.corpusStatus, writer.uint32(66).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): RagCorpus {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseRagCorpus();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.displayName = reader.string();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.description = reader.string();
          continue;
        case 6:
          if (tag !== 50) {
            break;
          }

          message.ragEmbeddingModelConfig = RagEmbeddingModelConfig.decode(reader, reader.uint32());
          continue;
        case 7:
          if (tag !== 58) {
            break;
          }

          message.ragVectorDbConfig = RagVectorDbConfig.decode(reader, reader.uint32());
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.createTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.updateTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        case 8:
          if (tag !== 66) {
            break;
          }

          message.corpusStatus = CorpusStatus.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): RagCorpus {
    return {
      name: isSet(object.name) ? globalThis.String(object.name) : "",
      displayName: isSet(object.displayName) ? globalThis.String(object.displayName) : "",
      description: isSet(object.description) ? globalThis.String(object.description) : "",
      ragEmbeddingModelConfig: isSet(object.ragEmbeddingModelConfig)
        ? RagEmbeddingModelConfig.fromJSON(object.ragEmbeddingModelConfig)
        : undefined,
      ragVectorDbConfig: isSet(object.ragVectorDbConfig)
        ? RagVectorDbConfig.fromJSON(object.ragVectorDbConfig)
        : undefined,
      createTime: isSet(object.createTime) ? fromJsonTimestamp(object.createTime) : undefined,
      updateTime: isSet(object.updateTime) ? fromJsonTimestamp(object.updateTime) : undefined,
      corpusStatus: isSet(object.corpusStatus) ? CorpusStatus.fromJSON(object.corpusStatus) : undefined,
    };
  },

  toJSON(message: RagCorpus): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    if (message.displayName !== "") {
      obj.displayName = message.displayName;
    }
    if (message.description !== "") {
      obj.description = message.description;
    }
    if (message.ragEmbeddingModelConfig !== undefined) {
      obj.ragEmbeddingModelConfig = RagEmbeddingModelConfig.toJSON(message.ragEmbeddingModelConfig);
    }
    if (message.ragVectorDbConfig !== undefined) {
      obj.ragVectorDbConfig = RagVectorDbConfig.toJSON(message.ragVectorDbConfig);
    }
    if (message.createTime !== undefined) {
      obj.createTime = message.createTime.toISOString();
    }
    if (message.updateTime !== undefined) {
      obj.updateTime = message.updateTime.toISOString();
    }
    if (message.corpusStatus !== undefined) {
      obj.corpusStatus = CorpusStatus.toJSON(message.corpusStatus);
    }
    return obj;
  },

  create(base?: DeepPartial<RagCorpus>): RagCorpus {
    return RagCorpus.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<RagCorpus>): RagCorpus {
    const message = createBaseRagCorpus();
    message.name = object.name ?? "";
    message.displayName = object.displayName ?? "";
    message.description = object.description ?? "";
    message.ragEmbeddingModelConfig =
      (object.ragEmbeddingModelConfig !== undefined && object.ragEmbeddingModelConfig !== null)
        ? RagEmbeddingModelConfig.fromPartial(object.ragEmbeddingModelConfig)
        : undefined;
    message.ragVectorDbConfig = (object.ragVectorDbConfig !== undefined && object.ragVectorDbConfig !== null)
      ? RagVectorDbConfig.fromPartial(object.ragVectorDbConfig)
      : undefined;
    message.createTime = object.createTime ?? undefined;
    message.updateTime = object.updateTime ?? undefined;
    message.corpusStatus = (object.corpusStatus !== undefined && object.corpusStatus !== null)
      ? CorpusStatus.fromPartial(object.corpusStatus)
      : undefined;
    return message;
  },
};

function createBaseRagFile(): RagFile {
  return {
    gcsSource: undefined,
    googleDriveSource: undefined,
    directUploadSource: undefined,
    slackSource: undefined,
    jiraSource: undefined,
    sharePointSources: undefined,
    name: "",
    displayName: "",
    description: "",
    sizeBytes: Long.ZERO,
    ragFileType: 0,
    createTime: undefined,
    updateTime: undefined,
    fileStatus: undefined,
  };
}

export const RagFile: MessageFns<RagFile> = {
  encode(message: RagFile, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.gcsSource !== undefined) {
      GcsSource.encode(message.gcsSource, writer.uint32(66).fork()).join();
    }
    if (message.googleDriveSource !== undefined) {
      GoogleDriveSource.encode(message.googleDriveSource, writer.uint32(74).fork()).join();
    }
    if (message.directUploadSource !== undefined) {
      DirectUploadSource.encode(message.directUploadSource, writer.uint32(82).fork()).join();
    }
    if (message.slackSource !== undefined) {
      SlackSource.encode(message.slackSource, writer.uint32(90).fork()).join();
    }
    if (message.jiraSource !== undefined) {
      JiraSource.encode(message.jiraSource, writer.uint32(98).fork()).join();
    }
    if (message.sharePointSources !== undefined) {
      SharePointSources.encode(message.sharePointSources, writer.uint32(114).fork()).join();
    }
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    if (message.displayName !== "") {
      writer.uint32(18).string(message.displayName);
    }
    if (message.description !== "") {
      writer.uint32(26).string(message.description);
    }
    if (!message.sizeBytes.equals(Long.ZERO)) {
      writer.uint32(32).int64(message.sizeBytes.toString());
    }
    if (message.ragFileType !== 0) {
      writer.uint32(40).int32(message.ragFileType);
    }
    if (message.createTime !== undefined) {
      Timestamp.encode(toTimestamp(message.createTime), writer.uint32(50).fork()).join();
    }
    if (message.updateTime !== undefined) {
      Timestamp.encode(toTimestamp(message.updateTime), writer.uint32(58).fork()).join();
    }
    if (message.fileStatus !== undefined) {
      FileStatus.encode(message.fileStatus, writer.uint32(106).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): RagFile {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseRagFile();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 8:
          if (tag !== 66) {
            break;
          }

          message.gcsSource = GcsSource.decode(reader, reader.uint32());
          continue;
        case 9:
          if (tag !== 74) {
            break;
          }

          message.googleDriveSource = GoogleDriveSource.decode(reader, reader.uint32());
          continue;
        case 10:
          if (tag !== 82) {
            break;
          }

          message.directUploadSource = DirectUploadSource.decode(reader, reader.uint32());
          continue;
        case 11:
          if (tag !== 90) {
            break;
          }

          message.slackSource = SlackSource.decode(reader, reader.uint32());
          continue;
        case 12:
          if (tag !== 98) {
            break;
          }

          message.jiraSource = JiraSource.decode(reader, reader.uint32());
          continue;
        case 14:
          if (tag !== 114) {
            break;
          }

          message.sharePointSources = SharePointSources.decode(reader, reader.uint32());
          continue;
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.displayName = reader.string();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.description = reader.string();
          continue;
        case 4:
          if (tag !== 32) {
            break;
          }

          message.sizeBytes = Long.fromString(reader.int64().toString());
          continue;
        case 5:
          if (tag !== 40) {
            break;
          }

          message.ragFileType = reader.int32() as any;
          continue;
        case 6:
          if (tag !== 50) {
            break;
          }

          message.createTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        case 7:
          if (tag !== 58) {
            break;
          }

          message.updateTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        case 13:
          if (tag !== 106) {
            break;
          }

          message.fileStatus = FileStatus.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): RagFile {
    return {
      gcsSource: isSet(object.gcsSource) ? GcsSource.fromJSON(object.gcsSource) : undefined,
      googleDriveSource: isSet(object.googleDriveSource)
        ? GoogleDriveSource.fromJSON(object.googleDriveSource)
        : undefined,
      directUploadSource: isSet(object.directUploadSource)
        ? DirectUploadSource.fromJSON(object.directUploadSource)
        : undefined,
      slackSource: isSet(object.slackSource) ? SlackSource.fromJSON(object.slackSource) : undefined,
      jiraSource: isSet(object.jiraSource) ? JiraSource.fromJSON(object.jiraSource) : undefined,
      sharePointSources: isSet(object.sharePointSources)
        ? SharePointSources.fromJSON(object.sharePointSources)
        : undefined,
      name: isSet(object.name) ? globalThis.String(object.name) : "",
      displayName: isSet(object.displayName) ? globalThis.String(object.displayName) : "",
      description: isSet(object.description) ? globalThis.String(object.description) : "",
      sizeBytes: isSet(object.sizeBytes) ? Long.fromValue(object.sizeBytes) : Long.ZERO,
      ragFileType: isSet(object.ragFileType) ? ragFile_RagFileTypeFromJSON(object.ragFileType) : 0,
      createTime: isSet(object.createTime) ? fromJsonTimestamp(object.createTime) : undefined,
      updateTime: isSet(object.updateTime) ? fromJsonTimestamp(object.updateTime) : undefined,
      fileStatus: isSet(object.fileStatus) ? FileStatus.fromJSON(object.fileStatus) : undefined,
    };
  },

  toJSON(message: RagFile): unknown {
    const obj: any = {};
    if (message.gcsSource !== undefined) {
      obj.gcsSource = GcsSource.toJSON(message.gcsSource);
    }
    if (message.googleDriveSource !== undefined) {
      obj.googleDriveSource = GoogleDriveSource.toJSON(message.googleDriveSource);
    }
    if (message.directUploadSource !== undefined) {
      obj.directUploadSource = DirectUploadSource.toJSON(message.directUploadSource);
    }
    if (message.slackSource !== undefined) {
      obj.slackSource = SlackSource.toJSON(message.slackSource);
    }
    if (message.jiraSource !== undefined) {
      obj.jiraSource = JiraSource.toJSON(message.jiraSource);
    }
    if (message.sharePointSources !== undefined) {
      obj.sharePointSources = SharePointSources.toJSON(message.sharePointSources);
    }
    if (message.name !== "") {
      obj.name = message.name;
    }
    if (message.displayName !== "") {
      obj.displayName = message.displayName;
    }
    if (message.description !== "") {
      obj.description = message.description;
    }
    if (!message.sizeBytes.equals(Long.ZERO)) {
      obj.sizeBytes = (message.sizeBytes || Long.ZERO).toString();
    }
    if (message.ragFileType !== 0) {
      obj.ragFileType = ragFile_RagFileTypeToJSON(message.ragFileType);
    }
    if (message.createTime !== undefined) {
      obj.createTime = message.createTime.toISOString();
    }
    if (message.updateTime !== undefined) {
      obj.updateTime = message.updateTime.toISOString();
    }
    if (message.fileStatus !== undefined) {
      obj.fileStatus = FileStatus.toJSON(message.fileStatus);
    }
    return obj;
  },

  create(base?: DeepPartial<RagFile>): RagFile {
    return RagFile.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<RagFile>): RagFile {
    const message = createBaseRagFile();
    message.gcsSource = (object.gcsSource !== undefined && object.gcsSource !== null)
      ? GcsSource.fromPartial(object.gcsSource)
      : undefined;
    message.googleDriveSource = (object.googleDriveSource !== undefined && object.googleDriveSource !== null)
      ? GoogleDriveSource.fromPartial(object.googleDriveSource)
      : undefined;
    message.directUploadSource = (object.directUploadSource !== undefined && object.directUploadSource !== null)
      ? DirectUploadSource.fromPartial(object.directUploadSource)
      : undefined;
    message.slackSource = (object.slackSource !== undefined && object.slackSource !== null)
      ? SlackSource.fromPartial(object.slackSource)
      : undefined;
    message.jiraSource = (object.jiraSource !== undefined && object.jiraSource !== null)
      ? JiraSource.fromPartial(object.jiraSource)
      : undefined;
    message.sharePointSources = (object.sharePointSources !== undefined && object.sharePointSources !== null)
      ? SharePointSources.fromPartial(object.sharePointSources)
      : undefined;
    message.name = object.name ?? "";
    message.displayName = object.displayName ?? "";
    message.description = object.description ?? "";
    message.sizeBytes = (object.sizeBytes !== undefined && object.sizeBytes !== null)
      ? Long.fromValue(object.sizeBytes)
      : Long.ZERO;
    message.ragFileType = object.ragFileType ?? 0;
    message.createTime = object.createTime ?? undefined;
    message.updateTime = object.updateTime ?? undefined;
    message.fileStatus = (object.fileStatus !== undefined && object.fileStatus !== null)
      ? FileStatus.fromPartial(object.fileStatus)
      : undefined;
    return message;
  },
};

function createBaseRagFileChunkingConfig(): RagFileChunkingConfig {
  return { chunkSize: 0, chunkOverlap: 0 };
}

export const RagFileChunkingConfig: MessageFns<RagFileChunkingConfig> = {
  encode(message: RagFileChunkingConfig, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.chunkSize !== 0) {
      writer.uint32(8).int32(message.chunkSize);
    }
    if (message.chunkOverlap !== 0) {
      writer.uint32(16).int32(message.chunkOverlap);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): RagFileChunkingConfig {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseRagFileChunkingConfig();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 8) {
            break;
          }

          message.chunkSize = reader.int32();
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.chunkOverlap = reader.int32();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): RagFileChunkingConfig {
    return {
      chunkSize: isSet(object.chunkSize) ? globalThis.Number(object.chunkSize) : 0,
      chunkOverlap: isSet(object.chunkOverlap) ? globalThis.Number(object.chunkOverlap) : 0,
    };
  },

  toJSON(message: RagFileChunkingConfig): unknown {
    const obj: any = {};
    if (message.chunkSize !== 0) {
      obj.chunkSize = Math.round(message.chunkSize);
    }
    if (message.chunkOverlap !== 0) {
      obj.chunkOverlap = Math.round(message.chunkOverlap);
    }
    return obj;
  },

  create(base?: DeepPartial<RagFileChunkingConfig>): RagFileChunkingConfig {
    return RagFileChunkingConfig.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<RagFileChunkingConfig>): RagFileChunkingConfig {
    const message = createBaseRagFileChunkingConfig();
    message.chunkSize = object.chunkSize ?? 0;
    message.chunkOverlap = object.chunkOverlap ?? 0;
    return message;
  },
};

function createBaseRagFileParsingConfig(): RagFileParsingConfig {
  return { useAdvancedPdfParsing: false };
}

export const RagFileParsingConfig: MessageFns<RagFileParsingConfig> = {
  encode(message: RagFileParsingConfig, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.useAdvancedPdfParsing !== false) {
      writer.uint32(16).bool(message.useAdvancedPdfParsing);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): RagFileParsingConfig {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseRagFileParsingConfig();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 2:
          if (tag !== 16) {
            break;
          }

          message.useAdvancedPdfParsing = reader.bool();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): RagFileParsingConfig {
    return {
      useAdvancedPdfParsing: isSet(object.useAdvancedPdfParsing)
        ? globalThis.Boolean(object.useAdvancedPdfParsing)
        : false,
    };
  },

  toJSON(message: RagFileParsingConfig): unknown {
    const obj: any = {};
    if (message.useAdvancedPdfParsing !== false) {
      obj.useAdvancedPdfParsing = message.useAdvancedPdfParsing;
    }
    return obj;
  },

  create(base?: DeepPartial<RagFileParsingConfig>): RagFileParsingConfig {
    return RagFileParsingConfig.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<RagFileParsingConfig>): RagFileParsingConfig {
    const message = createBaseRagFileParsingConfig();
    message.useAdvancedPdfParsing = object.useAdvancedPdfParsing ?? false;
    return message;
  },
};

function createBaseUploadRagFileConfig(): UploadRagFileConfig {
  return { ragFileChunkingConfig: undefined };
}

export const UploadRagFileConfig: MessageFns<UploadRagFileConfig> = {
  encode(message: UploadRagFileConfig, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.ragFileChunkingConfig !== undefined) {
      RagFileChunkingConfig.encode(message.ragFileChunkingConfig, writer.uint32(10).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): UploadRagFileConfig {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseUploadRagFileConfig();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.ragFileChunkingConfig = RagFileChunkingConfig.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): UploadRagFileConfig {
    return {
      ragFileChunkingConfig: isSet(object.ragFileChunkingConfig)
        ? RagFileChunkingConfig.fromJSON(object.ragFileChunkingConfig)
        : undefined,
    };
  },

  toJSON(message: UploadRagFileConfig): unknown {
    const obj: any = {};
    if (message.ragFileChunkingConfig !== undefined) {
      obj.ragFileChunkingConfig = RagFileChunkingConfig.toJSON(message.ragFileChunkingConfig);
    }
    return obj;
  },

  create(base?: DeepPartial<UploadRagFileConfig>): UploadRagFileConfig {
    return UploadRagFileConfig.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<UploadRagFileConfig>): UploadRagFileConfig {
    const message = createBaseUploadRagFileConfig();
    message.ragFileChunkingConfig =
      (object.ragFileChunkingConfig !== undefined && object.ragFileChunkingConfig !== null)
        ? RagFileChunkingConfig.fromPartial(object.ragFileChunkingConfig)
        : undefined;
    return message;
  },
};

function createBaseImportRagFilesConfig(): ImportRagFilesConfig {
  return {
    gcsSource: undefined,
    googleDriveSource: undefined,
    slackSource: undefined,
    jiraSource: undefined,
    sharePointSources: undefined,
    partialFailureGcsSink: undefined,
    partialFailureBigquerySink: undefined,
    ragFileChunkingConfig: undefined,
    ragFileParsingConfig: undefined,
    maxEmbeddingRequestsPerMin: 0,
  };
}

export const ImportRagFilesConfig: MessageFns<ImportRagFilesConfig> = {
  encode(message: ImportRagFilesConfig, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.gcsSource !== undefined) {
      GcsSource.encode(message.gcsSource, writer.uint32(18).fork()).join();
    }
    if (message.googleDriveSource !== undefined) {
      GoogleDriveSource.encode(message.googleDriveSource, writer.uint32(26).fork()).join();
    }
    if (message.slackSource !== undefined) {
      SlackSource.encode(message.slackSource, writer.uint32(50).fork()).join();
    }
    if (message.jiraSource !== undefined) {
      JiraSource.encode(message.jiraSource, writer.uint32(58).fork()).join();
    }
    if (message.sharePointSources !== undefined) {
      SharePointSources.encode(message.sharePointSources, writer.uint32(106).fork()).join();
    }
    if (message.partialFailureGcsSink !== undefined) {
      GcsDestination.encode(message.partialFailureGcsSink, writer.uint32(90).fork()).join();
    }
    if (message.partialFailureBigquerySink !== undefined) {
      BigQueryDestination.encode(message.partialFailureBigquerySink, writer.uint32(98).fork()).join();
    }
    if (message.ragFileChunkingConfig !== undefined) {
      RagFileChunkingConfig.encode(message.ragFileChunkingConfig, writer.uint32(34).fork()).join();
    }
    if (message.ragFileParsingConfig !== undefined) {
      RagFileParsingConfig.encode(message.ragFileParsingConfig, writer.uint32(66).fork()).join();
    }
    if (message.maxEmbeddingRequestsPerMin !== 0) {
      writer.uint32(40).int32(message.maxEmbeddingRequestsPerMin);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ImportRagFilesConfig {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseImportRagFilesConfig();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 2:
          if (tag !== 18) {
            break;
          }

          message.gcsSource = GcsSource.decode(reader, reader.uint32());
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.googleDriveSource = GoogleDriveSource.decode(reader, reader.uint32());
          continue;
        case 6:
          if (tag !== 50) {
            break;
          }

          message.slackSource = SlackSource.decode(reader, reader.uint32());
          continue;
        case 7:
          if (tag !== 58) {
            break;
          }

          message.jiraSource = JiraSource.decode(reader, reader.uint32());
          continue;
        case 13:
          if (tag !== 106) {
            break;
          }

          message.sharePointSources = SharePointSources.decode(reader, reader.uint32());
          continue;
        case 11:
          if (tag !== 90) {
            break;
          }

          message.partialFailureGcsSink = GcsDestination.decode(reader, reader.uint32());
          continue;
        case 12:
          if (tag !== 98) {
            break;
          }

          message.partialFailureBigquerySink = BigQueryDestination.decode(reader, reader.uint32());
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.ragFileChunkingConfig = RagFileChunkingConfig.decode(reader, reader.uint32());
          continue;
        case 8:
          if (tag !== 66) {
            break;
          }

          message.ragFileParsingConfig = RagFileParsingConfig.decode(reader, reader.uint32());
          continue;
        case 5:
          if (tag !== 40) {
            break;
          }

          message.maxEmbeddingRequestsPerMin = reader.int32();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ImportRagFilesConfig {
    return {
      gcsSource: isSet(object.gcsSource) ? GcsSource.fromJSON(object.gcsSource) : undefined,
      googleDriveSource: isSet(object.googleDriveSource)
        ? GoogleDriveSource.fromJSON(object.googleDriveSource)
        : undefined,
      slackSource: isSet(object.slackSource) ? SlackSource.fromJSON(object.slackSource) : undefined,
      jiraSource: isSet(object.jiraSource) ? JiraSource.fromJSON(object.jiraSource) : undefined,
      sharePointSources: isSet(object.sharePointSources)
        ? SharePointSources.fromJSON(object.sharePointSources)
        : undefined,
      partialFailureGcsSink: isSet(object.partialFailureGcsSink)
        ? GcsDestination.fromJSON(object.partialFailureGcsSink)
        : undefined,
      partialFailureBigquerySink: isSet(object.partialFailureBigquerySink)
        ? BigQueryDestination.fromJSON(object.partialFailureBigquerySink)
        : undefined,
      ragFileChunkingConfig: isSet(object.ragFileChunkingConfig)
        ? RagFileChunkingConfig.fromJSON(object.ragFileChunkingConfig)
        : undefined,
      ragFileParsingConfig: isSet(object.ragFileParsingConfig)
        ? RagFileParsingConfig.fromJSON(object.ragFileParsingConfig)
        : undefined,
      maxEmbeddingRequestsPerMin: isSet(object.maxEmbeddingRequestsPerMin)
        ? globalThis.Number(object.maxEmbeddingRequestsPerMin)
        : 0,
    };
  },

  toJSON(message: ImportRagFilesConfig): unknown {
    const obj: any = {};
    if (message.gcsSource !== undefined) {
      obj.gcsSource = GcsSource.toJSON(message.gcsSource);
    }
    if (message.googleDriveSource !== undefined) {
      obj.googleDriveSource = GoogleDriveSource.toJSON(message.googleDriveSource);
    }
    if (message.slackSource !== undefined) {
      obj.slackSource = SlackSource.toJSON(message.slackSource);
    }
    if (message.jiraSource !== undefined) {
      obj.jiraSource = JiraSource.toJSON(message.jiraSource);
    }
    if (message.sharePointSources !== undefined) {
      obj.sharePointSources = SharePointSources.toJSON(message.sharePointSources);
    }
    if (message.partialFailureGcsSink !== undefined) {
      obj.partialFailureGcsSink = GcsDestination.toJSON(message.partialFailureGcsSink);
    }
    if (message.partialFailureBigquerySink !== undefined) {
      obj.partialFailureBigquerySink = BigQueryDestination.toJSON(message.partialFailureBigquerySink);
    }
    if (message.ragFileChunkingConfig !== undefined) {
      obj.ragFileChunkingConfig = RagFileChunkingConfig.toJSON(message.ragFileChunkingConfig);
    }
    if (message.ragFileParsingConfig !== undefined) {
      obj.ragFileParsingConfig = RagFileParsingConfig.toJSON(message.ragFileParsingConfig);
    }
    if (message.maxEmbeddingRequestsPerMin !== 0) {
      obj.maxEmbeddingRequestsPerMin = Math.round(message.maxEmbeddingRequestsPerMin);
    }
    return obj;
  },

  create(base?: DeepPartial<ImportRagFilesConfig>): ImportRagFilesConfig {
    return ImportRagFilesConfig.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ImportRagFilesConfig>): ImportRagFilesConfig {
    const message = createBaseImportRagFilesConfig();
    message.gcsSource = (object.gcsSource !== undefined && object.gcsSource !== null)
      ? GcsSource.fromPartial(object.gcsSource)
      : undefined;
    message.googleDriveSource = (object.googleDriveSource !== undefined && object.googleDriveSource !== null)
      ? GoogleDriveSource.fromPartial(object.googleDriveSource)
      : undefined;
    message.slackSource = (object.slackSource !== undefined && object.slackSource !== null)
      ? SlackSource.fromPartial(object.slackSource)
      : undefined;
    message.jiraSource = (object.jiraSource !== undefined && object.jiraSource !== null)
      ? JiraSource.fromPartial(object.jiraSource)
      : undefined;
    message.sharePointSources = (object.sharePointSources !== undefined && object.sharePointSources !== null)
      ? SharePointSources.fromPartial(object.sharePointSources)
      : undefined;
    message.partialFailureGcsSink =
      (object.partialFailureGcsSink !== undefined && object.partialFailureGcsSink !== null)
        ? GcsDestination.fromPartial(object.partialFailureGcsSink)
        : undefined;
    message.partialFailureBigquerySink =
      (object.partialFailureBigquerySink !== undefined && object.partialFailureBigquerySink !== null)
        ? BigQueryDestination.fromPartial(object.partialFailureBigquerySink)
        : undefined;
    message.ragFileChunkingConfig =
      (object.ragFileChunkingConfig !== undefined && object.ragFileChunkingConfig !== null)
        ? RagFileChunkingConfig.fromPartial(object.ragFileChunkingConfig)
        : undefined;
    message.ragFileParsingConfig = (object.ragFileParsingConfig !== undefined && object.ragFileParsingConfig !== null)
      ? RagFileParsingConfig.fromPartial(object.ragFileParsingConfig)
      : undefined;
    message.maxEmbeddingRequestsPerMin = object.maxEmbeddingRequestsPerMin ?? 0;
    return message;
  },
};

type Builtin = Date | Function | Uint8Array | string | number | boolean | undefined;

export type DeepPartial<T> = T extends Builtin ? T
  : T extends Long ? string | number | Long : T extends globalThis.Array<infer U> ? globalThis.Array<DeepPartial<U>>
  : T extends ReadonlyArray<infer U> ? ReadonlyArray<DeepPartial<U>>
  : T extends {} ? { [K in keyof T]?: DeepPartial<T[K]> }
  : Partial<T>;

function toTimestamp(date: Date): Timestamp {
  const seconds = numberToLong(Math.trunc(date.getTime() / 1_000));
  const nanos = (date.getTime() % 1_000) * 1_000_000;
  return { seconds, nanos };
}

function fromTimestamp(t: Timestamp): Date {
  let millis = (t.seconds.toNumber() || 0) * 1_000;
  millis += (t.nanos || 0) / 1_000_000;
  return new globalThis.Date(millis);
}

function fromJsonTimestamp(o: any): Date {
  if (o instanceof globalThis.Date) {
    return o;
  } else if (typeof o === "string") {
    return new globalThis.Date(o);
  } else {
    return fromTimestamp(Timestamp.fromJSON(o));
  }
}

function numberToLong(number: number) {
  return Long.fromNumber(number);
}

function isSet(value: any): boolean {
  return value !== null && value !== undefined;
}

export interface MessageFns<T> {
  encode(message: T, writer?: BinaryWriter): BinaryWriter;
  decode(input: BinaryReader | Uint8Array, length?: number): T;
  fromJSON(object: any): T;
  toJSON(message: T): unknown;
  create(base?: DeepPartial<T>): T;
  fromPartial(object: DeepPartial<T>): T;
}
