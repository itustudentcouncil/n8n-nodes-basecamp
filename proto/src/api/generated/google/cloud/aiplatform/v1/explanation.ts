// Code generated by protoc-gen-ts_proto. DO NOT EDIT.
// versions:
//   protoc-gen-ts_proto  v2.2.0
//   protoc               unknown
// source: google/cloud/aiplatform/v1/explanation.proto

/* eslint-disable */
import { BinaryReader, BinaryWriter } from "@bufbuild/protobuf/wire";
import Long from "long";
import { ListValue, Value } from "../../../protobuf/struct.js";
import { ExplanationMetadata } from "./explanation_metadata.js";
import { GcsSource } from "./io.js";

export const protobufPackage = "google.cloud.aiplatform.v1";

/**
 * Explanation of a prediction (provided in
 * [PredictResponse.predictions][google.cloud.aiplatform.v1.PredictResponse.predictions])
 * produced by the Model on a given
 * [instance][google.cloud.aiplatform.v1.ExplainRequest.instances].
 */
export interface Explanation {
  /**
   * Output only. Feature attributions grouped by predicted outputs.
   *
   * For Models that predict only one output, such as regression Models that
   * predict only one score, there is only one attibution that explains the
   * predicted output. For Models that predict multiple outputs, such as
   * multiclass Models that predict multiple classes, each element explains one
   * specific item.
   * [Attribution.output_index][google.cloud.aiplatform.v1.Attribution.output_index]
   * can be used to identify which output this attribution is explaining.
   *
   * By default, we provide Shapley values for the predicted class. However,
   * you can configure the explanation request to generate Shapley values for
   * any other classes too. For example, if a model predicts a probability of
   * `0.4` for approving a loan application, the model's decision is to reject
   * the application since `p(reject) = 0.6 > p(approve) = 0.4`, and the default
   * Shapley values would be computed for rejection decision and not approval,
   * even though the latter might be the positive class.
   *
   * If users set
   * [ExplanationParameters.top_k][google.cloud.aiplatform.v1.ExplanationParameters.top_k],
   * the attributions are sorted by
   * [instance_output_value][Attributions.instance_output_value] in descending
   * order. If
   * [ExplanationParameters.output_indices][google.cloud.aiplatform.v1.ExplanationParameters.output_indices]
   * is specified, the attributions are stored by
   * [Attribution.output_index][google.cloud.aiplatform.v1.Attribution.output_index]
   * in the same order as they appear in the output_indices.
   */
  attributions: Attribution[];
  /**
   * Output only. List of the nearest neighbors for example-based explanations.
   *
   * For models deployed with the examples explanations feature enabled, the
   * attributions field is empty and instead the neighbors field is populated.
   */
  neighbors: Neighbor[];
}

/** Aggregated explanation metrics for a Model over a set of instances. */
export interface ModelExplanation {
  /**
   * Output only. Aggregated attributions explaining the Model's prediction
   * outputs over the set of instances. The attributions are grouped by outputs.
   *
   * For Models that predict only one output, such as regression Models that
   * predict only one score, there is only one attibution that explains the
   * predicted output. For Models that predict multiple outputs, such as
   * multiclass Models that predict multiple classes, each element explains one
   * specific item.
   * [Attribution.output_index][google.cloud.aiplatform.v1.Attribution.output_index]
   * can be used to identify which output this attribution is explaining.
   *
   * The
   * [baselineOutputValue][google.cloud.aiplatform.v1.Attribution.baseline_output_value],
   * [instanceOutputValue][google.cloud.aiplatform.v1.Attribution.instance_output_value]
   * and
   * [featureAttributions][google.cloud.aiplatform.v1.Attribution.feature_attributions]
   * fields are averaged over the test data.
   *
   * NOTE: Currently AutoML tabular classification Models produce only one
   * attribution, which averages attributions over all the classes it predicts.
   * [Attribution.approximation_error][google.cloud.aiplatform.v1.Attribution.approximation_error]
   * is not populated.
   */
  meanAttributions: Attribution[];
}

/** Attribution that explains a particular prediction output. */
export interface Attribution {
  /**
   * Output only. Model predicted output if the input instance is constructed
   * from the baselines of all the features defined in
   * [ExplanationMetadata.inputs][google.cloud.aiplatform.v1.ExplanationMetadata.inputs].
   * The field name of the output is determined by the key in
   * [ExplanationMetadata.outputs][google.cloud.aiplatform.v1.ExplanationMetadata.outputs].
   *
   * If the Model's predicted output has multiple dimensions (rank > 1), this is
   * the value in the output located by
   * [output_index][google.cloud.aiplatform.v1.Attribution.output_index].
   *
   * If there are multiple baselines, their output values are averaged.
   */
  baselineOutputValue: number;
  /**
   * Output only. Model predicted output on the corresponding [explanation
   * instance][ExplainRequest.instances]. The field name of the output is
   * determined by the key in
   * [ExplanationMetadata.outputs][google.cloud.aiplatform.v1.ExplanationMetadata.outputs].
   *
   * If the Model predicted output has multiple dimensions, this is the value in
   * the output located by
   * [output_index][google.cloud.aiplatform.v1.Attribution.output_index].
   */
  instanceOutputValue: number;
  /**
   * Output only. Attributions of each explained feature. Features are extracted
   * from the [prediction
   * instances][google.cloud.aiplatform.v1.ExplainRequest.instances] according
   * to [explanation metadata for
   * inputs][google.cloud.aiplatform.v1.ExplanationMetadata.inputs].
   *
   * The value is a struct, whose keys are the name of the feature. The values
   * are how much the feature in the
   * [instance][google.cloud.aiplatform.v1.ExplainRequest.instances] contributed
   * to the predicted result.
   *
   * The format of the value is determined by the feature's input format:
   *
   *   * If the feature is a scalar value, the attribution value is a
   *     [floating number][google.protobuf.Value.number_value].
   *
   *   * If the feature is an array of scalar values, the attribution value is
   *     an [array][google.protobuf.Value.list_value].
   *
   *   * If the feature is a struct, the attribution value is a
   *     [struct][google.protobuf.Value.struct_value]. The keys in the
   *     attribution value struct are the same as the keys in the feature
   *     struct. The formats of the values in the attribution struct are
   *     determined by the formats of the values in the feature struct.
   *
   * The
   * [ExplanationMetadata.feature_attributions_schema_uri][google.cloud.aiplatform.v1.ExplanationMetadata.feature_attributions_schema_uri]
   * field, pointed to by the
   * [ExplanationSpec][google.cloud.aiplatform.v1.ExplanationSpec] field of the
   * [Endpoint.deployed_models][google.cloud.aiplatform.v1.Endpoint.deployed_models]
   * object, points to the schema file that describes the features and their
   * attribution values (if it is populated).
   */
  featureAttributions:
    | any
    | undefined;
  /**
   * Output only. The index that locates the explained prediction output.
   *
   * If the prediction output is a scalar value, output_index is not populated.
   * If the prediction output has multiple dimensions, the length of the
   * output_index list is the same as the number of dimensions of the output.
   * The i-th element in output_index is the element index of the i-th dimension
   * of the output vector. Indices start from 0.
   */
  outputIndex: number[];
  /**
   * Output only. The display name of the output identified by
   * [output_index][google.cloud.aiplatform.v1.Attribution.output_index]. For
   * example, the predicted class name by a multi-classification Model.
   *
   * This field is only populated iff the Model predicts display names as a
   * separate field along with the explained output. The predicted display name
   * must has the same shape of the explained output, and can be located using
   * output_index.
   */
  outputDisplayName: string;
  /**
   * Output only. Error of
   * [feature_attributions][google.cloud.aiplatform.v1.Attribution.feature_attributions]
   * caused by approximation used in the explanation method. Lower value means
   * more precise attributions.
   *
   * * For Sampled Shapley
   * [attribution][google.cloud.aiplatform.v1.ExplanationParameters.sampled_shapley_attribution],
   * increasing
   * [path_count][google.cloud.aiplatform.v1.SampledShapleyAttribution.path_count]
   * might reduce the error.
   * * For Integrated Gradients
   * [attribution][google.cloud.aiplatform.v1.ExplanationParameters.integrated_gradients_attribution],
   * increasing
   * [step_count][google.cloud.aiplatform.v1.IntegratedGradientsAttribution.step_count]
   * might reduce the error.
   * * For [XRAI
   * attribution][google.cloud.aiplatform.v1.ExplanationParameters.xrai_attribution],
   * increasing
   * [step_count][google.cloud.aiplatform.v1.XraiAttribution.step_count] might
   * reduce the error.
   *
   * See [this introduction](/vertex-ai/docs/explainable-ai/overview)
   * for more information.
   */
  approximationError: number;
  /**
   * Output only. Name of the explain output. Specified as the key in
   * [ExplanationMetadata.outputs][google.cloud.aiplatform.v1.ExplanationMetadata.outputs].
   */
  outputName: string;
}

/** Neighbors for example-based explanations. */
export interface Neighbor {
  /** Output only. The neighbor id. */
  neighborId: string;
  /** Output only. The neighbor distance. */
  neighborDistance: number;
}

/** Specification of Model explanation. */
export interface ExplanationSpec {
  /** Required. Parameters that configure explaining of the Model's predictions. */
  parameters:
    | ExplanationParameters
    | undefined;
  /** Optional. Metadata describing the Model's input and output for explanation. */
  metadata: ExplanationMetadata | undefined;
}

/** Parameters to configure explaining for Model's predictions. */
export interface ExplanationParameters {
  /**
   * An attribution method that approximates Shapley values for features that
   * contribute to the label being predicted. A sampling strategy is used to
   * approximate the value rather than considering all subsets of features.
   * Refer to this paper for model details: https://arxiv.org/abs/1306.4265.
   */
  sampledShapleyAttribution?:
    | SampledShapleyAttribution
    | undefined;
  /**
   * An attribution method that computes Aumann-Shapley values taking
   * advantage of the model's fully differentiable structure. Refer to this
   * paper for more details: https://arxiv.org/abs/1703.01365
   */
  integratedGradientsAttribution?:
    | IntegratedGradientsAttribution
    | undefined;
  /**
   * An attribution method that redistributes Integrated Gradients
   * attribution to segmented regions, taking advantage of the model's fully
   * differentiable structure. Refer to this paper for
   * more details: https://arxiv.org/abs/1906.02825
   *
   * XRAI currently performs better on natural images, like a picture of a
   * house or an animal. If the images are taken in artificial environments,
   * like a lab or manufacturing line, or from diagnostic equipment, like
   * x-rays or quality-control cameras, use Integrated Gradients instead.
   */
  xraiAttribution?:
    | XraiAttribution
    | undefined;
  /**
   * Example-based explanations that returns the nearest neighbors from the
   * provided dataset.
   */
  examples?:
    | Examples
    | undefined;
  /**
   * If populated, returns attributions for top K indices of outputs
   * (defaults to 1). Only applies to Models that predicts more than one outputs
   * (e,g, multi-class Models). When set to -1, returns explanations for all
   * outputs.
   */
  topK: number;
  /**
   * If populated, only returns attributions that have
   * [output_index][google.cloud.aiplatform.v1.Attribution.output_index]
   * contained in output_indices. It must be an ndarray of integers, with the
   * same shape of the output it's explaining.
   *
   * If not populated, returns attributions for
   * [top_k][google.cloud.aiplatform.v1.ExplanationParameters.top_k] indices of
   * outputs. If neither top_k nor output_indices is populated, returns the
   * argmax index of the outputs.
   *
   * Only applicable to Models that predict multiple outputs (e,g, multi-class
   * Models that predict multiple classes).
   */
  outputIndices: Array<any> | undefined;
}

/**
 * An attribution method that approximates Shapley values for features that
 * contribute to the label being predicted. A sampling strategy is used to
 * approximate the value rather than considering all subsets of features.
 */
export interface SampledShapleyAttribution {
  /**
   * Required. The number of feature permutations to consider when approximating
   * the Shapley values.
   *
   * Valid range of its value is [1, 50], inclusively.
   */
  pathCount: number;
}

/**
 * An attribution method that computes the Aumann-Shapley value taking advantage
 * of the model's fully differentiable structure. Refer to this paper for
 * more details: https://arxiv.org/abs/1703.01365
 */
export interface IntegratedGradientsAttribution {
  /**
   * Required. The number of steps for approximating the path integral.
   * A good value to start is 50 and gradually increase until the
   * sum to diff property is within the desired error range.
   *
   * Valid range of its value is [1, 100], inclusively.
   */
  stepCount: number;
  /**
   * Config for SmoothGrad approximation of gradients.
   *
   * When enabled, the gradients are approximated by averaging the gradients
   * from noisy samples in the vicinity of the inputs. Adding
   * noise can help improve the computed gradients. Refer to this paper for more
   * details: https://arxiv.org/pdf/1706.03825.pdf
   */
  smoothGradConfig:
    | SmoothGradConfig
    | undefined;
  /**
   * Config for IG with blur baseline.
   *
   * When enabled, a linear path from the maximally blurred image to the input
   * image is created. Using a blurred baseline instead of zero (black image) is
   * motivated by the BlurIG approach explained here:
   * https://arxiv.org/abs/2004.03383
   */
  blurBaselineConfig: BlurBaselineConfig | undefined;
}

/**
 * An explanation method that redistributes Integrated Gradients
 * attributions to segmented regions, taking advantage of the model's fully
 * differentiable structure. Refer to this paper for more details:
 * https://arxiv.org/abs/1906.02825
 *
 * Supported only by image Models.
 */
export interface XraiAttribution {
  /**
   * Required. The number of steps for approximating the path integral.
   * A good value to start is 50 and gradually increase until the
   * sum to diff property is met within the desired error range.
   *
   * Valid range of its value is [1, 100], inclusively.
   */
  stepCount: number;
  /**
   * Config for SmoothGrad approximation of gradients.
   *
   * When enabled, the gradients are approximated by averaging the gradients
   * from noisy samples in the vicinity of the inputs. Adding
   * noise can help improve the computed gradients. Refer to this paper for more
   * details: https://arxiv.org/pdf/1706.03825.pdf
   */
  smoothGradConfig:
    | SmoothGradConfig
    | undefined;
  /**
   * Config for XRAI with blur baseline.
   *
   * When enabled, a linear path from the maximally blurred image to the input
   * image is created. Using a blurred baseline instead of zero (black image) is
   * motivated by the BlurIG approach explained here:
   * https://arxiv.org/abs/2004.03383
   */
  blurBaselineConfig: BlurBaselineConfig | undefined;
}

/**
 * Config for SmoothGrad approximation of gradients.
 *
 * When enabled, the gradients are approximated by averaging the gradients from
 * noisy samples in the vicinity of the inputs. Adding noise can help improve
 * the computed gradients. Refer to this paper for more details:
 * https://arxiv.org/pdf/1706.03825.pdf
 */
export interface SmoothGradConfig {
  /**
   * This is a single float value and will be used to add noise to all the
   * features. Use this field when all features are normalized to have the
   * same distribution: scale to range [0, 1], [-1, 1] or z-scoring, where
   * features are normalized to have 0-mean and 1-variance. Learn more about
   * [normalization](https://developers.google.com/machine-learning/data-prep/transform/normalization).
   *
   * For best results the recommended value is about 10% - 20% of the standard
   * deviation of the input feature. Refer to section 3.2 of the SmoothGrad
   * paper: https://arxiv.org/pdf/1706.03825.pdf. Defaults to 0.1.
   *
   * If the distribution is different per feature, set
   * [feature_noise_sigma][google.cloud.aiplatform.v1.SmoothGradConfig.feature_noise_sigma]
   * instead for each feature.
   */
  noiseSigma?:
    | number
    | undefined;
  /**
   * This is similar to
   * [noise_sigma][google.cloud.aiplatform.v1.SmoothGradConfig.noise_sigma],
   * but provides additional flexibility. A separate noise sigma can be
   * provided for each feature, which is useful if their distributions are
   * different. No noise is added to features that are not set. If this field
   * is unset,
   * [noise_sigma][google.cloud.aiplatform.v1.SmoothGradConfig.noise_sigma]
   * will be used for all features.
   */
  featureNoiseSigma?:
    | FeatureNoiseSigma
    | undefined;
  /**
   * The number of gradient samples to use for
   * approximation. The higher this number, the more accurate the gradient
   * is, but the runtime complexity increases by this factor as well.
   * Valid range of its value is [1, 50]. Defaults to 3.
   */
  noisySampleCount: number;
}

/**
 * Noise sigma by features. Noise sigma represents the standard deviation of the
 * gaussian kernel that will be used to add noise to interpolated inputs prior
 * to computing gradients.
 */
export interface FeatureNoiseSigma {
  /** Noise sigma per feature. No noise is added to features that are not set. */
  noiseSigma: FeatureNoiseSigma_NoiseSigmaForFeature[];
}

/** Noise sigma for a single feature. */
export interface FeatureNoiseSigma_NoiseSigmaForFeature {
  /**
   * The name of the input feature for which noise sigma is provided. The
   * features are defined in
   * [explanation metadata
   * inputs][google.cloud.aiplatform.v1.ExplanationMetadata.inputs].
   */
  name: string;
  /**
   * This represents the standard deviation of the Gaussian kernel that will
   * be used to add noise to the feature prior to computing gradients. Similar
   * to [noise_sigma][google.cloud.aiplatform.v1.SmoothGradConfig.noise_sigma]
   * but represents the noise added to the current feature. Defaults to 0.1.
   */
  sigma: number;
}

/**
 * Config for blur baseline.
 *
 * When enabled, a linear path from the maximally blurred image to the input
 * image is created. Using a blurred baseline instead of zero (black image) is
 * motivated by the BlurIG approach explained here:
 * https://arxiv.org/abs/2004.03383
 */
export interface BlurBaselineConfig {
  /**
   * The standard deviation of the blur kernel for the blurred baseline. The
   * same blurring parameter is used for both the height and the width
   * dimension. If not set, the method defaults to the zero (i.e. black for
   * images) baseline.
   */
  maxBlurSigma: number;
}

/**
 * Example-based explainability that returns the nearest neighbors from the
 * provided dataset.
 */
export interface Examples {
  /** The Cloud Storage input instances. */
  exampleGcsSource?:
    | Examples_ExampleGcsSource
    | undefined;
  /**
   * The full configuration for the generated index, the semantics are the
   * same as [metadata][google.cloud.aiplatform.v1.Index.metadata] and should
   * match
   * [NearestNeighborSearchConfig](https://cloud.google.com/vertex-ai/docs/explainable-ai/configuring-explanations-example-based#nearest-neighbor-search-config).
   */
  nearestNeighborSearchConfig?:
    | any
    | undefined;
  /**
   * Simplified preset configuration, which automatically sets configuration
   * values based on the desired query speed-precision trade-off and modality.
   */
  presets?:
    | Presets
    | undefined;
  /** The number of neighbors to return when querying for examples. */
  neighborCount: number;
}

/** The Cloud Storage input instances. */
export interface Examples_ExampleGcsSource {
  /**
   * The format in which instances are given, if not specified, assume it's
   * JSONL format. Currently only JSONL format is supported.
   */
  dataFormat: Examples_ExampleGcsSource_DataFormat;
  /** The Cloud Storage location for the input instances. */
  gcsSource: GcsSource | undefined;
}

/** The format of the input example instances. */
export enum Examples_ExampleGcsSource_DataFormat {
  /** DATA_FORMAT_UNSPECIFIED - Format unspecified, used when unset. */
  DATA_FORMAT_UNSPECIFIED = 0,
  /** JSONL - Examples are stored in JSONL files. */
  JSONL = 1,
  UNRECOGNIZED = -1,
}

export function examples_ExampleGcsSource_DataFormatFromJSON(object: any): Examples_ExampleGcsSource_DataFormat {
  switch (object) {
    case 0:
    case "DATA_FORMAT_UNSPECIFIED":
      return Examples_ExampleGcsSource_DataFormat.DATA_FORMAT_UNSPECIFIED;
    case 1:
    case "JSONL":
      return Examples_ExampleGcsSource_DataFormat.JSONL;
    case -1:
    case "UNRECOGNIZED":
    default:
      return Examples_ExampleGcsSource_DataFormat.UNRECOGNIZED;
  }
}

export function examples_ExampleGcsSource_DataFormatToJSON(object: Examples_ExampleGcsSource_DataFormat): string {
  switch (object) {
    case Examples_ExampleGcsSource_DataFormat.DATA_FORMAT_UNSPECIFIED:
      return "DATA_FORMAT_UNSPECIFIED";
    case Examples_ExampleGcsSource_DataFormat.JSONL:
      return "JSONL";
    case Examples_ExampleGcsSource_DataFormat.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/** Preset configuration for example-based explanations */
export interface Presets {
  /**
   * Preset option controlling parameters for speed-precision trade-off when
   * querying for examples. If omitted, defaults to `PRECISE`.
   */
  query?:
    | Presets_Query
    | undefined;
  /**
   * The modality of the uploaded model, which automatically configures the
   * distance measurement and feature normalization for the underlying example
   * index and queries. If your model does not precisely fit one of these types,
   * it is okay to choose the closest type.
   */
  modality: Presets_Modality;
}

/** Preset option controlling parameters for query speed-precision trade-off */
export enum Presets_Query {
  /** PRECISE - More precise neighbors as a trade-off against slower response. */
  PRECISE = 0,
  /** FAST - Faster response as a trade-off against less precise neighbors. */
  FAST = 1,
  UNRECOGNIZED = -1,
}

export function presets_QueryFromJSON(object: any): Presets_Query {
  switch (object) {
    case 0:
    case "PRECISE":
      return Presets_Query.PRECISE;
    case 1:
    case "FAST":
      return Presets_Query.FAST;
    case -1:
    case "UNRECOGNIZED":
    default:
      return Presets_Query.UNRECOGNIZED;
  }
}

export function presets_QueryToJSON(object: Presets_Query): string {
  switch (object) {
    case Presets_Query.PRECISE:
      return "PRECISE";
    case Presets_Query.FAST:
      return "FAST";
    case Presets_Query.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/** Preset option controlling parameters for different modalities */
export enum Presets_Modality {
  /** MODALITY_UNSPECIFIED - Should not be set. Added as a recommended best practice for enums */
  MODALITY_UNSPECIFIED = 0,
  /** IMAGE - IMAGE modality */
  IMAGE = 1,
  /** TEXT - TEXT modality */
  TEXT = 2,
  /** TABULAR - TABULAR modality */
  TABULAR = 3,
  UNRECOGNIZED = -1,
}

export function presets_ModalityFromJSON(object: any): Presets_Modality {
  switch (object) {
    case 0:
    case "MODALITY_UNSPECIFIED":
      return Presets_Modality.MODALITY_UNSPECIFIED;
    case 1:
    case "IMAGE":
      return Presets_Modality.IMAGE;
    case 2:
    case "TEXT":
      return Presets_Modality.TEXT;
    case 3:
    case "TABULAR":
      return Presets_Modality.TABULAR;
    case -1:
    case "UNRECOGNIZED":
    default:
      return Presets_Modality.UNRECOGNIZED;
  }
}

export function presets_ModalityToJSON(object: Presets_Modality): string {
  switch (object) {
    case Presets_Modality.MODALITY_UNSPECIFIED:
      return "MODALITY_UNSPECIFIED";
    case Presets_Modality.IMAGE:
      return "IMAGE";
    case Presets_Modality.TEXT:
      return "TEXT";
    case Presets_Modality.TABULAR:
      return "TABULAR";
    case Presets_Modality.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/**
 * The [ExplanationSpec][google.cloud.aiplatform.v1.ExplanationSpec] entries
 * that can be overridden at [online
 * explanation][google.cloud.aiplatform.v1.PredictionService.Explain] time.
 */
export interface ExplanationSpecOverride {
  /**
   * The parameters to be overridden. Note that the
   * attribution method cannot be changed. If not specified,
   * no parameter is overridden.
   */
  parameters:
    | ExplanationParameters
    | undefined;
  /** The metadata to be overridden. If not specified, no metadata is overridden. */
  metadata:
    | ExplanationMetadataOverride
    | undefined;
  /** The example-based explanations parameter overrides. */
  examplesOverride: ExamplesOverride | undefined;
}

/**
 * The [ExplanationMetadata][google.cloud.aiplatform.v1.ExplanationMetadata]
 * entries that can be overridden at [online
 * explanation][google.cloud.aiplatform.v1.PredictionService.Explain] time.
 */
export interface ExplanationMetadataOverride {
  /**
   * Required. Overrides the [input
   * metadata][google.cloud.aiplatform.v1.ExplanationMetadata.inputs] of the
   * features. The key is the name of the feature to be overridden. The keys
   * specified here must exist in the input metadata to be overridden. If a
   * feature is not specified here, the corresponding feature's input metadata
   * is not overridden.
   */
  inputs: { [key: string]: ExplanationMetadataOverride_InputMetadataOverride };
}

/**
 * The [input
 * metadata][google.cloud.aiplatform.v1.ExplanationMetadata.InputMetadata]
 * entries to be overridden.
 */
export interface ExplanationMetadataOverride_InputMetadataOverride {
  /**
   * Baseline inputs for this feature.
   *
   * This overrides the `input_baseline` field of the
   * [ExplanationMetadata.InputMetadata][google.cloud.aiplatform.v1.ExplanationMetadata.InputMetadata]
   * object of the corresponding feature's input metadata. If it's not
   * specified, the original baselines are not overridden.
   */
  inputBaselines: any[];
}

export interface ExplanationMetadataOverride_InputsEntry {
  key: string;
  value: ExplanationMetadataOverride_InputMetadataOverride | undefined;
}

/** Overrides for example-based explanations. */
export interface ExamplesOverride {
  /** The number of neighbors to return. */
  neighborCount: number;
  /** The number of neighbors to return that have the same crowding tag. */
  crowdingCount: number;
  /** Restrict the resulting nearest neighbors to respect these constraints. */
  restrictions: ExamplesRestrictionsNamespace[];
  /** If true, return the embeddings instead of neighbors. */
  returnEmbeddings: boolean;
  /** The format of the data being provided with each call. */
  dataFormat: ExamplesOverride_DataFormat;
}

/** Data format enum. */
export enum ExamplesOverride_DataFormat {
  /** DATA_FORMAT_UNSPECIFIED - Unspecified format. Must not be used. */
  DATA_FORMAT_UNSPECIFIED = 0,
  /** INSTANCES - Provided data is a set of model inputs. */
  INSTANCES = 1,
  /** EMBEDDINGS - Provided data is a set of embeddings. */
  EMBEDDINGS = 2,
  UNRECOGNIZED = -1,
}

export function examplesOverride_DataFormatFromJSON(object: any): ExamplesOverride_DataFormat {
  switch (object) {
    case 0:
    case "DATA_FORMAT_UNSPECIFIED":
      return ExamplesOverride_DataFormat.DATA_FORMAT_UNSPECIFIED;
    case 1:
    case "INSTANCES":
      return ExamplesOverride_DataFormat.INSTANCES;
    case 2:
    case "EMBEDDINGS":
      return ExamplesOverride_DataFormat.EMBEDDINGS;
    case -1:
    case "UNRECOGNIZED":
    default:
      return ExamplesOverride_DataFormat.UNRECOGNIZED;
  }
}

export function examplesOverride_DataFormatToJSON(object: ExamplesOverride_DataFormat): string {
  switch (object) {
    case ExamplesOverride_DataFormat.DATA_FORMAT_UNSPECIFIED:
      return "DATA_FORMAT_UNSPECIFIED";
    case ExamplesOverride_DataFormat.INSTANCES:
      return "INSTANCES";
    case ExamplesOverride_DataFormat.EMBEDDINGS:
      return "EMBEDDINGS";
    case ExamplesOverride_DataFormat.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/** Restrictions namespace for example-based explanations overrides. */
export interface ExamplesRestrictionsNamespace {
  /** The namespace name. */
  namespaceName: string;
  /** The list of allowed tags. */
  allow: string[];
  /** The list of deny tags. */
  deny: string[];
}

function createBaseExplanation(): Explanation {
  return { attributions: [], neighbors: [] };
}

export const Explanation: MessageFns<Explanation> = {
  encode(message: Explanation, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.attributions) {
      Attribution.encode(v!, writer.uint32(10).fork()).join();
    }
    for (const v of message.neighbors) {
      Neighbor.encode(v!, writer.uint32(18).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Explanation {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseExplanation();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.attributions.push(Attribution.decode(reader, reader.uint32()));
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.neighbors.push(Neighbor.decode(reader, reader.uint32()));
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Explanation {
    return {
      attributions: globalThis.Array.isArray(object?.attributions)
        ? object.attributions.map((e: any) => Attribution.fromJSON(e))
        : [],
      neighbors: globalThis.Array.isArray(object?.neighbors)
        ? object.neighbors.map((e: any) => Neighbor.fromJSON(e))
        : [],
    };
  },

  toJSON(message: Explanation): unknown {
    const obj: any = {};
    if (message.attributions?.length) {
      obj.attributions = message.attributions.map((e) => Attribution.toJSON(e));
    }
    if (message.neighbors?.length) {
      obj.neighbors = message.neighbors.map((e) => Neighbor.toJSON(e));
    }
    return obj;
  },

  create(base?: DeepPartial<Explanation>): Explanation {
    return Explanation.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<Explanation>): Explanation {
    const message = createBaseExplanation();
    message.attributions = object.attributions?.map((e) => Attribution.fromPartial(e)) || [];
    message.neighbors = object.neighbors?.map((e) => Neighbor.fromPartial(e)) || [];
    return message;
  },
};

function createBaseModelExplanation(): ModelExplanation {
  return { meanAttributions: [] };
}

export const ModelExplanation: MessageFns<ModelExplanation> = {
  encode(message: ModelExplanation, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.meanAttributions) {
      Attribution.encode(v!, writer.uint32(10).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ModelExplanation {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseModelExplanation();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.meanAttributions.push(Attribution.decode(reader, reader.uint32()));
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ModelExplanation {
    return {
      meanAttributions: globalThis.Array.isArray(object?.meanAttributions)
        ? object.meanAttributions.map((e: any) => Attribution.fromJSON(e))
        : [],
    };
  },

  toJSON(message: ModelExplanation): unknown {
    const obj: any = {};
    if (message.meanAttributions?.length) {
      obj.meanAttributions = message.meanAttributions.map((e) => Attribution.toJSON(e));
    }
    return obj;
  },

  create(base?: DeepPartial<ModelExplanation>): ModelExplanation {
    return ModelExplanation.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ModelExplanation>): ModelExplanation {
    const message = createBaseModelExplanation();
    message.meanAttributions = object.meanAttributions?.map((e) => Attribution.fromPartial(e)) || [];
    return message;
  },
};

function createBaseAttribution(): Attribution {
  return {
    baselineOutputValue: 0,
    instanceOutputValue: 0,
    featureAttributions: undefined,
    outputIndex: [],
    outputDisplayName: "",
    approximationError: 0,
    outputName: "",
  };
}

export const Attribution: MessageFns<Attribution> = {
  encode(message: Attribution, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.baselineOutputValue !== 0) {
      writer.uint32(9).double(message.baselineOutputValue);
    }
    if (message.instanceOutputValue !== 0) {
      writer.uint32(17).double(message.instanceOutputValue);
    }
    if (message.featureAttributions !== undefined) {
      Value.encode(Value.wrap(message.featureAttributions), writer.uint32(26).fork()).join();
    }
    writer.uint32(34).fork();
    for (const v of message.outputIndex) {
      writer.int32(v);
    }
    writer.join();
    if (message.outputDisplayName !== "") {
      writer.uint32(42).string(message.outputDisplayName);
    }
    if (message.approximationError !== 0) {
      writer.uint32(49).double(message.approximationError);
    }
    if (message.outputName !== "") {
      writer.uint32(58).string(message.outputName);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Attribution {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseAttribution();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 9) {
            break;
          }

          message.baselineOutputValue = reader.double();
          continue;
        case 2:
          if (tag !== 17) {
            break;
          }

          message.instanceOutputValue = reader.double();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.featureAttributions = Value.unwrap(Value.decode(reader, reader.uint32()));
          continue;
        case 4:
          if (tag === 32) {
            message.outputIndex.push(reader.int32());

            continue;
          }

          if (tag === 34) {
            const end2 = reader.uint32() + reader.pos;
            while (reader.pos < end2) {
              message.outputIndex.push(reader.int32());
            }

            continue;
          }

          break;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.outputDisplayName = reader.string();
          continue;
        case 6:
          if (tag !== 49) {
            break;
          }

          message.approximationError = reader.double();
          continue;
        case 7:
          if (tag !== 58) {
            break;
          }

          message.outputName = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Attribution {
    return {
      baselineOutputValue: isSet(object.baselineOutputValue) ? globalThis.Number(object.baselineOutputValue) : 0,
      instanceOutputValue: isSet(object.instanceOutputValue) ? globalThis.Number(object.instanceOutputValue) : 0,
      featureAttributions: isSet(object?.featureAttributions) ? object.featureAttributions : undefined,
      outputIndex: globalThis.Array.isArray(object?.outputIndex)
        ? object.outputIndex.map((e: any) => globalThis.Number(e))
        : [],
      outputDisplayName: isSet(object.outputDisplayName) ? globalThis.String(object.outputDisplayName) : "",
      approximationError: isSet(object.approximationError) ? globalThis.Number(object.approximationError) : 0,
      outputName: isSet(object.outputName) ? globalThis.String(object.outputName) : "",
    };
  },

  toJSON(message: Attribution): unknown {
    const obj: any = {};
    if (message.baselineOutputValue !== 0) {
      obj.baselineOutputValue = message.baselineOutputValue;
    }
    if (message.instanceOutputValue !== 0) {
      obj.instanceOutputValue = message.instanceOutputValue;
    }
    if (message.featureAttributions !== undefined) {
      obj.featureAttributions = message.featureAttributions;
    }
    if (message.outputIndex?.length) {
      obj.outputIndex = message.outputIndex.map((e) => Math.round(e));
    }
    if (message.outputDisplayName !== "") {
      obj.outputDisplayName = message.outputDisplayName;
    }
    if (message.approximationError !== 0) {
      obj.approximationError = message.approximationError;
    }
    if (message.outputName !== "") {
      obj.outputName = message.outputName;
    }
    return obj;
  },

  create(base?: DeepPartial<Attribution>): Attribution {
    return Attribution.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<Attribution>): Attribution {
    const message = createBaseAttribution();
    message.baselineOutputValue = object.baselineOutputValue ?? 0;
    message.instanceOutputValue = object.instanceOutputValue ?? 0;
    message.featureAttributions = object.featureAttributions ?? undefined;
    message.outputIndex = object.outputIndex?.map((e) => e) || [];
    message.outputDisplayName = object.outputDisplayName ?? "";
    message.approximationError = object.approximationError ?? 0;
    message.outputName = object.outputName ?? "";
    return message;
  },
};

function createBaseNeighbor(): Neighbor {
  return { neighborId: "", neighborDistance: 0 };
}

export const Neighbor: MessageFns<Neighbor> = {
  encode(message: Neighbor, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.neighborId !== "") {
      writer.uint32(10).string(message.neighborId);
    }
    if (message.neighborDistance !== 0) {
      writer.uint32(17).double(message.neighborDistance);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Neighbor {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseNeighbor();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.neighborId = reader.string();
          continue;
        case 2:
          if (tag !== 17) {
            break;
          }

          message.neighborDistance = reader.double();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Neighbor {
    return {
      neighborId: isSet(object.neighborId) ? globalThis.String(object.neighborId) : "",
      neighborDistance: isSet(object.neighborDistance) ? globalThis.Number(object.neighborDistance) : 0,
    };
  },

  toJSON(message: Neighbor): unknown {
    const obj: any = {};
    if (message.neighborId !== "") {
      obj.neighborId = message.neighborId;
    }
    if (message.neighborDistance !== 0) {
      obj.neighborDistance = message.neighborDistance;
    }
    return obj;
  },

  create(base?: DeepPartial<Neighbor>): Neighbor {
    return Neighbor.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<Neighbor>): Neighbor {
    const message = createBaseNeighbor();
    message.neighborId = object.neighborId ?? "";
    message.neighborDistance = object.neighborDistance ?? 0;
    return message;
  },
};

function createBaseExplanationSpec(): ExplanationSpec {
  return { parameters: undefined, metadata: undefined };
}

export const ExplanationSpec: MessageFns<ExplanationSpec> = {
  encode(message: ExplanationSpec, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.parameters !== undefined) {
      ExplanationParameters.encode(message.parameters, writer.uint32(10).fork()).join();
    }
    if (message.metadata !== undefined) {
      ExplanationMetadata.encode(message.metadata, writer.uint32(18).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ExplanationSpec {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseExplanationSpec();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.parameters = ExplanationParameters.decode(reader, reader.uint32());
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.metadata = ExplanationMetadata.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ExplanationSpec {
    return {
      parameters: isSet(object.parameters) ? ExplanationParameters.fromJSON(object.parameters) : undefined,
      metadata: isSet(object.metadata) ? ExplanationMetadata.fromJSON(object.metadata) : undefined,
    };
  },

  toJSON(message: ExplanationSpec): unknown {
    const obj: any = {};
    if (message.parameters !== undefined) {
      obj.parameters = ExplanationParameters.toJSON(message.parameters);
    }
    if (message.metadata !== undefined) {
      obj.metadata = ExplanationMetadata.toJSON(message.metadata);
    }
    return obj;
  },

  create(base?: DeepPartial<ExplanationSpec>): ExplanationSpec {
    return ExplanationSpec.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ExplanationSpec>): ExplanationSpec {
    const message = createBaseExplanationSpec();
    message.parameters = (object.parameters !== undefined && object.parameters !== null)
      ? ExplanationParameters.fromPartial(object.parameters)
      : undefined;
    message.metadata = (object.metadata !== undefined && object.metadata !== null)
      ? ExplanationMetadata.fromPartial(object.metadata)
      : undefined;
    return message;
  },
};

function createBaseExplanationParameters(): ExplanationParameters {
  return {
    sampledShapleyAttribution: undefined,
    integratedGradientsAttribution: undefined,
    xraiAttribution: undefined,
    examples: undefined,
    topK: 0,
    outputIndices: undefined,
  };
}

export const ExplanationParameters: MessageFns<ExplanationParameters> = {
  encode(message: ExplanationParameters, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.sampledShapleyAttribution !== undefined) {
      SampledShapleyAttribution.encode(message.sampledShapleyAttribution, writer.uint32(10).fork()).join();
    }
    if (message.integratedGradientsAttribution !== undefined) {
      IntegratedGradientsAttribution.encode(message.integratedGradientsAttribution, writer.uint32(18).fork()).join();
    }
    if (message.xraiAttribution !== undefined) {
      XraiAttribution.encode(message.xraiAttribution, writer.uint32(26).fork()).join();
    }
    if (message.examples !== undefined) {
      Examples.encode(message.examples, writer.uint32(58).fork()).join();
    }
    if (message.topK !== 0) {
      writer.uint32(32).int32(message.topK);
    }
    if (message.outputIndices !== undefined) {
      ListValue.encode(ListValue.wrap(message.outputIndices), writer.uint32(42).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ExplanationParameters {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseExplanationParameters();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.sampledShapleyAttribution = SampledShapleyAttribution.decode(reader, reader.uint32());
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.integratedGradientsAttribution = IntegratedGradientsAttribution.decode(reader, reader.uint32());
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.xraiAttribution = XraiAttribution.decode(reader, reader.uint32());
          continue;
        case 7:
          if (tag !== 58) {
            break;
          }

          message.examples = Examples.decode(reader, reader.uint32());
          continue;
        case 4:
          if (tag !== 32) {
            break;
          }

          message.topK = reader.int32();
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.outputIndices = ListValue.unwrap(ListValue.decode(reader, reader.uint32()));
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ExplanationParameters {
    return {
      sampledShapleyAttribution: isSet(object.sampledShapleyAttribution)
        ? SampledShapleyAttribution.fromJSON(object.sampledShapleyAttribution)
        : undefined,
      integratedGradientsAttribution: isSet(object.integratedGradientsAttribution)
        ? IntegratedGradientsAttribution.fromJSON(object.integratedGradientsAttribution)
        : undefined,
      xraiAttribution: isSet(object.xraiAttribution) ? XraiAttribution.fromJSON(object.xraiAttribution) : undefined,
      examples: isSet(object.examples) ? Examples.fromJSON(object.examples) : undefined,
      topK: isSet(object.topK) ? globalThis.Number(object.topK) : 0,
      outputIndices: globalThis.Array.isArray(object.outputIndices) ? [...object.outputIndices] : undefined,
    };
  },

  toJSON(message: ExplanationParameters): unknown {
    const obj: any = {};
    if (message.sampledShapleyAttribution !== undefined) {
      obj.sampledShapleyAttribution = SampledShapleyAttribution.toJSON(message.sampledShapleyAttribution);
    }
    if (message.integratedGradientsAttribution !== undefined) {
      obj.integratedGradientsAttribution = IntegratedGradientsAttribution.toJSON(
        message.integratedGradientsAttribution,
      );
    }
    if (message.xraiAttribution !== undefined) {
      obj.xraiAttribution = XraiAttribution.toJSON(message.xraiAttribution);
    }
    if (message.examples !== undefined) {
      obj.examples = Examples.toJSON(message.examples);
    }
    if (message.topK !== 0) {
      obj.topK = Math.round(message.topK);
    }
    if (message.outputIndices !== undefined) {
      obj.outputIndices = message.outputIndices;
    }
    return obj;
  },

  create(base?: DeepPartial<ExplanationParameters>): ExplanationParameters {
    return ExplanationParameters.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ExplanationParameters>): ExplanationParameters {
    const message = createBaseExplanationParameters();
    message.sampledShapleyAttribution =
      (object.sampledShapleyAttribution !== undefined && object.sampledShapleyAttribution !== null)
        ? SampledShapleyAttribution.fromPartial(object.sampledShapleyAttribution)
        : undefined;
    message.integratedGradientsAttribution =
      (object.integratedGradientsAttribution !== undefined && object.integratedGradientsAttribution !== null)
        ? IntegratedGradientsAttribution.fromPartial(object.integratedGradientsAttribution)
        : undefined;
    message.xraiAttribution = (object.xraiAttribution !== undefined && object.xraiAttribution !== null)
      ? XraiAttribution.fromPartial(object.xraiAttribution)
      : undefined;
    message.examples = (object.examples !== undefined && object.examples !== null)
      ? Examples.fromPartial(object.examples)
      : undefined;
    message.topK = object.topK ?? 0;
    message.outputIndices = object.outputIndices ?? undefined;
    return message;
  },
};

function createBaseSampledShapleyAttribution(): SampledShapleyAttribution {
  return { pathCount: 0 };
}

export const SampledShapleyAttribution: MessageFns<SampledShapleyAttribution> = {
  encode(message: SampledShapleyAttribution, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.pathCount !== 0) {
      writer.uint32(8).int32(message.pathCount);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): SampledShapleyAttribution {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseSampledShapleyAttribution();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 8) {
            break;
          }

          message.pathCount = reader.int32();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): SampledShapleyAttribution {
    return { pathCount: isSet(object.pathCount) ? globalThis.Number(object.pathCount) : 0 };
  },

  toJSON(message: SampledShapleyAttribution): unknown {
    const obj: any = {};
    if (message.pathCount !== 0) {
      obj.pathCount = Math.round(message.pathCount);
    }
    return obj;
  },

  create(base?: DeepPartial<SampledShapleyAttribution>): SampledShapleyAttribution {
    return SampledShapleyAttribution.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<SampledShapleyAttribution>): SampledShapleyAttribution {
    const message = createBaseSampledShapleyAttribution();
    message.pathCount = object.pathCount ?? 0;
    return message;
  },
};

function createBaseIntegratedGradientsAttribution(): IntegratedGradientsAttribution {
  return { stepCount: 0, smoothGradConfig: undefined, blurBaselineConfig: undefined };
}

export const IntegratedGradientsAttribution: MessageFns<IntegratedGradientsAttribution> = {
  encode(message: IntegratedGradientsAttribution, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.stepCount !== 0) {
      writer.uint32(8).int32(message.stepCount);
    }
    if (message.smoothGradConfig !== undefined) {
      SmoothGradConfig.encode(message.smoothGradConfig, writer.uint32(18).fork()).join();
    }
    if (message.blurBaselineConfig !== undefined) {
      BlurBaselineConfig.encode(message.blurBaselineConfig, writer.uint32(26).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): IntegratedGradientsAttribution {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseIntegratedGradientsAttribution();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 8) {
            break;
          }

          message.stepCount = reader.int32();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.smoothGradConfig = SmoothGradConfig.decode(reader, reader.uint32());
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.blurBaselineConfig = BlurBaselineConfig.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): IntegratedGradientsAttribution {
    return {
      stepCount: isSet(object.stepCount) ? globalThis.Number(object.stepCount) : 0,
      smoothGradConfig: isSet(object.smoothGradConfig) ? SmoothGradConfig.fromJSON(object.smoothGradConfig) : undefined,
      blurBaselineConfig: isSet(object.blurBaselineConfig)
        ? BlurBaselineConfig.fromJSON(object.blurBaselineConfig)
        : undefined,
    };
  },

  toJSON(message: IntegratedGradientsAttribution): unknown {
    const obj: any = {};
    if (message.stepCount !== 0) {
      obj.stepCount = Math.round(message.stepCount);
    }
    if (message.smoothGradConfig !== undefined) {
      obj.smoothGradConfig = SmoothGradConfig.toJSON(message.smoothGradConfig);
    }
    if (message.blurBaselineConfig !== undefined) {
      obj.blurBaselineConfig = BlurBaselineConfig.toJSON(message.blurBaselineConfig);
    }
    return obj;
  },

  create(base?: DeepPartial<IntegratedGradientsAttribution>): IntegratedGradientsAttribution {
    return IntegratedGradientsAttribution.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<IntegratedGradientsAttribution>): IntegratedGradientsAttribution {
    const message = createBaseIntegratedGradientsAttribution();
    message.stepCount = object.stepCount ?? 0;
    message.smoothGradConfig = (object.smoothGradConfig !== undefined && object.smoothGradConfig !== null)
      ? SmoothGradConfig.fromPartial(object.smoothGradConfig)
      : undefined;
    message.blurBaselineConfig = (object.blurBaselineConfig !== undefined && object.blurBaselineConfig !== null)
      ? BlurBaselineConfig.fromPartial(object.blurBaselineConfig)
      : undefined;
    return message;
  },
};

function createBaseXraiAttribution(): XraiAttribution {
  return { stepCount: 0, smoothGradConfig: undefined, blurBaselineConfig: undefined };
}

export const XraiAttribution: MessageFns<XraiAttribution> = {
  encode(message: XraiAttribution, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.stepCount !== 0) {
      writer.uint32(8).int32(message.stepCount);
    }
    if (message.smoothGradConfig !== undefined) {
      SmoothGradConfig.encode(message.smoothGradConfig, writer.uint32(18).fork()).join();
    }
    if (message.blurBaselineConfig !== undefined) {
      BlurBaselineConfig.encode(message.blurBaselineConfig, writer.uint32(26).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): XraiAttribution {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseXraiAttribution();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 8) {
            break;
          }

          message.stepCount = reader.int32();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.smoothGradConfig = SmoothGradConfig.decode(reader, reader.uint32());
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.blurBaselineConfig = BlurBaselineConfig.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): XraiAttribution {
    return {
      stepCount: isSet(object.stepCount) ? globalThis.Number(object.stepCount) : 0,
      smoothGradConfig: isSet(object.smoothGradConfig) ? SmoothGradConfig.fromJSON(object.smoothGradConfig) : undefined,
      blurBaselineConfig: isSet(object.blurBaselineConfig)
        ? BlurBaselineConfig.fromJSON(object.blurBaselineConfig)
        : undefined,
    };
  },

  toJSON(message: XraiAttribution): unknown {
    const obj: any = {};
    if (message.stepCount !== 0) {
      obj.stepCount = Math.round(message.stepCount);
    }
    if (message.smoothGradConfig !== undefined) {
      obj.smoothGradConfig = SmoothGradConfig.toJSON(message.smoothGradConfig);
    }
    if (message.blurBaselineConfig !== undefined) {
      obj.blurBaselineConfig = BlurBaselineConfig.toJSON(message.blurBaselineConfig);
    }
    return obj;
  },

  create(base?: DeepPartial<XraiAttribution>): XraiAttribution {
    return XraiAttribution.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<XraiAttribution>): XraiAttribution {
    const message = createBaseXraiAttribution();
    message.stepCount = object.stepCount ?? 0;
    message.smoothGradConfig = (object.smoothGradConfig !== undefined && object.smoothGradConfig !== null)
      ? SmoothGradConfig.fromPartial(object.smoothGradConfig)
      : undefined;
    message.blurBaselineConfig = (object.blurBaselineConfig !== undefined && object.blurBaselineConfig !== null)
      ? BlurBaselineConfig.fromPartial(object.blurBaselineConfig)
      : undefined;
    return message;
  },
};

function createBaseSmoothGradConfig(): SmoothGradConfig {
  return { noiseSigma: undefined, featureNoiseSigma: undefined, noisySampleCount: 0 };
}

export const SmoothGradConfig: MessageFns<SmoothGradConfig> = {
  encode(message: SmoothGradConfig, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.noiseSigma !== undefined) {
      writer.uint32(13).float(message.noiseSigma);
    }
    if (message.featureNoiseSigma !== undefined) {
      FeatureNoiseSigma.encode(message.featureNoiseSigma, writer.uint32(18).fork()).join();
    }
    if (message.noisySampleCount !== 0) {
      writer.uint32(24).int32(message.noisySampleCount);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): SmoothGradConfig {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseSmoothGradConfig();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 13) {
            break;
          }

          message.noiseSigma = reader.float();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.featureNoiseSigma = FeatureNoiseSigma.decode(reader, reader.uint32());
          continue;
        case 3:
          if (tag !== 24) {
            break;
          }

          message.noisySampleCount = reader.int32();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): SmoothGradConfig {
    return {
      noiseSigma: isSet(object.noiseSigma) ? globalThis.Number(object.noiseSigma) : undefined,
      featureNoiseSigma: isSet(object.featureNoiseSigma)
        ? FeatureNoiseSigma.fromJSON(object.featureNoiseSigma)
        : undefined,
      noisySampleCount: isSet(object.noisySampleCount) ? globalThis.Number(object.noisySampleCount) : 0,
    };
  },

  toJSON(message: SmoothGradConfig): unknown {
    const obj: any = {};
    if (message.noiseSigma !== undefined) {
      obj.noiseSigma = message.noiseSigma;
    }
    if (message.featureNoiseSigma !== undefined) {
      obj.featureNoiseSigma = FeatureNoiseSigma.toJSON(message.featureNoiseSigma);
    }
    if (message.noisySampleCount !== 0) {
      obj.noisySampleCount = Math.round(message.noisySampleCount);
    }
    return obj;
  },

  create(base?: DeepPartial<SmoothGradConfig>): SmoothGradConfig {
    return SmoothGradConfig.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<SmoothGradConfig>): SmoothGradConfig {
    const message = createBaseSmoothGradConfig();
    message.noiseSigma = object.noiseSigma ?? undefined;
    message.featureNoiseSigma = (object.featureNoiseSigma !== undefined && object.featureNoiseSigma !== null)
      ? FeatureNoiseSigma.fromPartial(object.featureNoiseSigma)
      : undefined;
    message.noisySampleCount = object.noisySampleCount ?? 0;
    return message;
  },
};

function createBaseFeatureNoiseSigma(): FeatureNoiseSigma {
  return { noiseSigma: [] };
}

export const FeatureNoiseSigma: MessageFns<FeatureNoiseSigma> = {
  encode(message: FeatureNoiseSigma, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.noiseSigma) {
      FeatureNoiseSigma_NoiseSigmaForFeature.encode(v!, writer.uint32(10).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): FeatureNoiseSigma {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseFeatureNoiseSigma();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.noiseSigma.push(FeatureNoiseSigma_NoiseSigmaForFeature.decode(reader, reader.uint32()));
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): FeatureNoiseSigma {
    return {
      noiseSigma: globalThis.Array.isArray(object?.noiseSigma)
        ? object.noiseSigma.map((e: any) => FeatureNoiseSigma_NoiseSigmaForFeature.fromJSON(e))
        : [],
    };
  },

  toJSON(message: FeatureNoiseSigma): unknown {
    const obj: any = {};
    if (message.noiseSigma?.length) {
      obj.noiseSigma = message.noiseSigma.map((e) => FeatureNoiseSigma_NoiseSigmaForFeature.toJSON(e));
    }
    return obj;
  },

  create(base?: DeepPartial<FeatureNoiseSigma>): FeatureNoiseSigma {
    return FeatureNoiseSigma.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<FeatureNoiseSigma>): FeatureNoiseSigma {
    const message = createBaseFeatureNoiseSigma();
    message.noiseSigma = object.noiseSigma?.map((e) => FeatureNoiseSigma_NoiseSigmaForFeature.fromPartial(e)) || [];
    return message;
  },
};

function createBaseFeatureNoiseSigma_NoiseSigmaForFeature(): FeatureNoiseSigma_NoiseSigmaForFeature {
  return { name: "", sigma: 0 };
}

export const FeatureNoiseSigma_NoiseSigmaForFeature: MessageFns<FeatureNoiseSigma_NoiseSigmaForFeature> = {
  encode(message: FeatureNoiseSigma_NoiseSigmaForFeature, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    if (message.sigma !== 0) {
      writer.uint32(21).float(message.sigma);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): FeatureNoiseSigma_NoiseSigmaForFeature {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseFeatureNoiseSigma_NoiseSigmaForFeature();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
        case 2:
          if (tag !== 21) {
            break;
          }

          message.sigma = reader.float();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): FeatureNoiseSigma_NoiseSigmaForFeature {
    return {
      name: isSet(object.name) ? globalThis.String(object.name) : "",
      sigma: isSet(object.sigma) ? globalThis.Number(object.sigma) : 0,
    };
  },

  toJSON(message: FeatureNoiseSigma_NoiseSigmaForFeature): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    if (message.sigma !== 0) {
      obj.sigma = message.sigma;
    }
    return obj;
  },

  create(base?: DeepPartial<FeatureNoiseSigma_NoiseSigmaForFeature>): FeatureNoiseSigma_NoiseSigmaForFeature {
    return FeatureNoiseSigma_NoiseSigmaForFeature.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<FeatureNoiseSigma_NoiseSigmaForFeature>): FeatureNoiseSigma_NoiseSigmaForFeature {
    const message = createBaseFeatureNoiseSigma_NoiseSigmaForFeature();
    message.name = object.name ?? "";
    message.sigma = object.sigma ?? 0;
    return message;
  },
};

function createBaseBlurBaselineConfig(): BlurBaselineConfig {
  return { maxBlurSigma: 0 };
}

export const BlurBaselineConfig: MessageFns<BlurBaselineConfig> = {
  encode(message: BlurBaselineConfig, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.maxBlurSigma !== 0) {
      writer.uint32(13).float(message.maxBlurSigma);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): BlurBaselineConfig {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseBlurBaselineConfig();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 13) {
            break;
          }

          message.maxBlurSigma = reader.float();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): BlurBaselineConfig {
    return { maxBlurSigma: isSet(object.maxBlurSigma) ? globalThis.Number(object.maxBlurSigma) : 0 };
  },

  toJSON(message: BlurBaselineConfig): unknown {
    const obj: any = {};
    if (message.maxBlurSigma !== 0) {
      obj.maxBlurSigma = message.maxBlurSigma;
    }
    return obj;
  },

  create(base?: DeepPartial<BlurBaselineConfig>): BlurBaselineConfig {
    return BlurBaselineConfig.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<BlurBaselineConfig>): BlurBaselineConfig {
    const message = createBaseBlurBaselineConfig();
    message.maxBlurSigma = object.maxBlurSigma ?? 0;
    return message;
  },
};

function createBaseExamples(): Examples {
  return { exampleGcsSource: undefined, nearestNeighborSearchConfig: undefined, presets: undefined, neighborCount: 0 };
}

export const Examples: MessageFns<Examples> = {
  encode(message: Examples, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.exampleGcsSource !== undefined) {
      Examples_ExampleGcsSource.encode(message.exampleGcsSource, writer.uint32(42).fork()).join();
    }
    if (message.nearestNeighborSearchConfig !== undefined) {
      Value.encode(Value.wrap(message.nearestNeighborSearchConfig), writer.uint32(18).fork()).join();
    }
    if (message.presets !== undefined) {
      Presets.encode(message.presets, writer.uint32(34).fork()).join();
    }
    if (message.neighborCount !== 0) {
      writer.uint32(24).int32(message.neighborCount);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Examples {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseExamples();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 5:
          if (tag !== 42) {
            break;
          }

          message.exampleGcsSource = Examples_ExampleGcsSource.decode(reader, reader.uint32());
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.nearestNeighborSearchConfig = Value.unwrap(Value.decode(reader, reader.uint32()));
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.presets = Presets.decode(reader, reader.uint32());
          continue;
        case 3:
          if (tag !== 24) {
            break;
          }

          message.neighborCount = reader.int32();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Examples {
    return {
      exampleGcsSource: isSet(object.exampleGcsSource)
        ? Examples_ExampleGcsSource.fromJSON(object.exampleGcsSource)
        : undefined,
      nearestNeighborSearchConfig: isSet(object?.nearestNeighborSearchConfig)
        ? object.nearestNeighborSearchConfig
        : undefined,
      presets: isSet(object.presets) ? Presets.fromJSON(object.presets) : undefined,
      neighborCount: isSet(object.neighborCount) ? globalThis.Number(object.neighborCount) : 0,
    };
  },

  toJSON(message: Examples): unknown {
    const obj: any = {};
    if (message.exampleGcsSource !== undefined) {
      obj.exampleGcsSource = Examples_ExampleGcsSource.toJSON(message.exampleGcsSource);
    }
    if (message.nearestNeighborSearchConfig !== undefined) {
      obj.nearestNeighborSearchConfig = message.nearestNeighborSearchConfig;
    }
    if (message.presets !== undefined) {
      obj.presets = Presets.toJSON(message.presets);
    }
    if (message.neighborCount !== 0) {
      obj.neighborCount = Math.round(message.neighborCount);
    }
    return obj;
  },

  create(base?: DeepPartial<Examples>): Examples {
    return Examples.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<Examples>): Examples {
    const message = createBaseExamples();
    message.exampleGcsSource = (object.exampleGcsSource !== undefined && object.exampleGcsSource !== null)
      ? Examples_ExampleGcsSource.fromPartial(object.exampleGcsSource)
      : undefined;
    message.nearestNeighborSearchConfig = object.nearestNeighborSearchConfig ?? undefined;
    message.presets = (object.presets !== undefined && object.presets !== null)
      ? Presets.fromPartial(object.presets)
      : undefined;
    message.neighborCount = object.neighborCount ?? 0;
    return message;
  },
};

function createBaseExamples_ExampleGcsSource(): Examples_ExampleGcsSource {
  return { dataFormat: 0, gcsSource: undefined };
}

export const Examples_ExampleGcsSource: MessageFns<Examples_ExampleGcsSource> = {
  encode(message: Examples_ExampleGcsSource, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.dataFormat !== 0) {
      writer.uint32(8).int32(message.dataFormat);
    }
    if (message.gcsSource !== undefined) {
      GcsSource.encode(message.gcsSource, writer.uint32(18).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Examples_ExampleGcsSource {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseExamples_ExampleGcsSource();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 8) {
            break;
          }

          message.dataFormat = reader.int32() as any;
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.gcsSource = GcsSource.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Examples_ExampleGcsSource {
    return {
      dataFormat: isSet(object.dataFormat) ? examples_ExampleGcsSource_DataFormatFromJSON(object.dataFormat) : 0,
      gcsSource: isSet(object.gcsSource) ? GcsSource.fromJSON(object.gcsSource) : undefined,
    };
  },

  toJSON(message: Examples_ExampleGcsSource): unknown {
    const obj: any = {};
    if (message.dataFormat !== 0) {
      obj.dataFormat = examples_ExampleGcsSource_DataFormatToJSON(message.dataFormat);
    }
    if (message.gcsSource !== undefined) {
      obj.gcsSource = GcsSource.toJSON(message.gcsSource);
    }
    return obj;
  },

  create(base?: DeepPartial<Examples_ExampleGcsSource>): Examples_ExampleGcsSource {
    return Examples_ExampleGcsSource.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<Examples_ExampleGcsSource>): Examples_ExampleGcsSource {
    const message = createBaseExamples_ExampleGcsSource();
    message.dataFormat = object.dataFormat ?? 0;
    message.gcsSource = (object.gcsSource !== undefined && object.gcsSource !== null)
      ? GcsSource.fromPartial(object.gcsSource)
      : undefined;
    return message;
  },
};

function createBasePresets(): Presets {
  return { query: undefined, modality: 0 };
}

export const Presets: MessageFns<Presets> = {
  encode(message: Presets, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.query !== undefined) {
      writer.uint32(8).int32(message.query);
    }
    if (message.modality !== 0) {
      writer.uint32(16).int32(message.modality);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Presets {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBasePresets();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 8) {
            break;
          }

          message.query = reader.int32() as any;
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.modality = reader.int32() as any;
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Presets {
    return {
      query: isSet(object.query) ? presets_QueryFromJSON(object.query) : undefined,
      modality: isSet(object.modality) ? presets_ModalityFromJSON(object.modality) : 0,
    };
  },

  toJSON(message: Presets): unknown {
    const obj: any = {};
    if (message.query !== undefined) {
      obj.query = presets_QueryToJSON(message.query);
    }
    if (message.modality !== 0) {
      obj.modality = presets_ModalityToJSON(message.modality);
    }
    return obj;
  },

  create(base?: DeepPartial<Presets>): Presets {
    return Presets.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<Presets>): Presets {
    const message = createBasePresets();
    message.query = object.query ?? undefined;
    message.modality = object.modality ?? 0;
    return message;
  },
};

function createBaseExplanationSpecOverride(): ExplanationSpecOverride {
  return { parameters: undefined, metadata: undefined, examplesOverride: undefined };
}

export const ExplanationSpecOverride: MessageFns<ExplanationSpecOverride> = {
  encode(message: ExplanationSpecOverride, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.parameters !== undefined) {
      ExplanationParameters.encode(message.parameters, writer.uint32(10).fork()).join();
    }
    if (message.metadata !== undefined) {
      ExplanationMetadataOverride.encode(message.metadata, writer.uint32(18).fork()).join();
    }
    if (message.examplesOverride !== undefined) {
      ExamplesOverride.encode(message.examplesOverride, writer.uint32(26).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ExplanationSpecOverride {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseExplanationSpecOverride();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.parameters = ExplanationParameters.decode(reader, reader.uint32());
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.metadata = ExplanationMetadataOverride.decode(reader, reader.uint32());
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.examplesOverride = ExamplesOverride.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ExplanationSpecOverride {
    return {
      parameters: isSet(object.parameters) ? ExplanationParameters.fromJSON(object.parameters) : undefined,
      metadata: isSet(object.metadata) ? ExplanationMetadataOverride.fromJSON(object.metadata) : undefined,
      examplesOverride: isSet(object.examplesOverride) ? ExamplesOverride.fromJSON(object.examplesOverride) : undefined,
    };
  },

  toJSON(message: ExplanationSpecOverride): unknown {
    const obj: any = {};
    if (message.parameters !== undefined) {
      obj.parameters = ExplanationParameters.toJSON(message.parameters);
    }
    if (message.metadata !== undefined) {
      obj.metadata = ExplanationMetadataOverride.toJSON(message.metadata);
    }
    if (message.examplesOverride !== undefined) {
      obj.examplesOverride = ExamplesOverride.toJSON(message.examplesOverride);
    }
    return obj;
  },

  create(base?: DeepPartial<ExplanationSpecOverride>): ExplanationSpecOverride {
    return ExplanationSpecOverride.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ExplanationSpecOverride>): ExplanationSpecOverride {
    const message = createBaseExplanationSpecOverride();
    message.parameters = (object.parameters !== undefined && object.parameters !== null)
      ? ExplanationParameters.fromPartial(object.parameters)
      : undefined;
    message.metadata = (object.metadata !== undefined && object.metadata !== null)
      ? ExplanationMetadataOverride.fromPartial(object.metadata)
      : undefined;
    message.examplesOverride = (object.examplesOverride !== undefined && object.examplesOverride !== null)
      ? ExamplesOverride.fromPartial(object.examplesOverride)
      : undefined;
    return message;
  },
};

function createBaseExplanationMetadataOverride(): ExplanationMetadataOverride {
  return { inputs: {} };
}

export const ExplanationMetadataOverride: MessageFns<ExplanationMetadataOverride> = {
  encode(message: ExplanationMetadataOverride, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    Object.entries(message.inputs).forEach(([key, value]) => {
      ExplanationMetadataOverride_InputsEntry.encode({ key: key as any, value }, writer.uint32(10).fork()).join();
    });
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ExplanationMetadataOverride {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseExplanationMetadataOverride();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          const entry1 = ExplanationMetadataOverride_InputsEntry.decode(reader, reader.uint32());
          if (entry1.value !== undefined) {
            message.inputs[entry1.key] = entry1.value;
          }
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ExplanationMetadataOverride {
    return {
      inputs: isObject(object.inputs)
        ? Object.entries(object.inputs).reduce<{ [key: string]: ExplanationMetadataOverride_InputMetadataOverride }>(
          (acc, [key, value]) => {
            acc[key] = ExplanationMetadataOverride_InputMetadataOverride.fromJSON(value);
            return acc;
          },
          {},
        )
        : {},
    };
  },

  toJSON(message: ExplanationMetadataOverride): unknown {
    const obj: any = {};
    if (message.inputs) {
      const entries = Object.entries(message.inputs);
      if (entries.length > 0) {
        obj.inputs = {};
        entries.forEach(([k, v]) => {
          obj.inputs[k] = ExplanationMetadataOverride_InputMetadataOverride.toJSON(v);
        });
      }
    }
    return obj;
  },

  create(base?: DeepPartial<ExplanationMetadataOverride>): ExplanationMetadataOverride {
    return ExplanationMetadataOverride.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ExplanationMetadataOverride>): ExplanationMetadataOverride {
    const message = createBaseExplanationMetadataOverride();
    message.inputs = Object.entries(object.inputs ?? {}).reduce<
      { [key: string]: ExplanationMetadataOverride_InputMetadataOverride }
    >((acc, [key, value]) => {
      if (value !== undefined) {
        acc[key] = ExplanationMetadataOverride_InputMetadataOverride.fromPartial(value);
      }
      return acc;
    }, {});
    return message;
  },
};

function createBaseExplanationMetadataOverride_InputMetadataOverride(): ExplanationMetadataOverride_InputMetadataOverride {
  return { inputBaselines: [] };
}

export const ExplanationMetadataOverride_InputMetadataOverride: MessageFns<
  ExplanationMetadataOverride_InputMetadataOverride
> = {
  encode(
    message: ExplanationMetadataOverride_InputMetadataOverride,
    writer: BinaryWriter = new BinaryWriter(),
  ): BinaryWriter {
    for (const v of message.inputBaselines) {
      Value.encode(Value.wrap(v!), writer.uint32(10).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ExplanationMetadataOverride_InputMetadataOverride {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseExplanationMetadataOverride_InputMetadataOverride();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.inputBaselines.push(Value.unwrap(Value.decode(reader, reader.uint32())));
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ExplanationMetadataOverride_InputMetadataOverride {
    return { inputBaselines: globalThis.Array.isArray(object?.inputBaselines) ? [...object.inputBaselines] : [] };
  },

  toJSON(message: ExplanationMetadataOverride_InputMetadataOverride): unknown {
    const obj: any = {};
    if (message.inputBaselines?.length) {
      obj.inputBaselines = message.inputBaselines;
    }
    return obj;
  },

  create(
    base?: DeepPartial<ExplanationMetadataOverride_InputMetadataOverride>,
  ): ExplanationMetadataOverride_InputMetadataOverride {
    return ExplanationMetadataOverride_InputMetadataOverride.fromPartial(base ?? {});
  },
  fromPartial(
    object: DeepPartial<ExplanationMetadataOverride_InputMetadataOverride>,
  ): ExplanationMetadataOverride_InputMetadataOverride {
    const message = createBaseExplanationMetadataOverride_InputMetadataOverride();
    message.inputBaselines = object.inputBaselines?.map((e) => e) || [];
    return message;
  },
};

function createBaseExplanationMetadataOverride_InputsEntry(): ExplanationMetadataOverride_InputsEntry {
  return { key: "", value: undefined };
}

export const ExplanationMetadataOverride_InputsEntry: MessageFns<ExplanationMetadataOverride_InputsEntry> = {
  encode(message: ExplanationMetadataOverride_InputsEntry, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.key !== "") {
      writer.uint32(10).string(message.key);
    }
    if (message.value !== undefined) {
      ExplanationMetadataOverride_InputMetadataOverride.encode(message.value, writer.uint32(18).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ExplanationMetadataOverride_InputsEntry {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseExplanationMetadataOverride_InputsEntry();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.key = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.value = ExplanationMetadataOverride_InputMetadataOverride.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ExplanationMetadataOverride_InputsEntry {
    return {
      key: isSet(object.key) ? globalThis.String(object.key) : "",
      value: isSet(object.value) ? ExplanationMetadataOverride_InputMetadataOverride.fromJSON(object.value) : undefined,
    };
  },

  toJSON(message: ExplanationMetadataOverride_InputsEntry): unknown {
    const obj: any = {};
    if (message.key !== "") {
      obj.key = message.key;
    }
    if (message.value !== undefined) {
      obj.value = ExplanationMetadataOverride_InputMetadataOverride.toJSON(message.value);
    }
    return obj;
  },

  create(base?: DeepPartial<ExplanationMetadataOverride_InputsEntry>): ExplanationMetadataOverride_InputsEntry {
    return ExplanationMetadataOverride_InputsEntry.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ExplanationMetadataOverride_InputsEntry>): ExplanationMetadataOverride_InputsEntry {
    const message = createBaseExplanationMetadataOverride_InputsEntry();
    message.key = object.key ?? "";
    message.value = (object.value !== undefined && object.value !== null)
      ? ExplanationMetadataOverride_InputMetadataOverride.fromPartial(object.value)
      : undefined;
    return message;
  },
};

function createBaseExamplesOverride(): ExamplesOverride {
  return { neighborCount: 0, crowdingCount: 0, restrictions: [], returnEmbeddings: false, dataFormat: 0 };
}

export const ExamplesOverride: MessageFns<ExamplesOverride> = {
  encode(message: ExamplesOverride, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.neighborCount !== 0) {
      writer.uint32(8).int32(message.neighborCount);
    }
    if (message.crowdingCount !== 0) {
      writer.uint32(16).int32(message.crowdingCount);
    }
    for (const v of message.restrictions) {
      ExamplesRestrictionsNamespace.encode(v!, writer.uint32(26).fork()).join();
    }
    if (message.returnEmbeddings !== false) {
      writer.uint32(32).bool(message.returnEmbeddings);
    }
    if (message.dataFormat !== 0) {
      writer.uint32(40).int32(message.dataFormat);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ExamplesOverride {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseExamplesOverride();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 8) {
            break;
          }

          message.neighborCount = reader.int32();
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.crowdingCount = reader.int32();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.restrictions.push(ExamplesRestrictionsNamespace.decode(reader, reader.uint32()));
          continue;
        case 4:
          if (tag !== 32) {
            break;
          }

          message.returnEmbeddings = reader.bool();
          continue;
        case 5:
          if (tag !== 40) {
            break;
          }

          message.dataFormat = reader.int32() as any;
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ExamplesOverride {
    return {
      neighborCount: isSet(object.neighborCount) ? globalThis.Number(object.neighborCount) : 0,
      crowdingCount: isSet(object.crowdingCount) ? globalThis.Number(object.crowdingCount) : 0,
      restrictions: globalThis.Array.isArray(object?.restrictions)
        ? object.restrictions.map((e: any) => ExamplesRestrictionsNamespace.fromJSON(e))
        : [],
      returnEmbeddings: isSet(object.returnEmbeddings) ? globalThis.Boolean(object.returnEmbeddings) : false,
      dataFormat: isSet(object.dataFormat) ? examplesOverride_DataFormatFromJSON(object.dataFormat) : 0,
    };
  },

  toJSON(message: ExamplesOverride): unknown {
    const obj: any = {};
    if (message.neighborCount !== 0) {
      obj.neighborCount = Math.round(message.neighborCount);
    }
    if (message.crowdingCount !== 0) {
      obj.crowdingCount = Math.round(message.crowdingCount);
    }
    if (message.restrictions?.length) {
      obj.restrictions = message.restrictions.map((e) => ExamplesRestrictionsNamespace.toJSON(e));
    }
    if (message.returnEmbeddings !== false) {
      obj.returnEmbeddings = message.returnEmbeddings;
    }
    if (message.dataFormat !== 0) {
      obj.dataFormat = examplesOverride_DataFormatToJSON(message.dataFormat);
    }
    return obj;
  },

  create(base?: DeepPartial<ExamplesOverride>): ExamplesOverride {
    return ExamplesOverride.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ExamplesOverride>): ExamplesOverride {
    const message = createBaseExamplesOverride();
    message.neighborCount = object.neighborCount ?? 0;
    message.crowdingCount = object.crowdingCount ?? 0;
    message.restrictions = object.restrictions?.map((e) => ExamplesRestrictionsNamespace.fromPartial(e)) || [];
    message.returnEmbeddings = object.returnEmbeddings ?? false;
    message.dataFormat = object.dataFormat ?? 0;
    return message;
  },
};

function createBaseExamplesRestrictionsNamespace(): ExamplesRestrictionsNamespace {
  return { namespaceName: "", allow: [], deny: [] };
}

export const ExamplesRestrictionsNamespace: MessageFns<ExamplesRestrictionsNamespace> = {
  encode(message: ExamplesRestrictionsNamespace, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.namespaceName !== "") {
      writer.uint32(10).string(message.namespaceName);
    }
    for (const v of message.allow) {
      writer.uint32(18).string(v!);
    }
    for (const v of message.deny) {
      writer.uint32(26).string(v!);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ExamplesRestrictionsNamespace {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseExamplesRestrictionsNamespace();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.namespaceName = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.allow.push(reader.string());
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.deny.push(reader.string());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ExamplesRestrictionsNamespace {
    return {
      namespaceName: isSet(object.namespaceName) ? globalThis.String(object.namespaceName) : "",
      allow: globalThis.Array.isArray(object?.allow) ? object.allow.map((e: any) => globalThis.String(e)) : [],
      deny: globalThis.Array.isArray(object?.deny) ? object.deny.map((e: any) => globalThis.String(e)) : [],
    };
  },

  toJSON(message: ExamplesRestrictionsNamespace): unknown {
    const obj: any = {};
    if (message.namespaceName !== "") {
      obj.namespaceName = message.namespaceName;
    }
    if (message.allow?.length) {
      obj.allow = message.allow;
    }
    if (message.deny?.length) {
      obj.deny = message.deny;
    }
    return obj;
  },

  create(base?: DeepPartial<ExamplesRestrictionsNamespace>): ExamplesRestrictionsNamespace {
    return ExamplesRestrictionsNamespace.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ExamplesRestrictionsNamespace>): ExamplesRestrictionsNamespace {
    const message = createBaseExamplesRestrictionsNamespace();
    message.namespaceName = object.namespaceName ?? "";
    message.allow = object.allow?.map((e) => e) || [];
    message.deny = object.deny?.map((e) => e) || [];
    return message;
  },
};

type Builtin = Date | Function | Uint8Array | string | number | boolean | undefined;

export type DeepPartial<T> = T extends Builtin ? T
  : T extends Long ? string | number | Long : T extends globalThis.Array<infer U> ? globalThis.Array<DeepPartial<U>>
  : T extends ReadonlyArray<infer U> ? ReadonlyArray<DeepPartial<U>>
  : T extends {} ? { [K in keyof T]?: DeepPartial<T[K]> }
  : Partial<T>;

function isObject(value: any): boolean {
  return typeof value === "object" && value !== null;
}

function isSet(value: any): boolean {
  return value !== null && value !== undefined;
}

export interface MessageFns<T> {
  encode(message: T, writer?: BinaryWriter): BinaryWriter;
  decode(input: BinaryReader | Uint8Array, length?: number): T;
  fromJSON(object: any): T;
  toJSON(message: T): unknown;
  create(base?: DeepPartial<T>): T;
  fromPartial(object: DeepPartial<T>): T;
}
