// Code generated by protoc-gen-ts_proto. DO NOT EDIT.
// versions:
//   protoc-gen-ts_proto  v2.2.0
//   protoc               unknown
// source: google/cloud/aiplatform/v1/schema/predict/instance/video_action_recognition.proto

/* eslint-disable */
import { BinaryReader, BinaryWriter } from "@bufbuild/protobuf/wire";
import Long from "long";

export const protobufPackage = "google.cloud.aiplatform.v1.schema.predict.instance";

/** Prediction input format for Video Action Recognition. */
export interface VideoActionRecognitionPredictionInstance {
  /**
   * The Google Cloud Storage location of the video on which to perform the
   * prediction.
   */
  content: string;
  /**
   * The MIME type of the content of the video. Only the following are
   * supported: video/mp4 video/avi video/quicktime
   */
  mimeType: string;
  /**
   * The beginning, inclusive, of the video's time segment on which to perform
   * the prediction. Expressed as a number of seconds as measured from the
   * start of the video, with "s" appended at the end. Fractions are allowed,
   * up to a microsecond precision.
   */
  timeSegmentStart: string;
  /**
   * The end, exclusive, of the video's time segment on which to perform
   * the prediction. Expressed as a number of seconds as measured from the
   * start of the video, with "s" appended at the end. Fractions are allowed,
   * up to a microsecond precision, and "inf" or "Infinity" is allowed, which
   * means the end of the video.
   */
  timeSegmentEnd: string;
}

function createBaseVideoActionRecognitionPredictionInstance(): VideoActionRecognitionPredictionInstance {
  return { content: "", mimeType: "", timeSegmentStart: "", timeSegmentEnd: "" };
}

export const VideoActionRecognitionPredictionInstance: MessageFns<VideoActionRecognitionPredictionInstance> = {
  encode(message: VideoActionRecognitionPredictionInstance, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.content !== "") {
      writer.uint32(10).string(message.content);
    }
    if (message.mimeType !== "") {
      writer.uint32(18).string(message.mimeType);
    }
    if (message.timeSegmentStart !== "") {
      writer.uint32(26).string(message.timeSegmentStart);
    }
    if (message.timeSegmentEnd !== "") {
      writer.uint32(34).string(message.timeSegmentEnd);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): VideoActionRecognitionPredictionInstance {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseVideoActionRecognitionPredictionInstance();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.content = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.mimeType = reader.string();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.timeSegmentStart = reader.string();
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.timeSegmentEnd = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): VideoActionRecognitionPredictionInstance {
    return {
      content: isSet(object.content) ? globalThis.String(object.content) : "",
      mimeType: isSet(object.mimeType) ? globalThis.String(object.mimeType) : "",
      timeSegmentStart: isSet(object.timeSegmentStart) ? globalThis.String(object.timeSegmentStart) : "",
      timeSegmentEnd: isSet(object.timeSegmentEnd) ? globalThis.String(object.timeSegmentEnd) : "",
    };
  },

  toJSON(message: VideoActionRecognitionPredictionInstance): unknown {
    const obj: any = {};
    if (message.content !== "") {
      obj.content = message.content;
    }
    if (message.mimeType !== "") {
      obj.mimeType = message.mimeType;
    }
    if (message.timeSegmentStart !== "") {
      obj.timeSegmentStart = message.timeSegmentStart;
    }
    if (message.timeSegmentEnd !== "") {
      obj.timeSegmentEnd = message.timeSegmentEnd;
    }
    return obj;
  },

  create(base?: DeepPartial<VideoActionRecognitionPredictionInstance>): VideoActionRecognitionPredictionInstance {
    return VideoActionRecognitionPredictionInstance.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<VideoActionRecognitionPredictionInstance>): VideoActionRecognitionPredictionInstance {
    const message = createBaseVideoActionRecognitionPredictionInstance();
    message.content = object.content ?? "";
    message.mimeType = object.mimeType ?? "";
    message.timeSegmentStart = object.timeSegmentStart ?? "";
    message.timeSegmentEnd = object.timeSegmentEnd ?? "";
    return message;
  },
};

type Builtin = Date | Function | Uint8Array | string | number | boolean | undefined;

export type DeepPartial<T> = T extends Builtin ? T
  : T extends Long ? string | number | Long : T extends globalThis.Array<infer U> ? globalThis.Array<DeepPartial<U>>
  : T extends ReadonlyArray<infer U> ? ReadonlyArray<DeepPartial<U>>
  : T extends {} ? { [K in keyof T]?: DeepPartial<T[K]> }
  : Partial<T>;

function isSet(value: any): boolean {
  return value !== null && value !== undefined;
}

export interface MessageFns<T> {
  encode(message: T, writer?: BinaryWriter): BinaryWriter;
  decode(input: BinaryReader | Uint8Array, length?: number): T;
  fromJSON(object: any): T;
  toJSON(message: T): unknown;
  create(base?: DeepPartial<T>): T;
  fromPartial(object: DeepPartial<T>): T;
}
