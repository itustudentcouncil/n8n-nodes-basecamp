// Code generated by protoc-gen-ts_proto. DO NOT EDIT.
// versions:
//   protoc-gen-ts_proto  v2.2.0
//   protoc               unknown
// source: google/cloud/speech/v2/cloud_speech.proto

/* eslint-disable */
import { BinaryReader, BinaryWriter } from "@bufbuild/protobuf/wire";
import Long from "long";
import { type CallContext, type CallOptions } from "nice-grpc-common";
import { Operation } from "../../../longrunning/operations.js";
import { Duration } from "../../../protobuf/duration.js";
import { FieldMask } from "../../../protobuf/field_mask.js";
import { Timestamp } from "../../../protobuf/timestamp.js";
import { Status } from "../../../rpc/status.js";

export const protobufPackage = "google.cloud.speech.v2";

/**
 * Request message for the
 * [CreateRecognizer][google.cloud.speech.v2.Speech.CreateRecognizer] method.
 */
export interface CreateRecognizerRequest {
  /** Required. The Recognizer to create. */
  recognizer:
    | Recognizer
    | undefined;
  /**
   * If set, validate the request and preview the Recognizer, but do not
   * actually create it.
   */
  validateOnly: boolean;
  /**
   * The ID to use for the Recognizer, which will become the final component of
   * the Recognizer's resource name.
   *
   * This value should be 4-63 characters, and valid characters
   * are /[a-z][0-9]-/.
   */
  recognizerId: string;
  /**
   * Required. The project and location where this Recognizer will be created.
   * The expected format is `projects/{project}/locations/{location}`.
   */
  parent: string;
}

/** Represents the metadata of a long-running operation. */
export interface OperationMetadata {
  /** The time the operation was created. */
  createTime:
    | Date
    | undefined;
  /** The time the operation was last updated. */
  updateTime:
    | Date
    | undefined;
  /** The resource path for the target of the operation. */
  resource: string;
  /** The method that triggered the operation. */
  method: string;
  /**
   * The [KMS key
   * name](https://cloud.google.com/kms/docs/resource-hierarchy#keys) with which
   * the content of the Operation is encrypted. The expected format is
   * `projects/{project}/locations/{location}/keyRings/{key_ring}/cryptoKeys/{crypto_key}`.
   */
  kmsKeyName: string;
  /**
   * The [KMS key version
   * name](https://cloud.google.com/kms/docs/resource-hierarchy#key_versions)
   * with which content of the Operation is encrypted. The expected format is
   * `projects/{project}/locations/{location}/keyRings/{key_ring}/cryptoKeys/{crypto_key}/cryptoKeyVersions/{crypto_key_version}`.
   */
  kmsKeyVersionName: string;
  /** The BatchRecognizeRequest that spawned the Operation. */
  batchRecognizeRequest?:
    | BatchRecognizeRequest
    | undefined;
  /** The CreateRecognizerRequest that spawned the Operation. */
  createRecognizerRequest?:
    | CreateRecognizerRequest
    | undefined;
  /** The UpdateRecognizerRequest that spawned the Operation. */
  updateRecognizerRequest?:
    | UpdateRecognizerRequest
    | undefined;
  /** The DeleteRecognizerRequest that spawned the Operation. */
  deleteRecognizerRequest?:
    | DeleteRecognizerRequest
    | undefined;
  /** The UndeleteRecognizerRequest that spawned the Operation. */
  undeleteRecognizerRequest?:
    | UndeleteRecognizerRequest
    | undefined;
  /** The CreateCustomClassRequest that spawned the Operation. */
  createCustomClassRequest?:
    | CreateCustomClassRequest
    | undefined;
  /** The UpdateCustomClassRequest that spawned the Operation. */
  updateCustomClassRequest?:
    | UpdateCustomClassRequest
    | undefined;
  /** The DeleteCustomClassRequest that spawned the Operation. */
  deleteCustomClassRequest?:
    | DeleteCustomClassRequest
    | undefined;
  /** The UndeleteCustomClassRequest that spawned the Operation. */
  undeleteCustomClassRequest?:
    | UndeleteCustomClassRequest
    | undefined;
  /** The CreatePhraseSetRequest that spawned the Operation. */
  createPhraseSetRequest?:
    | CreatePhraseSetRequest
    | undefined;
  /** The UpdatePhraseSetRequest that spawned the Operation. */
  updatePhraseSetRequest?:
    | UpdatePhraseSetRequest
    | undefined;
  /** The DeletePhraseSetRequest that spawned the Operation. */
  deletePhraseSetRequest?:
    | DeletePhraseSetRequest
    | undefined;
  /** The UndeletePhraseSetRequest that spawned the Operation. */
  undeletePhraseSetRequest?:
    | UndeletePhraseSetRequest
    | undefined;
  /**
   * The UpdateConfigRequest that spawned the Operation.
   *
   * @deprecated
   */
  updateConfigRequest?:
    | UpdateConfigRequest
    | undefined;
  /**
   * The percent progress of the Operation. Values can range from 0-100. If the
   * value is 100, then the operation is finished.
   */
  progressPercent: number;
  /** Metadata specific to the BatchRecognize method. */
  batchRecognizeMetadata?: BatchRecognizeMetadata | undefined;
}

/**
 * Request message for the
 * [ListRecognizers][google.cloud.speech.v2.Speech.ListRecognizers] method.
 */
export interface ListRecognizersRequest {
  /**
   * Required. The project and location of Recognizers to list. The expected
   * format is `projects/{project}/locations/{location}`.
   */
  parent: string;
  /**
   * The maximum number of Recognizers to return. The service may return fewer
   * than this value. If unspecified, at most 5 Recognizers will be returned.
   * The maximum value is 100; values above 100 will be coerced to 100.
   */
  pageSize: number;
  /**
   * A page token, received from a previous
   * [ListRecognizers][google.cloud.speech.v2.Speech.ListRecognizers] call.
   * Provide this to retrieve the subsequent page.
   *
   * When paginating, all other parameters provided to
   * [ListRecognizers][google.cloud.speech.v2.Speech.ListRecognizers] must match
   * the call that provided the page token.
   */
  pageToken: string;
  /** Whether, or not, to show resources that have been deleted. */
  showDeleted: boolean;
}

/**
 * Response message for the
 * [ListRecognizers][google.cloud.speech.v2.Speech.ListRecognizers] method.
 */
export interface ListRecognizersResponse {
  /** The list of requested Recognizers. */
  recognizers: Recognizer[];
  /**
   * A token, which can be sent as
   * [page_token][google.cloud.speech.v2.ListRecognizersRequest.page_token] to
   * retrieve the next page. If this field is omitted, there are no subsequent
   * pages. This token expires after 72 hours.
   */
  nextPageToken: string;
}

/**
 * Request message for the
 * [GetRecognizer][google.cloud.speech.v2.Speech.GetRecognizer] method.
 */
export interface GetRecognizerRequest {
  /**
   * Required. The name of the Recognizer to retrieve. The expected format is
   * `projects/{project}/locations/{location}/recognizers/{recognizer}`.
   */
  name: string;
}

/**
 * Request message for the
 * [UpdateRecognizer][google.cloud.speech.v2.Speech.UpdateRecognizer] method.
 */
export interface UpdateRecognizerRequest {
  /**
   * Required. The Recognizer to update.
   *
   * The Recognizer's `name` field is used to identify the Recognizer to update.
   * Format: `projects/{project}/locations/{location}/recognizers/{recognizer}`.
   */
  recognizer:
    | Recognizer
    | undefined;
  /**
   * The list of fields to update. If empty, all non-default valued fields are
   * considered for update. Use `*` to update the entire Recognizer resource.
   */
  updateMask:
    | string[]
    | undefined;
  /**
   * If set, validate the request and preview the updated Recognizer, but do not
   * actually update it.
   */
  validateOnly: boolean;
}

/**
 * Request message for the
 * [DeleteRecognizer][google.cloud.speech.v2.Speech.DeleteRecognizer] method.
 */
export interface DeleteRecognizerRequest {
  /**
   * Required. The name of the Recognizer to delete.
   * Format: `projects/{project}/locations/{location}/recognizers/{recognizer}`
   */
  name: string;
  /**
   * If set, validate the request and preview the deleted Recognizer, but do not
   * actually delete it.
   */
  validateOnly: boolean;
  /**
   * If set to true, and the Recognizer is not found, the request will succeed
   * and  be a no-op (no Operation is recorded in this case).
   */
  allowMissing: boolean;
  /**
   * This checksum is computed by the server based on the value of other
   * fields. This may be sent on update, undelete, and delete requests to ensure
   * the client has an up-to-date value before proceeding.
   */
  etag: string;
}

/**
 * Request message for the
 * [UndeleteRecognizer][google.cloud.speech.v2.Speech.UndeleteRecognizer]
 * method.
 */
export interface UndeleteRecognizerRequest {
  /**
   * Required. The name of the Recognizer to undelete.
   * Format: `projects/{project}/locations/{location}/recognizers/{recognizer}`
   */
  name: string;
  /**
   * If set, validate the request and preview the undeleted Recognizer, but do
   * not actually undelete it.
   */
  validateOnly: boolean;
  /**
   * This checksum is computed by the server based on the value of other
   * fields. This may be sent on update, undelete, and delete requests to ensure
   * the client has an up-to-date value before proceeding.
   */
  etag: string;
}

/** A Recognizer message. Stores recognition configuration and metadata. */
export interface Recognizer {
  /**
   * Output only. Identifier. The resource name of the Recognizer.
   * Format: `projects/{project}/locations/{location}/recognizers/{recognizer}`.
   */
  name: string;
  /** Output only. System-assigned unique identifier for the Recognizer. */
  uid: string;
  /**
   * User-settable, human-readable name for the Recognizer. Must be 63
   * characters or less.
   */
  displayName: string;
  /**
   * Optional. This field is now deprecated. Prefer the
   * [`model`][google.cloud.speech.v2.RecognitionConfig.model] field in the
   * [`RecognitionConfig`][google.cloud.speech.v2.RecognitionConfig] message.
   *
   * Which model to use for recognition requests. Select the model best suited
   * to your domain to get best results.
   *
   * Guidance for choosing which model to use can be found in the [Transcription
   * Models
   * Documentation](https://cloud.google.com/speech-to-text/v2/docs/transcription-model)
   * and the models supported in each region can be found in the [Table Of
   * Supported
   * Models](https://cloud.google.com/speech-to-text/v2/docs/speech-to-text-supported-languages).
   *
   * @deprecated
   */
  model: string;
  /**
   * Optional. This field is now deprecated. Prefer the
   * [`language_codes`][google.cloud.speech.v2.RecognitionConfig.language_codes]
   * field in the
   * [`RecognitionConfig`][google.cloud.speech.v2.RecognitionConfig] message.
   *
   * The language of the supplied audio as a
   * [BCP-47](https://www.rfc-editor.org/rfc/bcp/bcp47.txt) language tag.
   *
   * Supported languages for each model are listed in the [Table of Supported
   * Models](https://cloud.google.com/speech-to-text/v2/docs/speech-to-text-supported-languages).
   *
   * If additional languages are provided, recognition result will contain
   * recognition in the most likely language detected. The recognition result
   * will include the language tag of the language detected in the audio.
   * When you create or update a Recognizer, these values are
   * stored in normalized BCP-47 form. For example, "en-us" is stored as
   * "en-US".
   *
   * @deprecated
   */
  languageCodes: string[];
  /**
   * Default configuration to use for requests with this Recognizer.
   * This can be overwritten by inline configuration in the
   * [RecognizeRequest.config][google.cloud.speech.v2.RecognizeRequest.config]
   * field.
   */
  defaultRecognitionConfig:
    | RecognitionConfig
    | undefined;
  /**
   * Allows users to store small amounts of arbitrary data.
   * Both the key and the value must be 63 characters or less each.
   * At most 100 annotations.
   */
  annotations: { [key: string]: string };
  /** Output only. The Recognizer lifecycle state. */
  state: Recognizer_State;
  /** Output only. Creation time. */
  createTime:
    | Date
    | undefined;
  /** Output only. The most recent time this Recognizer was modified. */
  updateTime:
    | Date
    | undefined;
  /** Output only. The time at which this Recognizer was requested for deletion. */
  deleteTime:
    | Date
    | undefined;
  /** Output only. The time at which this Recognizer will be purged. */
  expireTime:
    | Date
    | undefined;
  /**
   * Output only. This checksum is computed by the server based on the value of
   * other fields. This may be sent on update, undelete, and delete requests to
   * ensure the client has an up-to-date value before proceeding.
   */
  etag: string;
  /**
   * Output only. Whether or not this Recognizer is in the process of being
   * updated.
   */
  reconciling: boolean;
  /**
   * Output only. The [KMS key
   * name](https://cloud.google.com/kms/docs/resource-hierarchy#keys) with which
   * the Recognizer is encrypted. The expected format is
   * `projects/{project}/locations/{location}/keyRings/{key_ring}/cryptoKeys/{crypto_key}`.
   */
  kmsKeyName: string;
  /**
   * Output only. The [KMS key version
   * name](https://cloud.google.com/kms/docs/resource-hierarchy#key_versions)
   * with which the Recognizer is encrypted. The expected format is
   * `projects/{project}/locations/{location}/keyRings/{key_ring}/cryptoKeys/{crypto_key}/cryptoKeyVersions/{crypto_key_version}`.
   */
  kmsKeyVersionName: string;
}

/** Set of states that define the lifecycle of a Recognizer. */
export enum Recognizer_State {
  /** STATE_UNSPECIFIED - The default value. This value is used if the state is omitted. */
  STATE_UNSPECIFIED = 0,
  /** ACTIVE - The Recognizer is active and ready for use. */
  ACTIVE = 2,
  /** DELETED - This Recognizer has been deleted. */
  DELETED = 4,
  UNRECOGNIZED = -1,
}

export function recognizer_StateFromJSON(object: any): Recognizer_State {
  switch (object) {
    case 0:
    case "STATE_UNSPECIFIED":
      return Recognizer_State.STATE_UNSPECIFIED;
    case 2:
    case "ACTIVE":
      return Recognizer_State.ACTIVE;
    case 4:
    case "DELETED":
      return Recognizer_State.DELETED;
    case -1:
    case "UNRECOGNIZED":
    default:
      return Recognizer_State.UNRECOGNIZED;
  }
}

export function recognizer_StateToJSON(object: Recognizer_State): string {
  switch (object) {
    case Recognizer_State.STATE_UNSPECIFIED:
      return "STATE_UNSPECIFIED";
    case Recognizer_State.ACTIVE:
      return "ACTIVE";
    case Recognizer_State.DELETED:
      return "DELETED";
    case Recognizer_State.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

export interface Recognizer_AnnotationsEntry {
  key: string;
  value: string;
}

/**
 * Automatically detected decoding parameters.
 * Supported for the following encodings:
 *
 * * WAV_LINEAR16: 16-bit signed little-endian PCM samples in a WAV container.
 *
 * * WAV_MULAW: 8-bit companded mulaw samples in a WAV container.
 *
 * * WAV_ALAW: 8-bit companded alaw samples in a WAV container.
 *
 * * RFC4867_5_AMR: AMR frames with an rfc4867.5 header.
 *
 * * RFC4867_5_AMRWB: AMR-WB frames with an rfc4867.5 header.
 *
 * * FLAC: FLAC frames in the "native FLAC" container format.
 *
 * * MP3: MPEG audio frames with optional (ignored) ID3 metadata.
 *
 * * OGG_OPUS: Opus audio frames in an Ogg container.
 *
 * * WEBM_OPUS: Opus audio frames in a WebM container.
 *
 * * MP4_AAC: AAC audio frames in an MP4 container.
 *
 * * M4A_AAC: AAC audio frames in an M4A container.
 *
 * * MOV_AAC: AAC audio frames in an MOV container.
 */
export interface AutoDetectDecodingConfig {
}

/** Explicitly specified decoding parameters. */
export interface ExplicitDecodingConfig {
  /** Required. Encoding of the audio data sent for recognition. */
  encoding: ExplicitDecodingConfig_AudioEncoding;
  /**
   * Sample rate in Hertz of the audio data sent for recognition. Valid
   * values are: 8000-48000. 16000 is optimal. For best results, set the
   * sampling rate of the audio source to 16000 Hz. If that's not possible, use
   * the native sample rate of the audio source (instead of re-sampling).
   * Supported for the following encodings:
   *
   * * LINEAR16: Headerless 16-bit signed little-endian PCM samples.
   *
   * * MULAW: Headerless 8-bit companded mulaw samples.
   *
   * * ALAW: Headerless 8-bit companded alaw samples.
   */
  sampleRateHertz: number;
  /**
   * Number of channels present in the audio data sent for recognition.
   * Supported for the following encodings:
   *
   * * LINEAR16: Headerless 16-bit signed little-endian PCM samples.
   *
   * * MULAW: Headerless 8-bit companded mulaw samples.
   *
   * * ALAW: Headerless 8-bit companded alaw samples.
   *
   * The maximum allowed value is 8.
   */
  audioChannelCount: number;
}

/** Supported audio data encodings. */
export enum ExplicitDecodingConfig_AudioEncoding {
  /** AUDIO_ENCODING_UNSPECIFIED - Default value. This value is unused. */
  AUDIO_ENCODING_UNSPECIFIED = 0,
  /** LINEAR16 - Headerless 16-bit signed little-endian PCM samples. */
  LINEAR16 = 1,
  /** MULAW - Headerless 8-bit companded mulaw samples. */
  MULAW = 2,
  /** ALAW - Headerless 8-bit companded alaw samples. */
  ALAW = 3,
  UNRECOGNIZED = -1,
}

export function explicitDecodingConfig_AudioEncodingFromJSON(object: any): ExplicitDecodingConfig_AudioEncoding {
  switch (object) {
    case 0:
    case "AUDIO_ENCODING_UNSPECIFIED":
      return ExplicitDecodingConfig_AudioEncoding.AUDIO_ENCODING_UNSPECIFIED;
    case 1:
    case "LINEAR16":
      return ExplicitDecodingConfig_AudioEncoding.LINEAR16;
    case 2:
    case "MULAW":
      return ExplicitDecodingConfig_AudioEncoding.MULAW;
    case 3:
    case "ALAW":
      return ExplicitDecodingConfig_AudioEncoding.ALAW;
    case -1:
    case "UNRECOGNIZED":
    default:
      return ExplicitDecodingConfig_AudioEncoding.UNRECOGNIZED;
  }
}

export function explicitDecodingConfig_AudioEncodingToJSON(object: ExplicitDecodingConfig_AudioEncoding): string {
  switch (object) {
    case ExplicitDecodingConfig_AudioEncoding.AUDIO_ENCODING_UNSPECIFIED:
      return "AUDIO_ENCODING_UNSPECIFIED";
    case ExplicitDecodingConfig_AudioEncoding.LINEAR16:
      return "LINEAR16";
    case ExplicitDecodingConfig_AudioEncoding.MULAW:
      return "MULAW";
    case ExplicitDecodingConfig_AudioEncoding.ALAW:
      return "ALAW";
    case ExplicitDecodingConfig_AudioEncoding.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/** Configuration to enable speaker diarization. */
export interface SpeakerDiarizationConfig {
  /**
   * Required. Minimum number of speakers in the conversation. This range gives
   * you more flexibility by allowing the system to automatically determine the
   * correct number of speakers.
   *
   * To fix the number of speakers detected in the audio, set
   * `min_speaker_count` = `max_speaker_count`.
   */
  minSpeakerCount: number;
  /**
   * Required. Maximum number of speakers in the conversation. Valid values are:
   * 1-6. Must be >= `min_speaker_count`. This range gives you more flexibility
   * by allowing the system to automatically determine the correct number of
   * speakers.
   */
  maxSpeakerCount: number;
}

/** Available recognition features. */
export interface RecognitionFeatures {
  /**
   * If set to `true`, the server will attempt to filter out profanities,
   * replacing all but the initial character in each filtered word with
   * asterisks, for instance, "f***". If set to `false` or omitted, profanities
   * won't be filtered out.
   */
  profanityFilter: boolean;
  /**
   * If `true`, the top result includes a list of words and the start and end
   * time offsets (timestamps) for those words. If `false`, no word-level time
   * offset information is returned. The default is `false`.
   */
  enableWordTimeOffsets: boolean;
  /**
   * If `true`, the top result includes a list of words and the confidence for
   * those words. If `false`, no word-level confidence information is returned.
   * The default is `false`.
   */
  enableWordConfidence: boolean;
  /**
   * If `true`, adds punctuation to recognition result hypotheses. This feature
   * is only available in select languages. The default `false` value does not
   * add punctuation to result hypotheses.
   */
  enableAutomaticPunctuation: boolean;
  /**
   * The spoken punctuation behavior for the call. If `true`, replaces spoken
   * punctuation with the corresponding symbols in the request. For example,
   * "how are you question mark" becomes "how are you?". See
   * https://cloud.google.com/speech-to-text/docs/spoken-punctuation for
   * support. If `false`, spoken punctuation is not replaced.
   */
  enableSpokenPunctuation: boolean;
  /**
   * The spoken emoji behavior for the call. If `true`, adds spoken emoji
   * formatting for the request. This will replace spoken emojis with the
   * corresponding Unicode symbols in the final transcript. If `false`, spoken
   * emojis are not replaced.
   */
  enableSpokenEmojis: boolean;
  /** Mode for recognizing multi-channel audio. */
  multiChannelMode: RecognitionFeatures_MultiChannelMode;
  /**
   * Configuration to enable speaker diarization and set additional
   * parameters to make diarization better suited for your application.
   * When this is enabled, we send all the words from the beginning of the
   * audio for the top alternative in every consecutive STREAMING responses.
   * This is done in order to improve our speaker tags as our models learn to
   * identify the speakers in the conversation over time.
   * For non-streaming requests, the diarization results will be provided only
   * in the top alternative of the FINAL SpeechRecognitionResult.
   */
  diarizationConfig:
    | SpeakerDiarizationConfig
    | undefined;
  /**
   * Maximum number of recognition hypotheses to be returned.
   * The server may return fewer than `max_alternatives`.
   * Valid values are `0`-`30`. A value of `0` or `1` will return a maximum of
   * one. If omitted, will return a maximum of one.
   */
  maxAlternatives: number;
}

/** Options for how to recognize multi-channel audio. */
export enum RecognitionFeatures_MultiChannelMode {
  /**
   * MULTI_CHANNEL_MODE_UNSPECIFIED - Default value for the multi-channel mode. If the audio contains
   * multiple channels, only the first channel will be transcribed; other
   * channels will be ignored.
   */
  MULTI_CHANNEL_MODE_UNSPECIFIED = 0,
  /**
   * SEPARATE_RECOGNITION_PER_CHANNEL - If selected, each channel in the provided audio is transcribed
   * independently. This cannot be selected if the selected
   * [model][google.cloud.speech.v2.Recognizer.model] is `latest_short`.
   */
  SEPARATE_RECOGNITION_PER_CHANNEL = 1,
  UNRECOGNIZED = -1,
}

export function recognitionFeatures_MultiChannelModeFromJSON(object: any): RecognitionFeatures_MultiChannelMode {
  switch (object) {
    case 0:
    case "MULTI_CHANNEL_MODE_UNSPECIFIED":
      return RecognitionFeatures_MultiChannelMode.MULTI_CHANNEL_MODE_UNSPECIFIED;
    case 1:
    case "SEPARATE_RECOGNITION_PER_CHANNEL":
      return RecognitionFeatures_MultiChannelMode.SEPARATE_RECOGNITION_PER_CHANNEL;
    case -1:
    case "UNRECOGNIZED":
    default:
      return RecognitionFeatures_MultiChannelMode.UNRECOGNIZED;
  }
}

export function recognitionFeatures_MultiChannelModeToJSON(object: RecognitionFeatures_MultiChannelMode): string {
  switch (object) {
    case RecognitionFeatures_MultiChannelMode.MULTI_CHANNEL_MODE_UNSPECIFIED:
      return "MULTI_CHANNEL_MODE_UNSPECIFIED";
    case RecognitionFeatures_MultiChannelMode.SEPARATE_RECOGNITION_PER_CHANNEL:
      return "SEPARATE_RECOGNITION_PER_CHANNEL";
    case RecognitionFeatures_MultiChannelMode.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/**
 * Transcription normalization configuration. Use transcription normalization
 * to automatically replace parts of the transcript with phrases of your
 * choosing. For StreamingRecognize, this normalization only applies to stable
 * partial transcripts (stability > 0.8) and final transcripts.
 */
export interface TranscriptNormalization {
  /**
   * A list of replacement entries. We will perform replacement with one entry
   * at a time. For example, the second entry in ["cat" => "dog", "mountain cat"
   * => "mountain dog"] will never be applied because we will always process the
   * first entry before it. At most 100 entries.
   */
  entries: TranscriptNormalization_Entry[];
}

/** A single replacement configuration. */
export interface TranscriptNormalization_Entry {
  /** What to replace. Max length is 100 characters. */
  search: string;
  /** What to replace with. Max length is 100 characters. */
  replace: string;
  /** Whether the search is case sensitive. */
  caseSensitive: boolean;
}

/**
 * Translation configuration. Use to translate the given audio into text for the
 * desired language.
 */
export interface TranslationConfig {
  /** Required. The language code to translate to. */
  targetLanguage: string;
}

/**
 * Provides "hints" to the speech recognizer to favor specific words and phrases
 * in the results. PhraseSets can be specified as an inline resource, or a
 * reference to an existing PhraseSet resource.
 */
export interface SpeechAdaptation {
  /** A list of inline or referenced PhraseSets. */
  phraseSets: SpeechAdaptation_AdaptationPhraseSet[];
  /**
   * A list of inline CustomClasses. Existing CustomClass resources can be
   * referenced directly in a PhraseSet.
   */
  customClasses: CustomClass[];
}

/**
 * A biasing PhraseSet, which can be either a string referencing the name of
 * an existing PhraseSets resource, or an inline definition of a PhraseSet.
 */
export interface SpeechAdaptation_AdaptationPhraseSet {
  /**
   * The name of an existing PhraseSet resource. The user must have read
   * access to the resource and it must not be deleted.
   */
  phraseSet?:
    | string
    | undefined;
  /** An inline defined PhraseSet. */
  inlinePhraseSet?: PhraseSet | undefined;
}

/**
 * Provides information to the Recognizer that specifies how to process the
 * recognition request.
 */
export interface RecognitionConfig {
  /**
   * Automatically detect decoding parameters.
   * Preferred for supported formats.
   */
  autoDecodingConfig?:
    | AutoDetectDecodingConfig
    | undefined;
  /**
   * Explicitly specified decoding parameters.
   * Required if using headerless PCM audio (linear16, mulaw, alaw).
   */
  explicitDecodingConfig?:
    | ExplicitDecodingConfig
    | undefined;
  /**
   * Optional. Which model to use for recognition requests. Select the model
   * best suited to your domain to get best results.
   *
   * Guidance for choosing which model to use can be found in the [Transcription
   * Models
   * Documentation](https://cloud.google.com/speech-to-text/v2/docs/transcription-model)
   * and the models supported in each region can be found in the [Table Of
   * Supported
   * Models](https://cloud.google.com/speech-to-text/v2/docs/speech-to-text-supported-languages).
   */
  model: string;
  /**
   * Optional. The language of the supplied audio as a
   * [BCP-47](https://www.rfc-editor.org/rfc/bcp/bcp47.txt) language tag.
   * Language tags are normalized to BCP-47 before they are used eg "en-us"
   * becomes "en-US".
   *
   * Supported languages for each model are listed in the [Table of Supported
   * Models](https://cloud.google.com/speech-to-text/v2/docs/speech-to-text-supported-languages).
   *
   * If additional languages are provided, recognition result will contain
   * recognition in the most likely language detected. The recognition result
   * will include the language tag of the language detected in the audio.
   */
  languageCodes: string[];
  /** Speech recognition features to enable. */
  features:
    | RecognitionFeatures
    | undefined;
  /**
   * Speech adaptation context that weights recognizer predictions for specific
   * words and phrases.
   */
  adaptation:
    | SpeechAdaptation
    | undefined;
  /**
   * Optional. Use transcription normalization to automatically replace parts of
   * the transcript with phrases of your choosing. For StreamingRecognize, this
   * normalization only applies to stable partial transcripts (stability > 0.8)
   * and final transcripts.
   */
  transcriptNormalization:
    | TranscriptNormalization
    | undefined;
  /**
   * Optional. Optional configuration used to automatically run translation on
   * the given audio to the desired language for supported models.
   */
  translationConfig: TranslationConfig | undefined;
}

/**
 * Request message for the
 * [Recognize][google.cloud.speech.v2.Speech.Recognize] method. Either
 * `content` or `uri` must be supplied. Supplying both or neither returns
 * [INVALID_ARGUMENT][google.rpc.Code.INVALID_ARGUMENT]. See [content
 * limits](https://cloud.google.com/speech-to-text/quotas#content).
 */
export interface RecognizeRequest {
  /**
   * Required. The name of the Recognizer to use during recognition. The
   * expected format is
   * `projects/{project}/locations/{location}/recognizers/{recognizer}`. The
   * {recognizer} segment may be set to `_` to use an empty implicit Recognizer.
   */
  recognizer: string;
  /**
   * Features and audio metadata to use for the Automatic Speech Recognition.
   * This field in combination with the
   * [config_mask][google.cloud.speech.v2.RecognizeRequest.config_mask] field
   * can be used to override parts of the
   * [default_recognition_config][google.cloud.speech.v2.Recognizer.default_recognition_config]
   * of the Recognizer resource.
   */
  config:
    | RecognitionConfig
    | undefined;
  /**
   * The list of fields in
   * [config][google.cloud.speech.v2.RecognizeRequest.config] that override the
   * values in the
   * [default_recognition_config][google.cloud.speech.v2.Recognizer.default_recognition_config]
   * of the recognizer during this recognition request. If no mask is provided,
   * all non-default valued fields in
   * [config][google.cloud.speech.v2.RecognizeRequest.config] override the
   * values in the recognizer for this recognition request. If a mask is
   * provided, only the fields listed in the mask override the config in the
   * recognizer for this recognition request. If a wildcard (`*`) is provided,
   * [config][google.cloud.speech.v2.RecognizeRequest.config] completely
   * overrides and replaces the config in the recognizer for this recognition
   * request.
   */
  configMask:
    | string[]
    | undefined;
  /**
   * The audio data bytes encoded as specified in
   * [RecognitionConfig][google.cloud.speech.v2.RecognitionConfig]. As
   * with all bytes fields, proto buffers use a pure binary representation,
   * whereas JSON representations use base64.
   */
  content?:
    | Buffer
    | undefined;
  /**
   * URI that points to a file that contains audio data bytes as specified in
   * [RecognitionConfig][google.cloud.speech.v2.RecognitionConfig]. The file
   * must not be compressed (for example, gzip). Currently, only Google Cloud
   * Storage URIs are supported, which must be specified in the following
   * format: `gs://bucket_name/object_name` (other URI formats return
   * [INVALID_ARGUMENT][google.rpc.Code.INVALID_ARGUMENT]). For more
   * information, see [Request
   * URIs](https://cloud.google.com/storage/docs/reference-uris).
   */
  uri?: string | undefined;
}

/** Metadata about the recognition request and response. */
export interface RecognitionResponseMetadata {
  /** Global request identifier auto-generated by the API. */
  requestId: string;
  /** When available, billed audio seconds for the corresponding request. */
  totalBilledDuration: Duration | undefined;
}

/** Alternative hypotheses (a.k.a. n-best list). */
export interface SpeechRecognitionAlternative {
  /** Transcript text representing the words that the user spoke. */
  transcript: string;
  /**
   * The confidence estimate between 0.0 and 1.0. A higher number
   * indicates an estimated greater likelihood that the recognized words are
   * correct. This field is set only for the top alternative of a non-streaming
   * result or, of a streaming result where
   * [is_final][google.cloud.speech.v2.StreamingRecognitionResult.is_final] is
   * set to `true`. This field is not guaranteed to be accurate and users should
   * not rely on it to be always provided. The default of 0.0 is a sentinel
   * value indicating `confidence` was not set.
   */
  confidence: number;
  /**
   * A list of word-specific information for each recognized word.
   * When the
   * [SpeakerDiarizationConfig][google.cloud.speech.v2.SpeakerDiarizationConfig]
   * is set, you will see all the words from the beginning of the audio.
   */
  words: WordInfo[];
}

/** Word-specific information for recognized words. */
export interface WordInfo {
  /**
   * Time offset relative to the beginning of the audio,
   * and corresponding to the start of the spoken word.
   * This field is only set if
   * [enable_word_time_offsets][google.cloud.speech.v2.RecognitionFeatures.enable_word_time_offsets]
   * is `true` and only in the top hypothesis. This is an experimental feature
   * and the accuracy of the time offset can vary.
   */
  startOffset:
    | Duration
    | undefined;
  /**
   * Time offset relative to the beginning of the audio,
   * and corresponding to the end of the spoken word.
   * This field is only set if
   * [enable_word_time_offsets][google.cloud.speech.v2.RecognitionFeatures.enable_word_time_offsets]
   * is `true` and only in the top hypothesis. This is an experimental feature
   * and the accuracy of the time offset can vary.
   */
  endOffset:
    | Duration
    | undefined;
  /** The word corresponding to this set of information. */
  word: string;
  /**
   * The confidence estimate between 0.0 and 1.0. A higher number
   * indicates an estimated greater likelihood that the recognized words are
   * correct. This field is set only for the top alternative of a non-streaming
   * result or, of a streaming result where
   * [is_final][google.cloud.speech.v2.StreamingRecognitionResult.is_final] is
   * set to `true`. This field is not guaranteed to be accurate and users should
   * not rely on it to be always provided. The default of 0.0 is a sentinel
   * value indicating `confidence` was not set.
   */
  confidence: number;
  /**
   * A distinct label is assigned for every speaker within the audio. This field
   * specifies which one of those speakers was detected to have spoken this
   * word. `speaker_label` is set if
   * [SpeakerDiarizationConfig][google.cloud.speech.v2.SpeakerDiarizationConfig]
   * is given and only in the top alternative.
   */
  speakerLabel: string;
}

/** A speech recognition result corresponding to a portion of the audio. */
export interface SpeechRecognitionResult {
  /**
   * May contain one or more recognition hypotheses. These alternatives are
   * ordered in terms of accuracy, with the top (first) alternative being the
   * most probable, as ranked by the recognizer.
   */
  alternatives: SpeechRecognitionAlternative[];
  /**
   * For multi-channel audio, this is the channel number corresponding to the
   * recognized result for the audio from that channel.
   * For `audio_channel_count` = `N`, its output values can range from `1` to
   * `N`.
   */
  channelTag: number;
  /**
   * Time offset of the end of this result relative to the beginning of the
   * audio.
   */
  resultEndOffset:
    | Duration
    | undefined;
  /**
   * Output only. The [BCP-47](https://www.rfc-editor.org/rfc/bcp/bcp47.txt)
   * language tag of the language in this result. This language code was
   * detected to have the most likelihood of being spoken in the audio.
   */
  languageCode: string;
}

/**
 * Response message for the
 * [Recognize][google.cloud.speech.v2.Speech.Recognize] method.
 */
export interface RecognizeResponse {
  /**
   * Sequential list of transcription results corresponding to sequential
   * portions of audio.
   */
  results: SpeechRecognitionResult[];
  /** Metadata about the recognition. */
  metadata: RecognitionResponseMetadata | undefined;
}

/** Available recognition features specific to streaming recognition requests. */
export interface StreamingRecognitionFeatures {
  /**
   * If `true`, responses with voice activity speech events will be returned as
   * they are detected.
   */
  enableVoiceActivityEvents: boolean;
  /**
   * Whether or not to stream interim results to the client. If set to true,
   * interim results will be streamed to the client. Otherwise, only the final
   * response will be streamed back.
   */
  interimResults: boolean;
  /**
   * If set, the server will automatically close the stream after the specified
   * duration has elapsed after the last VOICE_ACTIVITY speech event has been
   * sent. The field `voice_activity_events` must also be set to true.
   */
  voiceActivityTimeout: StreamingRecognitionFeatures_VoiceActivityTimeout | undefined;
}

/** Events that a timeout can be set on for voice activity. */
export interface StreamingRecognitionFeatures_VoiceActivityTimeout {
  /**
   * Duration to timeout the stream if no speech begins. If this is set and
   * no speech is detected in this duration at the start of the stream, the
   * server will close the stream.
   */
  speechStartTimeout:
    | Duration
    | undefined;
  /**
   * Duration to timeout the stream after speech ends. If this is set and no
   * speech is detected in this duration after speech was detected, the server
   * will close the stream.
   */
  speechEndTimeout: Duration | undefined;
}

/** Provides configuration information for the StreamingRecognize request. */
export interface StreamingRecognitionConfig {
  /**
   * Required. Features and audio metadata to use for the Automatic Speech
   * Recognition. This field in combination with the
   * [config_mask][google.cloud.speech.v2.StreamingRecognitionConfig.config_mask]
   * field can be used to override parts of the
   * [default_recognition_config][google.cloud.speech.v2.Recognizer.default_recognition_config]
   * of the Recognizer resource.
   */
  config:
    | RecognitionConfig
    | undefined;
  /**
   * The list of fields in
   * [config][google.cloud.speech.v2.StreamingRecognitionConfig.config] that
   * override the values in the
   * [default_recognition_config][google.cloud.speech.v2.Recognizer.default_recognition_config]
   * of the recognizer during this recognition request. If no mask is provided,
   * all non-default valued fields in
   * [config][google.cloud.speech.v2.StreamingRecognitionConfig.config] override
   * the values in the Recognizer for this recognition request. If a mask is
   * provided, only the fields listed in the mask override the config in the
   * Recognizer for this recognition request. If a wildcard (`*`) is provided,
   * [config][google.cloud.speech.v2.StreamingRecognitionConfig.config]
   * completely overrides and replaces the config in the recognizer for this
   * recognition request.
   */
  configMask:
    | string[]
    | undefined;
  /**
   * Speech recognition features to enable specific to streaming audio
   * recognition requests.
   */
  streamingFeatures: StreamingRecognitionFeatures | undefined;
}

/**
 * Request message for the
 * [StreamingRecognize][google.cloud.speech.v2.Speech.StreamingRecognize]
 * method. Multiple
 * [StreamingRecognizeRequest][google.cloud.speech.v2.StreamingRecognizeRequest]
 * messages are sent in one call.
 *
 * If the [Recognizer][google.cloud.speech.v2.Recognizer] referenced by
 * [recognizer][google.cloud.speech.v2.StreamingRecognizeRequest.recognizer]
 * contains a fully specified request configuration then the stream may only
 * contain messages with only
 * [audio][google.cloud.speech.v2.StreamingRecognizeRequest.audio] set.
 *
 * Otherwise the first message must contain a
 * [recognizer][google.cloud.speech.v2.StreamingRecognizeRequest.recognizer] and
 * a
 * [streaming_config][google.cloud.speech.v2.StreamingRecognizeRequest.streaming_config]
 * message that together fully specify the request configuration and must not
 * contain [audio][google.cloud.speech.v2.StreamingRecognizeRequest.audio]. All
 * subsequent messages must only have
 * [audio][google.cloud.speech.v2.StreamingRecognizeRequest.audio] set.
 */
export interface StreamingRecognizeRequest {
  /**
   * Required. The name of the Recognizer to use during recognition. The
   * expected format is
   * `projects/{project}/locations/{location}/recognizers/{recognizer}`. The
   * {recognizer} segment may be set to `_` to use an empty implicit Recognizer.
   */
  recognizer: string;
  /**
   * StreamingRecognitionConfig to be used in this recognition attempt.
   * If provided, it will override the default RecognitionConfig stored in the
   * Recognizer.
   */
  streamingConfig?:
    | StreamingRecognitionConfig
    | undefined;
  /**
   * Inline audio bytes to be Recognized.
   * Maximum size for this field is 15 KB per request.
   */
  audio?: Buffer | undefined;
}

/**
 * Request message for the
 * [BatchRecognize][google.cloud.speech.v2.Speech.BatchRecognize]
 * method.
 */
export interface BatchRecognizeRequest {
  /**
   * Required. The name of the Recognizer to use during recognition. The
   * expected format is
   * `projects/{project}/locations/{location}/recognizers/{recognizer}`. The
   * {recognizer} segment may be set to `_` to use an empty implicit Recognizer.
   */
  recognizer: string;
  /**
   * Features and audio metadata to use for the Automatic Speech Recognition.
   * This field in combination with the
   * [config_mask][google.cloud.speech.v2.BatchRecognizeRequest.config_mask]
   * field can be used to override parts of the
   * [default_recognition_config][google.cloud.speech.v2.Recognizer.default_recognition_config]
   * of the Recognizer resource.
   */
  config:
    | RecognitionConfig
    | undefined;
  /**
   * The list of fields in
   * [config][google.cloud.speech.v2.BatchRecognizeRequest.config] that override
   * the values in the
   * [default_recognition_config][google.cloud.speech.v2.Recognizer.default_recognition_config]
   * of the recognizer during this recognition request. If no mask is provided,
   * all given fields in
   * [config][google.cloud.speech.v2.BatchRecognizeRequest.config] override the
   * values in the recognizer for this recognition request. If a mask is
   * provided, only the fields listed in the mask override the config in the
   * recognizer for this recognition request. If a wildcard (`*`) is provided,
   * [config][google.cloud.speech.v2.BatchRecognizeRequest.config] completely
   * overrides and replaces the config in the recognizer for this recognition
   * request.
   */
  configMask:
    | string[]
    | undefined;
  /**
   * Audio files with file metadata for ASR.
   * The maximum number of files allowed to be specified is 15.
   */
  files: BatchRecognizeFileMetadata[];
  /** Configuration options for where to output the transcripts of each file. */
  recognitionOutputConfig:
    | RecognitionOutputConfig
    | undefined;
  /** Processing strategy to use for this request. */
  processingStrategy: BatchRecognizeRequest_ProcessingStrategy;
}

/** Possible processing strategies for batch requests. */
export enum BatchRecognizeRequest_ProcessingStrategy {
  /**
   * PROCESSING_STRATEGY_UNSPECIFIED - Default value for the processing strategy. The request is processed as
   * soon as its received.
   */
  PROCESSING_STRATEGY_UNSPECIFIED = 0,
  /**
   * DYNAMIC_BATCHING - If selected, processes the request during lower utilization periods for a
   * price discount. The request is fulfilled within 24 hours.
   */
  DYNAMIC_BATCHING = 1,
  UNRECOGNIZED = -1,
}

export function batchRecognizeRequest_ProcessingStrategyFromJSON(
  object: any,
): BatchRecognizeRequest_ProcessingStrategy {
  switch (object) {
    case 0:
    case "PROCESSING_STRATEGY_UNSPECIFIED":
      return BatchRecognizeRequest_ProcessingStrategy.PROCESSING_STRATEGY_UNSPECIFIED;
    case 1:
    case "DYNAMIC_BATCHING":
      return BatchRecognizeRequest_ProcessingStrategy.DYNAMIC_BATCHING;
    case -1:
    case "UNRECOGNIZED":
    default:
      return BatchRecognizeRequest_ProcessingStrategy.UNRECOGNIZED;
  }
}

export function batchRecognizeRequest_ProcessingStrategyToJSON(
  object: BatchRecognizeRequest_ProcessingStrategy,
): string {
  switch (object) {
    case BatchRecognizeRequest_ProcessingStrategy.PROCESSING_STRATEGY_UNSPECIFIED:
      return "PROCESSING_STRATEGY_UNSPECIFIED";
    case BatchRecognizeRequest_ProcessingStrategy.DYNAMIC_BATCHING:
      return "DYNAMIC_BATCHING";
    case BatchRecognizeRequest_ProcessingStrategy.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/** Output configurations for Cloud Storage. */
export interface GcsOutputConfig {
  /**
   * The Cloud Storage URI prefix with which recognition results will be
   * written.
   */
  uri: string;
}

/** Output configurations for inline response. */
export interface InlineOutputConfig {
}

/** Output configurations for serialized `BatchRecognizeResults` protos. */
export interface NativeOutputFileFormatConfig {
}

/**
 * Output configurations for [WebVTT](https://www.w3.org/TR/webvtt1/) formatted
 * subtitle file.
 */
export interface VttOutputFileFormatConfig {
}

/**
 * Output configurations [SubRip
 * Text](https://www.matroska.org/technical/subtitles.html#srt-subtitles)
 * formatted subtitle file.
 */
export interface SrtOutputFileFormatConfig {
}

/** Configuration for the format of the results stored to `output`. */
export interface OutputFormatConfig {
  /**
   * Configuration for the native output format. If this field is set or if no
   * other output format field is set then transcripts will be written to the
   * sink in the native format.
   */
  native:
    | NativeOutputFileFormatConfig
    | undefined;
  /**
   * Configuration for the vtt output format. If this field is set then
   * transcripts will be written to the sink in the vtt format.
   */
  vtt:
    | VttOutputFileFormatConfig
    | undefined;
  /**
   * Configuration for the srt output format. If this field is set then
   * transcripts will be written to the sink in the srt format.
   */
  srt: SrtOutputFileFormatConfig | undefined;
}

/** Configuration options for the output(s) of recognition. */
export interface RecognitionOutputConfig {
  /**
   * If this message is populated, recognition results are written to the
   * provided Google Cloud Storage URI.
   */
  gcsOutputConfig?:
    | GcsOutputConfig
    | undefined;
  /**
   * If this message is populated, recognition results are provided in the
   * [BatchRecognizeResponse][google.cloud.speech.v2.BatchRecognizeResponse]
   * message of the Operation when completed. This is only supported when
   * calling [BatchRecognize][google.cloud.speech.v2.Speech.BatchRecognize]
   * with just one audio file.
   */
  inlineResponseConfig?:
    | InlineOutputConfig
    | undefined;
  /**
   * Optional. Configuration for the format of the results stored to `output`.
   * If unspecified transcripts will be written in the `NATIVE` format only.
   */
  outputFormatConfig: OutputFormatConfig | undefined;
}

/**
 * Response message for
 * [BatchRecognize][google.cloud.speech.v2.Speech.BatchRecognize] that is
 * packaged into a longrunning [Operation][google.longrunning.Operation].
 */
export interface BatchRecognizeResponse {
  /** Map from filename to the final result for that file. */
  results: { [key: string]: BatchRecognizeFileResult };
  /** When available, billed audio seconds for the corresponding request. */
  totalBilledDuration: Duration | undefined;
}

export interface BatchRecognizeResponse_ResultsEntry {
  key: string;
  value: BatchRecognizeFileResult | undefined;
}

/**
 * Output type for Cloud Storage of BatchRecognize transcripts. Though this
 * proto isn't returned in this API anywhere, the Cloud Storage transcripts will
 * be this proto serialized and should be parsed as such.
 */
export interface BatchRecognizeResults {
  /**
   * Sequential list of transcription results corresponding to sequential
   * portions of audio.
   */
  results: SpeechRecognitionResult[];
  /** Metadata about the recognition. */
  metadata: RecognitionResponseMetadata | undefined;
}

/** Final results written to Cloud Storage. */
export interface CloudStorageResult {
  /** The Cloud Storage URI to which recognition results were written. */
  uri: string;
  /**
   * The Cloud Storage URI to which recognition results were written as VTT
   * formatted captions. This is populated only when `VTT` output is requested.
   */
  vttFormatUri: string;
  /**
   * The Cloud Storage URI to which recognition results were written as SRT
   * formatted captions. This is populated only when `SRT` output is requested.
   */
  srtFormatUri: string;
}

/** Final results returned inline in the recognition response. */
export interface InlineResult {
  /** The transcript for the audio file. */
  transcript:
    | BatchRecognizeResults
    | undefined;
  /**
   * The transcript for the audio file as VTT formatted captions. This is
   * populated only when `VTT` output is requested.
   */
  vttCaptions: string;
  /**
   * The transcript for the audio file as SRT formatted captions. This is
   * populated only when `SRT` output is requested.
   */
  srtCaptions: string;
}

/** Final results for a single file. */
export interface BatchRecognizeFileResult {
  /** Error if one was encountered. */
  error: Status | undefined;
  metadata:
    | RecognitionResponseMetadata
    | undefined;
  /**
   * Recognition results written to Cloud Storage. This is
   * populated only when
   * [GcsOutputConfig][google.cloud.speech.v2.GcsOutputConfig] is set in
   * the
   * [RecognitionOutputConfig][[google.cloud.speech.v2.RecognitionOutputConfig].
   */
  cloudStorageResult?:
    | CloudStorageResult
    | undefined;
  /**
   * Recognition results. This is populated only when
   * [InlineOutputConfig][google.cloud.speech.v2.InlineOutputConfig] is set in
   * the
   * [RecognitionOutputConfig][[google.cloud.speech.v2.RecognitionOutputConfig].
   */
  inlineResult?:
    | InlineResult
    | undefined;
  /**
   * Deprecated. Use `cloud_storage_result.native_format_uri` instead.
   *
   * @deprecated
   */
  uri: string;
  /**
   * Deprecated. Use `inline_result.transcript` instead.
   *
   * @deprecated
   */
  transcript: BatchRecognizeResults | undefined;
}

/**
 * Metadata about transcription for a single file (for example, progress
 * percent).
 */
export interface BatchRecognizeTranscriptionMetadata {
  /** How much of the file has been transcribed so far. */
  progressPercent: number;
  /** Error if one was encountered. */
  error:
    | Status
    | undefined;
  /** The Cloud Storage URI to which recognition results will be written. */
  uri: string;
}

/**
 * Operation metadata for
 * [BatchRecognize][google.cloud.speech.v2.Speech.BatchRecognize].
 */
export interface BatchRecognizeMetadata {
  /** Map from provided filename to the transcription metadata for that file. */
  transcriptionMetadata: { [key: string]: BatchRecognizeTranscriptionMetadata };
}

export interface BatchRecognizeMetadata_TranscriptionMetadataEntry {
  key: string;
  value: BatchRecognizeTranscriptionMetadata | undefined;
}

/** Metadata about a single file in a batch for BatchRecognize. */
export interface BatchRecognizeFileMetadata {
  /** Cloud Storage URI for the audio file. */
  uri?:
    | string
    | undefined;
  /**
   * Features and audio metadata to use for the Automatic Speech Recognition.
   * This field in combination with the
   * [config_mask][google.cloud.speech.v2.BatchRecognizeFileMetadata.config_mask]
   * field can be used to override parts of the
   * [default_recognition_config][google.cloud.speech.v2.Recognizer.default_recognition_config]
   * of the Recognizer resource as well as the
   * [config][google.cloud.speech.v2.BatchRecognizeRequest.config] at the
   * request level.
   */
  config:
    | RecognitionConfig
    | undefined;
  /**
   * The list of fields in
   * [config][google.cloud.speech.v2.BatchRecognizeFileMetadata.config] that
   * override the values in the
   * [default_recognition_config][google.cloud.speech.v2.Recognizer.default_recognition_config]
   * of the recognizer during this recognition request. If no mask is provided,
   * all non-default valued fields in
   * [config][google.cloud.speech.v2.BatchRecognizeFileMetadata.config] override
   * the values in the recognizer for this recognition request. If a mask is
   * provided, only the fields listed in the mask override the config in the
   * recognizer for this recognition request. If a wildcard (`*`) is provided,
   * [config][google.cloud.speech.v2.BatchRecognizeFileMetadata.config]
   * completely overrides and replaces the config in the recognizer for this
   * recognition request.
   */
  configMask: string[] | undefined;
}

/**
 * A streaming speech recognition result corresponding to a portion of the audio
 * that is currently being processed.
 */
export interface StreamingRecognitionResult {
  /**
   * May contain one or more recognition hypotheses. These alternatives are
   * ordered in terms of accuracy, with the top (first) alternative being the
   * most probable, as ranked by the recognizer.
   */
  alternatives: SpeechRecognitionAlternative[];
  /**
   * If `false`, this
   * [StreamingRecognitionResult][google.cloud.speech.v2.StreamingRecognitionResult]
   * represents an interim result that may change. If `true`, this is the final
   * time the speech service will return this particular
   * [StreamingRecognitionResult][google.cloud.speech.v2.StreamingRecognitionResult],
   * the recognizer will not return any further hypotheses for this portion of
   * the transcript and corresponding audio.
   */
  isFinal: boolean;
  /**
   * An estimate of the likelihood that the recognizer will not change its guess
   * about this interim result. Values range from 0.0 (completely unstable)
   * to 1.0 (completely stable). This field is only provided for interim results
   * ([is_final][google.cloud.speech.v2.StreamingRecognitionResult.is_final]=`false`).
   * The default of 0.0 is a sentinel value indicating `stability` was not set.
   */
  stability: number;
  /**
   * Time offset of the end of this result relative to the beginning of the
   * audio.
   */
  resultEndOffset:
    | Duration
    | undefined;
  /**
   * For multi-channel audio, this is the channel number corresponding to the
   * recognized result for the audio from that channel.
   * For
   * `audio_channel_count` = `N`, its output values can range from `1` to `N`.
   */
  channelTag: number;
  /**
   * Output only. The [BCP-47](https://www.rfc-editor.org/rfc/bcp/bcp47.txt)
   * language tag of the language in this result. This language code was
   * detected to have the most likelihood of being spoken in the audio.
   */
  languageCode: string;
}

/**
 * `StreamingRecognizeResponse` is the only message returned to the client by
 * `StreamingRecognize`. A series of zero or more `StreamingRecognizeResponse`
 * messages are streamed back to the client. If there is no recognizable
 * audio then no messages are streamed back to the client.
 *
 * Here are some examples of `StreamingRecognizeResponse`s that might
 * be returned while processing audio:
 *
 * 1. results { alternatives { transcript: "tube" } stability: 0.01 }
 *
 * 2. results { alternatives { transcript: "to be a" } stability: 0.01 }
 *
 * 3. results { alternatives { transcript: "to be" } stability: 0.9 }
 *    results { alternatives { transcript: " or not to be" } stability: 0.01 }
 *
 * 4. results { alternatives { transcript: "to be or not to be"
 *                             confidence: 0.92 }
 *              alternatives { transcript: "to bee or not to bee" }
 *              is_final: true }
 *
 * 5. results { alternatives { transcript: " that's" } stability: 0.01 }
 *
 * 6. results { alternatives { transcript: " that is" } stability: 0.9 }
 *    results { alternatives { transcript: " the question" } stability: 0.01 }
 *
 * 7. results { alternatives { transcript: " that is the question"
 *                             confidence: 0.98 }
 *              alternatives { transcript: " that was the question" }
 *              is_final: true }
 *
 * Notes:
 *
 * - Only two of the above responses #4 and #7 contain final results; they are
 *   indicated by `is_final: true`. Concatenating these together generates the
 *   full transcript: "to be or not to be that is the question".
 *
 * - The others contain interim `results`. #3 and #6 contain two interim
 *   `results`: the first portion has a high stability and is less likely to
 *   change; the second portion has a low stability and is very likely to
 *   change. A UI designer might choose to show only high stability `results`.
 *
 * - The specific `stability` and `confidence` values shown above are only for
 *   illustrative purposes. Actual values may vary.
 *
 * - In each response, only one of these fields will be set:
 *     `error`,
 *     `speech_event_type`, or
 *     one or more (repeated) `results`.
 */
export interface StreamingRecognizeResponse {
  /**
   * This repeated list contains zero or more results that
   * correspond to consecutive portions of the audio currently being processed.
   * It contains zero or one
   * [is_final][google.cloud.speech.v2.StreamingRecognitionResult.is_final]=`true`
   * result (the newly settled portion), followed by zero or more
   * [is_final][google.cloud.speech.v2.StreamingRecognitionResult.is_final]=`false`
   * results (the interim results).
   */
  results: StreamingRecognitionResult[];
  /** Indicates the type of speech event. */
  speechEventType: StreamingRecognizeResponse_SpeechEventType;
  /** Time offset between the beginning of the audio and event emission. */
  speechEventOffset:
    | Duration
    | undefined;
  /** Metadata about the recognition. */
  metadata: RecognitionResponseMetadata | undefined;
}

/** Indicates the type of speech event. */
export enum StreamingRecognizeResponse_SpeechEventType {
  /** SPEECH_EVENT_TYPE_UNSPECIFIED - No speech event specified. */
  SPEECH_EVENT_TYPE_UNSPECIFIED = 0,
  /**
   * END_OF_SINGLE_UTTERANCE - This event indicates that the server has detected the end of the user's
   * speech utterance and expects no additional speech. Therefore, the server
   * will not process additional audio and will close the gRPC bidirectional
   * stream. This event is only sent if there was a force cutoff due to
   * silence being detected early. This event is only available through the
   * `latest_short` [model][google.cloud.speech.v2.Recognizer.model].
   */
  END_OF_SINGLE_UTTERANCE = 1,
  /**
   * SPEECH_ACTIVITY_BEGIN - This event indicates that the server has detected the beginning of human
   * voice activity in the stream. This event can be returned multiple times
   * if speech starts and stops repeatedly throughout the stream. This event
   * is only sent if `voice_activity_events` is set to true.
   */
  SPEECH_ACTIVITY_BEGIN = 2,
  /**
   * SPEECH_ACTIVITY_END - This event indicates that the server has detected the end of human voice
   * activity in the stream. This event can be returned multiple times if
   * speech starts and stops repeatedly throughout the stream. This event is
   * only sent if `voice_activity_events` is set to true.
   */
  SPEECH_ACTIVITY_END = 3,
  UNRECOGNIZED = -1,
}

export function streamingRecognizeResponse_SpeechEventTypeFromJSON(
  object: any,
): StreamingRecognizeResponse_SpeechEventType {
  switch (object) {
    case 0:
    case "SPEECH_EVENT_TYPE_UNSPECIFIED":
      return StreamingRecognizeResponse_SpeechEventType.SPEECH_EVENT_TYPE_UNSPECIFIED;
    case 1:
    case "END_OF_SINGLE_UTTERANCE":
      return StreamingRecognizeResponse_SpeechEventType.END_OF_SINGLE_UTTERANCE;
    case 2:
    case "SPEECH_ACTIVITY_BEGIN":
      return StreamingRecognizeResponse_SpeechEventType.SPEECH_ACTIVITY_BEGIN;
    case 3:
    case "SPEECH_ACTIVITY_END":
      return StreamingRecognizeResponse_SpeechEventType.SPEECH_ACTIVITY_END;
    case -1:
    case "UNRECOGNIZED":
    default:
      return StreamingRecognizeResponse_SpeechEventType.UNRECOGNIZED;
  }
}

export function streamingRecognizeResponse_SpeechEventTypeToJSON(
  object: StreamingRecognizeResponse_SpeechEventType,
): string {
  switch (object) {
    case StreamingRecognizeResponse_SpeechEventType.SPEECH_EVENT_TYPE_UNSPECIFIED:
      return "SPEECH_EVENT_TYPE_UNSPECIFIED";
    case StreamingRecognizeResponse_SpeechEventType.END_OF_SINGLE_UTTERANCE:
      return "END_OF_SINGLE_UTTERANCE";
    case StreamingRecognizeResponse_SpeechEventType.SPEECH_ACTIVITY_BEGIN:
      return "SPEECH_ACTIVITY_BEGIN";
    case StreamingRecognizeResponse_SpeechEventType.SPEECH_ACTIVITY_END:
      return "SPEECH_ACTIVITY_END";
    case StreamingRecognizeResponse_SpeechEventType.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/**
 * Message representing the config for the Speech-to-Text API. This includes an
 * optional [KMS key](https://cloud.google.com/kms/docs/resource-hierarchy#keys)
 * with which incoming data will be encrypted.
 */
export interface Config {
  /**
   * Output only. Identifier. The name of the config resource. There is exactly
   * one config resource per project per location. The expected format is
   * `projects/{project}/locations/{location}/config`.
   */
  name: string;
  /**
   * Optional. An optional [KMS key
   * name](https://cloud.google.com/kms/docs/resource-hierarchy#keys) that if
   * present, will be used to encrypt Speech-to-Text resources at-rest. Updating
   * this key will not encrypt existing resources using this key; only new
   * resources will be encrypted using this key. The expected format is
   * `projects/{project}/locations/{location}/keyRings/{key_ring}/cryptoKeys/{crypto_key}`.
   */
  kmsKeyName: string;
  /** Output only. The most recent time this resource was modified. */
  updateTime: Date | undefined;
}

/**
 * Request message for the
 * [GetConfig][google.cloud.speech.v2.Speech.GetConfig] method.
 */
export interface GetConfigRequest {
  /**
   * Required. The name of the config to retrieve. There is exactly one config
   * resource per project per location. The expected format is
   * `projects/{project}/locations/{location}/config`.
   */
  name: string;
}

/**
 * Request message for the
 * [UpdateConfig][google.cloud.speech.v2.Speech.UpdateConfig] method.
 */
export interface UpdateConfigRequest {
  /**
   * Required. The config to update.
   *
   * The config's `name` field is used to identify the config to be updated.
   * The expected format is `projects/{project}/locations/{location}/config`.
   */
  config:
    | Config
    | undefined;
  /** The list of fields to be updated. */
  updateMask: string[] | undefined;
}

/**
 * CustomClass for biasing in speech recognition. Used to define a set of words
 * or phrases that represents a common concept or theme likely to appear in your
 * audio, for example a list of passenger ship names.
 */
export interface CustomClass {
  /**
   * Output only. Identifier. The resource name of the CustomClass.
   * Format:
   * `projects/{project}/locations/{location}/customClasses/{custom_class}`.
   */
  name: string;
  /** Output only. System-assigned unique identifier for the CustomClass. */
  uid: string;
  /**
   * Optional. User-settable, human-readable name for the CustomClass. Must be
   * 63 characters or less.
   */
  displayName: string;
  /** A collection of class items. */
  items: CustomClass_ClassItem[];
  /** Output only. The CustomClass lifecycle state. */
  state: CustomClass_State;
  /** Output only. Creation time. */
  createTime:
    | Date
    | undefined;
  /** Output only. The most recent time this resource was modified. */
  updateTime:
    | Date
    | undefined;
  /** Output only. The time at which this resource was requested for deletion. */
  deleteTime:
    | Date
    | undefined;
  /** Output only. The time at which this resource will be purged. */
  expireTime:
    | Date
    | undefined;
  /**
   * Optional. Allows users to store small amounts of arbitrary data.
   * Both the key and the value must be 63 characters or less each.
   * At most 100 annotations.
   */
  annotations: { [key: string]: string };
  /**
   * Output only. This checksum is computed by the server based on the value of
   * other fields. This may be sent on update, undelete, and delete requests to
   * ensure the client has an up-to-date value before proceeding.
   */
  etag: string;
  /**
   * Output only. Whether or not this CustomClass is in the process of being
   * updated.
   */
  reconciling: boolean;
  /**
   * Output only. The [KMS key
   * name](https://cloud.google.com/kms/docs/resource-hierarchy#keys) with which
   * the CustomClass is encrypted. The expected format is
   * `projects/{project}/locations/{location}/keyRings/{key_ring}/cryptoKeys/{crypto_key}`.
   */
  kmsKeyName: string;
  /**
   * Output only. The [KMS key version
   * name](https://cloud.google.com/kms/docs/resource-hierarchy#key_versions)
   * with which the CustomClass is encrypted. The expected format is
   * `projects/{project}/locations/{location}/keyRings/{key_ring}/cryptoKeys/{crypto_key}/cryptoKeyVersions/{crypto_key_version}`.
   */
  kmsKeyVersionName: string;
}

/** Set of states that define the lifecycle of a CustomClass. */
export enum CustomClass_State {
  /**
   * STATE_UNSPECIFIED - Unspecified state.  This is only used/useful for distinguishing
   * unset values.
   */
  STATE_UNSPECIFIED = 0,
  /** ACTIVE - The normal and active state. */
  ACTIVE = 2,
  /** DELETED - This CustomClass has been deleted. */
  DELETED = 4,
  UNRECOGNIZED = -1,
}

export function customClass_StateFromJSON(object: any): CustomClass_State {
  switch (object) {
    case 0:
    case "STATE_UNSPECIFIED":
      return CustomClass_State.STATE_UNSPECIFIED;
    case 2:
    case "ACTIVE":
      return CustomClass_State.ACTIVE;
    case 4:
    case "DELETED":
      return CustomClass_State.DELETED;
    case -1:
    case "UNRECOGNIZED":
    default:
      return CustomClass_State.UNRECOGNIZED;
  }
}

export function customClass_StateToJSON(object: CustomClass_State): string {
  switch (object) {
    case CustomClass_State.STATE_UNSPECIFIED:
      return "STATE_UNSPECIFIED";
    case CustomClass_State.ACTIVE:
      return "ACTIVE";
    case CustomClass_State.DELETED:
      return "DELETED";
    case CustomClass_State.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/** An item of the class. */
export interface CustomClass_ClassItem {
  /** The class item's value. */
  value: string;
}

export interface CustomClass_AnnotationsEntry {
  key: string;
  value: string;
}

/**
 * PhraseSet for biasing in speech recognition. A PhraseSet is used to provide
 * "hints" to the speech recognizer to favor specific words and phrases in the
 * results.
 */
export interface PhraseSet {
  /**
   * Output only. Identifier. The resource name of the PhraseSet.
   * Format: `projects/{project}/locations/{location}/phraseSets/{phrase_set}`.
   */
  name: string;
  /** Output only. System-assigned unique identifier for the PhraseSet. */
  uid: string;
  /** A list of word and phrases. */
  phrases: PhraseSet_Phrase[];
  /**
   * Hint Boost. Positive value will increase the probability that a specific
   * phrase will be recognized over other similar sounding phrases. The higher
   * the boost, the higher the chance of false positive recognition as well.
   * Valid `boost` values are between 0 (exclusive) and 20. We recommend using a
   * binary search approach to finding the optimal value for your use case as
   * well as adding phrases both with and without boost to your requests.
   */
  boost: number;
  /**
   * User-settable, human-readable name for the PhraseSet. Must be 63
   * characters or less.
   */
  displayName: string;
  /** Output only. The PhraseSet lifecycle state. */
  state: PhraseSet_State;
  /** Output only. Creation time. */
  createTime:
    | Date
    | undefined;
  /** Output only. The most recent time this resource was modified. */
  updateTime:
    | Date
    | undefined;
  /** Output only. The time at which this resource was requested for deletion. */
  deleteTime:
    | Date
    | undefined;
  /** Output only. The time at which this resource will be purged. */
  expireTime:
    | Date
    | undefined;
  /**
   * Allows users to store small amounts of arbitrary data.
   * Both the key and the value must be 63 characters or less each.
   * At most 100 annotations.
   */
  annotations: { [key: string]: string };
  /**
   * Output only. This checksum is computed by the server based on the value of
   * other fields. This may be sent on update, undelete, and delete requests to
   * ensure the client has an up-to-date value before proceeding.
   */
  etag: string;
  /**
   * Output only. Whether or not this PhraseSet is in the process of being
   * updated.
   */
  reconciling: boolean;
  /**
   * Output only. The [KMS key
   * name](https://cloud.google.com/kms/docs/resource-hierarchy#keys) with which
   * the PhraseSet is encrypted. The expected format is
   * `projects/{project}/locations/{location}/keyRings/{key_ring}/cryptoKeys/{crypto_key}`.
   */
  kmsKeyName: string;
  /**
   * Output only. The [KMS key version
   * name](https://cloud.google.com/kms/docs/resource-hierarchy#key_versions)
   * with which the PhraseSet is encrypted. The expected format is
   * `projects/{project}/locations/{location}/keyRings/{key_ring}/cryptoKeys/{crypto_key}/cryptoKeyVersions/{crypto_key_version}`.
   */
  kmsKeyVersionName: string;
}

/** Set of states that define the lifecycle of a PhraseSet. */
export enum PhraseSet_State {
  /**
   * STATE_UNSPECIFIED - Unspecified state.  This is only used/useful for distinguishing
   * unset values.
   */
  STATE_UNSPECIFIED = 0,
  /** ACTIVE - The normal and active state. */
  ACTIVE = 2,
  /** DELETED - This PhraseSet has been deleted. */
  DELETED = 4,
  UNRECOGNIZED = -1,
}

export function phraseSet_StateFromJSON(object: any): PhraseSet_State {
  switch (object) {
    case 0:
    case "STATE_UNSPECIFIED":
      return PhraseSet_State.STATE_UNSPECIFIED;
    case 2:
    case "ACTIVE":
      return PhraseSet_State.ACTIVE;
    case 4:
    case "DELETED":
      return PhraseSet_State.DELETED;
    case -1:
    case "UNRECOGNIZED":
    default:
      return PhraseSet_State.UNRECOGNIZED;
  }
}

export function phraseSet_StateToJSON(object: PhraseSet_State): string {
  switch (object) {
    case PhraseSet_State.STATE_UNSPECIFIED:
      return "STATE_UNSPECIFIED";
    case PhraseSet_State.ACTIVE:
      return "ACTIVE";
    case PhraseSet_State.DELETED:
      return "DELETED";
    case PhraseSet_State.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/**
 * A Phrase contains words and phrase "hints" so that the speech recognition
 * is more likely to recognize them. This can be used to improve the accuracy
 * for specific words and phrases, for example, if specific commands are
 * typically spoken by the user. This can also be used to add additional words
 * to the vocabulary of the recognizer.
 *
 * List items can also include CustomClass references containing groups of
 * words that represent common concepts that occur in natural language.
 */
export interface PhraseSet_Phrase {
  /** The phrase itself. */
  value: string;
  /**
   * Hint Boost. Overrides the boost set at the phrase set level.
   * Positive value will increase the probability that a specific phrase will
   * be recognized over other similar sounding phrases. The higher the boost,
   * the higher the chance of false positive recognition as well. Negative
   * boost values would correspond to anti-biasing. Anti-biasing is not
   * enabled, so negative boost values will return an error. Boost values must
   * be between 0 and 20. Any values outside that range will return an error.
   * We recommend using a binary search approach to finding the optimal value
   * for your use case as well as adding phrases both with and without boost
   * to your requests.
   */
  boost: number;
}

export interface PhraseSet_AnnotationsEntry {
  key: string;
  value: string;
}

/**
 * Request message for the
 * [CreateCustomClass][google.cloud.speech.v2.Speech.CreateCustomClass] method.
 */
export interface CreateCustomClassRequest {
  /** Required. The CustomClass to create. */
  customClass:
    | CustomClass
    | undefined;
  /**
   * If set, validate the request and preview the CustomClass, but do not
   * actually create it.
   */
  validateOnly: boolean;
  /**
   * The ID to use for the CustomClass, which will become the final component of
   * the CustomClass's resource name.
   *
   * This value should be 4-63 characters, and valid characters
   * are /[a-z][0-9]-/.
   */
  customClassId: string;
  /**
   * Required. The project and location where this CustomClass will be created.
   * The expected format is `projects/{project}/locations/{location}`.
   */
  parent: string;
}

/**
 * Request message for the
 * [ListCustomClasses][google.cloud.speech.v2.Speech.ListCustomClasses] method.
 */
export interface ListCustomClassesRequest {
  /**
   * Required. The project and location of CustomClass resources to list. The
   * expected format is `projects/{project}/locations/{location}`.
   */
  parent: string;
  /**
   * Number of results per requests. A valid page_size ranges from 0 to 100
   * inclusive. If the page_size is zero or unspecified, a page size of 5 will
   * be chosen. If the page size exceeds 100, it will be coerced down to 100.
   * Note that a call might return fewer results than the requested page size.
   */
  pageSize: number;
  /**
   * A page token, received from a previous
   * [ListCustomClasses][google.cloud.speech.v2.Speech.ListCustomClasses] call.
   * Provide this to retrieve the subsequent page.
   *
   * When paginating, all other parameters provided to
   * [ListCustomClasses][google.cloud.speech.v2.Speech.ListCustomClasses] must
   * match the call that provided the page token.
   */
  pageToken: string;
  /** Whether, or not, to show resources that have been deleted. */
  showDeleted: boolean;
}

/**
 * Response message for the
 * [ListCustomClasses][google.cloud.speech.v2.Speech.ListCustomClasses] method.
 */
export interface ListCustomClassesResponse {
  /** The list of requested CustomClasses. */
  customClasses: CustomClass[];
  /**
   * A token, which can be sent as
   * [page_token][google.cloud.speech.v2.ListCustomClassesRequest.page_token] to
   * retrieve the next page. If this field is omitted, there are no subsequent
   * pages. This token expires after 72 hours.
   */
  nextPageToken: string;
}

/**
 * Request message for the
 * [GetCustomClass][google.cloud.speech.v2.Speech.GetCustomClass] method.
 */
export interface GetCustomClassRequest {
  /**
   * Required. The name of the CustomClass to retrieve. The expected format is
   * `projects/{project}/locations/{location}/customClasses/{custom_class}`.
   */
  name: string;
}

/**
 * Request message for the
 * [UpdateCustomClass][google.cloud.speech.v2.Speech.UpdateCustomClass] method.
 */
export interface UpdateCustomClassRequest {
  /**
   * Required. The CustomClass to update.
   *
   * The CustomClass's `name` field is used to identify the CustomClass to
   * update. Format:
   * `projects/{project}/locations/{location}/customClasses/{custom_class}`.
   */
  customClass:
    | CustomClass
    | undefined;
  /**
   * The list of fields to be updated. If empty, all fields are considered for
   * update.
   */
  updateMask:
    | string[]
    | undefined;
  /**
   * If set, validate the request and preview the updated CustomClass, but do
   * not actually update it.
   */
  validateOnly: boolean;
}

/**
 * Request message for the
 * [DeleteCustomClass][google.cloud.speech.v2.Speech.DeleteCustomClass] method.
 */
export interface DeleteCustomClassRequest {
  /**
   * Required. The name of the CustomClass to delete.
   * Format:
   * `projects/{project}/locations/{location}/customClasses/{custom_class}`
   */
  name: string;
  /**
   * If set, validate the request and preview the deleted CustomClass, but do
   * not actually delete it.
   */
  validateOnly: boolean;
  /**
   * If set to true, and the CustomClass is not found, the request will succeed
   * and  be a no-op (no Operation is recorded in this case).
   */
  allowMissing: boolean;
  /**
   * This checksum is computed by the server based on the value of other
   * fields. This may be sent on update, undelete, and delete requests to ensure
   * the client has an up-to-date value before proceeding.
   */
  etag: string;
}

/**
 * Request message for the
 * [UndeleteCustomClass][google.cloud.speech.v2.Speech.UndeleteCustomClass]
 * method.
 */
export interface UndeleteCustomClassRequest {
  /**
   * Required. The name of the CustomClass to undelete.
   * Format:
   * `projects/{project}/locations/{location}/customClasses/{custom_class}`
   */
  name: string;
  /**
   * If set, validate the request and preview the undeleted CustomClass, but do
   * not actually undelete it.
   */
  validateOnly: boolean;
  /**
   * This checksum is computed by the server based on the value of other
   * fields. This may be sent on update, undelete, and delete requests to ensure
   * the client has an up-to-date value before proceeding.
   */
  etag: string;
}

/**
 * Request message for the
 * [CreatePhraseSet][google.cloud.speech.v2.Speech.CreatePhraseSet] method.
 */
export interface CreatePhraseSetRequest {
  /** Required. The PhraseSet to create. */
  phraseSet:
    | PhraseSet
    | undefined;
  /**
   * If set, validate the request and preview the PhraseSet, but do not
   * actually create it.
   */
  validateOnly: boolean;
  /**
   * The ID to use for the PhraseSet, which will become the final component of
   * the PhraseSet's resource name.
   *
   * This value should be 4-63 characters, and valid characters
   * are /[a-z][0-9]-/.
   */
  phraseSetId: string;
  /**
   * Required. The project and location where this PhraseSet will be created.
   * The expected format is `projects/{project}/locations/{location}`.
   */
  parent: string;
}

/**
 * Request message for the
 * [ListPhraseSets][google.cloud.speech.v2.Speech.ListPhraseSets] method.
 */
export interface ListPhraseSetsRequest {
  /**
   * Required. The project and location of PhraseSet resources to list. The
   * expected format is `projects/{project}/locations/{location}`.
   */
  parent: string;
  /**
   * The maximum number of PhraseSets to return. The service may return fewer
   * than this value. If unspecified, at most 5 PhraseSets will be returned.
   * The maximum value is 100; values above 100 will be coerced to 100.
   */
  pageSize: number;
  /**
   * A page token, received from a previous
   * [ListPhraseSets][google.cloud.speech.v2.Speech.ListPhraseSets] call.
   * Provide this to retrieve the subsequent page.
   *
   * When paginating, all other parameters provided to
   * [ListPhraseSets][google.cloud.speech.v2.Speech.ListPhraseSets] must match
   * the call that provided the page token.
   */
  pageToken: string;
  /** Whether, or not, to show resources that have been deleted. */
  showDeleted: boolean;
}

/**
 * Response message for the
 * [ListPhraseSets][google.cloud.speech.v2.Speech.ListPhraseSets] method.
 */
export interface ListPhraseSetsResponse {
  /** The list of requested PhraseSets. */
  phraseSets: PhraseSet[];
  /**
   * A token, which can be sent as
   * [page_token][google.cloud.speech.v2.ListPhraseSetsRequest.page_token] to
   * retrieve the next page. If this field is omitted, there are no subsequent
   * pages. This token expires after 72 hours.
   */
  nextPageToken: string;
}

/**
 * Request message for the
 * [GetPhraseSet][google.cloud.speech.v2.Speech.GetPhraseSet] method.
 */
export interface GetPhraseSetRequest {
  /**
   * Required. The name of the PhraseSet to retrieve. The expected format is
   * `projects/{project}/locations/{location}/phraseSets/{phrase_set}`.
   */
  name: string;
}

/**
 * Request message for the
 * [UpdatePhraseSet][google.cloud.speech.v2.Speech.UpdatePhraseSet] method.
 */
export interface UpdatePhraseSetRequest {
  /**
   * Required. The PhraseSet to update.
   *
   * The PhraseSet's `name` field is used to identify the PhraseSet to update.
   * Format: `projects/{project}/locations/{location}/phraseSets/{phrase_set}`.
   */
  phraseSet:
    | PhraseSet
    | undefined;
  /**
   * The list of fields to update. If empty, all non-default valued fields are
   * considered for update. Use `*` to update the entire PhraseSet resource.
   */
  updateMask:
    | string[]
    | undefined;
  /**
   * If set, validate the request and preview the updated PhraseSet, but do not
   * actually update it.
   */
  validateOnly: boolean;
}

/**
 * Request message for the
 * [DeletePhraseSet][google.cloud.speech.v2.Speech.DeletePhraseSet] method.
 */
export interface DeletePhraseSetRequest {
  /**
   * Required. The name of the PhraseSet to delete.
   * Format: `projects/{project}/locations/{location}/phraseSets/{phrase_set}`
   */
  name: string;
  /**
   * If set, validate the request and preview the deleted PhraseSet, but do not
   * actually delete it.
   */
  validateOnly: boolean;
  /**
   * If set to true, and the PhraseSet is not found, the request will succeed
   * and  be a no-op (no Operation is recorded in this case).
   */
  allowMissing: boolean;
  /**
   * This checksum is computed by the server based on the value of other
   * fields. This may be sent on update, undelete, and delete requests to ensure
   * the client has an up-to-date value before proceeding.
   */
  etag: string;
}

/**
 * Request message for the
 * [UndeletePhraseSet][google.cloud.speech.v2.Speech.UndeletePhraseSet]
 * method.
 */
export interface UndeletePhraseSetRequest {
  /**
   * Required. The name of the PhraseSet to undelete.
   * Format: `projects/{project}/locations/{location}/phraseSets/{phrase_set}`
   */
  name: string;
  /**
   * If set, validate the request and preview the undeleted PhraseSet, but do
   * not actually undelete it.
   */
  validateOnly: boolean;
  /**
   * This checksum is computed by the server based on the value of other
   * fields. This may be sent on update, undelete, and delete requests to ensure
   * the client has an up-to-date value before proceeding.
   */
  etag: string;
}

function createBaseCreateRecognizerRequest(): CreateRecognizerRequest {
  return { recognizer: undefined, validateOnly: false, recognizerId: "", parent: "" };
}

export const CreateRecognizerRequest: MessageFns<CreateRecognizerRequest> = {
  encode(message: CreateRecognizerRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.recognizer !== undefined) {
      Recognizer.encode(message.recognizer, writer.uint32(10).fork()).join();
    }
    if (message.validateOnly !== false) {
      writer.uint32(16).bool(message.validateOnly);
    }
    if (message.recognizerId !== "") {
      writer.uint32(26).string(message.recognizerId);
    }
    if (message.parent !== "") {
      writer.uint32(34).string(message.parent);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): CreateRecognizerRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseCreateRecognizerRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.recognizer = Recognizer.decode(reader, reader.uint32());
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.validateOnly = reader.bool();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.recognizerId = reader.string();
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.parent = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): CreateRecognizerRequest {
    return {
      recognizer: isSet(object.recognizer) ? Recognizer.fromJSON(object.recognizer) : undefined,
      validateOnly: isSet(object.validateOnly) ? globalThis.Boolean(object.validateOnly) : false,
      recognizerId: isSet(object.recognizerId) ? globalThis.String(object.recognizerId) : "",
      parent: isSet(object.parent) ? globalThis.String(object.parent) : "",
    };
  },

  toJSON(message: CreateRecognizerRequest): unknown {
    const obj: any = {};
    if (message.recognizer !== undefined) {
      obj.recognizer = Recognizer.toJSON(message.recognizer);
    }
    if (message.validateOnly !== false) {
      obj.validateOnly = message.validateOnly;
    }
    if (message.recognizerId !== "") {
      obj.recognizerId = message.recognizerId;
    }
    if (message.parent !== "") {
      obj.parent = message.parent;
    }
    return obj;
  },

  create(base?: DeepPartial<CreateRecognizerRequest>): CreateRecognizerRequest {
    return CreateRecognizerRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<CreateRecognizerRequest>): CreateRecognizerRequest {
    const message = createBaseCreateRecognizerRequest();
    message.recognizer = (object.recognizer !== undefined && object.recognizer !== null)
      ? Recognizer.fromPartial(object.recognizer)
      : undefined;
    message.validateOnly = object.validateOnly ?? false;
    message.recognizerId = object.recognizerId ?? "";
    message.parent = object.parent ?? "";
    return message;
  },
};

function createBaseOperationMetadata(): OperationMetadata {
  return {
    createTime: undefined,
    updateTime: undefined,
    resource: "",
    method: "",
    kmsKeyName: "",
    kmsKeyVersionName: "",
    batchRecognizeRequest: undefined,
    createRecognizerRequest: undefined,
    updateRecognizerRequest: undefined,
    deleteRecognizerRequest: undefined,
    undeleteRecognizerRequest: undefined,
    createCustomClassRequest: undefined,
    updateCustomClassRequest: undefined,
    deleteCustomClassRequest: undefined,
    undeleteCustomClassRequest: undefined,
    createPhraseSetRequest: undefined,
    updatePhraseSetRequest: undefined,
    deletePhraseSetRequest: undefined,
    undeletePhraseSetRequest: undefined,
    updateConfigRequest: undefined,
    progressPercent: 0,
    batchRecognizeMetadata: undefined,
  };
}

export const OperationMetadata: MessageFns<OperationMetadata> = {
  encode(message: OperationMetadata, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.createTime !== undefined) {
      Timestamp.encode(toTimestamp(message.createTime), writer.uint32(10).fork()).join();
    }
    if (message.updateTime !== undefined) {
      Timestamp.encode(toTimestamp(message.updateTime), writer.uint32(18).fork()).join();
    }
    if (message.resource !== "") {
      writer.uint32(26).string(message.resource);
    }
    if (message.method !== "") {
      writer.uint32(34).string(message.method);
    }
    if (message.kmsKeyName !== "") {
      writer.uint32(50).string(message.kmsKeyName);
    }
    if (message.kmsKeyVersionName !== "") {
      writer.uint32(58).string(message.kmsKeyVersionName);
    }
    if (message.batchRecognizeRequest !== undefined) {
      BatchRecognizeRequest.encode(message.batchRecognizeRequest, writer.uint32(66).fork()).join();
    }
    if (message.createRecognizerRequest !== undefined) {
      CreateRecognizerRequest.encode(message.createRecognizerRequest, writer.uint32(74).fork()).join();
    }
    if (message.updateRecognizerRequest !== undefined) {
      UpdateRecognizerRequest.encode(message.updateRecognizerRequest, writer.uint32(82).fork()).join();
    }
    if (message.deleteRecognizerRequest !== undefined) {
      DeleteRecognizerRequest.encode(message.deleteRecognizerRequest, writer.uint32(90).fork()).join();
    }
    if (message.undeleteRecognizerRequest !== undefined) {
      UndeleteRecognizerRequest.encode(message.undeleteRecognizerRequest, writer.uint32(98).fork()).join();
    }
    if (message.createCustomClassRequest !== undefined) {
      CreateCustomClassRequest.encode(message.createCustomClassRequest, writer.uint32(106).fork()).join();
    }
    if (message.updateCustomClassRequest !== undefined) {
      UpdateCustomClassRequest.encode(message.updateCustomClassRequest, writer.uint32(114).fork()).join();
    }
    if (message.deleteCustomClassRequest !== undefined) {
      DeleteCustomClassRequest.encode(message.deleteCustomClassRequest, writer.uint32(122).fork()).join();
    }
    if (message.undeleteCustomClassRequest !== undefined) {
      UndeleteCustomClassRequest.encode(message.undeleteCustomClassRequest, writer.uint32(130).fork()).join();
    }
    if (message.createPhraseSetRequest !== undefined) {
      CreatePhraseSetRequest.encode(message.createPhraseSetRequest, writer.uint32(138).fork()).join();
    }
    if (message.updatePhraseSetRequest !== undefined) {
      UpdatePhraseSetRequest.encode(message.updatePhraseSetRequest, writer.uint32(146).fork()).join();
    }
    if (message.deletePhraseSetRequest !== undefined) {
      DeletePhraseSetRequest.encode(message.deletePhraseSetRequest, writer.uint32(154).fork()).join();
    }
    if (message.undeletePhraseSetRequest !== undefined) {
      UndeletePhraseSetRequest.encode(message.undeletePhraseSetRequest, writer.uint32(162).fork()).join();
    }
    if (message.updateConfigRequest !== undefined) {
      UpdateConfigRequest.encode(message.updateConfigRequest, writer.uint32(170).fork()).join();
    }
    if (message.progressPercent !== 0) {
      writer.uint32(176).int32(message.progressPercent);
    }
    if (message.batchRecognizeMetadata !== undefined) {
      BatchRecognizeMetadata.encode(message.batchRecognizeMetadata, writer.uint32(186).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): OperationMetadata {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseOperationMetadata();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.createTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.updateTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.resource = reader.string();
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.method = reader.string();
          continue;
        case 6:
          if (tag !== 50) {
            break;
          }

          message.kmsKeyName = reader.string();
          continue;
        case 7:
          if (tag !== 58) {
            break;
          }

          message.kmsKeyVersionName = reader.string();
          continue;
        case 8:
          if (tag !== 66) {
            break;
          }

          message.batchRecognizeRequest = BatchRecognizeRequest.decode(reader, reader.uint32());
          continue;
        case 9:
          if (tag !== 74) {
            break;
          }

          message.createRecognizerRequest = CreateRecognizerRequest.decode(reader, reader.uint32());
          continue;
        case 10:
          if (tag !== 82) {
            break;
          }

          message.updateRecognizerRequest = UpdateRecognizerRequest.decode(reader, reader.uint32());
          continue;
        case 11:
          if (tag !== 90) {
            break;
          }

          message.deleteRecognizerRequest = DeleteRecognizerRequest.decode(reader, reader.uint32());
          continue;
        case 12:
          if (tag !== 98) {
            break;
          }

          message.undeleteRecognizerRequest = UndeleteRecognizerRequest.decode(reader, reader.uint32());
          continue;
        case 13:
          if (tag !== 106) {
            break;
          }

          message.createCustomClassRequest = CreateCustomClassRequest.decode(reader, reader.uint32());
          continue;
        case 14:
          if (tag !== 114) {
            break;
          }

          message.updateCustomClassRequest = UpdateCustomClassRequest.decode(reader, reader.uint32());
          continue;
        case 15:
          if (tag !== 122) {
            break;
          }

          message.deleteCustomClassRequest = DeleteCustomClassRequest.decode(reader, reader.uint32());
          continue;
        case 16:
          if (tag !== 130) {
            break;
          }

          message.undeleteCustomClassRequest = UndeleteCustomClassRequest.decode(reader, reader.uint32());
          continue;
        case 17:
          if (tag !== 138) {
            break;
          }

          message.createPhraseSetRequest = CreatePhraseSetRequest.decode(reader, reader.uint32());
          continue;
        case 18:
          if (tag !== 146) {
            break;
          }

          message.updatePhraseSetRequest = UpdatePhraseSetRequest.decode(reader, reader.uint32());
          continue;
        case 19:
          if (tag !== 154) {
            break;
          }

          message.deletePhraseSetRequest = DeletePhraseSetRequest.decode(reader, reader.uint32());
          continue;
        case 20:
          if (tag !== 162) {
            break;
          }

          message.undeletePhraseSetRequest = UndeletePhraseSetRequest.decode(reader, reader.uint32());
          continue;
        case 21:
          if (tag !== 170) {
            break;
          }

          message.updateConfigRequest = UpdateConfigRequest.decode(reader, reader.uint32());
          continue;
        case 22:
          if (tag !== 176) {
            break;
          }

          message.progressPercent = reader.int32();
          continue;
        case 23:
          if (tag !== 186) {
            break;
          }

          message.batchRecognizeMetadata = BatchRecognizeMetadata.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): OperationMetadata {
    return {
      createTime: isSet(object.createTime) ? fromJsonTimestamp(object.createTime) : undefined,
      updateTime: isSet(object.updateTime) ? fromJsonTimestamp(object.updateTime) : undefined,
      resource: isSet(object.resource) ? globalThis.String(object.resource) : "",
      method: isSet(object.method) ? globalThis.String(object.method) : "",
      kmsKeyName: isSet(object.kmsKeyName) ? globalThis.String(object.kmsKeyName) : "",
      kmsKeyVersionName: isSet(object.kmsKeyVersionName) ? globalThis.String(object.kmsKeyVersionName) : "",
      batchRecognizeRequest: isSet(object.batchRecognizeRequest)
        ? BatchRecognizeRequest.fromJSON(object.batchRecognizeRequest)
        : undefined,
      createRecognizerRequest: isSet(object.createRecognizerRequest)
        ? CreateRecognizerRequest.fromJSON(object.createRecognizerRequest)
        : undefined,
      updateRecognizerRequest: isSet(object.updateRecognizerRequest)
        ? UpdateRecognizerRequest.fromJSON(object.updateRecognizerRequest)
        : undefined,
      deleteRecognizerRequest: isSet(object.deleteRecognizerRequest)
        ? DeleteRecognizerRequest.fromJSON(object.deleteRecognizerRequest)
        : undefined,
      undeleteRecognizerRequest: isSet(object.undeleteRecognizerRequest)
        ? UndeleteRecognizerRequest.fromJSON(object.undeleteRecognizerRequest)
        : undefined,
      createCustomClassRequest: isSet(object.createCustomClassRequest)
        ? CreateCustomClassRequest.fromJSON(object.createCustomClassRequest)
        : undefined,
      updateCustomClassRequest: isSet(object.updateCustomClassRequest)
        ? UpdateCustomClassRequest.fromJSON(object.updateCustomClassRequest)
        : undefined,
      deleteCustomClassRequest: isSet(object.deleteCustomClassRequest)
        ? DeleteCustomClassRequest.fromJSON(object.deleteCustomClassRequest)
        : undefined,
      undeleteCustomClassRequest: isSet(object.undeleteCustomClassRequest)
        ? UndeleteCustomClassRequest.fromJSON(object.undeleteCustomClassRequest)
        : undefined,
      createPhraseSetRequest: isSet(object.createPhraseSetRequest)
        ? CreatePhraseSetRequest.fromJSON(object.createPhraseSetRequest)
        : undefined,
      updatePhraseSetRequest: isSet(object.updatePhraseSetRequest)
        ? UpdatePhraseSetRequest.fromJSON(object.updatePhraseSetRequest)
        : undefined,
      deletePhraseSetRequest: isSet(object.deletePhraseSetRequest)
        ? DeletePhraseSetRequest.fromJSON(object.deletePhraseSetRequest)
        : undefined,
      undeletePhraseSetRequest: isSet(object.undeletePhraseSetRequest)
        ? UndeletePhraseSetRequest.fromJSON(object.undeletePhraseSetRequest)
        : undefined,
      updateConfigRequest: isSet(object.updateConfigRequest)
        ? UpdateConfigRequest.fromJSON(object.updateConfigRequest)
        : undefined,
      progressPercent: isSet(object.progressPercent) ? globalThis.Number(object.progressPercent) : 0,
      batchRecognizeMetadata: isSet(object.batchRecognizeMetadata)
        ? BatchRecognizeMetadata.fromJSON(object.batchRecognizeMetadata)
        : undefined,
    };
  },

  toJSON(message: OperationMetadata): unknown {
    const obj: any = {};
    if (message.createTime !== undefined) {
      obj.createTime = message.createTime.toISOString();
    }
    if (message.updateTime !== undefined) {
      obj.updateTime = message.updateTime.toISOString();
    }
    if (message.resource !== "") {
      obj.resource = message.resource;
    }
    if (message.method !== "") {
      obj.method = message.method;
    }
    if (message.kmsKeyName !== "") {
      obj.kmsKeyName = message.kmsKeyName;
    }
    if (message.kmsKeyVersionName !== "") {
      obj.kmsKeyVersionName = message.kmsKeyVersionName;
    }
    if (message.batchRecognizeRequest !== undefined) {
      obj.batchRecognizeRequest = BatchRecognizeRequest.toJSON(message.batchRecognizeRequest);
    }
    if (message.createRecognizerRequest !== undefined) {
      obj.createRecognizerRequest = CreateRecognizerRequest.toJSON(message.createRecognizerRequest);
    }
    if (message.updateRecognizerRequest !== undefined) {
      obj.updateRecognizerRequest = UpdateRecognizerRequest.toJSON(message.updateRecognizerRequest);
    }
    if (message.deleteRecognizerRequest !== undefined) {
      obj.deleteRecognizerRequest = DeleteRecognizerRequest.toJSON(message.deleteRecognizerRequest);
    }
    if (message.undeleteRecognizerRequest !== undefined) {
      obj.undeleteRecognizerRequest = UndeleteRecognizerRequest.toJSON(message.undeleteRecognizerRequest);
    }
    if (message.createCustomClassRequest !== undefined) {
      obj.createCustomClassRequest = CreateCustomClassRequest.toJSON(message.createCustomClassRequest);
    }
    if (message.updateCustomClassRequest !== undefined) {
      obj.updateCustomClassRequest = UpdateCustomClassRequest.toJSON(message.updateCustomClassRequest);
    }
    if (message.deleteCustomClassRequest !== undefined) {
      obj.deleteCustomClassRequest = DeleteCustomClassRequest.toJSON(message.deleteCustomClassRequest);
    }
    if (message.undeleteCustomClassRequest !== undefined) {
      obj.undeleteCustomClassRequest = UndeleteCustomClassRequest.toJSON(message.undeleteCustomClassRequest);
    }
    if (message.createPhraseSetRequest !== undefined) {
      obj.createPhraseSetRequest = CreatePhraseSetRequest.toJSON(message.createPhraseSetRequest);
    }
    if (message.updatePhraseSetRequest !== undefined) {
      obj.updatePhraseSetRequest = UpdatePhraseSetRequest.toJSON(message.updatePhraseSetRequest);
    }
    if (message.deletePhraseSetRequest !== undefined) {
      obj.deletePhraseSetRequest = DeletePhraseSetRequest.toJSON(message.deletePhraseSetRequest);
    }
    if (message.undeletePhraseSetRequest !== undefined) {
      obj.undeletePhraseSetRequest = UndeletePhraseSetRequest.toJSON(message.undeletePhraseSetRequest);
    }
    if (message.updateConfigRequest !== undefined) {
      obj.updateConfigRequest = UpdateConfigRequest.toJSON(message.updateConfigRequest);
    }
    if (message.progressPercent !== 0) {
      obj.progressPercent = Math.round(message.progressPercent);
    }
    if (message.batchRecognizeMetadata !== undefined) {
      obj.batchRecognizeMetadata = BatchRecognizeMetadata.toJSON(message.batchRecognizeMetadata);
    }
    return obj;
  },

  create(base?: DeepPartial<OperationMetadata>): OperationMetadata {
    return OperationMetadata.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<OperationMetadata>): OperationMetadata {
    const message = createBaseOperationMetadata();
    message.createTime = object.createTime ?? undefined;
    message.updateTime = object.updateTime ?? undefined;
    message.resource = object.resource ?? "";
    message.method = object.method ?? "";
    message.kmsKeyName = object.kmsKeyName ?? "";
    message.kmsKeyVersionName = object.kmsKeyVersionName ?? "";
    message.batchRecognizeRequest =
      (object.batchRecognizeRequest !== undefined && object.batchRecognizeRequest !== null)
        ? BatchRecognizeRequest.fromPartial(object.batchRecognizeRequest)
        : undefined;
    message.createRecognizerRequest =
      (object.createRecognizerRequest !== undefined && object.createRecognizerRequest !== null)
        ? CreateRecognizerRequest.fromPartial(object.createRecognizerRequest)
        : undefined;
    message.updateRecognizerRequest =
      (object.updateRecognizerRequest !== undefined && object.updateRecognizerRequest !== null)
        ? UpdateRecognizerRequest.fromPartial(object.updateRecognizerRequest)
        : undefined;
    message.deleteRecognizerRequest =
      (object.deleteRecognizerRequest !== undefined && object.deleteRecognizerRequest !== null)
        ? DeleteRecognizerRequest.fromPartial(object.deleteRecognizerRequest)
        : undefined;
    message.undeleteRecognizerRequest =
      (object.undeleteRecognizerRequest !== undefined && object.undeleteRecognizerRequest !== null)
        ? UndeleteRecognizerRequest.fromPartial(object.undeleteRecognizerRequest)
        : undefined;
    message.createCustomClassRequest =
      (object.createCustomClassRequest !== undefined && object.createCustomClassRequest !== null)
        ? CreateCustomClassRequest.fromPartial(object.createCustomClassRequest)
        : undefined;
    message.updateCustomClassRequest =
      (object.updateCustomClassRequest !== undefined && object.updateCustomClassRequest !== null)
        ? UpdateCustomClassRequest.fromPartial(object.updateCustomClassRequest)
        : undefined;
    message.deleteCustomClassRequest =
      (object.deleteCustomClassRequest !== undefined && object.deleteCustomClassRequest !== null)
        ? DeleteCustomClassRequest.fromPartial(object.deleteCustomClassRequest)
        : undefined;
    message.undeleteCustomClassRequest =
      (object.undeleteCustomClassRequest !== undefined && object.undeleteCustomClassRequest !== null)
        ? UndeleteCustomClassRequest.fromPartial(object.undeleteCustomClassRequest)
        : undefined;
    message.createPhraseSetRequest =
      (object.createPhraseSetRequest !== undefined && object.createPhraseSetRequest !== null)
        ? CreatePhraseSetRequest.fromPartial(object.createPhraseSetRequest)
        : undefined;
    message.updatePhraseSetRequest =
      (object.updatePhraseSetRequest !== undefined && object.updatePhraseSetRequest !== null)
        ? UpdatePhraseSetRequest.fromPartial(object.updatePhraseSetRequest)
        : undefined;
    message.deletePhraseSetRequest =
      (object.deletePhraseSetRequest !== undefined && object.deletePhraseSetRequest !== null)
        ? DeletePhraseSetRequest.fromPartial(object.deletePhraseSetRequest)
        : undefined;
    message.undeletePhraseSetRequest =
      (object.undeletePhraseSetRequest !== undefined && object.undeletePhraseSetRequest !== null)
        ? UndeletePhraseSetRequest.fromPartial(object.undeletePhraseSetRequest)
        : undefined;
    message.updateConfigRequest = (object.updateConfigRequest !== undefined && object.updateConfigRequest !== null)
      ? UpdateConfigRequest.fromPartial(object.updateConfigRequest)
      : undefined;
    message.progressPercent = object.progressPercent ?? 0;
    message.batchRecognizeMetadata =
      (object.batchRecognizeMetadata !== undefined && object.batchRecognizeMetadata !== null)
        ? BatchRecognizeMetadata.fromPartial(object.batchRecognizeMetadata)
        : undefined;
    return message;
  },
};

function createBaseListRecognizersRequest(): ListRecognizersRequest {
  return { parent: "", pageSize: 0, pageToken: "", showDeleted: false };
}

export const ListRecognizersRequest: MessageFns<ListRecognizersRequest> = {
  encode(message: ListRecognizersRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.parent !== "") {
      writer.uint32(10).string(message.parent);
    }
    if (message.pageSize !== 0) {
      writer.uint32(16).int32(message.pageSize);
    }
    if (message.pageToken !== "") {
      writer.uint32(26).string(message.pageToken);
    }
    if (message.showDeleted !== false) {
      writer.uint32(32).bool(message.showDeleted);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ListRecognizersRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseListRecognizersRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.parent = reader.string();
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.pageSize = reader.int32();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.pageToken = reader.string();
          continue;
        case 4:
          if (tag !== 32) {
            break;
          }

          message.showDeleted = reader.bool();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ListRecognizersRequest {
    return {
      parent: isSet(object.parent) ? globalThis.String(object.parent) : "",
      pageSize: isSet(object.pageSize) ? globalThis.Number(object.pageSize) : 0,
      pageToken: isSet(object.pageToken) ? globalThis.String(object.pageToken) : "",
      showDeleted: isSet(object.showDeleted) ? globalThis.Boolean(object.showDeleted) : false,
    };
  },

  toJSON(message: ListRecognizersRequest): unknown {
    const obj: any = {};
    if (message.parent !== "") {
      obj.parent = message.parent;
    }
    if (message.pageSize !== 0) {
      obj.pageSize = Math.round(message.pageSize);
    }
    if (message.pageToken !== "") {
      obj.pageToken = message.pageToken;
    }
    if (message.showDeleted !== false) {
      obj.showDeleted = message.showDeleted;
    }
    return obj;
  },

  create(base?: DeepPartial<ListRecognizersRequest>): ListRecognizersRequest {
    return ListRecognizersRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ListRecognizersRequest>): ListRecognizersRequest {
    const message = createBaseListRecognizersRequest();
    message.parent = object.parent ?? "";
    message.pageSize = object.pageSize ?? 0;
    message.pageToken = object.pageToken ?? "";
    message.showDeleted = object.showDeleted ?? false;
    return message;
  },
};

function createBaseListRecognizersResponse(): ListRecognizersResponse {
  return { recognizers: [], nextPageToken: "" };
}

export const ListRecognizersResponse: MessageFns<ListRecognizersResponse> = {
  encode(message: ListRecognizersResponse, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.recognizers) {
      Recognizer.encode(v!, writer.uint32(10).fork()).join();
    }
    if (message.nextPageToken !== "") {
      writer.uint32(18).string(message.nextPageToken);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ListRecognizersResponse {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseListRecognizersResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.recognizers.push(Recognizer.decode(reader, reader.uint32()));
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.nextPageToken = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ListRecognizersResponse {
    return {
      recognizers: globalThis.Array.isArray(object?.recognizers)
        ? object.recognizers.map((e: any) => Recognizer.fromJSON(e))
        : [],
      nextPageToken: isSet(object.nextPageToken) ? globalThis.String(object.nextPageToken) : "",
    };
  },

  toJSON(message: ListRecognizersResponse): unknown {
    const obj: any = {};
    if (message.recognizers?.length) {
      obj.recognizers = message.recognizers.map((e) => Recognizer.toJSON(e));
    }
    if (message.nextPageToken !== "") {
      obj.nextPageToken = message.nextPageToken;
    }
    return obj;
  },

  create(base?: DeepPartial<ListRecognizersResponse>): ListRecognizersResponse {
    return ListRecognizersResponse.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ListRecognizersResponse>): ListRecognizersResponse {
    const message = createBaseListRecognizersResponse();
    message.recognizers = object.recognizers?.map((e) => Recognizer.fromPartial(e)) || [];
    message.nextPageToken = object.nextPageToken ?? "";
    return message;
  },
};

function createBaseGetRecognizerRequest(): GetRecognizerRequest {
  return { name: "" };
}

export const GetRecognizerRequest: MessageFns<GetRecognizerRequest> = {
  encode(message: GetRecognizerRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): GetRecognizerRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseGetRecognizerRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): GetRecognizerRequest {
    return { name: isSet(object.name) ? globalThis.String(object.name) : "" };
  },

  toJSON(message: GetRecognizerRequest): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    return obj;
  },

  create(base?: DeepPartial<GetRecognizerRequest>): GetRecognizerRequest {
    return GetRecognizerRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<GetRecognizerRequest>): GetRecognizerRequest {
    const message = createBaseGetRecognizerRequest();
    message.name = object.name ?? "";
    return message;
  },
};

function createBaseUpdateRecognizerRequest(): UpdateRecognizerRequest {
  return { recognizer: undefined, updateMask: undefined, validateOnly: false };
}

export const UpdateRecognizerRequest: MessageFns<UpdateRecognizerRequest> = {
  encode(message: UpdateRecognizerRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.recognizer !== undefined) {
      Recognizer.encode(message.recognizer, writer.uint32(10).fork()).join();
    }
    if (message.updateMask !== undefined) {
      FieldMask.encode(FieldMask.wrap(message.updateMask), writer.uint32(18).fork()).join();
    }
    if (message.validateOnly !== false) {
      writer.uint32(32).bool(message.validateOnly);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): UpdateRecognizerRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseUpdateRecognizerRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.recognizer = Recognizer.decode(reader, reader.uint32());
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.updateMask = FieldMask.unwrap(FieldMask.decode(reader, reader.uint32()));
          continue;
        case 4:
          if (tag !== 32) {
            break;
          }

          message.validateOnly = reader.bool();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): UpdateRecognizerRequest {
    return {
      recognizer: isSet(object.recognizer) ? Recognizer.fromJSON(object.recognizer) : undefined,
      updateMask: isSet(object.updateMask) ? FieldMask.unwrap(FieldMask.fromJSON(object.updateMask)) : undefined,
      validateOnly: isSet(object.validateOnly) ? globalThis.Boolean(object.validateOnly) : false,
    };
  },

  toJSON(message: UpdateRecognizerRequest): unknown {
    const obj: any = {};
    if (message.recognizer !== undefined) {
      obj.recognizer = Recognizer.toJSON(message.recognizer);
    }
    if (message.updateMask !== undefined) {
      obj.updateMask = FieldMask.toJSON(FieldMask.wrap(message.updateMask));
    }
    if (message.validateOnly !== false) {
      obj.validateOnly = message.validateOnly;
    }
    return obj;
  },

  create(base?: DeepPartial<UpdateRecognizerRequest>): UpdateRecognizerRequest {
    return UpdateRecognizerRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<UpdateRecognizerRequest>): UpdateRecognizerRequest {
    const message = createBaseUpdateRecognizerRequest();
    message.recognizer = (object.recognizer !== undefined && object.recognizer !== null)
      ? Recognizer.fromPartial(object.recognizer)
      : undefined;
    message.updateMask = object.updateMask ?? undefined;
    message.validateOnly = object.validateOnly ?? false;
    return message;
  },
};

function createBaseDeleteRecognizerRequest(): DeleteRecognizerRequest {
  return { name: "", validateOnly: false, allowMissing: false, etag: "" };
}

export const DeleteRecognizerRequest: MessageFns<DeleteRecognizerRequest> = {
  encode(message: DeleteRecognizerRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    if (message.validateOnly !== false) {
      writer.uint32(16).bool(message.validateOnly);
    }
    if (message.allowMissing !== false) {
      writer.uint32(32).bool(message.allowMissing);
    }
    if (message.etag !== "") {
      writer.uint32(26).string(message.etag);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): DeleteRecognizerRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDeleteRecognizerRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.validateOnly = reader.bool();
          continue;
        case 4:
          if (tag !== 32) {
            break;
          }

          message.allowMissing = reader.bool();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.etag = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): DeleteRecognizerRequest {
    return {
      name: isSet(object.name) ? globalThis.String(object.name) : "",
      validateOnly: isSet(object.validateOnly) ? globalThis.Boolean(object.validateOnly) : false,
      allowMissing: isSet(object.allowMissing) ? globalThis.Boolean(object.allowMissing) : false,
      etag: isSet(object.etag) ? globalThis.String(object.etag) : "",
    };
  },

  toJSON(message: DeleteRecognizerRequest): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    if (message.validateOnly !== false) {
      obj.validateOnly = message.validateOnly;
    }
    if (message.allowMissing !== false) {
      obj.allowMissing = message.allowMissing;
    }
    if (message.etag !== "") {
      obj.etag = message.etag;
    }
    return obj;
  },

  create(base?: DeepPartial<DeleteRecognizerRequest>): DeleteRecognizerRequest {
    return DeleteRecognizerRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<DeleteRecognizerRequest>): DeleteRecognizerRequest {
    const message = createBaseDeleteRecognizerRequest();
    message.name = object.name ?? "";
    message.validateOnly = object.validateOnly ?? false;
    message.allowMissing = object.allowMissing ?? false;
    message.etag = object.etag ?? "";
    return message;
  },
};

function createBaseUndeleteRecognizerRequest(): UndeleteRecognizerRequest {
  return { name: "", validateOnly: false, etag: "" };
}

export const UndeleteRecognizerRequest: MessageFns<UndeleteRecognizerRequest> = {
  encode(message: UndeleteRecognizerRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    if (message.validateOnly !== false) {
      writer.uint32(24).bool(message.validateOnly);
    }
    if (message.etag !== "") {
      writer.uint32(34).string(message.etag);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): UndeleteRecognizerRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseUndeleteRecognizerRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
        case 3:
          if (tag !== 24) {
            break;
          }

          message.validateOnly = reader.bool();
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.etag = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): UndeleteRecognizerRequest {
    return {
      name: isSet(object.name) ? globalThis.String(object.name) : "",
      validateOnly: isSet(object.validateOnly) ? globalThis.Boolean(object.validateOnly) : false,
      etag: isSet(object.etag) ? globalThis.String(object.etag) : "",
    };
  },

  toJSON(message: UndeleteRecognizerRequest): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    if (message.validateOnly !== false) {
      obj.validateOnly = message.validateOnly;
    }
    if (message.etag !== "") {
      obj.etag = message.etag;
    }
    return obj;
  },

  create(base?: DeepPartial<UndeleteRecognizerRequest>): UndeleteRecognizerRequest {
    return UndeleteRecognizerRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<UndeleteRecognizerRequest>): UndeleteRecognizerRequest {
    const message = createBaseUndeleteRecognizerRequest();
    message.name = object.name ?? "";
    message.validateOnly = object.validateOnly ?? false;
    message.etag = object.etag ?? "";
    return message;
  },
};

function createBaseRecognizer(): Recognizer {
  return {
    name: "",
    uid: "",
    displayName: "",
    model: "",
    languageCodes: [],
    defaultRecognitionConfig: undefined,
    annotations: {},
    state: 0,
    createTime: undefined,
    updateTime: undefined,
    deleteTime: undefined,
    expireTime: undefined,
    etag: "",
    reconciling: false,
    kmsKeyName: "",
    kmsKeyVersionName: "",
  };
}

export const Recognizer: MessageFns<Recognizer> = {
  encode(message: Recognizer, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    if (message.uid !== "") {
      writer.uint32(18).string(message.uid);
    }
    if (message.displayName !== "") {
      writer.uint32(26).string(message.displayName);
    }
    if (message.model !== "") {
      writer.uint32(34).string(message.model);
    }
    for (const v of message.languageCodes) {
      writer.uint32(138).string(v!);
    }
    if (message.defaultRecognitionConfig !== undefined) {
      RecognitionConfig.encode(message.defaultRecognitionConfig, writer.uint32(50).fork()).join();
    }
    Object.entries(message.annotations).forEach(([key, value]) => {
      Recognizer_AnnotationsEntry.encode({ key: key as any, value }, writer.uint32(58).fork()).join();
    });
    if (message.state !== 0) {
      writer.uint32(64).int32(message.state);
    }
    if (message.createTime !== undefined) {
      Timestamp.encode(toTimestamp(message.createTime), writer.uint32(74).fork()).join();
    }
    if (message.updateTime !== undefined) {
      Timestamp.encode(toTimestamp(message.updateTime), writer.uint32(82).fork()).join();
    }
    if (message.deleteTime !== undefined) {
      Timestamp.encode(toTimestamp(message.deleteTime), writer.uint32(90).fork()).join();
    }
    if (message.expireTime !== undefined) {
      Timestamp.encode(toTimestamp(message.expireTime), writer.uint32(114).fork()).join();
    }
    if (message.etag !== "") {
      writer.uint32(98).string(message.etag);
    }
    if (message.reconciling !== false) {
      writer.uint32(104).bool(message.reconciling);
    }
    if (message.kmsKeyName !== "") {
      writer.uint32(122).string(message.kmsKeyName);
    }
    if (message.kmsKeyVersionName !== "") {
      writer.uint32(130).string(message.kmsKeyVersionName);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Recognizer {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseRecognizer();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.uid = reader.string();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.displayName = reader.string();
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.model = reader.string();
          continue;
        case 17:
          if (tag !== 138) {
            break;
          }

          message.languageCodes.push(reader.string());
          continue;
        case 6:
          if (tag !== 50) {
            break;
          }

          message.defaultRecognitionConfig = RecognitionConfig.decode(reader, reader.uint32());
          continue;
        case 7:
          if (tag !== 58) {
            break;
          }

          const entry7 = Recognizer_AnnotationsEntry.decode(reader, reader.uint32());
          if (entry7.value !== undefined) {
            message.annotations[entry7.key] = entry7.value;
          }
          continue;
        case 8:
          if (tag !== 64) {
            break;
          }

          message.state = reader.int32() as any;
          continue;
        case 9:
          if (tag !== 74) {
            break;
          }

          message.createTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        case 10:
          if (tag !== 82) {
            break;
          }

          message.updateTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        case 11:
          if (tag !== 90) {
            break;
          }

          message.deleteTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        case 14:
          if (tag !== 114) {
            break;
          }

          message.expireTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        case 12:
          if (tag !== 98) {
            break;
          }

          message.etag = reader.string();
          continue;
        case 13:
          if (tag !== 104) {
            break;
          }

          message.reconciling = reader.bool();
          continue;
        case 15:
          if (tag !== 122) {
            break;
          }

          message.kmsKeyName = reader.string();
          continue;
        case 16:
          if (tag !== 130) {
            break;
          }

          message.kmsKeyVersionName = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Recognizer {
    return {
      name: isSet(object.name) ? globalThis.String(object.name) : "",
      uid: isSet(object.uid) ? globalThis.String(object.uid) : "",
      displayName: isSet(object.displayName) ? globalThis.String(object.displayName) : "",
      model: isSet(object.model) ? globalThis.String(object.model) : "",
      languageCodes: globalThis.Array.isArray(object?.languageCodes)
        ? object.languageCodes.map((e: any) => globalThis.String(e))
        : [],
      defaultRecognitionConfig: isSet(object.defaultRecognitionConfig)
        ? RecognitionConfig.fromJSON(object.defaultRecognitionConfig)
        : undefined,
      annotations: isObject(object.annotations)
        ? Object.entries(object.annotations).reduce<{ [key: string]: string }>((acc, [key, value]) => {
          acc[key] = String(value);
          return acc;
        }, {})
        : {},
      state: isSet(object.state) ? recognizer_StateFromJSON(object.state) : 0,
      createTime: isSet(object.createTime) ? fromJsonTimestamp(object.createTime) : undefined,
      updateTime: isSet(object.updateTime) ? fromJsonTimestamp(object.updateTime) : undefined,
      deleteTime: isSet(object.deleteTime) ? fromJsonTimestamp(object.deleteTime) : undefined,
      expireTime: isSet(object.expireTime) ? fromJsonTimestamp(object.expireTime) : undefined,
      etag: isSet(object.etag) ? globalThis.String(object.etag) : "",
      reconciling: isSet(object.reconciling) ? globalThis.Boolean(object.reconciling) : false,
      kmsKeyName: isSet(object.kmsKeyName) ? globalThis.String(object.kmsKeyName) : "",
      kmsKeyVersionName: isSet(object.kmsKeyVersionName) ? globalThis.String(object.kmsKeyVersionName) : "",
    };
  },

  toJSON(message: Recognizer): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    if (message.uid !== "") {
      obj.uid = message.uid;
    }
    if (message.displayName !== "") {
      obj.displayName = message.displayName;
    }
    if (message.model !== "") {
      obj.model = message.model;
    }
    if (message.languageCodes?.length) {
      obj.languageCodes = message.languageCodes;
    }
    if (message.defaultRecognitionConfig !== undefined) {
      obj.defaultRecognitionConfig = RecognitionConfig.toJSON(message.defaultRecognitionConfig);
    }
    if (message.annotations) {
      const entries = Object.entries(message.annotations);
      if (entries.length > 0) {
        obj.annotations = {};
        entries.forEach(([k, v]) => {
          obj.annotations[k] = v;
        });
      }
    }
    if (message.state !== 0) {
      obj.state = recognizer_StateToJSON(message.state);
    }
    if (message.createTime !== undefined) {
      obj.createTime = message.createTime.toISOString();
    }
    if (message.updateTime !== undefined) {
      obj.updateTime = message.updateTime.toISOString();
    }
    if (message.deleteTime !== undefined) {
      obj.deleteTime = message.deleteTime.toISOString();
    }
    if (message.expireTime !== undefined) {
      obj.expireTime = message.expireTime.toISOString();
    }
    if (message.etag !== "") {
      obj.etag = message.etag;
    }
    if (message.reconciling !== false) {
      obj.reconciling = message.reconciling;
    }
    if (message.kmsKeyName !== "") {
      obj.kmsKeyName = message.kmsKeyName;
    }
    if (message.kmsKeyVersionName !== "") {
      obj.kmsKeyVersionName = message.kmsKeyVersionName;
    }
    return obj;
  },

  create(base?: DeepPartial<Recognizer>): Recognizer {
    return Recognizer.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<Recognizer>): Recognizer {
    const message = createBaseRecognizer();
    message.name = object.name ?? "";
    message.uid = object.uid ?? "";
    message.displayName = object.displayName ?? "";
    message.model = object.model ?? "";
    message.languageCodes = object.languageCodes?.map((e) => e) || [];
    message.defaultRecognitionConfig =
      (object.defaultRecognitionConfig !== undefined && object.defaultRecognitionConfig !== null)
        ? RecognitionConfig.fromPartial(object.defaultRecognitionConfig)
        : undefined;
    message.annotations = Object.entries(object.annotations ?? {}).reduce<{ [key: string]: string }>(
      (acc, [key, value]) => {
        if (value !== undefined) {
          acc[key] = globalThis.String(value);
        }
        return acc;
      },
      {},
    );
    message.state = object.state ?? 0;
    message.createTime = object.createTime ?? undefined;
    message.updateTime = object.updateTime ?? undefined;
    message.deleteTime = object.deleteTime ?? undefined;
    message.expireTime = object.expireTime ?? undefined;
    message.etag = object.etag ?? "";
    message.reconciling = object.reconciling ?? false;
    message.kmsKeyName = object.kmsKeyName ?? "";
    message.kmsKeyVersionName = object.kmsKeyVersionName ?? "";
    return message;
  },
};

function createBaseRecognizer_AnnotationsEntry(): Recognizer_AnnotationsEntry {
  return { key: "", value: "" };
}

export const Recognizer_AnnotationsEntry: MessageFns<Recognizer_AnnotationsEntry> = {
  encode(message: Recognizer_AnnotationsEntry, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.key !== "") {
      writer.uint32(10).string(message.key);
    }
    if (message.value !== "") {
      writer.uint32(18).string(message.value);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Recognizer_AnnotationsEntry {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseRecognizer_AnnotationsEntry();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.key = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.value = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Recognizer_AnnotationsEntry {
    return {
      key: isSet(object.key) ? globalThis.String(object.key) : "",
      value: isSet(object.value) ? globalThis.String(object.value) : "",
    };
  },

  toJSON(message: Recognizer_AnnotationsEntry): unknown {
    const obj: any = {};
    if (message.key !== "") {
      obj.key = message.key;
    }
    if (message.value !== "") {
      obj.value = message.value;
    }
    return obj;
  },

  create(base?: DeepPartial<Recognizer_AnnotationsEntry>): Recognizer_AnnotationsEntry {
    return Recognizer_AnnotationsEntry.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<Recognizer_AnnotationsEntry>): Recognizer_AnnotationsEntry {
    const message = createBaseRecognizer_AnnotationsEntry();
    message.key = object.key ?? "";
    message.value = object.value ?? "";
    return message;
  },
};

function createBaseAutoDetectDecodingConfig(): AutoDetectDecodingConfig {
  return {};
}

export const AutoDetectDecodingConfig: MessageFns<AutoDetectDecodingConfig> = {
  encode(_: AutoDetectDecodingConfig, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): AutoDetectDecodingConfig {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseAutoDetectDecodingConfig();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(_: any): AutoDetectDecodingConfig {
    return {};
  },

  toJSON(_: AutoDetectDecodingConfig): unknown {
    const obj: any = {};
    return obj;
  },

  create(base?: DeepPartial<AutoDetectDecodingConfig>): AutoDetectDecodingConfig {
    return AutoDetectDecodingConfig.fromPartial(base ?? {});
  },
  fromPartial(_: DeepPartial<AutoDetectDecodingConfig>): AutoDetectDecodingConfig {
    const message = createBaseAutoDetectDecodingConfig();
    return message;
  },
};

function createBaseExplicitDecodingConfig(): ExplicitDecodingConfig {
  return { encoding: 0, sampleRateHertz: 0, audioChannelCount: 0 };
}

export const ExplicitDecodingConfig: MessageFns<ExplicitDecodingConfig> = {
  encode(message: ExplicitDecodingConfig, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.encoding !== 0) {
      writer.uint32(8).int32(message.encoding);
    }
    if (message.sampleRateHertz !== 0) {
      writer.uint32(16).int32(message.sampleRateHertz);
    }
    if (message.audioChannelCount !== 0) {
      writer.uint32(24).int32(message.audioChannelCount);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ExplicitDecodingConfig {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseExplicitDecodingConfig();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 8) {
            break;
          }

          message.encoding = reader.int32() as any;
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.sampleRateHertz = reader.int32();
          continue;
        case 3:
          if (tag !== 24) {
            break;
          }

          message.audioChannelCount = reader.int32();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ExplicitDecodingConfig {
    return {
      encoding: isSet(object.encoding) ? explicitDecodingConfig_AudioEncodingFromJSON(object.encoding) : 0,
      sampleRateHertz: isSet(object.sampleRateHertz) ? globalThis.Number(object.sampleRateHertz) : 0,
      audioChannelCount: isSet(object.audioChannelCount) ? globalThis.Number(object.audioChannelCount) : 0,
    };
  },

  toJSON(message: ExplicitDecodingConfig): unknown {
    const obj: any = {};
    if (message.encoding !== 0) {
      obj.encoding = explicitDecodingConfig_AudioEncodingToJSON(message.encoding);
    }
    if (message.sampleRateHertz !== 0) {
      obj.sampleRateHertz = Math.round(message.sampleRateHertz);
    }
    if (message.audioChannelCount !== 0) {
      obj.audioChannelCount = Math.round(message.audioChannelCount);
    }
    return obj;
  },

  create(base?: DeepPartial<ExplicitDecodingConfig>): ExplicitDecodingConfig {
    return ExplicitDecodingConfig.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ExplicitDecodingConfig>): ExplicitDecodingConfig {
    const message = createBaseExplicitDecodingConfig();
    message.encoding = object.encoding ?? 0;
    message.sampleRateHertz = object.sampleRateHertz ?? 0;
    message.audioChannelCount = object.audioChannelCount ?? 0;
    return message;
  },
};

function createBaseSpeakerDiarizationConfig(): SpeakerDiarizationConfig {
  return { minSpeakerCount: 0, maxSpeakerCount: 0 };
}

export const SpeakerDiarizationConfig: MessageFns<SpeakerDiarizationConfig> = {
  encode(message: SpeakerDiarizationConfig, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.minSpeakerCount !== 0) {
      writer.uint32(16).int32(message.minSpeakerCount);
    }
    if (message.maxSpeakerCount !== 0) {
      writer.uint32(24).int32(message.maxSpeakerCount);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): SpeakerDiarizationConfig {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseSpeakerDiarizationConfig();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 2:
          if (tag !== 16) {
            break;
          }

          message.minSpeakerCount = reader.int32();
          continue;
        case 3:
          if (tag !== 24) {
            break;
          }

          message.maxSpeakerCount = reader.int32();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): SpeakerDiarizationConfig {
    return {
      minSpeakerCount: isSet(object.minSpeakerCount) ? globalThis.Number(object.minSpeakerCount) : 0,
      maxSpeakerCount: isSet(object.maxSpeakerCount) ? globalThis.Number(object.maxSpeakerCount) : 0,
    };
  },

  toJSON(message: SpeakerDiarizationConfig): unknown {
    const obj: any = {};
    if (message.minSpeakerCount !== 0) {
      obj.minSpeakerCount = Math.round(message.minSpeakerCount);
    }
    if (message.maxSpeakerCount !== 0) {
      obj.maxSpeakerCount = Math.round(message.maxSpeakerCount);
    }
    return obj;
  },

  create(base?: DeepPartial<SpeakerDiarizationConfig>): SpeakerDiarizationConfig {
    return SpeakerDiarizationConfig.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<SpeakerDiarizationConfig>): SpeakerDiarizationConfig {
    const message = createBaseSpeakerDiarizationConfig();
    message.minSpeakerCount = object.minSpeakerCount ?? 0;
    message.maxSpeakerCount = object.maxSpeakerCount ?? 0;
    return message;
  },
};

function createBaseRecognitionFeatures(): RecognitionFeatures {
  return {
    profanityFilter: false,
    enableWordTimeOffsets: false,
    enableWordConfidence: false,
    enableAutomaticPunctuation: false,
    enableSpokenPunctuation: false,
    enableSpokenEmojis: false,
    multiChannelMode: 0,
    diarizationConfig: undefined,
    maxAlternatives: 0,
  };
}

export const RecognitionFeatures: MessageFns<RecognitionFeatures> = {
  encode(message: RecognitionFeatures, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.profanityFilter !== false) {
      writer.uint32(8).bool(message.profanityFilter);
    }
    if (message.enableWordTimeOffsets !== false) {
      writer.uint32(16).bool(message.enableWordTimeOffsets);
    }
    if (message.enableWordConfidence !== false) {
      writer.uint32(24).bool(message.enableWordConfidence);
    }
    if (message.enableAutomaticPunctuation !== false) {
      writer.uint32(32).bool(message.enableAutomaticPunctuation);
    }
    if (message.enableSpokenPunctuation !== false) {
      writer.uint32(112).bool(message.enableSpokenPunctuation);
    }
    if (message.enableSpokenEmojis !== false) {
      writer.uint32(120).bool(message.enableSpokenEmojis);
    }
    if (message.multiChannelMode !== 0) {
      writer.uint32(136).int32(message.multiChannelMode);
    }
    if (message.diarizationConfig !== undefined) {
      SpeakerDiarizationConfig.encode(message.diarizationConfig, writer.uint32(74).fork()).join();
    }
    if (message.maxAlternatives !== 0) {
      writer.uint32(128).int32(message.maxAlternatives);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): RecognitionFeatures {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseRecognitionFeatures();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 8) {
            break;
          }

          message.profanityFilter = reader.bool();
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.enableWordTimeOffsets = reader.bool();
          continue;
        case 3:
          if (tag !== 24) {
            break;
          }

          message.enableWordConfidence = reader.bool();
          continue;
        case 4:
          if (tag !== 32) {
            break;
          }

          message.enableAutomaticPunctuation = reader.bool();
          continue;
        case 14:
          if (tag !== 112) {
            break;
          }

          message.enableSpokenPunctuation = reader.bool();
          continue;
        case 15:
          if (tag !== 120) {
            break;
          }

          message.enableSpokenEmojis = reader.bool();
          continue;
        case 17:
          if (tag !== 136) {
            break;
          }

          message.multiChannelMode = reader.int32() as any;
          continue;
        case 9:
          if (tag !== 74) {
            break;
          }

          message.diarizationConfig = SpeakerDiarizationConfig.decode(reader, reader.uint32());
          continue;
        case 16:
          if (tag !== 128) {
            break;
          }

          message.maxAlternatives = reader.int32();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): RecognitionFeatures {
    return {
      profanityFilter: isSet(object.profanityFilter) ? globalThis.Boolean(object.profanityFilter) : false,
      enableWordTimeOffsets: isSet(object.enableWordTimeOffsets)
        ? globalThis.Boolean(object.enableWordTimeOffsets)
        : false,
      enableWordConfidence: isSet(object.enableWordConfidence)
        ? globalThis.Boolean(object.enableWordConfidence)
        : false,
      enableAutomaticPunctuation: isSet(object.enableAutomaticPunctuation)
        ? globalThis.Boolean(object.enableAutomaticPunctuation)
        : false,
      enableSpokenPunctuation: isSet(object.enableSpokenPunctuation)
        ? globalThis.Boolean(object.enableSpokenPunctuation)
        : false,
      enableSpokenEmojis: isSet(object.enableSpokenEmojis) ? globalThis.Boolean(object.enableSpokenEmojis) : false,
      multiChannelMode: isSet(object.multiChannelMode)
        ? recognitionFeatures_MultiChannelModeFromJSON(object.multiChannelMode)
        : 0,
      diarizationConfig: isSet(object.diarizationConfig)
        ? SpeakerDiarizationConfig.fromJSON(object.diarizationConfig)
        : undefined,
      maxAlternatives: isSet(object.maxAlternatives) ? globalThis.Number(object.maxAlternatives) : 0,
    };
  },

  toJSON(message: RecognitionFeatures): unknown {
    const obj: any = {};
    if (message.profanityFilter !== false) {
      obj.profanityFilter = message.profanityFilter;
    }
    if (message.enableWordTimeOffsets !== false) {
      obj.enableWordTimeOffsets = message.enableWordTimeOffsets;
    }
    if (message.enableWordConfidence !== false) {
      obj.enableWordConfidence = message.enableWordConfidence;
    }
    if (message.enableAutomaticPunctuation !== false) {
      obj.enableAutomaticPunctuation = message.enableAutomaticPunctuation;
    }
    if (message.enableSpokenPunctuation !== false) {
      obj.enableSpokenPunctuation = message.enableSpokenPunctuation;
    }
    if (message.enableSpokenEmojis !== false) {
      obj.enableSpokenEmojis = message.enableSpokenEmojis;
    }
    if (message.multiChannelMode !== 0) {
      obj.multiChannelMode = recognitionFeatures_MultiChannelModeToJSON(message.multiChannelMode);
    }
    if (message.diarizationConfig !== undefined) {
      obj.diarizationConfig = SpeakerDiarizationConfig.toJSON(message.diarizationConfig);
    }
    if (message.maxAlternatives !== 0) {
      obj.maxAlternatives = Math.round(message.maxAlternatives);
    }
    return obj;
  },

  create(base?: DeepPartial<RecognitionFeatures>): RecognitionFeatures {
    return RecognitionFeatures.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<RecognitionFeatures>): RecognitionFeatures {
    const message = createBaseRecognitionFeatures();
    message.profanityFilter = object.profanityFilter ?? false;
    message.enableWordTimeOffsets = object.enableWordTimeOffsets ?? false;
    message.enableWordConfidence = object.enableWordConfidence ?? false;
    message.enableAutomaticPunctuation = object.enableAutomaticPunctuation ?? false;
    message.enableSpokenPunctuation = object.enableSpokenPunctuation ?? false;
    message.enableSpokenEmojis = object.enableSpokenEmojis ?? false;
    message.multiChannelMode = object.multiChannelMode ?? 0;
    message.diarizationConfig = (object.diarizationConfig !== undefined && object.diarizationConfig !== null)
      ? SpeakerDiarizationConfig.fromPartial(object.diarizationConfig)
      : undefined;
    message.maxAlternatives = object.maxAlternatives ?? 0;
    return message;
  },
};

function createBaseTranscriptNormalization(): TranscriptNormalization {
  return { entries: [] };
}

export const TranscriptNormalization: MessageFns<TranscriptNormalization> = {
  encode(message: TranscriptNormalization, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.entries) {
      TranscriptNormalization_Entry.encode(v!, writer.uint32(10).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): TranscriptNormalization {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseTranscriptNormalization();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.entries.push(TranscriptNormalization_Entry.decode(reader, reader.uint32()));
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): TranscriptNormalization {
    return {
      entries: globalThis.Array.isArray(object?.entries)
        ? object.entries.map((e: any) => TranscriptNormalization_Entry.fromJSON(e))
        : [],
    };
  },

  toJSON(message: TranscriptNormalization): unknown {
    const obj: any = {};
    if (message.entries?.length) {
      obj.entries = message.entries.map((e) => TranscriptNormalization_Entry.toJSON(e));
    }
    return obj;
  },

  create(base?: DeepPartial<TranscriptNormalization>): TranscriptNormalization {
    return TranscriptNormalization.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<TranscriptNormalization>): TranscriptNormalization {
    const message = createBaseTranscriptNormalization();
    message.entries = object.entries?.map((e) => TranscriptNormalization_Entry.fromPartial(e)) || [];
    return message;
  },
};

function createBaseTranscriptNormalization_Entry(): TranscriptNormalization_Entry {
  return { search: "", replace: "", caseSensitive: false };
}

export const TranscriptNormalization_Entry: MessageFns<TranscriptNormalization_Entry> = {
  encode(message: TranscriptNormalization_Entry, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.search !== "") {
      writer.uint32(10).string(message.search);
    }
    if (message.replace !== "") {
      writer.uint32(18).string(message.replace);
    }
    if (message.caseSensitive !== false) {
      writer.uint32(24).bool(message.caseSensitive);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): TranscriptNormalization_Entry {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseTranscriptNormalization_Entry();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.search = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.replace = reader.string();
          continue;
        case 3:
          if (tag !== 24) {
            break;
          }

          message.caseSensitive = reader.bool();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): TranscriptNormalization_Entry {
    return {
      search: isSet(object.search) ? globalThis.String(object.search) : "",
      replace: isSet(object.replace) ? globalThis.String(object.replace) : "",
      caseSensitive: isSet(object.caseSensitive) ? globalThis.Boolean(object.caseSensitive) : false,
    };
  },

  toJSON(message: TranscriptNormalization_Entry): unknown {
    const obj: any = {};
    if (message.search !== "") {
      obj.search = message.search;
    }
    if (message.replace !== "") {
      obj.replace = message.replace;
    }
    if (message.caseSensitive !== false) {
      obj.caseSensitive = message.caseSensitive;
    }
    return obj;
  },

  create(base?: DeepPartial<TranscriptNormalization_Entry>): TranscriptNormalization_Entry {
    return TranscriptNormalization_Entry.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<TranscriptNormalization_Entry>): TranscriptNormalization_Entry {
    const message = createBaseTranscriptNormalization_Entry();
    message.search = object.search ?? "";
    message.replace = object.replace ?? "";
    message.caseSensitive = object.caseSensitive ?? false;
    return message;
  },
};

function createBaseTranslationConfig(): TranslationConfig {
  return { targetLanguage: "" };
}

export const TranslationConfig: MessageFns<TranslationConfig> = {
  encode(message: TranslationConfig, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.targetLanguage !== "") {
      writer.uint32(10).string(message.targetLanguage);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): TranslationConfig {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseTranslationConfig();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.targetLanguage = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): TranslationConfig {
    return { targetLanguage: isSet(object.targetLanguage) ? globalThis.String(object.targetLanguage) : "" };
  },

  toJSON(message: TranslationConfig): unknown {
    const obj: any = {};
    if (message.targetLanguage !== "") {
      obj.targetLanguage = message.targetLanguage;
    }
    return obj;
  },

  create(base?: DeepPartial<TranslationConfig>): TranslationConfig {
    return TranslationConfig.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<TranslationConfig>): TranslationConfig {
    const message = createBaseTranslationConfig();
    message.targetLanguage = object.targetLanguage ?? "";
    return message;
  },
};

function createBaseSpeechAdaptation(): SpeechAdaptation {
  return { phraseSets: [], customClasses: [] };
}

export const SpeechAdaptation: MessageFns<SpeechAdaptation> = {
  encode(message: SpeechAdaptation, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.phraseSets) {
      SpeechAdaptation_AdaptationPhraseSet.encode(v!, writer.uint32(10).fork()).join();
    }
    for (const v of message.customClasses) {
      CustomClass.encode(v!, writer.uint32(18).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): SpeechAdaptation {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseSpeechAdaptation();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.phraseSets.push(SpeechAdaptation_AdaptationPhraseSet.decode(reader, reader.uint32()));
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.customClasses.push(CustomClass.decode(reader, reader.uint32()));
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): SpeechAdaptation {
    return {
      phraseSets: globalThis.Array.isArray(object?.phraseSets)
        ? object.phraseSets.map((e: any) => SpeechAdaptation_AdaptationPhraseSet.fromJSON(e))
        : [],
      customClasses: globalThis.Array.isArray(object?.customClasses)
        ? object.customClasses.map((e: any) => CustomClass.fromJSON(e))
        : [],
    };
  },

  toJSON(message: SpeechAdaptation): unknown {
    const obj: any = {};
    if (message.phraseSets?.length) {
      obj.phraseSets = message.phraseSets.map((e) => SpeechAdaptation_AdaptationPhraseSet.toJSON(e));
    }
    if (message.customClasses?.length) {
      obj.customClasses = message.customClasses.map((e) => CustomClass.toJSON(e));
    }
    return obj;
  },

  create(base?: DeepPartial<SpeechAdaptation>): SpeechAdaptation {
    return SpeechAdaptation.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<SpeechAdaptation>): SpeechAdaptation {
    const message = createBaseSpeechAdaptation();
    message.phraseSets = object.phraseSets?.map((e) => SpeechAdaptation_AdaptationPhraseSet.fromPartial(e)) || [];
    message.customClasses = object.customClasses?.map((e) => CustomClass.fromPartial(e)) || [];
    return message;
  },
};

function createBaseSpeechAdaptation_AdaptationPhraseSet(): SpeechAdaptation_AdaptationPhraseSet {
  return { phraseSet: undefined, inlinePhraseSet: undefined };
}

export const SpeechAdaptation_AdaptationPhraseSet: MessageFns<SpeechAdaptation_AdaptationPhraseSet> = {
  encode(message: SpeechAdaptation_AdaptationPhraseSet, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.phraseSet !== undefined) {
      writer.uint32(10).string(message.phraseSet);
    }
    if (message.inlinePhraseSet !== undefined) {
      PhraseSet.encode(message.inlinePhraseSet, writer.uint32(18).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): SpeechAdaptation_AdaptationPhraseSet {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseSpeechAdaptation_AdaptationPhraseSet();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.phraseSet = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.inlinePhraseSet = PhraseSet.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): SpeechAdaptation_AdaptationPhraseSet {
    return {
      phraseSet: isSet(object.phraseSet) ? globalThis.String(object.phraseSet) : undefined,
      inlinePhraseSet: isSet(object.inlinePhraseSet) ? PhraseSet.fromJSON(object.inlinePhraseSet) : undefined,
    };
  },

  toJSON(message: SpeechAdaptation_AdaptationPhraseSet): unknown {
    const obj: any = {};
    if (message.phraseSet !== undefined) {
      obj.phraseSet = message.phraseSet;
    }
    if (message.inlinePhraseSet !== undefined) {
      obj.inlinePhraseSet = PhraseSet.toJSON(message.inlinePhraseSet);
    }
    return obj;
  },

  create(base?: DeepPartial<SpeechAdaptation_AdaptationPhraseSet>): SpeechAdaptation_AdaptationPhraseSet {
    return SpeechAdaptation_AdaptationPhraseSet.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<SpeechAdaptation_AdaptationPhraseSet>): SpeechAdaptation_AdaptationPhraseSet {
    const message = createBaseSpeechAdaptation_AdaptationPhraseSet();
    message.phraseSet = object.phraseSet ?? undefined;
    message.inlinePhraseSet = (object.inlinePhraseSet !== undefined && object.inlinePhraseSet !== null)
      ? PhraseSet.fromPartial(object.inlinePhraseSet)
      : undefined;
    return message;
  },
};

function createBaseRecognitionConfig(): RecognitionConfig {
  return {
    autoDecodingConfig: undefined,
    explicitDecodingConfig: undefined,
    model: "",
    languageCodes: [],
    features: undefined,
    adaptation: undefined,
    transcriptNormalization: undefined,
    translationConfig: undefined,
  };
}

export const RecognitionConfig: MessageFns<RecognitionConfig> = {
  encode(message: RecognitionConfig, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.autoDecodingConfig !== undefined) {
      AutoDetectDecodingConfig.encode(message.autoDecodingConfig, writer.uint32(58).fork()).join();
    }
    if (message.explicitDecodingConfig !== undefined) {
      ExplicitDecodingConfig.encode(message.explicitDecodingConfig, writer.uint32(66).fork()).join();
    }
    if (message.model !== "") {
      writer.uint32(74).string(message.model);
    }
    for (const v of message.languageCodes) {
      writer.uint32(82).string(v!);
    }
    if (message.features !== undefined) {
      RecognitionFeatures.encode(message.features, writer.uint32(18).fork()).join();
    }
    if (message.adaptation !== undefined) {
      SpeechAdaptation.encode(message.adaptation, writer.uint32(50).fork()).join();
    }
    if (message.transcriptNormalization !== undefined) {
      TranscriptNormalization.encode(message.transcriptNormalization, writer.uint32(90).fork()).join();
    }
    if (message.translationConfig !== undefined) {
      TranslationConfig.encode(message.translationConfig, writer.uint32(122).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): RecognitionConfig {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseRecognitionConfig();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 7:
          if (tag !== 58) {
            break;
          }

          message.autoDecodingConfig = AutoDetectDecodingConfig.decode(reader, reader.uint32());
          continue;
        case 8:
          if (tag !== 66) {
            break;
          }

          message.explicitDecodingConfig = ExplicitDecodingConfig.decode(reader, reader.uint32());
          continue;
        case 9:
          if (tag !== 74) {
            break;
          }

          message.model = reader.string();
          continue;
        case 10:
          if (tag !== 82) {
            break;
          }

          message.languageCodes.push(reader.string());
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.features = RecognitionFeatures.decode(reader, reader.uint32());
          continue;
        case 6:
          if (tag !== 50) {
            break;
          }

          message.adaptation = SpeechAdaptation.decode(reader, reader.uint32());
          continue;
        case 11:
          if (tag !== 90) {
            break;
          }

          message.transcriptNormalization = TranscriptNormalization.decode(reader, reader.uint32());
          continue;
        case 15:
          if (tag !== 122) {
            break;
          }

          message.translationConfig = TranslationConfig.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): RecognitionConfig {
    return {
      autoDecodingConfig: isSet(object.autoDecodingConfig)
        ? AutoDetectDecodingConfig.fromJSON(object.autoDecodingConfig)
        : undefined,
      explicitDecodingConfig: isSet(object.explicitDecodingConfig)
        ? ExplicitDecodingConfig.fromJSON(object.explicitDecodingConfig)
        : undefined,
      model: isSet(object.model) ? globalThis.String(object.model) : "",
      languageCodes: globalThis.Array.isArray(object?.languageCodes)
        ? object.languageCodes.map((e: any) => globalThis.String(e))
        : [],
      features: isSet(object.features) ? RecognitionFeatures.fromJSON(object.features) : undefined,
      adaptation: isSet(object.adaptation) ? SpeechAdaptation.fromJSON(object.adaptation) : undefined,
      transcriptNormalization: isSet(object.transcriptNormalization)
        ? TranscriptNormalization.fromJSON(object.transcriptNormalization)
        : undefined,
      translationConfig: isSet(object.translationConfig)
        ? TranslationConfig.fromJSON(object.translationConfig)
        : undefined,
    };
  },

  toJSON(message: RecognitionConfig): unknown {
    const obj: any = {};
    if (message.autoDecodingConfig !== undefined) {
      obj.autoDecodingConfig = AutoDetectDecodingConfig.toJSON(message.autoDecodingConfig);
    }
    if (message.explicitDecodingConfig !== undefined) {
      obj.explicitDecodingConfig = ExplicitDecodingConfig.toJSON(message.explicitDecodingConfig);
    }
    if (message.model !== "") {
      obj.model = message.model;
    }
    if (message.languageCodes?.length) {
      obj.languageCodes = message.languageCodes;
    }
    if (message.features !== undefined) {
      obj.features = RecognitionFeatures.toJSON(message.features);
    }
    if (message.adaptation !== undefined) {
      obj.adaptation = SpeechAdaptation.toJSON(message.adaptation);
    }
    if (message.transcriptNormalization !== undefined) {
      obj.transcriptNormalization = TranscriptNormalization.toJSON(message.transcriptNormalization);
    }
    if (message.translationConfig !== undefined) {
      obj.translationConfig = TranslationConfig.toJSON(message.translationConfig);
    }
    return obj;
  },

  create(base?: DeepPartial<RecognitionConfig>): RecognitionConfig {
    return RecognitionConfig.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<RecognitionConfig>): RecognitionConfig {
    const message = createBaseRecognitionConfig();
    message.autoDecodingConfig = (object.autoDecodingConfig !== undefined && object.autoDecodingConfig !== null)
      ? AutoDetectDecodingConfig.fromPartial(object.autoDecodingConfig)
      : undefined;
    message.explicitDecodingConfig =
      (object.explicitDecodingConfig !== undefined && object.explicitDecodingConfig !== null)
        ? ExplicitDecodingConfig.fromPartial(object.explicitDecodingConfig)
        : undefined;
    message.model = object.model ?? "";
    message.languageCodes = object.languageCodes?.map((e) => e) || [];
    message.features = (object.features !== undefined && object.features !== null)
      ? RecognitionFeatures.fromPartial(object.features)
      : undefined;
    message.adaptation = (object.adaptation !== undefined && object.adaptation !== null)
      ? SpeechAdaptation.fromPartial(object.adaptation)
      : undefined;
    message.transcriptNormalization =
      (object.transcriptNormalization !== undefined && object.transcriptNormalization !== null)
        ? TranscriptNormalization.fromPartial(object.transcriptNormalization)
        : undefined;
    message.translationConfig = (object.translationConfig !== undefined && object.translationConfig !== null)
      ? TranslationConfig.fromPartial(object.translationConfig)
      : undefined;
    return message;
  },
};

function createBaseRecognizeRequest(): RecognizeRequest {
  return { recognizer: "", config: undefined, configMask: undefined, content: undefined, uri: undefined };
}

export const RecognizeRequest: MessageFns<RecognizeRequest> = {
  encode(message: RecognizeRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.recognizer !== "") {
      writer.uint32(26).string(message.recognizer);
    }
    if (message.config !== undefined) {
      RecognitionConfig.encode(message.config, writer.uint32(10).fork()).join();
    }
    if (message.configMask !== undefined) {
      FieldMask.encode(FieldMask.wrap(message.configMask), writer.uint32(66).fork()).join();
    }
    if (message.content !== undefined) {
      writer.uint32(42).bytes(message.content);
    }
    if (message.uri !== undefined) {
      writer.uint32(50).string(message.uri);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): RecognizeRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseRecognizeRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 3:
          if (tag !== 26) {
            break;
          }

          message.recognizer = reader.string();
          continue;
        case 1:
          if (tag !== 10) {
            break;
          }

          message.config = RecognitionConfig.decode(reader, reader.uint32());
          continue;
        case 8:
          if (tag !== 66) {
            break;
          }

          message.configMask = FieldMask.unwrap(FieldMask.decode(reader, reader.uint32()));
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.content = Buffer.from(reader.bytes());
          continue;
        case 6:
          if (tag !== 50) {
            break;
          }

          message.uri = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): RecognizeRequest {
    return {
      recognizer: isSet(object.recognizer) ? globalThis.String(object.recognizer) : "",
      config: isSet(object.config) ? RecognitionConfig.fromJSON(object.config) : undefined,
      configMask: isSet(object.configMask) ? FieldMask.unwrap(FieldMask.fromJSON(object.configMask)) : undefined,
      content: isSet(object.content) ? Buffer.from(bytesFromBase64(object.content)) : undefined,
      uri: isSet(object.uri) ? globalThis.String(object.uri) : undefined,
    };
  },

  toJSON(message: RecognizeRequest): unknown {
    const obj: any = {};
    if (message.recognizer !== "") {
      obj.recognizer = message.recognizer;
    }
    if (message.config !== undefined) {
      obj.config = RecognitionConfig.toJSON(message.config);
    }
    if (message.configMask !== undefined) {
      obj.configMask = FieldMask.toJSON(FieldMask.wrap(message.configMask));
    }
    if (message.content !== undefined) {
      obj.content = base64FromBytes(message.content);
    }
    if (message.uri !== undefined) {
      obj.uri = message.uri;
    }
    return obj;
  },

  create(base?: DeepPartial<RecognizeRequest>): RecognizeRequest {
    return RecognizeRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<RecognizeRequest>): RecognizeRequest {
    const message = createBaseRecognizeRequest();
    message.recognizer = object.recognizer ?? "";
    message.config = (object.config !== undefined && object.config !== null)
      ? RecognitionConfig.fromPartial(object.config)
      : undefined;
    message.configMask = object.configMask ?? undefined;
    message.content = object.content ?? undefined;
    message.uri = object.uri ?? undefined;
    return message;
  },
};

function createBaseRecognitionResponseMetadata(): RecognitionResponseMetadata {
  return { requestId: "", totalBilledDuration: undefined };
}

export const RecognitionResponseMetadata: MessageFns<RecognitionResponseMetadata> = {
  encode(message: RecognitionResponseMetadata, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.requestId !== "") {
      writer.uint32(74).string(message.requestId);
    }
    if (message.totalBilledDuration !== undefined) {
      Duration.encode(message.totalBilledDuration, writer.uint32(50).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): RecognitionResponseMetadata {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseRecognitionResponseMetadata();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 9:
          if (tag !== 74) {
            break;
          }

          message.requestId = reader.string();
          continue;
        case 6:
          if (tag !== 50) {
            break;
          }

          message.totalBilledDuration = Duration.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): RecognitionResponseMetadata {
    return {
      requestId: isSet(object.requestId) ? globalThis.String(object.requestId) : "",
      totalBilledDuration: isSet(object.totalBilledDuration)
        ? Duration.fromJSON(object.totalBilledDuration)
        : undefined,
    };
  },

  toJSON(message: RecognitionResponseMetadata): unknown {
    const obj: any = {};
    if (message.requestId !== "") {
      obj.requestId = message.requestId;
    }
    if (message.totalBilledDuration !== undefined) {
      obj.totalBilledDuration = Duration.toJSON(message.totalBilledDuration);
    }
    return obj;
  },

  create(base?: DeepPartial<RecognitionResponseMetadata>): RecognitionResponseMetadata {
    return RecognitionResponseMetadata.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<RecognitionResponseMetadata>): RecognitionResponseMetadata {
    const message = createBaseRecognitionResponseMetadata();
    message.requestId = object.requestId ?? "";
    message.totalBilledDuration = (object.totalBilledDuration !== undefined && object.totalBilledDuration !== null)
      ? Duration.fromPartial(object.totalBilledDuration)
      : undefined;
    return message;
  },
};

function createBaseSpeechRecognitionAlternative(): SpeechRecognitionAlternative {
  return { transcript: "", confidence: 0, words: [] };
}

export const SpeechRecognitionAlternative: MessageFns<SpeechRecognitionAlternative> = {
  encode(message: SpeechRecognitionAlternative, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.transcript !== "") {
      writer.uint32(10).string(message.transcript);
    }
    if (message.confidence !== 0) {
      writer.uint32(21).float(message.confidence);
    }
    for (const v of message.words) {
      WordInfo.encode(v!, writer.uint32(26).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): SpeechRecognitionAlternative {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseSpeechRecognitionAlternative();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.transcript = reader.string();
          continue;
        case 2:
          if (tag !== 21) {
            break;
          }

          message.confidence = reader.float();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.words.push(WordInfo.decode(reader, reader.uint32()));
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): SpeechRecognitionAlternative {
    return {
      transcript: isSet(object.transcript) ? globalThis.String(object.transcript) : "",
      confidence: isSet(object.confidence) ? globalThis.Number(object.confidence) : 0,
      words: globalThis.Array.isArray(object?.words) ? object.words.map((e: any) => WordInfo.fromJSON(e)) : [],
    };
  },

  toJSON(message: SpeechRecognitionAlternative): unknown {
    const obj: any = {};
    if (message.transcript !== "") {
      obj.transcript = message.transcript;
    }
    if (message.confidence !== 0) {
      obj.confidence = message.confidence;
    }
    if (message.words?.length) {
      obj.words = message.words.map((e) => WordInfo.toJSON(e));
    }
    return obj;
  },

  create(base?: DeepPartial<SpeechRecognitionAlternative>): SpeechRecognitionAlternative {
    return SpeechRecognitionAlternative.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<SpeechRecognitionAlternative>): SpeechRecognitionAlternative {
    const message = createBaseSpeechRecognitionAlternative();
    message.transcript = object.transcript ?? "";
    message.confidence = object.confidence ?? 0;
    message.words = object.words?.map((e) => WordInfo.fromPartial(e)) || [];
    return message;
  },
};

function createBaseWordInfo(): WordInfo {
  return { startOffset: undefined, endOffset: undefined, word: "", confidence: 0, speakerLabel: "" };
}

export const WordInfo: MessageFns<WordInfo> = {
  encode(message: WordInfo, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.startOffset !== undefined) {
      Duration.encode(message.startOffset, writer.uint32(10).fork()).join();
    }
    if (message.endOffset !== undefined) {
      Duration.encode(message.endOffset, writer.uint32(18).fork()).join();
    }
    if (message.word !== "") {
      writer.uint32(26).string(message.word);
    }
    if (message.confidence !== 0) {
      writer.uint32(37).float(message.confidence);
    }
    if (message.speakerLabel !== "") {
      writer.uint32(50).string(message.speakerLabel);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): WordInfo {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseWordInfo();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.startOffset = Duration.decode(reader, reader.uint32());
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.endOffset = Duration.decode(reader, reader.uint32());
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.word = reader.string();
          continue;
        case 4:
          if (tag !== 37) {
            break;
          }

          message.confidence = reader.float();
          continue;
        case 6:
          if (tag !== 50) {
            break;
          }

          message.speakerLabel = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): WordInfo {
    return {
      startOffset: isSet(object.startOffset) ? Duration.fromJSON(object.startOffset) : undefined,
      endOffset: isSet(object.endOffset) ? Duration.fromJSON(object.endOffset) : undefined,
      word: isSet(object.word) ? globalThis.String(object.word) : "",
      confidence: isSet(object.confidence) ? globalThis.Number(object.confidence) : 0,
      speakerLabel: isSet(object.speakerLabel) ? globalThis.String(object.speakerLabel) : "",
    };
  },

  toJSON(message: WordInfo): unknown {
    const obj: any = {};
    if (message.startOffset !== undefined) {
      obj.startOffset = Duration.toJSON(message.startOffset);
    }
    if (message.endOffset !== undefined) {
      obj.endOffset = Duration.toJSON(message.endOffset);
    }
    if (message.word !== "") {
      obj.word = message.word;
    }
    if (message.confidence !== 0) {
      obj.confidence = message.confidence;
    }
    if (message.speakerLabel !== "") {
      obj.speakerLabel = message.speakerLabel;
    }
    return obj;
  },

  create(base?: DeepPartial<WordInfo>): WordInfo {
    return WordInfo.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<WordInfo>): WordInfo {
    const message = createBaseWordInfo();
    message.startOffset = (object.startOffset !== undefined && object.startOffset !== null)
      ? Duration.fromPartial(object.startOffset)
      : undefined;
    message.endOffset = (object.endOffset !== undefined && object.endOffset !== null)
      ? Duration.fromPartial(object.endOffset)
      : undefined;
    message.word = object.word ?? "";
    message.confidence = object.confidence ?? 0;
    message.speakerLabel = object.speakerLabel ?? "";
    return message;
  },
};

function createBaseSpeechRecognitionResult(): SpeechRecognitionResult {
  return { alternatives: [], channelTag: 0, resultEndOffset: undefined, languageCode: "" };
}

export const SpeechRecognitionResult: MessageFns<SpeechRecognitionResult> = {
  encode(message: SpeechRecognitionResult, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.alternatives) {
      SpeechRecognitionAlternative.encode(v!, writer.uint32(10).fork()).join();
    }
    if (message.channelTag !== 0) {
      writer.uint32(16).int32(message.channelTag);
    }
    if (message.resultEndOffset !== undefined) {
      Duration.encode(message.resultEndOffset, writer.uint32(34).fork()).join();
    }
    if (message.languageCode !== "") {
      writer.uint32(42).string(message.languageCode);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): SpeechRecognitionResult {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseSpeechRecognitionResult();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.alternatives.push(SpeechRecognitionAlternative.decode(reader, reader.uint32()));
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.channelTag = reader.int32();
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.resultEndOffset = Duration.decode(reader, reader.uint32());
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.languageCode = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): SpeechRecognitionResult {
    return {
      alternatives: globalThis.Array.isArray(object?.alternatives)
        ? object.alternatives.map((e: any) => SpeechRecognitionAlternative.fromJSON(e))
        : [],
      channelTag: isSet(object.channelTag) ? globalThis.Number(object.channelTag) : 0,
      resultEndOffset: isSet(object.resultEndOffset) ? Duration.fromJSON(object.resultEndOffset) : undefined,
      languageCode: isSet(object.languageCode) ? globalThis.String(object.languageCode) : "",
    };
  },

  toJSON(message: SpeechRecognitionResult): unknown {
    const obj: any = {};
    if (message.alternatives?.length) {
      obj.alternatives = message.alternatives.map((e) => SpeechRecognitionAlternative.toJSON(e));
    }
    if (message.channelTag !== 0) {
      obj.channelTag = Math.round(message.channelTag);
    }
    if (message.resultEndOffset !== undefined) {
      obj.resultEndOffset = Duration.toJSON(message.resultEndOffset);
    }
    if (message.languageCode !== "") {
      obj.languageCode = message.languageCode;
    }
    return obj;
  },

  create(base?: DeepPartial<SpeechRecognitionResult>): SpeechRecognitionResult {
    return SpeechRecognitionResult.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<SpeechRecognitionResult>): SpeechRecognitionResult {
    const message = createBaseSpeechRecognitionResult();
    message.alternatives = object.alternatives?.map((e) => SpeechRecognitionAlternative.fromPartial(e)) || [];
    message.channelTag = object.channelTag ?? 0;
    message.resultEndOffset = (object.resultEndOffset !== undefined && object.resultEndOffset !== null)
      ? Duration.fromPartial(object.resultEndOffset)
      : undefined;
    message.languageCode = object.languageCode ?? "";
    return message;
  },
};

function createBaseRecognizeResponse(): RecognizeResponse {
  return { results: [], metadata: undefined };
}

export const RecognizeResponse: MessageFns<RecognizeResponse> = {
  encode(message: RecognizeResponse, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.results) {
      SpeechRecognitionResult.encode(v!, writer.uint32(26).fork()).join();
    }
    if (message.metadata !== undefined) {
      RecognitionResponseMetadata.encode(message.metadata, writer.uint32(18).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): RecognizeResponse {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseRecognizeResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 3:
          if (tag !== 26) {
            break;
          }

          message.results.push(SpeechRecognitionResult.decode(reader, reader.uint32()));
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.metadata = RecognitionResponseMetadata.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): RecognizeResponse {
    return {
      results: globalThis.Array.isArray(object?.results)
        ? object.results.map((e: any) => SpeechRecognitionResult.fromJSON(e))
        : [],
      metadata: isSet(object.metadata) ? RecognitionResponseMetadata.fromJSON(object.metadata) : undefined,
    };
  },

  toJSON(message: RecognizeResponse): unknown {
    const obj: any = {};
    if (message.results?.length) {
      obj.results = message.results.map((e) => SpeechRecognitionResult.toJSON(e));
    }
    if (message.metadata !== undefined) {
      obj.metadata = RecognitionResponseMetadata.toJSON(message.metadata);
    }
    return obj;
  },

  create(base?: DeepPartial<RecognizeResponse>): RecognizeResponse {
    return RecognizeResponse.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<RecognizeResponse>): RecognizeResponse {
    const message = createBaseRecognizeResponse();
    message.results = object.results?.map((e) => SpeechRecognitionResult.fromPartial(e)) || [];
    message.metadata = (object.metadata !== undefined && object.metadata !== null)
      ? RecognitionResponseMetadata.fromPartial(object.metadata)
      : undefined;
    return message;
  },
};

function createBaseStreamingRecognitionFeatures(): StreamingRecognitionFeatures {
  return { enableVoiceActivityEvents: false, interimResults: false, voiceActivityTimeout: undefined };
}

export const StreamingRecognitionFeatures: MessageFns<StreamingRecognitionFeatures> = {
  encode(message: StreamingRecognitionFeatures, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.enableVoiceActivityEvents !== false) {
      writer.uint32(8).bool(message.enableVoiceActivityEvents);
    }
    if (message.interimResults !== false) {
      writer.uint32(16).bool(message.interimResults);
    }
    if (message.voiceActivityTimeout !== undefined) {
      StreamingRecognitionFeatures_VoiceActivityTimeout.encode(message.voiceActivityTimeout, writer.uint32(26).fork())
        .join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): StreamingRecognitionFeatures {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseStreamingRecognitionFeatures();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 8) {
            break;
          }

          message.enableVoiceActivityEvents = reader.bool();
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.interimResults = reader.bool();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.voiceActivityTimeout = StreamingRecognitionFeatures_VoiceActivityTimeout.decode(
            reader,
            reader.uint32(),
          );
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): StreamingRecognitionFeatures {
    return {
      enableVoiceActivityEvents: isSet(object.enableVoiceActivityEvents)
        ? globalThis.Boolean(object.enableVoiceActivityEvents)
        : false,
      interimResults: isSet(object.interimResults) ? globalThis.Boolean(object.interimResults) : false,
      voiceActivityTimeout: isSet(object.voiceActivityTimeout)
        ? StreamingRecognitionFeatures_VoiceActivityTimeout.fromJSON(object.voiceActivityTimeout)
        : undefined,
    };
  },

  toJSON(message: StreamingRecognitionFeatures): unknown {
    const obj: any = {};
    if (message.enableVoiceActivityEvents !== false) {
      obj.enableVoiceActivityEvents = message.enableVoiceActivityEvents;
    }
    if (message.interimResults !== false) {
      obj.interimResults = message.interimResults;
    }
    if (message.voiceActivityTimeout !== undefined) {
      obj.voiceActivityTimeout = StreamingRecognitionFeatures_VoiceActivityTimeout.toJSON(message.voiceActivityTimeout);
    }
    return obj;
  },

  create(base?: DeepPartial<StreamingRecognitionFeatures>): StreamingRecognitionFeatures {
    return StreamingRecognitionFeatures.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<StreamingRecognitionFeatures>): StreamingRecognitionFeatures {
    const message = createBaseStreamingRecognitionFeatures();
    message.enableVoiceActivityEvents = object.enableVoiceActivityEvents ?? false;
    message.interimResults = object.interimResults ?? false;
    message.voiceActivityTimeout = (object.voiceActivityTimeout !== undefined && object.voiceActivityTimeout !== null)
      ? StreamingRecognitionFeatures_VoiceActivityTimeout.fromPartial(object.voiceActivityTimeout)
      : undefined;
    return message;
  },
};

function createBaseStreamingRecognitionFeatures_VoiceActivityTimeout(): StreamingRecognitionFeatures_VoiceActivityTimeout {
  return { speechStartTimeout: undefined, speechEndTimeout: undefined };
}

export const StreamingRecognitionFeatures_VoiceActivityTimeout: MessageFns<
  StreamingRecognitionFeatures_VoiceActivityTimeout
> = {
  encode(
    message: StreamingRecognitionFeatures_VoiceActivityTimeout,
    writer: BinaryWriter = new BinaryWriter(),
  ): BinaryWriter {
    if (message.speechStartTimeout !== undefined) {
      Duration.encode(message.speechStartTimeout, writer.uint32(10).fork()).join();
    }
    if (message.speechEndTimeout !== undefined) {
      Duration.encode(message.speechEndTimeout, writer.uint32(18).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): StreamingRecognitionFeatures_VoiceActivityTimeout {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseStreamingRecognitionFeatures_VoiceActivityTimeout();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.speechStartTimeout = Duration.decode(reader, reader.uint32());
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.speechEndTimeout = Duration.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): StreamingRecognitionFeatures_VoiceActivityTimeout {
    return {
      speechStartTimeout: isSet(object.speechStartTimeout) ? Duration.fromJSON(object.speechStartTimeout) : undefined,
      speechEndTimeout: isSet(object.speechEndTimeout) ? Duration.fromJSON(object.speechEndTimeout) : undefined,
    };
  },

  toJSON(message: StreamingRecognitionFeatures_VoiceActivityTimeout): unknown {
    const obj: any = {};
    if (message.speechStartTimeout !== undefined) {
      obj.speechStartTimeout = Duration.toJSON(message.speechStartTimeout);
    }
    if (message.speechEndTimeout !== undefined) {
      obj.speechEndTimeout = Duration.toJSON(message.speechEndTimeout);
    }
    return obj;
  },

  create(
    base?: DeepPartial<StreamingRecognitionFeatures_VoiceActivityTimeout>,
  ): StreamingRecognitionFeatures_VoiceActivityTimeout {
    return StreamingRecognitionFeatures_VoiceActivityTimeout.fromPartial(base ?? {});
  },
  fromPartial(
    object: DeepPartial<StreamingRecognitionFeatures_VoiceActivityTimeout>,
  ): StreamingRecognitionFeatures_VoiceActivityTimeout {
    const message = createBaseStreamingRecognitionFeatures_VoiceActivityTimeout();
    message.speechStartTimeout = (object.speechStartTimeout !== undefined && object.speechStartTimeout !== null)
      ? Duration.fromPartial(object.speechStartTimeout)
      : undefined;
    message.speechEndTimeout = (object.speechEndTimeout !== undefined && object.speechEndTimeout !== null)
      ? Duration.fromPartial(object.speechEndTimeout)
      : undefined;
    return message;
  },
};

function createBaseStreamingRecognitionConfig(): StreamingRecognitionConfig {
  return { config: undefined, configMask: undefined, streamingFeatures: undefined };
}

export const StreamingRecognitionConfig: MessageFns<StreamingRecognitionConfig> = {
  encode(message: StreamingRecognitionConfig, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.config !== undefined) {
      RecognitionConfig.encode(message.config, writer.uint32(10).fork()).join();
    }
    if (message.configMask !== undefined) {
      FieldMask.encode(FieldMask.wrap(message.configMask), writer.uint32(26).fork()).join();
    }
    if (message.streamingFeatures !== undefined) {
      StreamingRecognitionFeatures.encode(message.streamingFeatures, writer.uint32(18).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): StreamingRecognitionConfig {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseStreamingRecognitionConfig();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.config = RecognitionConfig.decode(reader, reader.uint32());
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.configMask = FieldMask.unwrap(FieldMask.decode(reader, reader.uint32()));
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.streamingFeatures = StreamingRecognitionFeatures.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): StreamingRecognitionConfig {
    return {
      config: isSet(object.config) ? RecognitionConfig.fromJSON(object.config) : undefined,
      configMask: isSet(object.configMask) ? FieldMask.unwrap(FieldMask.fromJSON(object.configMask)) : undefined,
      streamingFeatures: isSet(object.streamingFeatures)
        ? StreamingRecognitionFeatures.fromJSON(object.streamingFeatures)
        : undefined,
    };
  },

  toJSON(message: StreamingRecognitionConfig): unknown {
    const obj: any = {};
    if (message.config !== undefined) {
      obj.config = RecognitionConfig.toJSON(message.config);
    }
    if (message.configMask !== undefined) {
      obj.configMask = FieldMask.toJSON(FieldMask.wrap(message.configMask));
    }
    if (message.streamingFeatures !== undefined) {
      obj.streamingFeatures = StreamingRecognitionFeatures.toJSON(message.streamingFeatures);
    }
    return obj;
  },

  create(base?: DeepPartial<StreamingRecognitionConfig>): StreamingRecognitionConfig {
    return StreamingRecognitionConfig.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<StreamingRecognitionConfig>): StreamingRecognitionConfig {
    const message = createBaseStreamingRecognitionConfig();
    message.config = (object.config !== undefined && object.config !== null)
      ? RecognitionConfig.fromPartial(object.config)
      : undefined;
    message.configMask = object.configMask ?? undefined;
    message.streamingFeatures = (object.streamingFeatures !== undefined && object.streamingFeatures !== null)
      ? StreamingRecognitionFeatures.fromPartial(object.streamingFeatures)
      : undefined;
    return message;
  },
};

function createBaseStreamingRecognizeRequest(): StreamingRecognizeRequest {
  return { recognizer: "", streamingConfig: undefined, audio: undefined };
}

export const StreamingRecognizeRequest: MessageFns<StreamingRecognizeRequest> = {
  encode(message: StreamingRecognizeRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.recognizer !== "") {
      writer.uint32(26).string(message.recognizer);
    }
    if (message.streamingConfig !== undefined) {
      StreamingRecognitionConfig.encode(message.streamingConfig, writer.uint32(50).fork()).join();
    }
    if (message.audio !== undefined) {
      writer.uint32(42).bytes(message.audio);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): StreamingRecognizeRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseStreamingRecognizeRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 3:
          if (tag !== 26) {
            break;
          }

          message.recognizer = reader.string();
          continue;
        case 6:
          if (tag !== 50) {
            break;
          }

          message.streamingConfig = StreamingRecognitionConfig.decode(reader, reader.uint32());
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.audio = Buffer.from(reader.bytes());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): StreamingRecognizeRequest {
    return {
      recognizer: isSet(object.recognizer) ? globalThis.String(object.recognizer) : "",
      streamingConfig: isSet(object.streamingConfig)
        ? StreamingRecognitionConfig.fromJSON(object.streamingConfig)
        : undefined,
      audio: isSet(object.audio) ? Buffer.from(bytesFromBase64(object.audio)) : undefined,
    };
  },

  toJSON(message: StreamingRecognizeRequest): unknown {
    const obj: any = {};
    if (message.recognizer !== "") {
      obj.recognizer = message.recognizer;
    }
    if (message.streamingConfig !== undefined) {
      obj.streamingConfig = StreamingRecognitionConfig.toJSON(message.streamingConfig);
    }
    if (message.audio !== undefined) {
      obj.audio = base64FromBytes(message.audio);
    }
    return obj;
  },

  create(base?: DeepPartial<StreamingRecognizeRequest>): StreamingRecognizeRequest {
    return StreamingRecognizeRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<StreamingRecognizeRequest>): StreamingRecognizeRequest {
    const message = createBaseStreamingRecognizeRequest();
    message.recognizer = object.recognizer ?? "";
    message.streamingConfig = (object.streamingConfig !== undefined && object.streamingConfig !== null)
      ? StreamingRecognitionConfig.fromPartial(object.streamingConfig)
      : undefined;
    message.audio = object.audio ?? undefined;
    return message;
  },
};

function createBaseBatchRecognizeRequest(): BatchRecognizeRequest {
  return {
    recognizer: "",
    config: undefined,
    configMask: undefined,
    files: [],
    recognitionOutputConfig: undefined,
    processingStrategy: 0,
  };
}

export const BatchRecognizeRequest: MessageFns<BatchRecognizeRequest> = {
  encode(message: BatchRecognizeRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.recognizer !== "") {
      writer.uint32(10).string(message.recognizer);
    }
    if (message.config !== undefined) {
      RecognitionConfig.encode(message.config, writer.uint32(34).fork()).join();
    }
    if (message.configMask !== undefined) {
      FieldMask.encode(FieldMask.wrap(message.configMask), writer.uint32(42).fork()).join();
    }
    for (const v of message.files) {
      BatchRecognizeFileMetadata.encode(v!, writer.uint32(26).fork()).join();
    }
    if (message.recognitionOutputConfig !== undefined) {
      RecognitionOutputConfig.encode(message.recognitionOutputConfig, writer.uint32(50).fork()).join();
    }
    if (message.processingStrategy !== 0) {
      writer.uint32(56).int32(message.processingStrategy);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): BatchRecognizeRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseBatchRecognizeRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.recognizer = reader.string();
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.config = RecognitionConfig.decode(reader, reader.uint32());
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.configMask = FieldMask.unwrap(FieldMask.decode(reader, reader.uint32()));
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.files.push(BatchRecognizeFileMetadata.decode(reader, reader.uint32()));
          continue;
        case 6:
          if (tag !== 50) {
            break;
          }

          message.recognitionOutputConfig = RecognitionOutputConfig.decode(reader, reader.uint32());
          continue;
        case 7:
          if (tag !== 56) {
            break;
          }

          message.processingStrategy = reader.int32() as any;
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): BatchRecognizeRequest {
    return {
      recognizer: isSet(object.recognizer) ? globalThis.String(object.recognizer) : "",
      config: isSet(object.config) ? RecognitionConfig.fromJSON(object.config) : undefined,
      configMask: isSet(object.configMask) ? FieldMask.unwrap(FieldMask.fromJSON(object.configMask)) : undefined,
      files: globalThis.Array.isArray(object?.files)
        ? object.files.map((e: any) => BatchRecognizeFileMetadata.fromJSON(e))
        : [],
      recognitionOutputConfig: isSet(object.recognitionOutputConfig)
        ? RecognitionOutputConfig.fromJSON(object.recognitionOutputConfig)
        : undefined,
      processingStrategy: isSet(object.processingStrategy)
        ? batchRecognizeRequest_ProcessingStrategyFromJSON(object.processingStrategy)
        : 0,
    };
  },

  toJSON(message: BatchRecognizeRequest): unknown {
    const obj: any = {};
    if (message.recognizer !== "") {
      obj.recognizer = message.recognizer;
    }
    if (message.config !== undefined) {
      obj.config = RecognitionConfig.toJSON(message.config);
    }
    if (message.configMask !== undefined) {
      obj.configMask = FieldMask.toJSON(FieldMask.wrap(message.configMask));
    }
    if (message.files?.length) {
      obj.files = message.files.map((e) => BatchRecognizeFileMetadata.toJSON(e));
    }
    if (message.recognitionOutputConfig !== undefined) {
      obj.recognitionOutputConfig = RecognitionOutputConfig.toJSON(message.recognitionOutputConfig);
    }
    if (message.processingStrategy !== 0) {
      obj.processingStrategy = batchRecognizeRequest_ProcessingStrategyToJSON(message.processingStrategy);
    }
    return obj;
  },

  create(base?: DeepPartial<BatchRecognizeRequest>): BatchRecognizeRequest {
    return BatchRecognizeRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<BatchRecognizeRequest>): BatchRecognizeRequest {
    const message = createBaseBatchRecognizeRequest();
    message.recognizer = object.recognizer ?? "";
    message.config = (object.config !== undefined && object.config !== null)
      ? RecognitionConfig.fromPartial(object.config)
      : undefined;
    message.configMask = object.configMask ?? undefined;
    message.files = object.files?.map((e) => BatchRecognizeFileMetadata.fromPartial(e)) || [];
    message.recognitionOutputConfig =
      (object.recognitionOutputConfig !== undefined && object.recognitionOutputConfig !== null)
        ? RecognitionOutputConfig.fromPartial(object.recognitionOutputConfig)
        : undefined;
    message.processingStrategy = object.processingStrategy ?? 0;
    return message;
  },
};

function createBaseGcsOutputConfig(): GcsOutputConfig {
  return { uri: "" };
}

export const GcsOutputConfig: MessageFns<GcsOutputConfig> = {
  encode(message: GcsOutputConfig, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.uri !== "") {
      writer.uint32(10).string(message.uri);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): GcsOutputConfig {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseGcsOutputConfig();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.uri = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): GcsOutputConfig {
    return { uri: isSet(object.uri) ? globalThis.String(object.uri) : "" };
  },

  toJSON(message: GcsOutputConfig): unknown {
    const obj: any = {};
    if (message.uri !== "") {
      obj.uri = message.uri;
    }
    return obj;
  },

  create(base?: DeepPartial<GcsOutputConfig>): GcsOutputConfig {
    return GcsOutputConfig.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<GcsOutputConfig>): GcsOutputConfig {
    const message = createBaseGcsOutputConfig();
    message.uri = object.uri ?? "";
    return message;
  },
};

function createBaseInlineOutputConfig(): InlineOutputConfig {
  return {};
}

export const InlineOutputConfig: MessageFns<InlineOutputConfig> = {
  encode(_: InlineOutputConfig, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): InlineOutputConfig {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseInlineOutputConfig();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(_: any): InlineOutputConfig {
    return {};
  },

  toJSON(_: InlineOutputConfig): unknown {
    const obj: any = {};
    return obj;
  },

  create(base?: DeepPartial<InlineOutputConfig>): InlineOutputConfig {
    return InlineOutputConfig.fromPartial(base ?? {});
  },
  fromPartial(_: DeepPartial<InlineOutputConfig>): InlineOutputConfig {
    const message = createBaseInlineOutputConfig();
    return message;
  },
};

function createBaseNativeOutputFileFormatConfig(): NativeOutputFileFormatConfig {
  return {};
}

export const NativeOutputFileFormatConfig: MessageFns<NativeOutputFileFormatConfig> = {
  encode(_: NativeOutputFileFormatConfig, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): NativeOutputFileFormatConfig {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseNativeOutputFileFormatConfig();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(_: any): NativeOutputFileFormatConfig {
    return {};
  },

  toJSON(_: NativeOutputFileFormatConfig): unknown {
    const obj: any = {};
    return obj;
  },

  create(base?: DeepPartial<NativeOutputFileFormatConfig>): NativeOutputFileFormatConfig {
    return NativeOutputFileFormatConfig.fromPartial(base ?? {});
  },
  fromPartial(_: DeepPartial<NativeOutputFileFormatConfig>): NativeOutputFileFormatConfig {
    const message = createBaseNativeOutputFileFormatConfig();
    return message;
  },
};

function createBaseVttOutputFileFormatConfig(): VttOutputFileFormatConfig {
  return {};
}

export const VttOutputFileFormatConfig: MessageFns<VttOutputFileFormatConfig> = {
  encode(_: VttOutputFileFormatConfig, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): VttOutputFileFormatConfig {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseVttOutputFileFormatConfig();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(_: any): VttOutputFileFormatConfig {
    return {};
  },

  toJSON(_: VttOutputFileFormatConfig): unknown {
    const obj: any = {};
    return obj;
  },

  create(base?: DeepPartial<VttOutputFileFormatConfig>): VttOutputFileFormatConfig {
    return VttOutputFileFormatConfig.fromPartial(base ?? {});
  },
  fromPartial(_: DeepPartial<VttOutputFileFormatConfig>): VttOutputFileFormatConfig {
    const message = createBaseVttOutputFileFormatConfig();
    return message;
  },
};

function createBaseSrtOutputFileFormatConfig(): SrtOutputFileFormatConfig {
  return {};
}

export const SrtOutputFileFormatConfig: MessageFns<SrtOutputFileFormatConfig> = {
  encode(_: SrtOutputFileFormatConfig, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): SrtOutputFileFormatConfig {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseSrtOutputFileFormatConfig();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(_: any): SrtOutputFileFormatConfig {
    return {};
  },

  toJSON(_: SrtOutputFileFormatConfig): unknown {
    const obj: any = {};
    return obj;
  },

  create(base?: DeepPartial<SrtOutputFileFormatConfig>): SrtOutputFileFormatConfig {
    return SrtOutputFileFormatConfig.fromPartial(base ?? {});
  },
  fromPartial(_: DeepPartial<SrtOutputFileFormatConfig>): SrtOutputFileFormatConfig {
    const message = createBaseSrtOutputFileFormatConfig();
    return message;
  },
};

function createBaseOutputFormatConfig(): OutputFormatConfig {
  return { native: undefined, vtt: undefined, srt: undefined };
}

export const OutputFormatConfig: MessageFns<OutputFormatConfig> = {
  encode(message: OutputFormatConfig, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.native !== undefined) {
      NativeOutputFileFormatConfig.encode(message.native, writer.uint32(10).fork()).join();
    }
    if (message.vtt !== undefined) {
      VttOutputFileFormatConfig.encode(message.vtt, writer.uint32(18).fork()).join();
    }
    if (message.srt !== undefined) {
      SrtOutputFileFormatConfig.encode(message.srt, writer.uint32(26).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): OutputFormatConfig {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseOutputFormatConfig();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.native = NativeOutputFileFormatConfig.decode(reader, reader.uint32());
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.vtt = VttOutputFileFormatConfig.decode(reader, reader.uint32());
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.srt = SrtOutputFileFormatConfig.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): OutputFormatConfig {
    return {
      native: isSet(object.native) ? NativeOutputFileFormatConfig.fromJSON(object.native) : undefined,
      vtt: isSet(object.vtt) ? VttOutputFileFormatConfig.fromJSON(object.vtt) : undefined,
      srt: isSet(object.srt) ? SrtOutputFileFormatConfig.fromJSON(object.srt) : undefined,
    };
  },

  toJSON(message: OutputFormatConfig): unknown {
    const obj: any = {};
    if (message.native !== undefined) {
      obj.native = NativeOutputFileFormatConfig.toJSON(message.native);
    }
    if (message.vtt !== undefined) {
      obj.vtt = VttOutputFileFormatConfig.toJSON(message.vtt);
    }
    if (message.srt !== undefined) {
      obj.srt = SrtOutputFileFormatConfig.toJSON(message.srt);
    }
    return obj;
  },

  create(base?: DeepPartial<OutputFormatConfig>): OutputFormatConfig {
    return OutputFormatConfig.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<OutputFormatConfig>): OutputFormatConfig {
    const message = createBaseOutputFormatConfig();
    message.native = (object.native !== undefined && object.native !== null)
      ? NativeOutputFileFormatConfig.fromPartial(object.native)
      : undefined;
    message.vtt = (object.vtt !== undefined && object.vtt !== null)
      ? VttOutputFileFormatConfig.fromPartial(object.vtt)
      : undefined;
    message.srt = (object.srt !== undefined && object.srt !== null)
      ? SrtOutputFileFormatConfig.fromPartial(object.srt)
      : undefined;
    return message;
  },
};

function createBaseRecognitionOutputConfig(): RecognitionOutputConfig {
  return { gcsOutputConfig: undefined, inlineResponseConfig: undefined, outputFormatConfig: undefined };
}

export const RecognitionOutputConfig: MessageFns<RecognitionOutputConfig> = {
  encode(message: RecognitionOutputConfig, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.gcsOutputConfig !== undefined) {
      GcsOutputConfig.encode(message.gcsOutputConfig, writer.uint32(10).fork()).join();
    }
    if (message.inlineResponseConfig !== undefined) {
      InlineOutputConfig.encode(message.inlineResponseConfig, writer.uint32(18).fork()).join();
    }
    if (message.outputFormatConfig !== undefined) {
      OutputFormatConfig.encode(message.outputFormatConfig, writer.uint32(26).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): RecognitionOutputConfig {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseRecognitionOutputConfig();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.gcsOutputConfig = GcsOutputConfig.decode(reader, reader.uint32());
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.inlineResponseConfig = InlineOutputConfig.decode(reader, reader.uint32());
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.outputFormatConfig = OutputFormatConfig.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): RecognitionOutputConfig {
    return {
      gcsOutputConfig: isSet(object.gcsOutputConfig) ? GcsOutputConfig.fromJSON(object.gcsOutputConfig) : undefined,
      inlineResponseConfig: isSet(object.inlineResponseConfig)
        ? InlineOutputConfig.fromJSON(object.inlineResponseConfig)
        : undefined,
      outputFormatConfig: isSet(object.outputFormatConfig)
        ? OutputFormatConfig.fromJSON(object.outputFormatConfig)
        : undefined,
    };
  },

  toJSON(message: RecognitionOutputConfig): unknown {
    const obj: any = {};
    if (message.gcsOutputConfig !== undefined) {
      obj.gcsOutputConfig = GcsOutputConfig.toJSON(message.gcsOutputConfig);
    }
    if (message.inlineResponseConfig !== undefined) {
      obj.inlineResponseConfig = InlineOutputConfig.toJSON(message.inlineResponseConfig);
    }
    if (message.outputFormatConfig !== undefined) {
      obj.outputFormatConfig = OutputFormatConfig.toJSON(message.outputFormatConfig);
    }
    return obj;
  },

  create(base?: DeepPartial<RecognitionOutputConfig>): RecognitionOutputConfig {
    return RecognitionOutputConfig.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<RecognitionOutputConfig>): RecognitionOutputConfig {
    const message = createBaseRecognitionOutputConfig();
    message.gcsOutputConfig = (object.gcsOutputConfig !== undefined && object.gcsOutputConfig !== null)
      ? GcsOutputConfig.fromPartial(object.gcsOutputConfig)
      : undefined;
    message.inlineResponseConfig = (object.inlineResponseConfig !== undefined && object.inlineResponseConfig !== null)
      ? InlineOutputConfig.fromPartial(object.inlineResponseConfig)
      : undefined;
    message.outputFormatConfig = (object.outputFormatConfig !== undefined && object.outputFormatConfig !== null)
      ? OutputFormatConfig.fromPartial(object.outputFormatConfig)
      : undefined;
    return message;
  },
};

function createBaseBatchRecognizeResponse(): BatchRecognizeResponse {
  return { results: {}, totalBilledDuration: undefined };
}

export const BatchRecognizeResponse: MessageFns<BatchRecognizeResponse> = {
  encode(message: BatchRecognizeResponse, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    Object.entries(message.results).forEach(([key, value]) => {
      BatchRecognizeResponse_ResultsEntry.encode({ key: key as any, value }, writer.uint32(10).fork()).join();
    });
    if (message.totalBilledDuration !== undefined) {
      Duration.encode(message.totalBilledDuration, writer.uint32(18).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): BatchRecognizeResponse {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseBatchRecognizeResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          const entry1 = BatchRecognizeResponse_ResultsEntry.decode(reader, reader.uint32());
          if (entry1.value !== undefined) {
            message.results[entry1.key] = entry1.value;
          }
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.totalBilledDuration = Duration.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): BatchRecognizeResponse {
    return {
      results: isObject(object.results)
        ? Object.entries(object.results).reduce<{ [key: string]: BatchRecognizeFileResult }>((acc, [key, value]) => {
          acc[key] = BatchRecognizeFileResult.fromJSON(value);
          return acc;
        }, {})
        : {},
      totalBilledDuration: isSet(object.totalBilledDuration)
        ? Duration.fromJSON(object.totalBilledDuration)
        : undefined,
    };
  },

  toJSON(message: BatchRecognizeResponse): unknown {
    const obj: any = {};
    if (message.results) {
      const entries = Object.entries(message.results);
      if (entries.length > 0) {
        obj.results = {};
        entries.forEach(([k, v]) => {
          obj.results[k] = BatchRecognizeFileResult.toJSON(v);
        });
      }
    }
    if (message.totalBilledDuration !== undefined) {
      obj.totalBilledDuration = Duration.toJSON(message.totalBilledDuration);
    }
    return obj;
  },

  create(base?: DeepPartial<BatchRecognizeResponse>): BatchRecognizeResponse {
    return BatchRecognizeResponse.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<BatchRecognizeResponse>): BatchRecognizeResponse {
    const message = createBaseBatchRecognizeResponse();
    message.results = Object.entries(object.results ?? {}).reduce<{ [key: string]: BatchRecognizeFileResult }>(
      (acc, [key, value]) => {
        if (value !== undefined) {
          acc[key] = BatchRecognizeFileResult.fromPartial(value);
        }
        return acc;
      },
      {},
    );
    message.totalBilledDuration = (object.totalBilledDuration !== undefined && object.totalBilledDuration !== null)
      ? Duration.fromPartial(object.totalBilledDuration)
      : undefined;
    return message;
  },
};

function createBaseBatchRecognizeResponse_ResultsEntry(): BatchRecognizeResponse_ResultsEntry {
  return { key: "", value: undefined };
}

export const BatchRecognizeResponse_ResultsEntry: MessageFns<BatchRecognizeResponse_ResultsEntry> = {
  encode(message: BatchRecognizeResponse_ResultsEntry, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.key !== "") {
      writer.uint32(10).string(message.key);
    }
    if (message.value !== undefined) {
      BatchRecognizeFileResult.encode(message.value, writer.uint32(18).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): BatchRecognizeResponse_ResultsEntry {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseBatchRecognizeResponse_ResultsEntry();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.key = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.value = BatchRecognizeFileResult.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): BatchRecognizeResponse_ResultsEntry {
    return {
      key: isSet(object.key) ? globalThis.String(object.key) : "",
      value: isSet(object.value) ? BatchRecognizeFileResult.fromJSON(object.value) : undefined,
    };
  },

  toJSON(message: BatchRecognizeResponse_ResultsEntry): unknown {
    const obj: any = {};
    if (message.key !== "") {
      obj.key = message.key;
    }
    if (message.value !== undefined) {
      obj.value = BatchRecognizeFileResult.toJSON(message.value);
    }
    return obj;
  },

  create(base?: DeepPartial<BatchRecognizeResponse_ResultsEntry>): BatchRecognizeResponse_ResultsEntry {
    return BatchRecognizeResponse_ResultsEntry.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<BatchRecognizeResponse_ResultsEntry>): BatchRecognizeResponse_ResultsEntry {
    const message = createBaseBatchRecognizeResponse_ResultsEntry();
    message.key = object.key ?? "";
    message.value = (object.value !== undefined && object.value !== null)
      ? BatchRecognizeFileResult.fromPartial(object.value)
      : undefined;
    return message;
  },
};

function createBaseBatchRecognizeResults(): BatchRecognizeResults {
  return { results: [], metadata: undefined };
}

export const BatchRecognizeResults: MessageFns<BatchRecognizeResults> = {
  encode(message: BatchRecognizeResults, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.results) {
      SpeechRecognitionResult.encode(v!, writer.uint32(10).fork()).join();
    }
    if (message.metadata !== undefined) {
      RecognitionResponseMetadata.encode(message.metadata, writer.uint32(18).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): BatchRecognizeResults {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseBatchRecognizeResults();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.results.push(SpeechRecognitionResult.decode(reader, reader.uint32()));
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.metadata = RecognitionResponseMetadata.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): BatchRecognizeResults {
    return {
      results: globalThis.Array.isArray(object?.results)
        ? object.results.map((e: any) => SpeechRecognitionResult.fromJSON(e))
        : [],
      metadata: isSet(object.metadata) ? RecognitionResponseMetadata.fromJSON(object.metadata) : undefined,
    };
  },

  toJSON(message: BatchRecognizeResults): unknown {
    const obj: any = {};
    if (message.results?.length) {
      obj.results = message.results.map((e) => SpeechRecognitionResult.toJSON(e));
    }
    if (message.metadata !== undefined) {
      obj.metadata = RecognitionResponseMetadata.toJSON(message.metadata);
    }
    return obj;
  },

  create(base?: DeepPartial<BatchRecognizeResults>): BatchRecognizeResults {
    return BatchRecognizeResults.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<BatchRecognizeResults>): BatchRecognizeResults {
    const message = createBaseBatchRecognizeResults();
    message.results = object.results?.map((e) => SpeechRecognitionResult.fromPartial(e)) || [];
    message.metadata = (object.metadata !== undefined && object.metadata !== null)
      ? RecognitionResponseMetadata.fromPartial(object.metadata)
      : undefined;
    return message;
  },
};

function createBaseCloudStorageResult(): CloudStorageResult {
  return { uri: "", vttFormatUri: "", srtFormatUri: "" };
}

export const CloudStorageResult: MessageFns<CloudStorageResult> = {
  encode(message: CloudStorageResult, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.uri !== "") {
      writer.uint32(10).string(message.uri);
    }
    if (message.vttFormatUri !== "") {
      writer.uint32(18).string(message.vttFormatUri);
    }
    if (message.srtFormatUri !== "") {
      writer.uint32(26).string(message.srtFormatUri);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): CloudStorageResult {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseCloudStorageResult();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.uri = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.vttFormatUri = reader.string();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.srtFormatUri = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): CloudStorageResult {
    return {
      uri: isSet(object.uri) ? globalThis.String(object.uri) : "",
      vttFormatUri: isSet(object.vttFormatUri) ? globalThis.String(object.vttFormatUri) : "",
      srtFormatUri: isSet(object.srtFormatUri) ? globalThis.String(object.srtFormatUri) : "",
    };
  },

  toJSON(message: CloudStorageResult): unknown {
    const obj: any = {};
    if (message.uri !== "") {
      obj.uri = message.uri;
    }
    if (message.vttFormatUri !== "") {
      obj.vttFormatUri = message.vttFormatUri;
    }
    if (message.srtFormatUri !== "") {
      obj.srtFormatUri = message.srtFormatUri;
    }
    return obj;
  },

  create(base?: DeepPartial<CloudStorageResult>): CloudStorageResult {
    return CloudStorageResult.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<CloudStorageResult>): CloudStorageResult {
    const message = createBaseCloudStorageResult();
    message.uri = object.uri ?? "";
    message.vttFormatUri = object.vttFormatUri ?? "";
    message.srtFormatUri = object.srtFormatUri ?? "";
    return message;
  },
};

function createBaseInlineResult(): InlineResult {
  return { transcript: undefined, vttCaptions: "", srtCaptions: "" };
}

export const InlineResult: MessageFns<InlineResult> = {
  encode(message: InlineResult, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.transcript !== undefined) {
      BatchRecognizeResults.encode(message.transcript, writer.uint32(10).fork()).join();
    }
    if (message.vttCaptions !== "") {
      writer.uint32(18).string(message.vttCaptions);
    }
    if (message.srtCaptions !== "") {
      writer.uint32(26).string(message.srtCaptions);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): InlineResult {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseInlineResult();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.transcript = BatchRecognizeResults.decode(reader, reader.uint32());
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.vttCaptions = reader.string();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.srtCaptions = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): InlineResult {
    return {
      transcript: isSet(object.transcript) ? BatchRecognizeResults.fromJSON(object.transcript) : undefined,
      vttCaptions: isSet(object.vttCaptions) ? globalThis.String(object.vttCaptions) : "",
      srtCaptions: isSet(object.srtCaptions) ? globalThis.String(object.srtCaptions) : "",
    };
  },

  toJSON(message: InlineResult): unknown {
    const obj: any = {};
    if (message.transcript !== undefined) {
      obj.transcript = BatchRecognizeResults.toJSON(message.transcript);
    }
    if (message.vttCaptions !== "") {
      obj.vttCaptions = message.vttCaptions;
    }
    if (message.srtCaptions !== "") {
      obj.srtCaptions = message.srtCaptions;
    }
    return obj;
  },

  create(base?: DeepPartial<InlineResult>): InlineResult {
    return InlineResult.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<InlineResult>): InlineResult {
    const message = createBaseInlineResult();
    message.transcript = (object.transcript !== undefined && object.transcript !== null)
      ? BatchRecognizeResults.fromPartial(object.transcript)
      : undefined;
    message.vttCaptions = object.vttCaptions ?? "";
    message.srtCaptions = object.srtCaptions ?? "";
    return message;
  },
};

function createBaseBatchRecognizeFileResult(): BatchRecognizeFileResult {
  return {
    error: undefined,
    metadata: undefined,
    cloudStorageResult: undefined,
    inlineResult: undefined,
    uri: "",
    transcript: undefined,
  };
}

export const BatchRecognizeFileResult: MessageFns<BatchRecognizeFileResult> = {
  encode(message: BatchRecognizeFileResult, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.error !== undefined) {
      Status.encode(message.error, writer.uint32(18).fork()).join();
    }
    if (message.metadata !== undefined) {
      RecognitionResponseMetadata.encode(message.metadata, writer.uint32(26).fork()).join();
    }
    if (message.cloudStorageResult !== undefined) {
      CloudStorageResult.encode(message.cloudStorageResult, writer.uint32(42).fork()).join();
    }
    if (message.inlineResult !== undefined) {
      InlineResult.encode(message.inlineResult, writer.uint32(50).fork()).join();
    }
    if (message.uri !== "") {
      writer.uint32(10).string(message.uri);
    }
    if (message.transcript !== undefined) {
      BatchRecognizeResults.encode(message.transcript, writer.uint32(34).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): BatchRecognizeFileResult {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseBatchRecognizeFileResult();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 2:
          if (tag !== 18) {
            break;
          }

          message.error = Status.decode(reader, reader.uint32());
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.metadata = RecognitionResponseMetadata.decode(reader, reader.uint32());
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.cloudStorageResult = CloudStorageResult.decode(reader, reader.uint32());
          continue;
        case 6:
          if (tag !== 50) {
            break;
          }

          message.inlineResult = InlineResult.decode(reader, reader.uint32());
          continue;
        case 1:
          if (tag !== 10) {
            break;
          }

          message.uri = reader.string();
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.transcript = BatchRecognizeResults.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): BatchRecognizeFileResult {
    return {
      error: isSet(object.error) ? Status.fromJSON(object.error) : undefined,
      metadata: isSet(object.metadata) ? RecognitionResponseMetadata.fromJSON(object.metadata) : undefined,
      cloudStorageResult: isSet(object.cloudStorageResult)
        ? CloudStorageResult.fromJSON(object.cloudStorageResult)
        : undefined,
      inlineResult: isSet(object.inlineResult) ? InlineResult.fromJSON(object.inlineResult) : undefined,
      uri: isSet(object.uri) ? globalThis.String(object.uri) : "",
      transcript: isSet(object.transcript) ? BatchRecognizeResults.fromJSON(object.transcript) : undefined,
    };
  },

  toJSON(message: BatchRecognizeFileResult): unknown {
    const obj: any = {};
    if (message.error !== undefined) {
      obj.error = Status.toJSON(message.error);
    }
    if (message.metadata !== undefined) {
      obj.metadata = RecognitionResponseMetadata.toJSON(message.metadata);
    }
    if (message.cloudStorageResult !== undefined) {
      obj.cloudStorageResult = CloudStorageResult.toJSON(message.cloudStorageResult);
    }
    if (message.inlineResult !== undefined) {
      obj.inlineResult = InlineResult.toJSON(message.inlineResult);
    }
    if (message.uri !== "") {
      obj.uri = message.uri;
    }
    if (message.transcript !== undefined) {
      obj.transcript = BatchRecognizeResults.toJSON(message.transcript);
    }
    return obj;
  },

  create(base?: DeepPartial<BatchRecognizeFileResult>): BatchRecognizeFileResult {
    return BatchRecognizeFileResult.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<BatchRecognizeFileResult>): BatchRecognizeFileResult {
    const message = createBaseBatchRecognizeFileResult();
    message.error = (object.error !== undefined && object.error !== null)
      ? Status.fromPartial(object.error)
      : undefined;
    message.metadata = (object.metadata !== undefined && object.metadata !== null)
      ? RecognitionResponseMetadata.fromPartial(object.metadata)
      : undefined;
    message.cloudStorageResult = (object.cloudStorageResult !== undefined && object.cloudStorageResult !== null)
      ? CloudStorageResult.fromPartial(object.cloudStorageResult)
      : undefined;
    message.inlineResult = (object.inlineResult !== undefined && object.inlineResult !== null)
      ? InlineResult.fromPartial(object.inlineResult)
      : undefined;
    message.uri = object.uri ?? "";
    message.transcript = (object.transcript !== undefined && object.transcript !== null)
      ? BatchRecognizeResults.fromPartial(object.transcript)
      : undefined;
    return message;
  },
};

function createBaseBatchRecognizeTranscriptionMetadata(): BatchRecognizeTranscriptionMetadata {
  return { progressPercent: 0, error: undefined, uri: "" };
}

export const BatchRecognizeTranscriptionMetadata: MessageFns<BatchRecognizeTranscriptionMetadata> = {
  encode(message: BatchRecognizeTranscriptionMetadata, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.progressPercent !== 0) {
      writer.uint32(8).int32(message.progressPercent);
    }
    if (message.error !== undefined) {
      Status.encode(message.error, writer.uint32(18).fork()).join();
    }
    if (message.uri !== "") {
      writer.uint32(26).string(message.uri);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): BatchRecognizeTranscriptionMetadata {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseBatchRecognizeTranscriptionMetadata();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 8) {
            break;
          }

          message.progressPercent = reader.int32();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.error = Status.decode(reader, reader.uint32());
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.uri = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): BatchRecognizeTranscriptionMetadata {
    return {
      progressPercent: isSet(object.progressPercent) ? globalThis.Number(object.progressPercent) : 0,
      error: isSet(object.error) ? Status.fromJSON(object.error) : undefined,
      uri: isSet(object.uri) ? globalThis.String(object.uri) : "",
    };
  },

  toJSON(message: BatchRecognizeTranscriptionMetadata): unknown {
    const obj: any = {};
    if (message.progressPercent !== 0) {
      obj.progressPercent = Math.round(message.progressPercent);
    }
    if (message.error !== undefined) {
      obj.error = Status.toJSON(message.error);
    }
    if (message.uri !== "") {
      obj.uri = message.uri;
    }
    return obj;
  },

  create(base?: DeepPartial<BatchRecognizeTranscriptionMetadata>): BatchRecognizeTranscriptionMetadata {
    return BatchRecognizeTranscriptionMetadata.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<BatchRecognizeTranscriptionMetadata>): BatchRecognizeTranscriptionMetadata {
    const message = createBaseBatchRecognizeTranscriptionMetadata();
    message.progressPercent = object.progressPercent ?? 0;
    message.error = (object.error !== undefined && object.error !== null)
      ? Status.fromPartial(object.error)
      : undefined;
    message.uri = object.uri ?? "";
    return message;
  },
};

function createBaseBatchRecognizeMetadata(): BatchRecognizeMetadata {
  return { transcriptionMetadata: {} };
}

export const BatchRecognizeMetadata: MessageFns<BatchRecognizeMetadata> = {
  encode(message: BatchRecognizeMetadata, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    Object.entries(message.transcriptionMetadata).forEach(([key, value]) => {
      BatchRecognizeMetadata_TranscriptionMetadataEntry.encode({ key: key as any, value }, writer.uint32(10).fork())
        .join();
    });
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): BatchRecognizeMetadata {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseBatchRecognizeMetadata();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          const entry1 = BatchRecognizeMetadata_TranscriptionMetadataEntry.decode(reader, reader.uint32());
          if (entry1.value !== undefined) {
            message.transcriptionMetadata[entry1.key] = entry1.value;
          }
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): BatchRecognizeMetadata {
    return {
      transcriptionMetadata: isObject(object.transcriptionMetadata)
        ? Object.entries(object.transcriptionMetadata).reduce<{ [key: string]: BatchRecognizeTranscriptionMetadata }>(
          (acc, [key, value]) => {
            acc[key] = BatchRecognizeTranscriptionMetadata.fromJSON(value);
            return acc;
          },
          {},
        )
        : {},
    };
  },

  toJSON(message: BatchRecognizeMetadata): unknown {
    const obj: any = {};
    if (message.transcriptionMetadata) {
      const entries = Object.entries(message.transcriptionMetadata);
      if (entries.length > 0) {
        obj.transcriptionMetadata = {};
        entries.forEach(([k, v]) => {
          obj.transcriptionMetadata[k] = BatchRecognizeTranscriptionMetadata.toJSON(v);
        });
      }
    }
    return obj;
  },

  create(base?: DeepPartial<BatchRecognizeMetadata>): BatchRecognizeMetadata {
    return BatchRecognizeMetadata.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<BatchRecognizeMetadata>): BatchRecognizeMetadata {
    const message = createBaseBatchRecognizeMetadata();
    message.transcriptionMetadata = Object.entries(object.transcriptionMetadata ?? {}).reduce<
      { [key: string]: BatchRecognizeTranscriptionMetadata }
    >((acc, [key, value]) => {
      if (value !== undefined) {
        acc[key] = BatchRecognizeTranscriptionMetadata.fromPartial(value);
      }
      return acc;
    }, {});
    return message;
  },
};

function createBaseBatchRecognizeMetadata_TranscriptionMetadataEntry(): BatchRecognizeMetadata_TranscriptionMetadataEntry {
  return { key: "", value: undefined };
}

export const BatchRecognizeMetadata_TranscriptionMetadataEntry: MessageFns<
  BatchRecognizeMetadata_TranscriptionMetadataEntry
> = {
  encode(
    message: BatchRecognizeMetadata_TranscriptionMetadataEntry,
    writer: BinaryWriter = new BinaryWriter(),
  ): BinaryWriter {
    if (message.key !== "") {
      writer.uint32(10).string(message.key);
    }
    if (message.value !== undefined) {
      BatchRecognizeTranscriptionMetadata.encode(message.value, writer.uint32(18).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): BatchRecognizeMetadata_TranscriptionMetadataEntry {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseBatchRecognizeMetadata_TranscriptionMetadataEntry();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.key = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.value = BatchRecognizeTranscriptionMetadata.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): BatchRecognizeMetadata_TranscriptionMetadataEntry {
    return {
      key: isSet(object.key) ? globalThis.String(object.key) : "",
      value: isSet(object.value) ? BatchRecognizeTranscriptionMetadata.fromJSON(object.value) : undefined,
    };
  },

  toJSON(message: BatchRecognizeMetadata_TranscriptionMetadataEntry): unknown {
    const obj: any = {};
    if (message.key !== "") {
      obj.key = message.key;
    }
    if (message.value !== undefined) {
      obj.value = BatchRecognizeTranscriptionMetadata.toJSON(message.value);
    }
    return obj;
  },

  create(
    base?: DeepPartial<BatchRecognizeMetadata_TranscriptionMetadataEntry>,
  ): BatchRecognizeMetadata_TranscriptionMetadataEntry {
    return BatchRecognizeMetadata_TranscriptionMetadataEntry.fromPartial(base ?? {});
  },
  fromPartial(
    object: DeepPartial<BatchRecognizeMetadata_TranscriptionMetadataEntry>,
  ): BatchRecognizeMetadata_TranscriptionMetadataEntry {
    const message = createBaseBatchRecognizeMetadata_TranscriptionMetadataEntry();
    message.key = object.key ?? "";
    message.value = (object.value !== undefined && object.value !== null)
      ? BatchRecognizeTranscriptionMetadata.fromPartial(object.value)
      : undefined;
    return message;
  },
};

function createBaseBatchRecognizeFileMetadata(): BatchRecognizeFileMetadata {
  return { uri: undefined, config: undefined, configMask: undefined };
}

export const BatchRecognizeFileMetadata: MessageFns<BatchRecognizeFileMetadata> = {
  encode(message: BatchRecognizeFileMetadata, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.uri !== undefined) {
      writer.uint32(10).string(message.uri);
    }
    if (message.config !== undefined) {
      RecognitionConfig.encode(message.config, writer.uint32(34).fork()).join();
    }
    if (message.configMask !== undefined) {
      FieldMask.encode(FieldMask.wrap(message.configMask), writer.uint32(42).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): BatchRecognizeFileMetadata {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseBatchRecognizeFileMetadata();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.uri = reader.string();
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.config = RecognitionConfig.decode(reader, reader.uint32());
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.configMask = FieldMask.unwrap(FieldMask.decode(reader, reader.uint32()));
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): BatchRecognizeFileMetadata {
    return {
      uri: isSet(object.uri) ? globalThis.String(object.uri) : undefined,
      config: isSet(object.config) ? RecognitionConfig.fromJSON(object.config) : undefined,
      configMask: isSet(object.configMask) ? FieldMask.unwrap(FieldMask.fromJSON(object.configMask)) : undefined,
    };
  },

  toJSON(message: BatchRecognizeFileMetadata): unknown {
    const obj: any = {};
    if (message.uri !== undefined) {
      obj.uri = message.uri;
    }
    if (message.config !== undefined) {
      obj.config = RecognitionConfig.toJSON(message.config);
    }
    if (message.configMask !== undefined) {
      obj.configMask = FieldMask.toJSON(FieldMask.wrap(message.configMask));
    }
    return obj;
  },

  create(base?: DeepPartial<BatchRecognizeFileMetadata>): BatchRecognizeFileMetadata {
    return BatchRecognizeFileMetadata.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<BatchRecognizeFileMetadata>): BatchRecognizeFileMetadata {
    const message = createBaseBatchRecognizeFileMetadata();
    message.uri = object.uri ?? undefined;
    message.config = (object.config !== undefined && object.config !== null)
      ? RecognitionConfig.fromPartial(object.config)
      : undefined;
    message.configMask = object.configMask ?? undefined;
    return message;
  },
};

function createBaseStreamingRecognitionResult(): StreamingRecognitionResult {
  return {
    alternatives: [],
    isFinal: false,
    stability: 0,
    resultEndOffset: undefined,
    channelTag: 0,
    languageCode: "",
  };
}

export const StreamingRecognitionResult: MessageFns<StreamingRecognitionResult> = {
  encode(message: StreamingRecognitionResult, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.alternatives) {
      SpeechRecognitionAlternative.encode(v!, writer.uint32(10).fork()).join();
    }
    if (message.isFinal !== false) {
      writer.uint32(16).bool(message.isFinal);
    }
    if (message.stability !== 0) {
      writer.uint32(29).float(message.stability);
    }
    if (message.resultEndOffset !== undefined) {
      Duration.encode(message.resultEndOffset, writer.uint32(34).fork()).join();
    }
    if (message.channelTag !== 0) {
      writer.uint32(40).int32(message.channelTag);
    }
    if (message.languageCode !== "") {
      writer.uint32(50).string(message.languageCode);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): StreamingRecognitionResult {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseStreamingRecognitionResult();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.alternatives.push(SpeechRecognitionAlternative.decode(reader, reader.uint32()));
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.isFinal = reader.bool();
          continue;
        case 3:
          if (tag !== 29) {
            break;
          }

          message.stability = reader.float();
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.resultEndOffset = Duration.decode(reader, reader.uint32());
          continue;
        case 5:
          if (tag !== 40) {
            break;
          }

          message.channelTag = reader.int32();
          continue;
        case 6:
          if (tag !== 50) {
            break;
          }

          message.languageCode = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): StreamingRecognitionResult {
    return {
      alternatives: globalThis.Array.isArray(object?.alternatives)
        ? object.alternatives.map((e: any) => SpeechRecognitionAlternative.fromJSON(e))
        : [],
      isFinal: isSet(object.isFinal) ? globalThis.Boolean(object.isFinal) : false,
      stability: isSet(object.stability) ? globalThis.Number(object.stability) : 0,
      resultEndOffset: isSet(object.resultEndOffset) ? Duration.fromJSON(object.resultEndOffset) : undefined,
      channelTag: isSet(object.channelTag) ? globalThis.Number(object.channelTag) : 0,
      languageCode: isSet(object.languageCode) ? globalThis.String(object.languageCode) : "",
    };
  },

  toJSON(message: StreamingRecognitionResult): unknown {
    const obj: any = {};
    if (message.alternatives?.length) {
      obj.alternatives = message.alternatives.map((e) => SpeechRecognitionAlternative.toJSON(e));
    }
    if (message.isFinal !== false) {
      obj.isFinal = message.isFinal;
    }
    if (message.stability !== 0) {
      obj.stability = message.stability;
    }
    if (message.resultEndOffset !== undefined) {
      obj.resultEndOffset = Duration.toJSON(message.resultEndOffset);
    }
    if (message.channelTag !== 0) {
      obj.channelTag = Math.round(message.channelTag);
    }
    if (message.languageCode !== "") {
      obj.languageCode = message.languageCode;
    }
    return obj;
  },

  create(base?: DeepPartial<StreamingRecognitionResult>): StreamingRecognitionResult {
    return StreamingRecognitionResult.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<StreamingRecognitionResult>): StreamingRecognitionResult {
    const message = createBaseStreamingRecognitionResult();
    message.alternatives = object.alternatives?.map((e) => SpeechRecognitionAlternative.fromPartial(e)) || [];
    message.isFinal = object.isFinal ?? false;
    message.stability = object.stability ?? 0;
    message.resultEndOffset = (object.resultEndOffset !== undefined && object.resultEndOffset !== null)
      ? Duration.fromPartial(object.resultEndOffset)
      : undefined;
    message.channelTag = object.channelTag ?? 0;
    message.languageCode = object.languageCode ?? "";
    return message;
  },
};

function createBaseStreamingRecognizeResponse(): StreamingRecognizeResponse {
  return { results: [], speechEventType: 0, speechEventOffset: undefined, metadata: undefined };
}

export const StreamingRecognizeResponse: MessageFns<StreamingRecognizeResponse> = {
  encode(message: StreamingRecognizeResponse, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.results) {
      StreamingRecognitionResult.encode(v!, writer.uint32(50).fork()).join();
    }
    if (message.speechEventType !== 0) {
      writer.uint32(24).int32(message.speechEventType);
    }
    if (message.speechEventOffset !== undefined) {
      Duration.encode(message.speechEventOffset, writer.uint32(58).fork()).join();
    }
    if (message.metadata !== undefined) {
      RecognitionResponseMetadata.encode(message.metadata, writer.uint32(42).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): StreamingRecognizeResponse {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseStreamingRecognizeResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 6:
          if (tag !== 50) {
            break;
          }

          message.results.push(StreamingRecognitionResult.decode(reader, reader.uint32()));
          continue;
        case 3:
          if (tag !== 24) {
            break;
          }

          message.speechEventType = reader.int32() as any;
          continue;
        case 7:
          if (tag !== 58) {
            break;
          }

          message.speechEventOffset = Duration.decode(reader, reader.uint32());
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.metadata = RecognitionResponseMetadata.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): StreamingRecognizeResponse {
    return {
      results: globalThis.Array.isArray(object?.results)
        ? object.results.map((e: any) => StreamingRecognitionResult.fromJSON(e))
        : [],
      speechEventType: isSet(object.speechEventType)
        ? streamingRecognizeResponse_SpeechEventTypeFromJSON(object.speechEventType)
        : 0,
      speechEventOffset: isSet(object.speechEventOffset) ? Duration.fromJSON(object.speechEventOffset) : undefined,
      metadata: isSet(object.metadata) ? RecognitionResponseMetadata.fromJSON(object.metadata) : undefined,
    };
  },

  toJSON(message: StreamingRecognizeResponse): unknown {
    const obj: any = {};
    if (message.results?.length) {
      obj.results = message.results.map((e) => StreamingRecognitionResult.toJSON(e));
    }
    if (message.speechEventType !== 0) {
      obj.speechEventType = streamingRecognizeResponse_SpeechEventTypeToJSON(message.speechEventType);
    }
    if (message.speechEventOffset !== undefined) {
      obj.speechEventOffset = Duration.toJSON(message.speechEventOffset);
    }
    if (message.metadata !== undefined) {
      obj.metadata = RecognitionResponseMetadata.toJSON(message.metadata);
    }
    return obj;
  },

  create(base?: DeepPartial<StreamingRecognizeResponse>): StreamingRecognizeResponse {
    return StreamingRecognizeResponse.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<StreamingRecognizeResponse>): StreamingRecognizeResponse {
    const message = createBaseStreamingRecognizeResponse();
    message.results = object.results?.map((e) => StreamingRecognitionResult.fromPartial(e)) || [];
    message.speechEventType = object.speechEventType ?? 0;
    message.speechEventOffset = (object.speechEventOffset !== undefined && object.speechEventOffset !== null)
      ? Duration.fromPartial(object.speechEventOffset)
      : undefined;
    message.metadata = (object.metadata !== undefined && object.metadata !== null)
      ? RecognitionResponseMetadata.fromPartial(object.metadata)
      : undefined;
    return message;
  },
};

function createBaseConfig(): Config {
  return { name: "", kmsKeyName: "", updateTime: undefined };
}

export const Config: MessageFns<Config> = {
  encode(message: Config, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    if (message.kmsKeyName !== "") {
      writer.uint32(18).string(message.kmsKeyName);
    }
    if (message.updateTime !== undefined) {
      Timestamp.encode(toTimestamp(message.updateTime), writer.uint32(26).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Config {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseConfig();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.kmsKeyName = reader.string();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.updateTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Config {
    return {
      name: isSet(object.name) ? globalThis.String(object.name) : "",
      kmsKeyName: isSet(object.kmsKeyName) ? globalThis.String(object.kmsKeyName) : "",
      updateTime: isSet(object.updateTime) ? fromJsonTimestamp(object.updateTime) : undefined,
    };
  },

  toJSON(message: Config): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    if (message.kmsKeyName !== "") {
      obj.kmsKeyName = message.kmsKeyName;
    }
    if (message.updateTime !== undefined) {
      obj.updateTime = message.updateTime.toISOString();
    }
    return obj;
  },

  create(base?: DeepPartial<Config>): Config {
    return Config.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<Config>): Config {
    const message = createBaseConfig();
    message.name = object.name ?? "";
    message.kmsKeyName = object.kmsKeyName ?? "";
    message.updateTime = object.updateTime ?? undefined;
    return message;
  },
};

function createBaseGetConfigRequest(): GetConfigRequest {
  return { name: "" };
}

export const GetConfigRequest: MessageFns<GetConfigRequest> = {
  encode(message: GetConfigRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): GetConfigRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseGetConfigRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): GetConfigRequest {
    return { name: isSet(object.name) ? globalThis.String(object.name) : "" };
  },

  toJSON(message: GetConfigRequest): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    return obj;
  },

  create(base?: DeepPartial<GetConfigRequest>): GetConfigRequest {
    return GetConfigRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<GetConfigRequest>): GetConfigRequest {
    const message = createBaseGetConfigRequest();
    message.name = object.name ?? "";
    return message;
  },
};

function createBaseUpdateConfigRequest(): UpdateConfigRequest {
  return { config: undefined, updateMask: undefined };
}

export const UpdateConfigRequest: MessageFns<UpdateConfigRequest> = {
  encode(message: UpdateConfigRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.config !== undefined) {
      Config.encode(message.config, writer.uint32(10).fork()).join();
    }
    if (message.updateMask !== undefined) {
      FieldMask.encode(FieldMask.wrap(message.updateMask), writer.uint32(18).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): UpdateConfigRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseUpdateConfigRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.config = Config.decode(reader, reader.uint32());
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.updateMask = FieldMask.unwrap(FieldMask.decode(reader, reader.uint32()));
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): UpdateConfigRequest {
    return {
      config: isSet(object.config) ? Config.fromJSON(object.config) : undefined,
      updateMask: isSet(object.updateMask) ? FieldMask.unwrap(FieldMask.fromJSON(object.updateMask)) : undefined,
    };
  },

  toJSON(message: UpdateConfigRequest): unknown {
    const obj: any = {};
    if (message.config !== undefined) {
      obj.config = Config.toJSON(message.config);
    }
    if (message.updateMask !== undefined) {
      obj.updateMask = FieldMask.toJSON(FieldMask.wrap(message.updateMask));
    }
    return obj;
  },

  create(base?: DeepPartial<UpdateConfigRequest>): UpdateConfigRequest {
    return UpdateConfigRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<UpdateConfigRequest>): UpdateConfigRequest {
    const message = createBaseUpdateConfigRequest();
    message.config = (object.config !== undefined && object.config !== null)
      ? Config.fromPartial(object.config)
      : undefined;
    message.updateMask = object.updateMask ?? undefined;
    return message;
  },
};

function createBaseCustomClass(): CustomClass {
  return {
    name: "",
    uid: "",
    displayName: "",
    items: [],
    state: 0,
    createTime: undefined,
    updateTime: undefined,
    deleteTime: undefined,
    expireTime: undefined,
    annotations: {},
    etag: "",
    reconciling: false,
    kmsKeyName: "",
    kmsKeyVersionName: "",
  };
}

export const CustomClass: MessageFns<CustomClass> = {
  encode(message: CustomClass, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    if (message.uid !== "") {
      writer.uint32(18).string(message.uid);
    }
    if (message.displayName !== "") {
      writer.uint32(34).string(message.displayName);
    }
    for (const v of message.items) {
      CustomClass_ClassItem.encode(v!, writer.uint32(42).fork()).join();
    }
    if (message.state !== 0) {
      writer.uint32(120).int32(message.state);
    }
    if (message.createTime !== undefined) {
      Timestamp.encode(toTimestamp(message.createTime), writer.uint32(50).fork()).join();
    }
    if (message.updateTime !== undefined) {
      Timestamp.encode(toTimestamp(message.updateTime), writer.uint32(58).fork()).join();
    }
    if (message.deleteTime !== undefined) {
      Timestamp.encode(toTimestamp(message.deleteTime), writer.uint32(66).fork()).join();
    }
    if (message.expireTime !== undefined) {
      Timestamp.encode(toTimestamp(message.expireTime), writer.uint32(74).fork()).join();
    }
    Object.entries(message.annotations).forEach(([key, value]) => {
      CustomClass_AnnotationsEntry.encode({ key: key as any, value }, writer.uint32(82).fork()).join();
    });
    if (message.etag !== "") {
      writer.uint32(90).string(message.etag);
    }
    if (message.reconciling !== false) {
      writer.uint32(96).bool(message.reconciling);
    }
    if (message.kmsKeyName !== "") {
      writer.uint32(106).string(message.kmsKeyName);
    }
    if (message.kmsKeyVersionName !== "") {
      writer.uint32(114).string(message.kmsKeyVersionName);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): CustomClass {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseCustomClass();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.uid = reader.string();
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.displayName = reader.string();
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.items.push(CustomClass_ClassItem.decode(reader, reader.uint32()));
          continue;
        case 15:
          if (tag !== 120) {
            break;
          }

          message.state = reader.int32() as any;
          continue;
        case 6:
          if (tag !== 50) {
            break;
          }

          message.createTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        case 7:
          if (tag !== 58) {
            break;
          }

          message.updateTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        case 8:
          if (tag !== 66) {
            break;
          }

          message.deleteTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        case 9:
          if (tag !== 74) {
            break;
          }

          message.expireTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        case 10:
          if (tag !== 82) {
            break;
          }

          const entry10 = CustomClass_AnnotationsEntry.decode(reader, reader.uint32());
          if (entry10.value !== undefined) {
            message.annotations[entry10.key] = entry10.value;
          }
          continue;
        case 11:
          if (tag !== 90) {
            break;
          }

          message.etag = reader.string();
          continue;
        case 12:
          if (tag !== 96) {
            break;
          }

          message.reconciling = reader.bool();
          continue;
        case 13:
          if (tag !== 106) {
            break;
          }

          message.kmsKeyName = reader.string();
          continue;
        case 14:
          if (tag !== 114) {
            break;
          }

          message.kmsKeyVersionName = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): CustomClass {
    return {
      name: isSet(object.name) ? globalThis.String(object.name) : "",
      uid: isSet(object.uid) ? globalThis.String(object.uid) : "",
      displayName: isSet(object.displayName) ? globalThis.String(object.displayName) : "",
      items: globalThis.Array.isArray(object?.items)
        ? object.items.map((e: any) => CustomClass_ClassItem.fromJSON(e))
        : [],
      state: isSet(object.state) ? customClass_StateFromJSON(object.state) : 0,
      createTime: isSet(object.createTime) ? fromJsonTimestamp(object.createTime) : undefined,
      updateTime: isSet(object.updateTime) ? fromJsonTimestamp(object.updateTime) : undefined,
      deleteTime: isSet(object.deleteTime) ? fromJsonTimestamp(object.deleteTime) : undefined,
      expireTime: isSet(object.expireTime) ? fromJsonTimestamp(object.expireTime) : undefined,
      annotations: isObject(object.annotations)
        ? Object.entries(object.annotations).reduce<{ [key: string]: string }>((acc, [key, value]) => {
          acc[key] = String(value);
          return acc;
        }, {})
        : {},
      etag: isSet(object.etag) ? globalThis.String(object.etag) : "",
      reconciling: isSet(object.reconciling) ? globalThis.Boolean(object.reconciling) : false,
      kmsKeyName: isSet(object.kmsKeyName) ? globalThis.String(object.kmsKeyName) : "",
      kmsKeyVersionName: isSet(object.kmsKeyVersionName) ? globalThis.String(object.kmsKeyVersionName) : "",
    };
  },

  toJSON(message: CustomClass): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    if (message.uid !== "") {
      obj.uid = message.uid;
    }
    if (message.displayName !== "") {
      obj.displayName = message.displayName;
    }
    if (message.items?.length) {
      obj.items = message.items.map((e) => CustomClass_ClassItem.toJSON(e));
    }
    if (message.state !== 0) {
      obj.state = customClass_StateToJSON(message.state);
    }
    if (message.createTime !== undefined) {
      obj.createTime = message.createTime.toISOString();
    }
    if (message.updateTime !== undefined) {
      obj.updateTime = message.updateTime.toISOString();
    }
    if (message.deleteTime !== undefined) {
      obj.deleteTime = message.deleteTime.toISOString();
    }
    if (message.expireTime !== undefined) {
      obj.expireTime = message.expireTime.toISOString();
    }
    if (message.annotations) {
      const entries = Object.entries(message.annotations);
      if (entries.length > 0) {
        obj.annotations = {};
        entries.forEach(([k, v]) => {
          obj.annotations[k] = v;
        });
      }
    }
    if (message.etag !== "") {
      obj.etag = message.etag;
    }
    if (message.reconciling !== false) {
      obj.reconciling = message.reconciling;
    }
    if (message.kmsKeyName !== "") {
      obj.kmsKeyName = message.kmsKeyName;
    }
    if (message.kmsKeyVersionName !== "") {
      obj.kmsKeyVersionName = message.kmsKeyVersionName;
    }
    return obj;
  },

  create(base?: DeepPartial<CustomClass>): CustomClass {
    return CustomClass.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<CustomClass>): CustomClass {
    const message = createBaseCustomClass();
    message.name = object.name ?? "";
    message.uid = object.uid ?? "";
    message.displayName = object.displayName ?? "";
    message.items = object.items?.map((e) => CustomClass_ClassItem.fromPartial(e)) || [];
    message.state = object.state ?? 0;
    message.createTime = object.createTime ?? undefined;
    message.updateTime = object.updateTime ?? undefined;
    message.deleteTime = object.deleteTime ?? undefined;
    message.expireTime = object.expireTime ?? undefined;
    message.annotations = Object.entries(object.annotations ?? {}).reduce<{ [key: string]: string }>(
      (acc, [key, value]) => {
        if (value !== undefined) {
          acc[key] = globalThis.String(value);
        }
        return acc;
      },
      {},
    );
    message.etag = object.etag ?? "";
    message.reconciling = object.reconciling ?? false;
    message.kmsKeyName = object.kmsKeyName ?? "";
    message.kmsKeyVersionName = object.kmsKeyVersionName ?? "";
    return message;
  },
};

function createBaseCustomClass_ClassItem(): CustomClass_ClassItem {
  return { value: "" };
}

export const CustomClass_ClassItem: MessageFns<CustomClass_ClassItem> = {
  encode(message: CustomClass_ClassItem, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.value !== "") {
      writer.uint32(10).string(message.value);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): CustomClass_ClassItem {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseCustomClass_ClassItem();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.value = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): CustomClass_ClassItem {
    return { value: isSet(object.value) ? globalThis.String(object.value) : "" };
  },

  toJSON(message: CustomClass_ClassItem): unknown {
    const obj: any = {};
    if (message.value !== "") {
      obj.value = message.value;
    }
    return obj;
  },

  create(base?: DeepPartial<CustomClass_ClassItem>): CustomClass_ClassItem {
    return CustomClass_ClassItem.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<CustomClass_ClassItem>): CustomClass_ClassItem {
    const message = createBaseCustomClass_ClassItem();
    message.value = object.value ?? "";
    return message;
  },
};

function createBaseCustomClass_AnnotationsEntry(): CustomClass_AnnotationsEntry {
  return { key: "", value: "" };
}

export const CustomClass_AnnotationsEntry: MessageFns<CustomClass_AnnotationsEntry> = {
  encode(message: CustomClass_AnnotationsEntry, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.key !== "") {
      writer.uint32(10).string(message.key);
    }
    if (message.value !== "") {
      writer.uint32(18).string(message.value);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): CustomClass_AnnotationsEntry {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseCustomClass_AnnotationsEntry();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.key = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.value = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): CustomClass_AnnotationsEntry {
    return {
      key: isSet(object.key) ? globalThis.String(object.key) : "",
      value: isSet(object.value) ? globalThis.String(object.value) : "",
    };
  },

  toJSON(message: CustomClass_AnnotationsEntry): unknown {
    const obj: any = {};
    if (message.key !== "") {
      obj.key = message.key;
    }
    if (message.value !== "") {
      obj.value = message.value;
    }
    return obj;
  },

  create(base?: DeepPartial<CustomClass_AnnotationsEntry>): CustomClass_AnnotationsEntry {
    return CustomClass_AnnotationsEntry.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<CustomClass_AnnotationsEntry>): CustomClass_AnnotationsEntry {
    const message = createBaseCustomClass_AnnotationsEntry();
    message.key = object.key ?? "";
    message.value = object.value ?? "";
    return message;
  },
};

function createBasePhraseSet(): PhraseSet {
  return {
    name: "",
    uid: "",
    phrases: [],
    boost: 0,
    displayName: "",
    state: 0,
    createTime: undefined,
    updateTime: undefined,
    deleteTime: undefined,
    expireTime: undefined,
    annotations: {},
    etag: "",
    reconciling: false,
    kmsKeyName: "",
    kmsKeyVersionName: "",
  };
}

export const PhraseSet: MessageFns<PhraseSet> = {
  encode(message: PhraseSet, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    if (message.uid !== "") {
      writer.uint32(18).string(message.uid);
    }
    for (const v of message.phrases) {
      PhraseSet_Phrase.encode(v!, writer.uint32(26).fork()).join();
    }
    if (message.boost !== 0) {
      writer.uint32(37).float(message.boost);
    }
    if (message.displayName !== "") {
      writer.uint32(42).string(message.displayName);
    }
    if (message.state !== 0) {
      writer.uint32(120).int32(message.state);
    }
    if (message.createTime !== undefined) {
      Timestamp.encode(toTimestamp(message.createTime), writer.uint32(50).fork()).join();
    }
    if (message.updateTime !== undefined) {
      Timestamp.encode(toTimestamp(message.updateTime), writer.uint32(58).fork()).join();
    }
    if (message.deleteTime !== undefined) {
      Timestamp.encode(toTimestamp(message.deleteTime), writer.uint32(66).fork()).join();
    }
    if (message.expireTime !== undefined) {
      Timestamp.encode(toTimestamp(message.expireTime), writer.uint32(74).fork()).join();
    }
    Object.entries(message.annotations).forEach(([key, value]) => {
      PhraseSet_AnnotationsEntry.encode({ key: key as any, value }, writer.uint32(82).fork()).join();
    });
    if (message.etag !== "") {
      writer.uint32(90).string(message.etag);
    }
    if (message.reconciling !== false) {
      writer.uint32(96).bool(message.reconciling);
    }
    if (message.kmsKeyName !== "") {
      writer.uint32(106).string(message.kmsKeyName);
    }
    if (message.kmsKeyVersionName !== "") {
      writer.uint32(114).string(message.kmsKeyVersionName);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): PhraseSet {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBasePhraseSet();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.uid = reader.string();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.phrases.push(PhraseSet_Phrase.decode(reader, reader.uint32()));
          continue;
        case 4:
          if (tag !== 37) {
            break;
          }

          message.boost = reader.float();
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.displayName = reader.string();
          continue;
        case 15:
          if (tag !== 120) {
            break;
          }

          message.state = reader.int32() as any;
          continue;
        case 6:
          if (tag !== 50) {
            break;
          }

          message.createTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        case 7:
          if (tag !== 58) {
            break;
          }

          message.updateTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        case 8:
          if (tag !== 66) {
            break;
          }

          message.deleteTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        case 9:
          if (tag !== 74) {
            break;
          }

          message.expireTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        case 10:
          if (tag !== 82) {
            break;
          }

          const entry10 = PhraseSet_AnnotationsEntry.decode(reader, reader.uint32());
          if (entry10.value !== undefined) {
            message.annotations[entry10.key] = entry10.value;
          }
          continue;
        case 11:
          if (tag !== 90) {
            break;
          }

          message.etag = reader.string();
          continue;
        case 12:
          if (tag !== 96) {
            break;
          }

          message.reconciling = reader.bool();
          continue;
        case 13:
          if (tag !== 106) {
            break;
          }

          message.kmsKeyName = reader.string();
          continue;
        case 14:
          if (tag !== 114) {
            break;
          }

          message.kmsKeyVersionName = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): PhraseSet {
    return {
      name: isSet(object.name) ? globalThis.String(object.name) : "",
      uid: isSet(object.uid) ? globalThis.String(object.uid) : "",
      phrases: globalThis.Array.isArray(object?.phrases)
        ? object.phrases.map((e: any) => PhraseSet_Phrase.fromJSON(e))
        : [],
      boost: isSet(object.boost) ? globalThis.Number(object.boost) : 0,
      displayName: isSet(object.displayName) ? globalThis.String(object.displayName) : "",
      state: isSet(object.state) ? phraseSet_StateFromJSON(object.state) : 0,
      createTime: isSet(object.createTime) ? fromJsonTimestamp(object.createTime) : undefined,
      updateTime: isSet(object.updateTime) ? fromJsonTimestamp(object.updateTime) : undefined,
      deleteTime: isSet(object.deleteTime) ? fromJsonTimestamp(object.deleteTime) : undefined,
      expireTime: isSet(object.expireTime) ? fromJsonTimestamp(object.expireTime) : undefined,
      annotations: isObject(object.annotations)
        ? Object.entries(object.annotations).reduce<{ [key: string]: string }>((acc, [key, value]) => {
          acc[key] = String(value);
          return acc;
        }, {})
        : {},
      etag: isSet(object.etag) ? globalThis.String(object.etag) : "",
      reconciling: isSet(object.reconciling) ? globalThis.Boolean(object.reconciling) : false,
      kmsKeyName: isSet(object.kmsKeyName) ? globalThis.String(object.kmsKeyName) : "",
      kmsKeyVersionName: isSet(object.kmsKeyVersionName) ? globalThis.String(object.kmsKeyVersionName) : "",
    };
  },

  toJSON(message: PhraseSet): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    if (message.uid !== "") {
      obj.uid = message.uid;
    }
    if (message.phrases?.length) {
      obj.phrases = message.phrases.map((e) => PhraseSet_Phrase.toJSON(e));
    }
    if (message.boost !== 0) {
      obj.boost = message.boost;
    }
    if (message.displayName !== "") {
      obj.displayName = message.displayName;
    }
    if (message.state !== 0) {
      obj.state = phraseSet_StateToJSON(message.state);
    }
    if (message.createTime !== undefined) {
      obj.createTime = message.createTime.toISOString();
    }
    if (message.updateTime !== undefined) {
      obj.updateTime = message.updateTime.toISOString();
    }
    if (message.deleteTime !== undefined) {
      obj.deleteTime = message.deleteTime.toISOString();
    }
    if (message.expireTime !== undefined) {
      obj.expireTime = message.expireTime.toISOString();
    }
    if (message.annotations) {
      const entries = Object.entries(message.annotations);
      if (entries.length > 0) {
        obj.annotations = {};
        entries.forEach(([k, v]) => {
          obj.annotations[k] = v;
        });
      }
    }
    if (message.etag !== "") {
      obj.etag = message.etag;
    }
    if (message.reconciling !== false) {
      obj.reconciling = message.reconciling;
    }
    if (message.kmsKeyName !== "") {
      obj.kmsKeyName = message.kmsKeyName;
    }
    if (message.kmsKeyVersionName !== "") {
      obj.kmsKeyVersionName = message.kmsKeyVersionName;
    }
    return obj;
  },

  create(base?: DeepPartial<PhraseSet>): PhraseSet {
    return PhraseSet.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<PhraseSet>): PhraseSet {
    const message = createBasePhraseSet();
    message.name = object.name ?? "";
    message.uid = object.uid ?? "";
    message.phrases = object.phrases?.map((e) => PhraseSet_Phrase.fromPartial(e)) || [];
    message.boost = object.boost ?? 0;
    message.displayName = object.displayName ?? "";
    message.state = object.state ?? 0;
    message.createTime = object.createTime ?? undefined;
    message.updateTime = object.updateTime ?? undefined;
    message.deleteTime = object.deleteTime ?? undefined;
    message.expireTime = object.expireTime ?? undefined;
    message.annotations = Object.entries(object.annotations ?? {}).reduce<{ [key: string]: string }>(
      (acc, [key, value]) => {
        if (value !== undefined) {
          acc[key] = globalThis.String(value);
        }
        return acc;
      },
      {},
    );
    message.etag = object.etag ?? "";
    message.reconciling = object.reconciling ?? false;
    message.kmsKeyName = object.kmsKeyName ?? "";
    message.kmsKeyVersionName = object.kmsKeyVersionName ?? "";
    return message;
  },
};

function createBasePhraseSet_Phrase(): PhraseSet_Phrase {
  return { value: "", boost: 0 };
}

export const PhraseSet_Phrase: MessageFns<PhraseSet_Phrase> = {
  encode(message: PhraseSet_Phrase, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.value !== "") {
      writer.uint32(10).string(message.value);
    }
    if (message.boost !== 0) {
      writer.uint32(21).float(message.boost);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): PhraseSet_Phrase {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBasePhraseSet_Phrase();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.value = reader.string();
          continue;
        case 2:
          if (tag !== 21) {
            break;
          }

          message.boost = reader.float();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): PhraseSet_Phrase {
    return {
      value: isSet(object.value) ? globalThis.String(object.value) : "",
      boost: isSet(object.boost) ? globalThis.Number(object.boost) : 0,
    };
  },

  toJSON(message: PhraseSet_Phrase): unknown {
    const obj: any = {};
    if (message.value !== "") {
      obj.value = message.value;
    }
    if (message.boost !== 0) {
      obj.boost = message.boost;
    }
    return obj;
  },

  create(base?: DeepPartial<PhraseSet_Phrase>): PhraseSet_Phrase {
    return PhraseSet_Phrase.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<PhraseSet_Phrase>): PhraseSet_Phrase {
    const message = createBasePhraseSet_Phrase();
    message.value = object.value ?? "";
    message.boost = object.boost ?? 0;
    return message;
  },
};

function createBasePhraseSet_AnnotationsEntry(): PhraseSet_AnnotationsEntry {
  return { key: "", value: "" };
}

export const PhraseSet_AnnotationsEntry: MessageFns<PhraseSet_AnnotationsEntry> = {
  encode(message: PhraseSet_AnnotationsEntry, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.key !== "") {
      writer.uint32(10).string(message.key);
    }
    if (message.value !== "") {
      writer.uint32(18).string(message.value);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): PhraseSet_AnnotationsEntry {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBasePhraseSet_AnnotationsEntry();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.key = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.value = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): PhraseSet_AnnotationsEntry {
    return {
      key: isSet(object.key) ? globalThis.String(object.key) : "",
      value: isSet(object.value) ? globalThis.String(object.value) : "",
    };
  },

  toJSON(message: PhraseSet_AnnotationsEntry): unknown {
    const obj: any = {};
    if (message.key !== "") {
      obj.key = message.key;
    }
    if (message.value !== "") {
      obj.value = message.value;
    }
    return obj;
  },

  create(base?: DeepPartial<PhraseSet_AnnotationsEntry>): PhraseSet_AnnotationsEntry {
    return PhraseSet_AnnotationsEntry.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<PhraseSet_AnnotationsEntry>): PhraseSet_AnnotationsEntry {
    const message = createBasePhraseSet_AnnotationsEntry();
    message.key = object.key ?? "";
    message.value = object.value ?? "";
    return message;
  },
};

function createBaseCreateCustomClassRequest(): CreateCustomClassRequest {
  return { customClass: undefined, validateOnly: false, customClassId: "", parent: "" };
}

export const CreateCustomClassRequest: MessageFns<CreateCustomClassRequest> = {
  encode(message: CreateCustomClassRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.customClass !== undefined) {
      CustomClass.encode(message.customClass, writer.uint32(10).fork()).join();
    }
    if (message.validateOnly !== false) {
      writer.uint32(16).bool(message.validateOnly);
    }
    if (message.customClassId !== "") {
      writer.uint32(26).string(message.customClassId);
    }
    if (message.parent !== "") {
      writer.uint32(34).string(message.parent);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): CreateCustomClassRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseCreateCustomClassRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.customClass = CustomClass.decode(reader, reader.uint32());
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.validateOnly = reader.bool();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.customClassId = reader.string();
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.parent = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): CreateCustomClassRequest {
    return {
      customClass: isSet(object.customClass) ? CustomClass.fromJSON(object.customClass) : undefined,
      validateOnly: isSet(object.validateOnly) ? globalThis.Boolean(object.validateOnly) : false,
      customClassId: isSet(object.customClassId) ? globalThis.String(object.customClassId) : "",
      parent: isSet(object.parent) ? globalThis.String(object.parent) : "",
    };
  },

  toJSON(message: CreateCustomClassRequest): unknown {
    const obj: any = {};
    if (message.customClass !== undefined) {
      obj.customClass = CustomClass.toJSON(message.customClass);
    }
    if (message.validateOnly !== false) {
      obj.validateOnly = message.validateOnly;
    }
    if (message.customClassId !== "") {
      obj.customClassId = message.customClassId;
    }
    if (message.parent !== "") {
      obj.parent = message.parent;
    }
    return obj;
  },

  create(base?: DeepPartial<CreateCustomClassRequest>): CreateCustomClassRequest {
    return CreateCustomClassRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<CreateCustomClassRequest>): CreateCustomClassRequest {
    const message = createBaseCreateCustomClassRequest();
    message.customClass = (object.customClass !== undefined && object.customClass !== null)
      ? CustomClass.fromPartial(object.customClass)
      : undefined;
    message.validateOnly = object.validateOnly ?? false;
    message.customClassId = object.customClassId ?? "";
    message.parent = object.parent ?? "";
    return message;
  },
};

function createBaseListCustomClassesRequest(): ListCustomClassesRequest {
  return { parent: "", pageSize: 0, pageToken: "", showDeleted: false };
}

export const ListCustomClassesRequest: MessageFns<ListCustomClassesRequest> = {
  encode(message: ListCustomClassesRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.parent !== "") {
      writer.uint32(10).string(message.parent);
    }
    if (message.pageSize !== 0) {
      writer.uint32(16).int32(message.pageSize);
    }
    if (message.pageToken !== "") {
      writer.uint32(26).string(message.pageToken);
    }
    if (message.showDeleted !== false) {
      writer.uint32(32).bool(message.showDeleted);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ListCustomClassesRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseListCustomClassesRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.parent = reader.string();
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.pageSize = reader.int32();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.pageToken = reader.string();
          continue;
        case 4:
          if (tag !== 32) {
            break;
          }

          message.showDeleted = reader.bool();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ListCustomClassesRequest {
    return {
      parent: isSet(object.parent) ? globalThis.String(object.parent) : "",
      pageSize: isSet(object.pageSize) ? globalThis.Number(object.pageSize) : 0,
      pageToken: isSet(object.pageToken) ? globalThis.String(object.pageToken) : "",
      showDeleted: isSet(object.showDeleted) ? globalThis.Boolean(object.showDeleted) : false,
    };
  },

  toJSON(message: ListCustomClassesRequest): unknown {
    const obj: any = {};
    if (message.parent !== "") {
      obj.parent = message.parent;
    }
    if (message.pageSize !== 0) {
      obj.pageSize = Math.round(message.pageSize);
    }
    if (message.pageToken !== "") {
      obj.pageToken = message.pageToken;
    }
    if (message.showDeleted !== false) {
      obj.showDeleted = message.showDeleted;
    }
    return obj;
  },

  create(base?: DeepPartial<ListCustomClassesRequest>): ListCustomClassesRequest {
    return ListCustomClassesRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ListCustomClassesRequest>): ListCustomClassesRequest {
    const message = createBaseListCustomClassesRequest();
    message.parent = object.parent ?? "";
    message.pageSize = object.pageSize ?? 0;
    message.pageToken = object.pageToken ?? "";
    message.showDeleted = object.showDeleted ?? false;
    return message;
  },
};

function createBaseListCustomClassesResponse(): ListCustomClassesResponse {
  return { customClasses: [], nextPageToken: "" };
}

export const ListCustomClassesResponse: MessageFns<ListCustomClassesResponse> = {
  encode(message: ListCustomClassesResponse, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.customClasses) {
      CustomClass.encode(v!, writer.uint32(10).fork()).join();
    }
    if (message.nextPageToken !== "") {
      writer.uint32(18).string(message.nextPageToken);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ListCustomClassesResponse {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseListCustomClassesResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.customClasses.push(CustomClass.decode(reader, reader.uint32()));
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.nextPageToken = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ListCustomClassesResponse {
    return {
      customClasses: globalThis.Array.isArray(object?.customClasses)
        ? object.customClasses.map((e: any) => CustomClass.fromJSON(e))
        : [],
      nextPageToken: isSet(object.nextPageToken) ? globalThis.String(object.nextPageToken) : "",
    };
  },

  toJSON(message: ListCustomClassesResponse): unknown {
    const obj: any = {};
    if (message.customClasses?.length) {
      obj.customClasses = message.customClasses.map((e) => CustomClass.toJSON(e));
    }
    if (message.nextPageToken !== "") {
      obj.nextPageToken = message.nextPageToken;
    }
    return obj;
  },

  create(base?: DeepPartial<ListCustomClassesResponse>): ListCustomClassesResponse {
    return ListCustomClassesResponse.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ListCustomClassesResponse>): ListCustomClassesResponse {
    const message = createBaseListCustomClassesResponse();
    message.customClasses = object.customClasses?.map((e) => CustomClass.fromPartial(e)) || [];
    message.nextPageToken = object.nextPageToken ?? "";
    return message;
  },
};

function createBaseGetCustomClassRequest(): GetCustomClassRequest {
  return { name: "" };
}

export const GetCustomClassRequest: MessageFns<GetCustomClassRequest> = {
  encode(message: GetCustomClassRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): GetCustomClassRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseGetCustomClassRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): GetCustomClassRequest {
    return { name: isSet(object.name) ? globalThis.String(object.name) : "" };
  },

  toJSON(message: GetCustomClassRequest): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    return obj;
  },

  create(base?: DeepPartial<GetCustomClassRequest>): GetCustomClassRequest {
    return GetCustomClassRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<GetCustomClassRequest>): GetCustomClassRequest {
    const message = createBaseGetCustomClassRequest();
    message.name = object.name ?? "";
    return message;
  },
};

function createBaseUpdateCustomClassRequest(): UpdateCustomClassRequest {
  return { customClass: undefined, updateMask: undefined, validateOnly: false };
}

export const UpdateCustomClassRequest: MessageFns<UpdateCustomClassRequest> = {
  encode(message: UpdateCustomClassRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.customClass !== undefined) {
      CustomClass.encode(message.customClass, writer.uint32(10).fork()).join();
    }
    if (message.updateMask !== undefined) {
      FieldMask.encode(FieldMask.wrap(message.updateMask), writer.uint32(18).fork()).join();
    }
    if (message.validateOnly !== false) {
      writer.uint32(32).bool(message.validateOnly);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): UpdateCustomClassRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseUpdateCustomClassRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.customClass = CustomClass.decode(reader, reader.uint32());
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.updateMask = FieldMask.unwrap(FieldMask.decode(reader, reader.uint32()));
          continue;
        case 4:
          if (tag !== 32) {
            break;
          }

          message.validateOnly = reader.bool();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): UpdateCustomClassRequest {
    return {
      customClass: isSet(object.customClass) ? CustomClass.fromJSON(object.customClass) : undefined,
      updateMask: isSet(object.updateMask) ? FieldMask.unwrap(FieldMask.fromJSON(object.updateMask)) : undefined,
      validateOnly: isSet(object.validateOnly) ? globalThis.Boolean(object.validateOnly) : false,
    };
  },

  toJSON(message: UpdateCustomClassRequest): unknown {
    const obj: any = {};
    if (message.customClass !== undefined) {
      obj.customClass = CustomClass.toJSON(message.customClass);
    }
    if (message.updateMask !== undefined) {
      obj.updateMask = FieldMask.toJSON(FieldMask.wrap(message.updateMask));
    }
    if (message.validateOnly !== false) {
      obj.validateOnly = message.validateOnly;
    }
    return obj;
  },

  create(base?: DeepPartial<UpdateCustomClassRequest>): UpdateCustomClassRequest {
    return UpdateCustomClassRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<UpdateCustomClassRequest>): UpdateCustomClassRequest {
    const message = createBaseUpdateCustomClassRequest();
    message.customClass = (object.customClass !== undefined && object.customClass !== null)
      ? CustomClass.fromPartial(object.customClass)
      : undefined;
    message.updateMask = object.updateMask ?? undefined;
    message.validateOnly = object.validateOnly ?? false;
    return message;
  },
};

function createBaseDeleteCustomClassRequest(): DeleteCustomClassRequest {
  return { name: "", validateOnly: false, allowMissing: false, etag: "" };
}

export const DeleteCustomClassRequest: MessageFns<DeleteCustomClassRequest> = {
  encode(message: DeleteCustomClassRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    if (message.validateOnly !== false) {
      writer.uint32(16).bool(message.validateOnly);
    }
    if (message.allowMissing !== false) {
      writer.uint32(32).bool(message.allowMissing);
    }
    if (message.etag !== "") {
      writer.uint32(26).string(message.etag);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): DeleteCustomClassRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDeleteCustomClassRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.validateOnly = reader.bool();
          continue;
        case 4:
          if (tag !== 32) {
            break;
          }

          message.allowMissing = reader.bool();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.etag = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): DeleteCustomClassRequest {
    return {
      name: isSet(object.name) ? globalThis.String(object.name) : "",
      validateOnly: isSet(object.validateOnly) ? globalThis.Boolean(object.validateOnly) : false,
      allowMissing: isSet(object.allowMissing) ? globalThis.Boolean(object.allowMissing) : false,
      etag: isSet(object.etag) ? globalThis.String(object.etag) : "",
    };
  },

  toJSON(message: DeleteCustomClassRequest): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    if (message.validateOnly !== false) {
      obj.validateOnly = message.validateOnly;
    }
    if (message.allowMissing !== false) {
      obj.allowMissing = message.allowMissing;
    }
    if (message.etag !== "") {
      obj.etag = message.etag;
    }
    return obj;
  },

  create(base?: DeepPartial<DeleteCustomClassRequest>): DeleteCustomClassRequest {
    return DeleteCustomClassRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<DeleteCustomClassRequest>): DeleteCustomClassRequest {
    const message = createBaseDeleteCustomClassRequest();
    message.name = object.name ?? "";
    message.validateOnly = object.validateOnly ?? false;
    message.allowMissing = object.allowMissing ?? false;
    message.etag = object.etag ?? "";
    return message;
  },
};

function createBaseUndeleteCustomClassRequest(): UndeleteCustomClassRequest {
  return { name: "", validateOnly: false, etag: "" };
}

export const UndeleteCustomClassRequest: MessageFns<UndeleteCustomClassRequest> = {
  encode(message: UndeleteCustomClassRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    if (message.validateOnly !== false) {
      writer.uint32(24).bool(message.validateOnly);
    }
    if (message.etag !== "") {
      writer.uint32(34).string(message.etag);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): UndeleteCustomClassRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseUndeleteCustomClassRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
        case 3:
          if (tag !== 24) {
            break;
          }

          message.validateOnly = reader.bool();
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.etag = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): UndeleteCustomClassRequest {
    return {
      name: isSet(object.name) ? globalThis.String(object.name) : "",
      validateOnly: isSet(object.validateOnly) ? globalThis.Boolean(object.validateOnly) : false,
      etag: isSet(object.etag) ? globalThis.String(object.etag) : "",
    };
  },

  toJSON(message: UndeleteCustomClassRequest): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    if (message.validateOnly !== false) {
      obj.validateOnly = message.validateOnly;
    }
    if (message.etag !== "") {
      obj.etag = message.etag;
    }
    return obj;
  },

  create(base?: DeepPartial<UndeleteCustomClassRequest>): UndeleteCustomClassRequest {
    return UndeleteCustomClassRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<UndeleteCustomClassRequest>): UndeleteCustomClassRequest {
    const message = createBaseUndeleteCustomClassRequest();
    message.name = object.name ?? "";
    message.validateOnly = object.validateOnly ?? false;
    message.etag = object.etag ?? "";
    return message;
  },
};

function createBaseCreatePhraseSetRequest(): CreatePhraseSetRequest {
  return { phraseSet: undefined, validateOnly: false, phraseSetId: "", parent: "" };
}

export const CreatePhraseSetRequest: MessageFns<CreatePhraseSetRequest> = {
  encode(message: CreatePhraseSetRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.phraseSet !== undefined) {
      PhraseSet.encode(message.phraseSet, writer.uint32(10).fork()).join();
    }
    if (message.validateOnly !== false) {
      writer.uint32(16).bool(message.validateOnly);
    }
    if (message.phraseSetId !== "") {
      writer.uint32(26).string(message.phraseSetId);
    }
    if (message.parent !== "") {
      writer.uint32(34).string(message.parent);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): CreatePhraseSetRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseCreatePhraseSetRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.phraseSet = PhraseSet.decode(reader, reader.uint32());
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.validateOnly = reader.bool();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.phraseSetId = reader.string();
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.parent = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): CreatePhraseSetRequest {
    return {
      phraseSet: isSet(object.phraseSet) ? PhraseSet.fromJSON(object.phraseSet) : undefined,
      validateOnly: isSet(object.validateOnly) ? globalThis.Boolean(object.validateOnly) : false,
      phraseSetId: isSet(object.phraseSetId) ? globalThis.String(object.phraseSetId) : "",
      parent: isSet(object.parent) ? globalThis.String(object.parent) : "",
    };
  },

  toJSON(message: CreatePhraseSetRequest): unknown {
    const obj: any = {};
    if (message.phraseSet !== undefined) {
      obj.phraseSet = PhraseSet.toJSON(message.phraseSet);
    }
    if (message.validateOnly !== false) {
      obj.validateOnly = message.validateOnly;
    }
    if (message.phraseSetId !== "") {
      obj.phraseSetId = message.phraseSetId;
    }
    if (message.parent !== "") {
      obj.parent = message.parent;
    }
    return obj;
  },

  create(base?: DeepPartial<CreatePhraseSetRequest>): CreatePhraseSetRequest {
    return CreatePhraseSetRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<CreatePhraseSetRequest>): CreatePhraseSetRequest {
    const message = createBaseCreatePhraseSetRequest();
    message.phraseSet = (object.phraseSet !== undefined && object.phraseSet !== null)
      ? PhraseSet.fromPartial(object.phraseSet)
      : undefined;
    message.validateOnly = object.validateOnly ?? false;
    message.phraseSetId = object.phraseSetId ?? "";
    message.parent = object.parent ?? "";
    return message;
  },
};

function createBaseListPhraseSetsRequest(): ListPhraseSetsRequest {
  return { parent: "", pageSize: 0, pageToken: "", showDeleted: false };
}

export const ListPhraseSetsRequest: MessageFns<ListPhraseSetsRequest> = {
  encode(message: ListPhraseSetsRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.parent !== "") {
      writer.uint32(10).string(message.parent);
    }
    if (message.pageSize !== 0) {
      writer.uint32(16).int32(message.pageSize);
    }
    if (message.pageToken !== "") {
      writer.uint32(26).string(message.pageToken);
    }
    if (message.showDeleted !== false) {
      writer.uint32(32).bool(message.showDeleted);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ListPhraseSetsRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseListPhraseSetsRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.parent = reader.string();
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.pageSize = reader.int32();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.pageToken = reader.string();
          continue;
        case 4:
          if (tag !== 32) {
            break;
          }

          message.showDeleted = reader.bool();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ListPhraseSetsRequest {
    return {
      parent: isSet(object.parent) ? globalThis.String(object.parent) : "",
      pageSize: isSet(object.pageSize) ? globalThis.Number(object.pageSize) : 0,
      pageToken: isSet(object.pageToken) ? globalThis.String(object.pageToken) : "",
      showDeleted: isSet(object.showDeleted) ? globalThis.Boolean(object.showDeleted) : false,
    };
  },

  toJSON(message: ListPhraseSetsRequest): unknown {
    const obj: any = {};
    if (message.parent !== "") {
      obj.parent = message.parent;
    }
    if (message.pageSize !== 0) {
      obj.pageSize = Math.round(message.pageSize);
    }
    if (message.pageToken !== "") {
      obj.pageToken = message.pageToken;
    }
    if (message.showDeleted !== false) {
      obj.showDeleted = message.showDeleted;
    }
    return obj;
  },

  create(base?: DeepPartial<ListPhraseSetsRequest>): ListPhraseSetsRequest {
    return ListPhraseSetsRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ListPhraseSetsRequest>): ListPhraseSetsRequest {
    const message = createBaseListPhraseSetsRequest();
    message.parent = object.parent ?? "";
    message.pageSize = object.pageSize ?? 0;
    message.pageToken = object.pageToken ?? "";
    message.showDeleted = object.showDeleted ?? false;
    return message;
  },
};

function createBaseListPhraseSetsResponse(): ListPhraseSetsResponse {
  return { phraseSets: [], nextPageToken: "" };
}

export const ListPhraseSetsResponse: MessageFns<ListPhraseSetsResponse> = {
  encode(message: ListPhraseSetsResponse, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.phraseSets) {
      PhraseSet.encode(v!, writer.uint32(10).fork()).join();
    }
    if (message.nextPageToken !== "") {
      writer.uint32(18).string(message.nextPageToken);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ListPhraseSetsResponse {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseListPhraseSetsResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.phraseSets.push(PhraseSet.decode(reader, reader.uint32()));
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.nextPageToken = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ListPhraseSetsResponse {
    return {
      phraseSets: globalThis.Array.isArray(object?.phraseSets)
        ? object.phraseSets.map((e: any) => PhraseSet.fromJSON(e))
        : [],
      nextPageToken: isSet(object.nextPageToken) ? globalThis.String(object.nextPageToken) : "",
    };
  },

  toJSON(message: ListPhraseSetsResponse): unknown {
    const obj: any = {};
    if (message.phraseSets?.length) {
      obj.phraseSets = message.phraseSets.map((e) => PhraseSet.toJSON(e));
    }
    if (message.nextPageToken !== "") {
      obj.nextPageToken = message.nextPageToken;
    }
    return obj;
  },

  create(base?: DeepPartial<ListPhraseSetsResponse>): ListPhraseSetsResponse {
    return ListPhraseSetsResponse.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ListPhraseSetsResponse>): ListPhraseSetsResponse {
    const message = createBaseListPhraseSetsResponse();
    message.phraseSets = object.phraseSets?.map((e) => PhraseSet.fromPartial(e)) || [];
    message.nextPageToken = object.nextPageToken ?? "";
    return message;
  },
};

function createBaseGetPhraseSetRequest(): GetPhraseSetRequest {
  return { name: "" };
}

export const GetPhraseSetRequest: MessageFns<GetPhraseSetRequest> = {
  encode(message: GetPhraseSetRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): GetPhraseSetRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseGetPhraseSetRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): GetPhraseSetRequest {
    return { name: isSet(object.name) ? globalThis.String(object.name) : "" };
  },

  toJSON(message: GetPhraseSetRequest): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    return obj;
  },

  create(base?: DeepPartial<GetPhraseSetRequest>): GetPhraseSetRequest {
    return GetPhraseSetRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<GetPhraseSetRequest>): GetPhraseSetRequest {
    const message = createBaseGetPhraseSetRequest();
    message.name = object.name ?? "";
    return message;
  },
};

function createBaseUpdatePhraseSetRequest(): UpdatePhraseSetRequest {
  return { phraseSet: undefined, updateMask: undefined, validateOnly: false };
}

export const UpdatePhraseSetRequest: MessageFns<UpdatePhraseSetRequest> = {
  encode(message: UpdatePhraseSetRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.phraseSet !== undefined) {
      PhraseSet.encode(message.phraseSet, writer.uint32(10).fork()).join();
    }
    if (message.updateMask !== undefined) {
      FieldMask.encode(FieldMask.wrap(message.updateMask), writer.uint32(18).fork()).join();
    }
    if (message.validateOnly !== false) {
      writer.uint32(32).bool(message.validateOnly);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): UpdatePhraseSetRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseUpdatePhraseSetRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.phraseSet = PhraseSet.decode(reader, reader.uint32());
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.updateMask = FieldMask.unwrap(FieldMask.decode(reader, reader.uint32()));
          continue;
        case 4:
          if (tag !== 32) {
            break;
          }

          message.validateOnly = reader.bool();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): UpdatePhraseSetRequest {
    return {
      phraseSet: isSet(object.phraseSet) ? PhraseSet.fromJSON(object.phraseSet) : undefined,
      updateMask: isSet(object.updateMask) ? FieldMask.unwrap(FieldMask.fromJSON(object.updateMask)) : undefined,
      validateOnly: isSet(object.validateOnly) ? globalThis.Boolean(object.validateOnly) : false,
    };
  },

  toJSON(message: UpdatePhraseSetRequest): unknown {
    const obj: any = {};
    if (message.phraseSet !== undefined) {
      obj.phraseSet = PhraseSet.toJSON(message.phraseSet);
    }
    if (message.updateMask !== undefined) {
      obj.updateMask = FieldMask.toJSON(FieldMask.wrap(message.updateMask));
    }
    if (message.validateOnly !== false) {
      obj.validateOnly = message.validateOnly;
    }
    return obj;
  },

  create(base?: DeepPartial<UpdatePhraseSetRequest>): UpdatePhraseSetRequest {
    return UpdatePhraseSetRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<UpdatePhraseSetRequest>): UpdatePhraseSetRequest {
    const message = createBaseUpdatePhraseSetRequest();
    message.phraseSet = (object.phraseSet !== undefined && object.phraseSet !== null)
      ? PhraseSet.fromPartial(object.phraseSet)
      : undefined;
    message.updateMask = object.updateMask ?? undefined;
    message.validateOnly = object.validateOnly ?? false;
    return message;
  },
};

function createBaseDeletePhraseSetRequest(): DeletePhraseSetRequest {
  return { name: "", validateOnly: false, allowMissing: false, etag: "" };
}

export const DeletePhraseSetRequest: MessageFns<DeletePhraseSetRequest> = {
  encode(message: DeletePhraseSetRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    if (message.validateOnly !== false) {
      writer.uint32(16).bool(message.validateOnly);
    }
    if (message.allowMissing !== false) {
      writer.uint32(32).bool(message.allowMissing);
    }
    if (message.etag !== "") {
      writer.uint32(26).string(message.etag);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): DeletePhraseSetRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDeletePhraseSetRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.validateOnly = reader.bool();
          continue;
        case 4:
          if (tag !== 32) {
            break;
          }

          message.allowMissing = reader.bool();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.etag = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): DeletePhraseSetRequest {
    return {
      name: isSet(object.name) ? globalThis.String(object.name) : "",
      validateOnly: isSet(object.validateOnly) ? globalThis.Boolean(object.validateOnly) : false,
      allowMissing: isSet(object.allowMissing) ? globalThis.Boolean(object.allowMissing) : false,
      etag: isSet(object.etag) ? globalThis.String(object.etag) : "",
    };
  },

  toJSON(message: DeletePhraseSetRequest): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    if (message.validateOnly !== false) {
      obj.validateOnly = message.validateOnly;
    }
    if (message.allowMissing !== false) {
      obj.allowMissing = message.allowMissing;
    }
    if (message.etag !== "") {
      obj.etag = message.etag;
    }
    return obj;
  },

  create(base?: DeepPartial<DeletePhraseSetRequest>): DeletePhraseSetRequest {
    return DeletePhraseSetRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<DeletePhraseSetRequest>): DeletePhraseSetRequest {
    const message = createBaseDeletePhraseSetRequest();
    message.name = object.name ?? "";
    message.validateOnly = object.validateOnly ?? false;
    message.allowMissing = object.allowMissing ?? false;
    message.etag = object.etag ?? "";
    return message;
  },
};

function createBaseUndeletePhraseSetRequest(): UndeletePhraseSetRequest {
  return { name: "", validateOnly: false, etag: "" };
}

export const UndeletePhraseSetRequest: MessageFns<UndeletePhraseSetRequest> = {
  encode(message: UndeletePhraseSetRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    if (message.validateOnly !== false) {
      writer.uint32(24).bool(message.validateOnly);
    }
    if (message.etag !== "") {
      writer.uint32(34).string(message.etag);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): UndeletePhraseSetRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseUndeletePhraseSetRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
        case 3:
          if (tag !== 24) {
            break;
          }

          message.validateOnly = reader.bool();
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.etag = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): UndeletePhraseSetRequest {
    return {
      name: isSet(object.name) ? globalThis.String(object.name) : "",
      validateOnly: isSet(object.validateOnly) ? globalThis.Boolean(object.validateOnly) : false,
      etag: isSet(object.etag) ? globalThis.String(object.etag) : "",
    };
  },

  toJSON(message: UndeletePhraseSetRequest): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    if (message.validateOnly !== false) {
      obj.validateOnly = message.validateOnly;
    }
    if (message.etag !== "") {
      obj.etag = message.etag;
    }
    return obj;
  },

  create(base?: DeepPartial<UndeletePhraseSetRequest>): UndeletePhraseSetRequest {
    return UndeletePhraseSetRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<UndeletePhraseSetRequest>): UndeletePhraseSetRequest {
    const message = createBaseUndeletePhraseSetRequest();
    message.name = object.name ?? "";
    message.validateOnly = object.validateOnly ?? false;
    message.etag = object.etag ?? "";
    return message;
  },
};

/** Enables speech transcription and resource management. */
export type SpeechDefinition = typeof SpeechDefinition;
export const SpeechDefinition = {
  name: "Speech",
  fullName: "google.cloud.speech.v2.Speech",
  methods: {
    /** Creates a [Recognizer][google.cloud.speech.v2.Recognizer]. */
    createRecognizer: {
      name: "CreateRecognizer",
      requestType: CreateRecognizerRequest,
      requestStream: false,
      responseType: Operation,
      responseStream: false,
      options: {
        _unknownFields: {
          8394: [
            Buffer.from([
              31,
              10,
              10,
              82,
              101,
              99,
              111,
              103,
              110,
              105,
              122,
              101,
              114,
              18,
              17,
              79,
              112,
              101,
              114,
              97,
              116,
              105,
              111,
              110,
              77,
              101,
              116,
              97,
              100,
              97,
              116,
              97,
            ]),
          ],
          8410: [
            Buffer.from([
              31,
              112,
              97,
              114,
              101,
              110,
              116,
              44,
              114,
              101,
              99,
              111,
              103,
              110,
              105,
              122,
              101,
              114,
              44,
              114,
              101,
              99,
              111,
              103,
              110,
              105,
              122,
              101,
              114,
              95,
              105,
              100,
            ]),
          ],
          578365826: [
            Buffer.from([
              61,
              58,
              10,
              114,
              101,
              99,
              111,
              103,
              110,
              105,
              122,
              101,
              114,
              34,
              47,
              47,
              118,
              50,
              47,
              123,
              112,
              97,
              114,
              101,
              110,
              116,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              125,
              47,
              114,
              101,
              99,
              111,
              103,
              110,
              105,
              122,
              101,
              114,
              115,
            ]),
          ],
        },
      },
    },
    /** Lists Recognizers. */
    listRecognizers: {
      name: "ListRecognizers",
      requestType: ListRecognizersRequest,
      requestStream: false,
      responseType: ListRecognizersResponse,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [Buffer.from([6, 112, 97, 114, 101, 110, 116])],
          578365826: [
            Buffer.from([
              49,
              18,
              47,
              47,
              118,
              50,
              47,
              123,
              112,
              97,
              114,
              101,
              110,
              116,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              125,
              47,
              114,
              101,
              99,
              111,
              103,
              110,
              105,
              122,
              101,
              114,
              115,
            ]),
          ],
        },
      },
    },
    /**
     * Returns the requested
     * [Recognizer][google.cloud.speech.v2.Recognizer]. Fails with
     * [NOT_FOUND][google.rpc.Code.NOT_FOUND] if the requested Recognizer doesn't
     * exist.
     */
    getRecognizer: {
      name: "GetRecognizer",
      requestType: GetRecognizerRequest,
      requestStream: false,
      responseType: Recognizer,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [Buffer.from([4, 110, 97, 109, 101])],
          578365826: [
            Buffer.from([
              49,
              18,
              47,
              47,
              118,
              50,
              47,
              123,
              110,
              97,
              109,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              114,
              101,
              99,
              111,
              103,
              110,
              105,
              122,
              101,
              114,
              115,
              47,
              42,
              125,
            ]),
          ],
        },
      },
    },
    /** Updates the [Recognizer][google.cloud.speech.v2.Recognizer]. */
    updateRecognizer: {
      name: "UpdateRecognizer",
      requestType: UpdateRecognizerRequest,
      requestStream: false,
      responseType: Operation,
      responseStream: false,
      options: {
        _unknownFields: {
          8394: [
            Buffer.from([
              31,
              10,
              10,
              82,
              101,
              99,
              111,
              103,
              110,
              105,
              122,
              101,
              114,
              18,
              17,
              79,
              112,
              101,
              114,
              97,
              116,
              105,
              111,
              110,
              77,
              101,
              116,
              97,
              100,
              97,
              116,
              97,
            ]),
          ],
          8410: [
            Buffer.from([
              22,
              114,
              101,
              99,
              111,
              103,
              110,
              105,
              122,
              101,
              114,
              44,
              117,
              112,
              100,
              97,
              116,
              101,
              95,
              109,
              97,
              115,
              107,
            ]),
          ],
          578365826: [
            Buffer.from([
              72,
              58,
              10,
              114,
              101,
              99,
              111,
              103,
              110,
              105,
              122,
              101,
              114,
              50,
              58,
              47,
              118,
              50,
              47,
              123,
              114,
              101,
              99,
              111,
              103,
              110,
              105,
              122,
              101,
              114,
              46,
              110,
              97,
              109,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              114,
              101,
              99,
              111,
              103,
              110,
              105,
              122,
              101,
              114,
              115,
              47,
              42,
              125,
            ]),
          ],
        },
      },
    },
    /** Deletes the [Recognizer][google.cloud.speech.v2.Recognizer]. */
    deleteRecognizer: {
      name: "DeleteRecognizer",
      requestType: DeleteRecognizerRequest,
      requestStream: false,
      responseType: Operation,
      responseStream: false,
      options: {
        _unknownFields: {
          8394: [
            Buffer.from([
              31,
              10,
              10,
              82,
              101,
              99,
              111,
              103,
              110,
              105,
              122,
              101,
              114,
              18,
              17,
              79,
              112,
              101,
              114,
              97,
              116,
              105,
              111,
              110,
              77,
              101,
              116,
              97,
              100,
              97,
              116,
              97,
            ]),
          ],
          8410: [Buffer.from([4, 110, 97, 109, 101])],
          578365826: [
            Buffer.from([
              49,
              42,
              47,
              47,
              118,
              50,
              47,
              123,
              110,
              97,
              109,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              114,
              101,
              99,
              111,
              103,
              110,
              105,
              122,
              101,
              114,
              115,
              47,
              42,
              125,
            ]),
          ],
        },
      },
    },
    /** Undeletes the [Recognizer][google.cloud.speech.v2.Recognizer]. */
    undeleteRecognizer: {
      name: "UndeleteRecognizer",
      requestType: UndeleteRecognizerRequest,
      requestStream: false,
      responseType: Operation,
      responseStream: false,
      options: {
        _unknownFields: {
          8394: [
            Buffer.from([
              31,
              10,
              10,
              82,
              101,
              99,
              111,
              103,
              110,
              105,
              122,
              101,
              114,
              18,
              17,
              79,
              112,
              101,
              114,
              97,
              116,
              105,
              111,
              110,
              77,
              101,
              116,
              97,
              100,
              97,
              116,
              97,
            ]),
          ],
          8410: [Buffer.from([4, 110, 97, 109, 101])],
          578365826: [
            Buffer.from([
              61,
              58,
              1,
              42,
              34,
              56,
              47,
              118,
              50,
              47,
              123,
              110,
              97,
              109,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              114,
              101,
              99,
              111,
              103,
              110,
              105,
              122,
              101,
              114,
              115,
              47,
              42,
              125,
              58,
              117,
              110,
              100,
              101,
              108,
              101,
              116,
              101,
            ]),
          ],
        },
      },
    },
    /**
     * Performs synchronous Speech recognition: receive results after all audio
     * has been sent and processed.
     */
    recognize: {
      name: "Recognize",
      requestType: RecognizeRequest,
      requestStream: false,
      responseType: RecognizeResponse,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [
            Buffer.from([
              37,
              114,
              101,
              99,
              111,
              103,
              110,
              105,
              122,
              101,
              114,
              44,
              99,
              111,
              110,
              102,
              105,
              103,
              44,
              99,
              111,
              110,
              102,
              105,
              103,
              95,
              109,
              97,
              115,
              107,
              44,
              99,
              111,
              110,
              116,
              101,
              110,
              116,
            ]),
            Buffer.from([
              33,
              114,
              101,
              99,
              111,
              103,
              110,
              105,
              122,
              101,
              114,
              44,
              99,
              111,
              110,
              102,
              105,
              103,
              44,
              99,
              111,
              110,
              102,
              105,
              103,
              95,
              109,
              97,
              115,
              107,
              44,
              117,
              114,
              105,
            ]),
          ],
          578365826: [
            Buffer.from([
              68,
              58,
              1,
              42,
              34,
              63,
              47,
              118,
              50,
              47,
              123,
              114,
              101,
              99,
              111,
              103,
              110,
              105,
              122,
              101,
              114,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              114,
              101,
              99,
              111,
              103,
              110,
              105,
              122,
              101,
              114,
              115,
              47,
              42,
              125,
              58,
              114,
              101,
              99,
              111,
              103,
              110,
              105,
              122,
              101,
            ]),
          ],
        },
      },
    },
    /**
     * Performs bidirectional streaming speech recognition: receive results while
     * sending audio. This method is only available via the gRPC API (not REST).
     */
    streamingRecognize: {
      name: "StreamingRecognize",
      requestType: StreamingRecognizeRequest,
      requestStream: true,
      responseType: StreamingRecognizeResponse,
      responseStream: true,
      options: {},
    },
    /**
     * Performs batch asynchronous speech recognition: send a request with N
     * audio files and receive a long running operation that can be polled to see
     * when the transcriptions are finished.
     */
    batchRecognize: {
      name: "BatchRecognize",
      requestType: BatchRecognizeRequest,
      requestStream: false,
      responseType: Operation,
      responseStream: false,
      options: {
        _unknownFields: {
          8394: [
            Buffer.from([
              43,
              10,
              22,
              66,
              97,
              116,
              99,
              104,
              82,
              101,
              99,
              111,
              103,
              110,
              105,
              122,
              101,
              82,
              101,
              115,
              112,
              111,
              110,
              115,
              101,
              18,
              17,
              79,
              112,
              101,
              114,
              97,
              116,
              105,
              111,
              110,
              77,
              101,
              116,
              97,
              100,
              97,
              116,
              97,
            ]),
          ],
          8410: [
            Buffer.from([
              35,
              114,
              101,
              99,
              111,
              103,
              110,
              105,
              122,
              101,
              114,
              44,
              99,
              111,
              110,
              102,
              105,
              103,
              44,
              99,
              111,
              110,
              102,
              105,
              103,
              95,
              109,
              97,
              115,
              107,
              44,
              102,
              105,
              108,
              101,
              115,
            ]),
          ],
          578365826: [
            Buffer.from([
              73,
              58,
              1,
              42,
              34,
              68,
              47,
              118,
              50,
              47,
              123,
              114,
              101,
              99,
              111,
              103,
              110,
              105,
              122,
              101,
              114,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              114,
              101,
              99,
              111,
              103,
              110,
              105,
              122,
              101,
              114,
              115,
              47,
              42,
              125,
              58,
              98,
              97,
              116,
              99,
              104,
              82,
              101,
              99,
              111,
              103,
              110,
              105,
              122,
              101,
            ]),
          ],
        },
      },
    },
    /** Returns the requested [Config][google.cloud.speech.v2.Config]. */
    getConfig: {
      name: "GetConfig",
      requestType: GetConfigRequest,
      requestStream: false,
      responseType: Config,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [Buffer.from([4, 110, 97, 109, 101])],
          578365826: [
            Buffer.from([
              42,
              18,
              40,
              47,
              118,
              50,
              47,
              123,
              110,
              97,
              109,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              99,
              111,
              110,
              102,
              105,
              103,
              125,
            ]),
          ],
        },
      },
    },
    /** Updates the [Config][google.cloud.speech.v2.Config]. */
    updateConfig: {
      name: "UpdateConfig",
      requestType: UpdateConfigRequest,
      requestStream: false,
      responseType: Config,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [
            Buffer.from([18, 99, 111, 110, 102, 105, 103, 44, 117, 112, 100, 97, 116, 101, 95, 109, 97, 115, 107]),
          ],
          578365826: [
            Buffer.from([
              57,
              58,
              6,
              99,
              111,
              110,
              102,
              105,
              103,
              50,
              47,
              47,
              118,
              50,
              47,
              123,
              99,
              111,
              110,
              102,
              105,
              103,
              46,
              110,
              97,
              109,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              99,
              111,
              110,
              102,
              105,
              103,
              125,
            ]),
          ],
        },
      },
    },
    /** Creates a [CustomClass][google.cloud.speech.v2.CustomClass]. */
    createCustomClass: {
      name: "CreateCustomClass",
      requestType: CreateCustomClassRequest,
      requestStream: false,
      responseType: Operation,
      responseStream: false,
      options: {
        _unknownFields: {
          8394: [
            Buffer.from([
              32,
              10,
              11,
              67,
              117,
              115,
              116,
              111,
              109,
              67,
              108,
              97,
              115,
              115,
              18,
              17,
              79,
              112,
              101,
              114,
              97,
              116,
              105,
              111,
              110,
              77,
              101,
              116,
              97,
              100,
              97,
              116,
              97,
            ]),
          ],
          8410: [
            Buffer.from([
              35,
              112,
              97,
              114,
              101,
              110,
              116,
              44,
              99,
              117,
              115,
              116,
              111,
              109,
              95,
              99,
              108,
              97,
              115,
              115,
              44,
              99,
              117,
              115,
              116,
              111,
              109,
              95,
              99,
              108,
              97,
              115,
              115,
              95,
              105,
              100,
            ]),
          ],
          578365826: [
            Buffer.from([
              65,
              58,
              12,
              99,
              117,
              115,
              116,
              111,
              109,
              95,
              99,
              108,
              97,
              115,
              115,
              34,
              49,
              47,
              118,
              50,
              47,
              123,
              112,
              97,
              114,
              101,
              110,
              116,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              125,
              47,
              99,
              117,
              115,
              116,
              111,
              109,
              67,
              108,
              97,
              115,
              115,
              101,
              115,
            ]),
          ],
        },
      },
    },
    /** Lists CustomClasses. */
    listCustomClasses: {
      name: "ListCustomClasses",
      requestType: ListCustomClassesRequest,
      requestStream: false,
      responseType: ListCustomClassesResponse,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [Buffer.from([6, 112, 97, 114, 101, 110, 116])],
          578365826: [
            Buffer.from([
              51,
              18,
              49,
              47,
              118,
              50,
              47,
              123,
              112,
              97,
              114,
              101,
              110,
              116,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              125,
              47,
              99,
              117,
              115,
              116,
              111,
              109,
              67,
              108,
              97,
              115,
              115,
              101,
              115,
            ]),
          ],
        },
      },
    },
    /**
     * Returns the requested
     * [CustomClass][google.cloud.speech.v2.CustomClass].
     */
    getCustomClass: {
      name: "GetCustomClass",
      requestType: GetCustomClassRequest,
      requestStream: false,
      responseType: CustomClass,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [Buffer.from([4, 110, 97, 109, 101])],
          578365826: [
            Buffer.from([
              51,
              18,
              49,
              47,
              118,
              50,
              47,
              123,
              110,
              97,
              109,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              99,
              117,
              115,
              116,
              111,
              109,
              67,
              108,
              97,
              115,
              115,
              101,
              115,
              47,
              42,
              125,
            ]),
          ],
        },
      },
    },
    /** Updates the [CustomClass][google.cloud.speech.v2.CustomClass]. */
    updateCustomClass: {
      name: "UpdateCustomClass",
      requestType: UpdateCustomClassRequest,
      requestStream: false,
      responseType: Operation,
      responseStream: false,
      options: {
        _unknownFields: {
          8394: [
            Buffer.from([
              32,
              10,
              11,
              67,
              117,
              115,
              116,
              111,
              109,
              67,
              108,
              97,
              115,
              115,
              18,
              17,
              79,
              112,
              101,
              114,
              97,
              116,
              105,
              111,
              110,
              77,
              101,
              116,
              97,
              100,
              97,
              116,
              97,
            ]),
          ],
          8410: [
            Buffer.from([
              24,
              99,
              117,
              115,
              116,
              111,
              109,
              95,
              99,
              108,
              97,
              115,
              115,
              44,
              117,
              112,
              100,
              97,
              116,
              101,
              95,
              109,
              97,
              115,
              107,
            ]),
          ],
          578365826: [
            Buffer.from([
              78,
              58,
              12,
              99,
              117,
              115,
              116,
              111,
              109,
              95,
              99,
              108,
              97,
              115,
              115,
              50,
              62,
              47,
              118,
              50,
              47,
              123,
              99,
              117,
              115,
              116,
              111,
              109,
              95,
              99,
              108,
              97,
              115,
              115,
              46,
              110,
              97,
              109,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              99,
              117,
              115,
              116,
              111,
              109,
              67,
              108,
              97,
              115,
              115,
              101,
              115,
              47,
              42,
              125,
            ]),
          ],
        },
      },
    },
    /** Deletes the [CustomClass][google.cloud.speech.v2.CustomClass]. */
    deleteCustomClass: {
      name: "DeleteCustomClass",
      requestType: DeleteCustomClassRequest,
      requestStream: false,
      responseType: Operation,
      responseStream: false,
      options: {
        _unknownFields: {
          8394: [
            Buffer.from([
              32,
              10,
              11,
              67,
              117,
              115,
              116,
              111,
              109,
              67,
              108,
              97,
              115,
              115,
              18,
              17,
              79,
              112,
              101,
              114,
              97,
              116,
              105,
              111,
              110,
              77,
              101,
              116,
              97,
              100,
              97,
              116,
              97,
            ]),
          ],
          8410: [Buffer.from([4, 110, 97, 109, 101])],
          578365826: [
            Buffer.from([
              51,
              42,
              49,
              47,
              118,
              50,
              47,
              123,
              110,
              97,
              109,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              99,
              117,
              115,
              116,
              111,
              109,
              67,
              108,
              97,
              115,
              115,
              101,
              115,
              47,
              42,
              125,
            ]),
          ],
        },
      },
    },
    /** Undeletes the [CustomClass][google.cloud.speech.v2.CustomClass]. */
    undeleteCustomClass: {
      name: "UndeleteCustomClass",
      requestType: UndeleteCustomClassRequest,
      requestStream: false,
      responseType: Operation,
      responseStream: false,
      options: {
        _unknownFields: {
          8394: [
            Buffer.from([
              32,
              10,
              11,
              67,
              117,
              115,
              116,
              111,
              109,
              67,
              108,
              97,
              115,
              115,
              18,
              17,
              79,
              112,
              101,
              114,
              97,
              116,
              105,
              111,
              110,
              77,
              101,
              116,
              97,
              100,
              97,
              116,
              97,
            ]),
          ],
          8410: [Buffer.from([4, 110, 97, 109, 101])],
          578365826: [
            Buffer.from([
              63,
              58,
              1,
              42,
              34,
              58,
              47,
              118,
              50,
              47,
              123,
              110,
              97,
              109,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              99,
              117,
              115,
              116,
              111,
              109,
              67,
              108,
              97,
              115,
              115,
              101,
              115,
              47,
              42,
              125,
              58,
              117,
              110,
              100,
              101,
              108,
              101,
              116,
              101,
            ]),
          ],
        },
      },
    },
    /** Creates a [PhraseSet][google.cloud.speech.v2.PhraseSet]. */
    createPhraseSet: {
      name: "CreatePhraseSet",
      requestType: CreatePhraseSetRequest,
      requestStream: false,
      responseType: Operation,
      responseStream: false,
      options: {
        _unknownFields: {
          8394: [
            Buffer.from([
              30,
              10,
              9,
              80,
              104,
              114,
              97,
              115,
              101,
              83,
              101,
              116,
              18,
              17,
              79,
              112,
              101,
              114,
              97,
              116,
              105,
              111,
              110,
              77,
              101,
              116,
              97,
              100,
              97,
              116,
              97,
            ]),
          ],
          8410: [
            Buffer.from([
              31,
              112,
              97,
              114,
              101,
              110,
              116,
              44,
              112,
              104,
              114,
              97,
              115,
              101,
              95,
              115,
              101,
              116,
              44,
              112,
              104,
              114,
              97,
              115,
              101,
              95,
              115,
              101,
              116,
              95,
              105,
              100,
            ]),
          ],
          578365826: [
            Buffer.from([
              60,
              58,
              10,
              112,
              104,
              114,
              97,
              115,
              101,
              95,
              115,
              101,
              116,
              34,
              46,
              47,
              118,
              50,
              47,
              123,
              112,
              97,
              114,
              101,
              110,
              116,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              125,
              47,
              112,
              104,
              114,
              97,
              115,
              101,
              83,
              101,
              116,
              115,
            ]),
          ],
        },
      },
    },
    /** Lists PhraseSets. */
    listPhraseSets: {
      name: "ListPhraseSets",
      requestType: ListPhraseSetsRequest,
      requestStream: false,
      responseType: ListPhraseSetsResponse,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [Buffer.from([6, 112, 97, 114, 101, 110, 116])],
          578365826: [
            Buffer.from([
              48,
              18,
              46,
              47,
              118,
              50,
              47,
              123,
              112,
              97,
              114,
              101,
              110,
              116,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              125,
              47,
              112,
              104,
              114,
              97,
              115,
              101,
              83,
              101,
              116,
              115,
            ]),
          ],
        },
      },
    },
    /**
     * Returns the requested
     * [PhraseSet][google.cloud.speech.v2.PhraseSet].
     */
    getPhraseSet: {
      name: "GetPhraseSet",
      requestType: GetPhraseSetRequest,
      requestStream: false,
      responseType: PhraseSet,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [Buffer.from([4, 110, 97, 109, 101])],
          578365826: [
            Buffer.from([
              48,
              18,
              46,
              47,
              118,
              50,
              47,
              123,
              110,
              97,
              109,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              112,
              104,
              114,
              97,
              115,
              101,
              83,
              101,
              116,
              115,
              47,
              42,
              125,
            ]),
          ],
        },
      },
    },
    /** Updates the [PhraseSet][google.cloud.speech.v2.PhraseSet]. */
    updatePhraseSet: {
      name: "UpdatePhraseSet",
      requestType: UpdatePhraseSetRequest,
      requestStream: false,
      responseType: Operation,
      responseStream: false,
      options: {
        _unknownFields: {
          8394: [
            Buffer.from([
              30,
              10,
              9,
              80,
              104,
              114,
              97,
              115,
              101,
              83,
              101,
              116,
              18,
              17,
              79,
              112,
              101,
              114,
              97,
              116,
              105,
              111,
              110,
              77,
              101,
              116,
              97,
              100,
              97,
              116,
              97,
            ]),
          ],
          8410: [
            Buffer.from([
              22,
              112,
              104,
              114,
              97,
              115,
              101,
              95,
              115,
              101,
              116,
              44,
              117,
              112,
              100,
              97,
              116,
              101,
              95,
              109,
              97,
              115,
              107,
            ]),
          ],
          578365826: [
            Buffer.from([
              71,
              58,
              10,
              112,
              104,
              114,
              97,
              115,
              101,
              95,
              115,
              101,
              116,
              50,
              57,
              47,
              118,
              50,
              47,
              123,
              112,
              104,
              114,
              97,
              115,
              101,
              95,
              115,
              101,
              116,
              46,
              110,
              97,
              109,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              112,
              104,
              114,
              97,
              115,
              101,
              83,
              101,
              116,
              115,
              47,
              42,
              125,
            ]),
          ],
        },
      },
    },
    /** Deletes the [PhraseSet][google.cloud.speech.v2.PhraseSet]. */
    deletePhraseSet: {
      name: "DeletePhraseSet",
      requestType: DeletePhraseSetRequest,
      requestStream: false,
      responseType: Operation,
      responseStream: false,
      options: {
        _unknownFields: {
          8394: [
            Buffer.from([
              30,
              10,
              9,
              80,
              104,
              114,
              97,
              115,
              101,
              83,
              101,
              116,
              18,
              17,
              79,
              112,
              101,
              114,
              97,
              116,
              105,
              111,
              110,
              77,
              101,
              116,
              97,
              100,
              97,
              116,
              97,
            ]),
          ],
          8410: [Buffer.from([4, 110, 97, 109, 101])],
          578365826: [
            Buffer.from([
              48,
              42,
              46,
              47,
              118,
              50,
              47,
              123,
              110,
              97,
              109,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              112,
              104,
              114,
              97,
              115,
              101,
              83,
              101,
              116,
              115,
              47,
              42,
              125,
            ]),
          ],
        },
      },
    },
    /** Undeletes the [PhraseSet][google.cloud.speech.v2.PhraseSet]. */
    undeletePhraseSet: {
      name: "UndeletePhraseSet",
      requestType: UndeletePhraseSetRequest,
      requestStream: false,
      responseType: Operation,
      responseStream: false,
      options: {
        _unknownFields: {
          8394: [
            Buffer.from([
              30,
              10,
              9,
              80,
              104,
              114,
              97,
              115,
              101,
              83,
              101,
              116,
              18,
              17,
              79,
              112,
              101,
              114,
              97,
              116,
              105,
              111,
              110,
              77,
              101,
              116,
              97,
              100,
              97,
              116,
              97,
            ]),
          ],
          8410: [Buffer.from([4, 110, 97, 109, 101])],
          578365826: [
            Buffer.from([
              60,
              58,
              1,
              42,
              34,
              55,
              47,
              118,
              50,
              47,
              123,
              110,
              97,
              109,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              112,
              104,
              114,
              97,
              115,
              101,
              83,
              101,
              116,
              115,
              47,
              42,
              125,
              58,
              117,
              110,
              100,
              101,
              108,
              101,
              116,
              101,
            ]),
          ],
        },
      },
    },
  },
} as const;

export interface SpeechServiceImplementation<CallContextExt = {}> {
  /** Creates a [Recognizer][google.cloud.speech.v2.Recognizer]. */
  createRecognizer(
    request: CreateRecognizerRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<Operation>>;
  /** Lists Recognizers. */
  listRecognizers(
    request: ListRecognizersRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<ListRecognizersResponse>>;
  /**
   * Returns the requested
   * [Recognizer][google.cloud.speech.v2.Recognizer]. Fails with
   * [NOT_FOUND][google.rpc.Code.NOT_FOUND] if the requested Recognizer doesn't
   * exist.
   */
  getRecognizer(request: GetRecognizerRequest, context: CallContext & CallContextExt): Promise<DeepPartial<Recognizer>>;
  /** Updates the [Recognizer][google.cloud.speech.v2.Recognizer]. */
  updateRecognizer(
    request: UpdateRecognizerRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<Operation>>;
  /** Deletes the [Recognizer][google.cloud.speech.v2.Recognizer]. */
  deleteRecognizer(
    request: DeleteRecognizerRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<Operation>>;
  /** Undeletes the [Recognizer][google.cloud.speech.v2.Recognizer]. */
  undeleteRecognizer(
    request: UndeleteRecognizerRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<Operation>>;
  /**
   * Performs synchronous Speech recognition: receive results after all audio
   * has been sent and processed.
   */
  recognize(request: RecognizeRequest, context: CallContext & CallContextExt): Promise<DeepPartial<RecognizeResponse>>;
  /**
   * Performs bidirectional streaming speech recognition: receive results while
   * sending audio. This method is only available via the gRPC API (not REST).
   */
  streamingRecognize(
    request: AsyncIterable<StreamingRecognizeRequest>,
    context: CallContext & CallContextExt,
  ): ServerStreamingMethodResult<DeepPartial<StreamingRecognizeResponse>>;
  /**
   * Performs batch asynchronous speech recognition: send a request with N
   * audio files and receive a long running operation that can be polled to see
   * when the transcriptions are finished.
   */
  batchRecognize(
    request: BatchRecognizeRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<Operation>>;
  /** Returns the requested [Config][google.cloud.speech.v2.Config]. */
  getConfig(request: GetConfigRequest, context: CallContext & CallContextExt): Promise<DeepPartial<Config>>;
  /** Updates the [Config][google.cloud.speech.v2.Config]. */
  updateConfig(request: UpdateConfigRequest, context: CallContext & CallContextExt): Promise<DeepPartial<Config>>;
  /** Creates a [CustomClass][google.cloud.speech.v2.CustomClass]. */
  createCustomClass(
    request: CreateCustomClassRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<Operation>>;
  /** Lists CustomClasses. */
  listCustomClasses(
    request: ListCustomClassesRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<ListCustomClassesResponse>>;
  /**
   * Returns the requested
   * [CustomClass][google.cloud.speech.v2.CustomClass].
   */
  getCustomClass(
    request: GetCustomClassRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<CustomClass>>;
  /** Updates the [CustomClass][google.cloud.speech.v2.CustomClass]. */
  updateCustomClass(
    request: UpdateCustomClassRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<Operation>>;
  /** Deletes the [CustomClass][google.cloud.speech.v2.CustomClass]. */
  deleteCustomClass(
    request: DeleteCustomClassRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<Operation>>;
  /** Undeletes the [CustomClass][google.cloud.speech.v2.CustomClass]. */
  undeleteCustomClass(
    request: UndeleteCustomClassRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<Operation>>;
  /** Creates a [PhraseSet][google.cloud.speech.v2.PhraseSet]. */
  createPhraseSet(
    request: CreatePhraseSetRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<Operation>>;
  /** Lists PhraseSets. */
  listPhraseSets(
    request: ListPhraseSetsRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<ListPhraseSetsResponse>>;
  /**
   * Returns the requested
   * [PhraseSet][google.cloud.speech.v2.PhraseSet].
   */
  getPhraseSet(request: GetPhraseSetRequest, context: CallContext & CallContextExt): Promise<DeepPartial<PhraseSet>>;
  /** Updates the [PhraseSet][google.cloud.speech.v2.PhraseSet]. */
  updatePhraseSet(
    request: UpdatePhraseSetRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<Operation>>;
  /** Deletes the [PhraseSet][google.cloud.speech.v2.PhraseSet]. */
  deletePhraseSet(
    request: DeletePhraseSetRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<Operation>>;
  /** Undeletes the [PhraseSet][google.cloud.speech.v2.PhraseSet]. */
  undeletePhraseSet(
    request: UndeletePhraseSetRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<Operation>>;
}

export interface SpeechClient<CallOptionsExt = {}> {
  /** Creates a [Recognizer][google.cloud.speech.v2.Recognizer]. */
  createRecognizer(
    request: DeepPartial<CreateRecognizerRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<Operation>;
  /** Lists Recognizers. */
  listRecognizers(
    request: DeepPartial<ListRecognizersRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<ListRecognizersResponse>;
  /**
   * Returns the requested
   * [Recognizer][google.cloud.speech.v2.Recognizer]. Fails with
   * [NOT_FOUND][google.rpc.Code.NOT_FOUND] if the requested Recognizer doesn't
   * exist.
   */
  getRecognizer(
    request: DeepPartial<GetRecognizerRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<Recognizer>;
  /** Updates the [Recognizer][google.cloud.speech.v2.Recognizer]. */
  updateRecognizer(
    request: DeepPartial<UpdateRecognizerRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<Operation>;
  /** Deletes the [Recognizer][google.cloud.speech.v2.Recognizer]. */
  deleteRecognizer(
    request: DeepPartial<DeleteRecognizerRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<Operation>;
  /** Undeletes the [Recognizer][google.cloud.speech.v2.Recognizer]. */
  undeleteRecognizer(
    request: DeepPartial<UndeleteRecognizerRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<Operation>;
  /**
   * Performs synchronous Speech recognition: receive results after all audio
   * has been sent and processed.
   */
  recognize(request: DeepPartial<RecognizeRequest>, options?: CallOptions & CallOptionsExt): Promise<RecognizeResponse>;
  /**
   * Performs bidirectional streaming speech recognition: receive results while
   * sending audio. This method is only available via the gRPC API (not REST).
   */
  streamingRecognize(
    request: AsyncIterable<DeepPartial<StreamingRecognizeRequest>>,
    options?: CallOptions & CallOptionsExt,
  ): AsyncIterable<StreamingRecognizeResponse>;
  /**
   * Performs batch asynchronous speech recognition: send a request with N
   * audio files and receive a long running operation that can be polled to see
   * when the transcriptions are finished.
   */
  batchRecognize(
    request: DeepPartial<BatchRecognizeRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<Operation>;
  /** Returns the requested [Config][google.cloud.speech.v2.Config]. */
  getConfig(request: DeepPartial<GetConfigRequest>, options?: CallOptions & CallOptionsExt): Promise<Config>;
  /** Updates the [Config][google.cloud.speech.v2.Config]. */
  updateConfig(request: DeepPartial<UpdateConfigRequest>, options?: CallOptions & CallOptionsExt): Promise<Config>;
  /** Creates a [CustomClass][google.cloud.speech.v2.CustomClass]. */
  createCustomClass(
    request: DeepPartial<CreateCustomClassRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<Operation>;
  /** Lists CustomClasses. */
  listCustomClasses(
    request: DeepPartial<ListCustomClassesRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<ListCustomClassesResponse>;
  /**
   * Returns the requested
   * [CustomClass][google.cloud.speech.v2.CustomClass].
   */
  getCustomClass(
    request: DeepPartial<GetCustomClassRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<CustomClass>;
  /** Updates the [CustomClass][google.cloud.speech.v2.CustomClass]. */
  updateCustomClass(
    request: DeepPartial<UpdateCustomClassRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<Operation>;
  /** Deletes the [CustomClass][google.cloud.speech.v2.CustomClass]. */
  deleteCustomClass(
    request: DeepPartial<DeleteCustomClassRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<Operation>;
  /** Undeletes the [CustomClass][google.cloud.speech.v2.CustomClass]. */
  undeleteCustomClass(
    request: DeepPartial<UndeleteCustomClassRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<Operation>;
  /** Creates a [PhraseSet][google.cloud.speech.v2.PhraseSet]. */
  createPhraseSet(
    request: DeepPartial<CreatePhraseSetRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<Operation>;
  /** Lists PhraseSets. */
  listPhraseSets(
    request: DeepPartial<ListPhraseSetsRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<ListPhraseSetsResponse>;
  /**
   * Returns the requested
   * [PhraseSet][google.cloud.speech.v2.PhraseSet].
   */
  getPhraseSet(request: DeepPartial<GetPhraseSetRequest>, options?: CallOptions & CallOptionsExt): Promise<PhraseSet>;
  /** Updates the [PhraseSet][google.cloud.speech.v2.PhraseSet]. */
  updatePhraseSet(
    request: DeepPartial<UpdatePhraseSetRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<Operation>;
  /** Deletes the [PhraseSet][google.cloud.speech.v2.PhraseSet]. */
  deletePhraseSet(
    request: DeepPartial<DeletePhraseSetRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<Operation>;
  /** Undeletes the [PhraseSet][google.cloud.speech.v2.PhraseSet]. */
  undeletePhraseSet(
    request: DeepPartial<UndeletePhraseSetRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<Operation>;
}

function bytesFromBase64(b64: string): Uint8Array {
  return Uint8Array.from(globalThis.Buffer.from(b64, "base64"));
}

function base64FromBytes(arr: Uint8Array): string {
  return globalThis.Buffer.from(arr).toString("base64");
}

type Builtin = Date | Function | Uint8Array | string | number | boolean | undefined;

export type DeepPartial<T> = T extends Builtin ? T
  : T extends Long ? string | number | Long : T extends globalThis.Array<infer U> ? globalThis.Array<DeepPartial<U>>
  : T extends ReadonlyArray<infer U> ? ReadonlyArray<DeepPartial<U>>
  : T extends {} ? { [K in keyof T]?: DeepPartial<T[K]> }
  : Partial<T>;

function toTimestamp(date: Date): Timestamp {
  const seconds = numberToLong(Math.trunc(date.getTime() / 1_000));
  const nanos = (date.getTime() % 1_000) * 1_000_000;
  return { seconds, nanos };
}

function fromTimestamp(t: Timestamp): Date {
  let millis = (t.seconds.toNumber() || 0) * 1_000;
  millis += (t.nanos || 0) / 1_000_000;
  return new globalThis.Date(millis);
}

function fromJsonTimestamp(o: any): Date {
  if (o instanceof globalThis.Date) {
    return o;
  } else if (typeof o === "string") {
    return new globalThis.Date(o);
  } else {
    return fromTimestamp(Timestamp.fromJSON(o));
  }
}

function numberToLong(number: number) {
  return Long.fromNumber(number);
}

function isObject(value: any): boolean {
  return typeof value === "object" && value !== null;
}

function isSet(value: any): boolean {
  return value !== null && value !== undefined;
}

export type ServerStreamingMethodResult<Response> = { [Symbol.asyncIterator](): AsyncIterator<Response, void> };

export interface MessageFns<T> {
  encode(message: T, writer?: BinaryWriter): BinaryWriter;
  decode(input: BinaryReader | Uint8Array, length?: number): T;
  fromJSON(object: any): T;
  toJSON(message: T): unknown;
  create(base?: DeepPartial<T>): T;
  fromPartial(object: DeepPartial<T>): T;
}
