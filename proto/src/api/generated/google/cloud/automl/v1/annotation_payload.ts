// Code generated by protoc-gen-ts_proto. DO NOT EDIT.
// versions:
//   protoc-gen-ts_proto  v2.2.0
//   protoc               unknown
// source: google/cloud/automl/v1/annotation_payload.proto

/* eslint-disable */
import { BinaryReader, BinaryWriter } from "@bufbuild/protobuf/wire";
import Long from "long";
import { ClassificationAnnotation } from "./classification.js";
import { ImageObjectDetectionAnnotation } from "./detection.js";
import { TextExtractionAnnotation } from "./text_extraction.js";
import { TextSentimentAnnotation } from "./text_sentiment.js";
import { TranslationAnnotation } from "./translation.js";

export const protobufPackage = "google.cloud.automl.v1";

/** Contains annotation information that is relevant to AutoML. */
export interface AnnotationPayload {
  /** Annotation details for translation. */
  translation?:
    | TranslationAnnotation
    | undefined;
  /** Annotation details for content or image classification. */
  classification?:
    | ClassificationAnnotation
    | undefined;
  /** Annotation details for image object detection. */
  imageObjectDetection?:
    | ImageObjectDetectionAnnotation
    | undefined;
  /** Annotation details for text extraction. */
  textExtraction?:
    | TextExtractionAnnotation
    | undefined;
  /** Annotation details for text sentiment. */
  textSentiment?:
    | TextSentimentAnnotation
    | undefined;
  /**
   * Output only . The resource ID of the annotation spec that
   * this annotation pertains to. The annotation spec comes from either an
   * ancestor dataset, or the dataset that was used to train the model in use.
   */
  annotationSpecId: string;
  /**
   * Output only. The value of
   * [display_name][google.cloud.automl.v1.AnnotationSpec.display_name]
   * when the model was trained. Because this field returns a value at model
   * training time, for different models trained using the same dataset, the
   * returned value could be different as model owner could update the
   * `display_name` between any two model training.
   */
  displayName: string;
}

function createBaseAnnotationPayload(): AnnotationPayload {
  return {
    translation: undefined,
    classification: undefined,
    imageObjectDetection: undefined,
    textExtraction: undefined,
    textSentiment: undefined,
    annotationSpecId: "",
    displayName: "",
  };
}

export const AnnotationPayload: MessageFns<AnnotationPayload> = {
  encode(message: AnnotationPayload, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.translation !== undefined) {
      TranslationAnnotation.encode(message.translation, writer.uint32(18).fork()).join();
    }
    if (message.classification !== undefined) {
      ClassificationAnnotation.encode(message.classification, writer.uint32(26).fork()).join();
    }
    if (message.imageObjectDetection !== undefined) {
      ImageObjectDetectionAnnotation.encode(message.imageObjectDetection, writer.uint32(34).fork()).join();
    }
    if (message.textExtraction !== undefined) {
      TextExtractionAnnotation.encode(message.textExtraction, writer.uint32(50).fork()).join();
    }
    if (message.textSentiment !== undefined) {
      TextSentimentAnnotation.encode(message.textSentiment, writer.uint32(58).fork()).join();
    }
    if (message.annotationSpecId !== "") {
      writer.uint32(10).string(message.annotationSpecId);
    }
    if (message.displayName !== "") {
      writer.uint32(42).string(message.displayName);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): AnnotationPayload {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseAnnotationPayload();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 2:
          if (tag !== 18) {
            break;
          }

          message.translation = TranslationAnnotation.decode(reader, reader.uint32());
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.classification = ClassificationAnnotation.decode(reader, reader.uint32());
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.imageObjectDetection = ImageObjectDetectionAnnotation.decode(reader, reader.uint32());
          continue;
        case 6:
          if (tag !== 50) {
            break;
          }

          message.textExtraction = TextExtractionAnnotation.decode(reader, reader.uint32());
          continue;
        case 7:
          if (tag !== 58) {
            break;
          }

          message.textSentiment = TextSentimentAnnotation.decode(reader, reader.uint32());
          continue;
        case 1:
          if (tag !== 10) {
            break;
          }

          message.annotationSpecId = reader.string();
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.displayName = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): AnnotationPayload {
    return {
      translation: isSet(object.translation) ? TranslationAnnotation.fromJSON(object.translation) : undefined,
      classification: isSet(object.classification)
        ? ClassificationAnnotation.fromJSON(object.classification)
        : undefined,
      imageObjectDetection: isSet(object.imageObjectDetection)
        ? ImageObjectDetectionAnnotation.fromJSON(object.imageObjectDetection)
        : undefined,
      textExtraction: isSet(object.textExtraction)
        ? TextExtractionAnnotation.fromJSON(object.textExtraction)
        : undefined,
      textSentiment: isSet(object.textSentiment) ? TextSentimentAnnotation.fromJSON(object.textSentiment) : undefined,
      annotationSpecId: isSet(object.annotationSpecId) ? globalThis.String(object.annotationSpecId) : "",
      displayName: isSet(object.displayName) ? globalThis.String(object.displayName) : "",
    };
  },

  toJSON(message: AnnotationPayload): unknown {
    const obj: any = {};
    if (message.translation !== undefined) {
      obj.translation = TranslationAnnotation.toJSON(message.translation);
    }
    if (message.classification !== undefined) {
      obj.classification = ClassificationAnnotation.toJSON(message.classification);
    }
    if (message.imageObjectDetection !== undefined) {
      obj.imageObjectDetection = ImageObjectDetectionAnnotation.toJSON(message.imageObjectDetection);
    }
    if (message.textExtraction !== undefined) {
      obj.textExtraction = TextExtractionAnnotation.toJSON(message.textExtraction);
    }
    if (message.textSentiment !== undefined) {
      obj.textSentiment = TextSentimentAnnotation.toJSON(message.textSentiment);
    }
    if (message.annotationSpecId !== "") {
      obj.annotationSpecId = message.annotationSpecId;
    }
    if (message.displayName !== "") {
      obj.displayName = message.displayName;
    }
    return obj;
  },

  create(base?: DeepPartial<AnnotationPayload>): AnnotationPayload {
    return AnnotationPayload.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<AnnotationPayload>): AnnotationPayload {
    const message = createBaseAnnotationPayload();
    message.translation = (object.translation !== undefined && object.translation !== null)
      ? TranslationAnnotation.fromPartial(object.translation)
      : undefined;
    message.classification = (object.classification !== undefined && object.classification !== null)
      ? ClassificationAnnotation.fromPartial(object.classification)
      : undefined;
    message.imageObjectDetection = (object.imageObjectDetection !== undefined && object.imageObjectDetection !== null)
      ? ImageObjectDetectionAnnotation.fromPartial(object.imageObjectDetection)
      : undefined;
    message.textExtraction = (object.textExtraction !== undefined && object.textExtraction !== null)
      ? TextExtractionAnnotation.fromPartial(object.textExtraction)
      : undefined;
    message.textSentiment = (object.textSentiment !== undefined && object.textSentiment !== null)
      ? TextSentimentAnnotation.fromPartial(object.textSentiment)
      : undefined;
    message.annotationSpecId = object.annotationSpecId ?? "";
    message.displayName = object.displayName ?? "";
    return message;
  },
};

type Builtin = Date | Function | Uint8Array | string | number | boolean | undefined;

export type DeepPartial<T> = T extends Builtin ? T
  : T extends Long ? string | number | Long : T extends globalThis.Array<infer U> ? globalThis.Array<DeepPartial<U>>
  : T extends ReadonlyArray<infer U> ? ReadonlyArray<DeepPartial<U>>
  : T extends {} ? { [K in keyof T]?: DeepPartial<T[K]> }
  : Partial<T>;

function isSet(value: any): boolean {
  return value !== null && value !== undefined;
}

export interface MessageFns<T> {
  encode(message: T, writer?: BinaryWriter): BinaryWriter;
  decode(input: BinaryReader | Uint8Array, length?: number): T;
  fromJSON(object: any): T;
  toJSON(message: T): unknown;
  create(base?: DeepPartial<T>): T;
  fromPartial(object: DeepPartial<T>): T;
}
