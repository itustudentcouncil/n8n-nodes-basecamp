// Code generated by protoc-gen-ts_proto. DO NOT EDIT.
// versions:
//   protoc-gen-ts_proto  v2.2.0
//   protoc               unknown
// source: google/cloud/automl/v1beta1/table_spec.proto

/* eslint-disable */
import { BinaryReader, BinaryWriter } from "@bufbuild/protobuf/wire";
import Long from "long";
import { InputConfig } from "./io.js";

export const protobufPackage = "google.cloud.automl.v1beta1";

/**
 * A specification of a relational table.
 * The table's schema is represented via its child column specs. It is
 * pre-populated as part of ImportData by schema inference algorithm, the
 * version of which is a required parameter of ImportData InputConfig.
 * Note: While working with a table, at times the schema may be
 * inconsistent with the data in the table (e.g. string in a FLOAT64 column).
 * The consistency validation is done upon creation of a model.
 * Used by:
 *   *   Tables
 */
export interface TableSpec {
  /**
   * Output only. The resource name of the table spec.
   * Form:
   *
   * `projects/{project_id}/locations/{location_id}/datasets/{dataset_id}/tableSpecs/{table_spec_id}`
   */
  name: string;
  /**
   * column_spec_id of the time column. Only used if the parent dataset's
   * ml_use_column_spec_id is not set. Used to split rows into TRAIN, VALIDATE
   * and TEST sets such that oldest rows go to TRAIN set, newest to TEST, and
   * those in between to VALIDATE.
   * Required type: TIMESTAMP.
   * If both this column and ml_use_column are not set, then ML use of all rows
   * will be assigned by AutoML. NOTE: Updates of this field will instantly
   * affect any other users concurrently working with the dataset.
   */
  timeColumnSpecId: string;
  /** Output only. The number of rows (i.e. examples) in the table. */
  rowCount: Long;
  /**
   * Output only. The number of valid rows (i.e. without values that don't match
   * DataType-s of their columns).
   */
  validRowCount: Long;
  /**
   * Output only. The number of columns of the table. That is, the number of
   * child ColumnSpec-s.
   */
  columnCount: Long;
  /**
   * Output only. Input configs via which data currently residing in the table
   * had been imported.
   */
  inputConfigs: InputConfig[];
  /**
   * Used to perform consistent read-modify-write updates. If not set, a blind
   * "overwrite" update happens.
   */
  etag: string;
}

function createBaseTableSpec(): TableSpec {
  return {
    name: "",
    timeColumnSpecId: "",
    rowCount: Long.ZERO,
    validRowCount: Long.ZERO,
    columnCount: Long.ZERO,
    inputConfigs: [],
    etag: "",
  };
}

export const TableSpec: MessageFns<TableSpec> = {
  encode(message: TableSpec, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    if (message.timeColumnSpecId !== "") {
      writer.uint32(18).string(message.timeColumnSpecId);
    }
    if (!message.rowCount.equals(Long.ZERO)) {
      writer.uint32(24).int64(message.rowCount.toString());
    }
    if (!message.validRowCount.equals(Long.ZERO)) {
      writer.uint32(32).int64(message.validRowCount.toString());
    }
    if (!message.columnCount.equals(Long.ZERO)) {
      writer.uint32(56).int64(message.columnCount.toString());
    }
    for (const v of message.inputConfigs) {
      InputConfig.encode(v!, writer.uint32(42).fork()).join();
    }
    if (message.etag !== "") {
      writer.uint32(50).string(message.etag);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): TableSpec {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseTableSpec();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.timeColumnSpecId = reader.string();
          continue;
        case 3:
          if (tag !== 24) {
            break;
          }

          message.rowCount = Long.fromString(reader.int64().toString());
          continue;
        case 4:
          if (tag !== 32) {
            break;
          }

          message.validRowCount = Long.fromString(reader.int64().toString());
          continue;
        case 7:
          if (tag !== 56) {
            break;
          }

          message.columnCount = Long.fromString(reader.int64().toString());
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.inputConfigs.push(InputConfig.decode(reader, reader.uint32()));
          continue;
        case 6:
          if (tag !== 50) {
            break;
          }

          message.etag = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): TableSpec {
    return {
      name: isSet(object.name) ? globalThis.String(object.name) : "",
      timeColumnSpecId: isSet(object.timeColumnSpecId) ? globalThis.String(object.timeColumnSpecId) : "",
      rowCount: isSet(object.rowCount) ? Long.fromValue(object.rowCount) : Long.ZERO,
      validRowCount: isSet(object.validRowCount) ? Long.fromValue(object.validRowCount) : Long.ZERO,
      columnCount: isSet(object.columnCount) ? Long.fromValue(object.columnCount) : Long.ZERO,
      inputConfigs: globalThis.Array.isArray(object?.inputConfigs)
        ? object.inputConfigs.map((e: any) => InputConfig.fromJSON(e))
        : [],
      etag: isSet(object.etag) ? globalThis.String(object.etag) : "",
    };
  },

  toJSON(message: TableSpec): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    if (message.timeColumnSpecId !== "") {
      obj.timeColumnSpecId = message.timeColumnSpecId;
    }
    if (!message.rowCount.equals(Long.ZERO)) {
      obj.rowCount = (message.rowCount || Long.ZERO).toString();
    }
    if (!message.validRowCount.equals(Long.ZERO)) {
      obj.validRowCount = (message.validRowCount || Long.ZERO).toString();
    }
    if (!message.columnCount.equals(Long.ZERO)) {
      obj.columnCount = (message.columnCount || Long.ZERO).toString();
    }
    if (message.inputConfigs?.length) {
      obj.inputConfigs = message.inputConfigs.map((e) => InputConfig.toJSON(e));
    }
    if (message.etag !== "") {
      obj.etag = message.etag;
    }
    return obj;
  },

  create(base?: DeepPartial<TableSpec>): TableSpec {
    return TableSpec.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<TableSpec>): TableSpec {
    const message = createBaseTableSpec();
    message.name = object.name ?? "";
    message.timeColumnSpecId = object.timeColumnSpecId ?? "";
    message.rowCount = (object.rowCount !== undefined && object.rowCount !== null)
      ? Long.fromValue(object.rowCount)
      : Long.ZERO;
    message.validRowCount = (object.validRowCount !== undefined && object.validRowCount !== null)
      ? Long.fromValue(object.validRowCount)
      : Long.ZERO;
    message.columnCount = (object.columnCount !== undefined && object.columnCount !== null)
      ? Long.fromValue(object.columnCount)
      : Long.ZERO;
    message.inputConfigs = object.inputConfigs?.map((e) => InputConfig.fromPartial(e)) || [];
    message.etag = object.etag ?? "";
    return message;
  },
};

type Builtin = Date | Function | Uint8Array | string | number | boolean | undefined;

export type DeepPartial<T> = T extends Builtin ? T
  : T extends Long ? string | number | Long : T extends globalThis.Array<infer U> ? globalThis.Array<DeepPartial<U>>
  : T extends ReadonlyArray<infer U> ? ReadonlyArray<DeepPartial<U>>
  : T extends {} ? { [K in keyof T]?: DeepPartial<T[K]> }
  : Partial<T>;

function isSet(value: any): boolean {
  return value !== null && value !== undefined;
}

export interface MessageFns<T> {
  encode(message: T, writer?: BinaryWriter): BinaryWriter;
  decode(input: BinaryReader | Uint8Array, length?: number): T;
  fromJSON(object: any): T;
  toJSON(message: T): unknown;
  create(base?: DeepPartial<T>): T;
  fromPartial(object: DeepPartial<T>): T;
}
