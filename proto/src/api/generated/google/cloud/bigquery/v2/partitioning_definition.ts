// Code generated by protoc-gen-ts_proto. DO NOT EDIT.
// versions:
//   protoc-gen-ts_proto  v2.2.0
//   protoc               unknown
// source: google/cloud/bigquery/v2/partitioning_definition.proto

/* eslint-disable */
import { BinaryReader, BinaryWriter } from "@bufbuild/protobuf/wire";
import Long from "long";

export const protobufPackage = "google.cloud.bigquery.v2";

/**
 * The partitioning information, which includes managed table, external table
 * and metastore partitioned table partition information.
 */
export interface PartitioningDefinition {
  /**
   * Optional. Details about each partitioning column. This field is output only
   * for all partitioning types other than metastore partitioned tables.
   * BigQuery native tables only support 1 partitioning column. Other table
   * types may support 0, 1 or more partitioning columns.
   * For metastore partitioned tables, the order must match the definition order
   * in the Hive Metastore, where it must match the physical layout of the
   * table. For example,
   *
   * CREATE TABLE a_table(id BIGINT, name STRING)
   * PARTITIONED BY (city STRING, state STRING).
   *
   * In this case the values must be ['city', 'state'] in that order.
   */
  partitionedColumn: PartitionedColumn[];
}

/** The partitioning column information. */
export interface PartitionedColumn {
  /** Required. The name of the partition column. */
  field?: string | undefined;
}

function createBasePartitioningDefinition(): PartitioningDefinition {
  return { partitionedColumn: [] };
}

export const PartitioningDefinition: MessageFns<PartitioningDefinition> = {
  encode(message: PartitioningDefinition, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.partitionedColumn) {
      PartitionedColumn.encode(v!, writer.uint32(10).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): PartitioningDefinition {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBasePartitioningDefinition();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.partitionedColumn.push(PartitionedColumn.decode(reader, reader.uint32()));
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): PartitioningDefinition {
    return {
      partitionedColumn: globalThis.Array.isArray(object?.partitionedColumn)
        ? object.partitionedColumn.map((e: any) => PartitionedColumn.fromJSON(e))
        : [],
    };
  },

  toJSON(message: PartitioningDefinition): unknown {
    const obj: any = {};
    if (message.partitionedColumn?.length) {
      obj.partitionedColumn = message.partitionedColumn.map((e) => PartitionedColumn.toJSON(e));
    }
    return obj;
  },

  create(base?: DeepPartial<PartitioningDefinition>): PartitioningDefinition {
    return PartitioningDefinition.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<PartitioningDefinition>): PartitioningDefinition {
    const message = createBasePartitioningDefinition();
    message.partitionedColumn = object.partitionedColumn?.map((e) => PartitionedColumn.fromPartial(e)) || [];
    return message;
  },
};

function createBasePartitionedColumn(): PartitionedColumn {
  return { field: undefined };
}

export const PartitionedColumn: MessageFns<PartitionedColumn> = {
  encode(message: PartitionedColumn, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.field !== undefined) {
      writer.uint32(10).string(message.field);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): PartitionedColumn {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBasePartitionedColumn();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.field = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): PartitionedColumn {
    return { field: isSet(object.field) ? globalThis.String(object.field) : undefined };
  },

  toJSON(message: PartitionedColumn): unknown {
    const obj: any = {};
    if (message.field !== undefined) {
      obj.field = message.field;
    }
    return obj;
  },

  create(base?: DeepPartial<PartitionedColumn>): PartitionedColumn {
    return PartitionedColumn.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<PartitionedColumn>): PartitionedColumn {
    const message = createBasePartitionedColumn();
    message.field = object.field ?? undefined;
    return message;
  },
};

type Builtin = Date | Function | Uint8Array | string | number | boolean | undefined;

export type DeepPartial<T> = T extends Builtin ? T
  : T extends Long ? string | number | Long : T extends globalThis.Array<infer U> ? globalThis.Array<DeepPartial<U>>
  : T extends ReadonlyArray<infer U> ? ReadonlyArray<DeepPartial<U>>
  : T extends {} ? { [K in keyof T]?: DeepPartial<T[K]> }
  : Partial<T>;

function isSet(value: any): boolean {
  return value !== null && value !== undefined;
}

export interface MessageFns<T> {
  encode(message: T, writer?: BinaryWriter): BinaryWriter;
  decode(input: BinaryReader | Uint8Array, length?: number): T;
  fromJSON(object: any): T;
  toJSON(message: T): unknown;
  create(base?: DeepPartial<T>): T;
  fromPartial(object: DeepPartial<T>): T;
}
