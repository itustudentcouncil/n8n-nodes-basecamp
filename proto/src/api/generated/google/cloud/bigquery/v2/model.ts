// Code generated by protoc-gen-ts_proto. DO NOT EDIT.
// versions:
//   protoc-gen-ts_proto  v2.2.0
//   protoc               unknown
// source: google/cloud/bigquery/v2/model.proto

/* eslint-disable */
import { BinaryReader, BinaryWriter } from "@bufbuild/protobuf/wire";
import Long from "long";
import { type CallContext, type CallOptions } from "nice-grpc-common";
import { Empty } from "../../../protobuf/empty.js";
import { Timestamp } from "../../../protobuf/timestamp.js";
import { BoolValue, DoubleValue, Int32Value, Int64Value, UInt32Value } from "../../../protobuf/wrappers.js";
import { EncryptionConfiguration } from "./encryption_config.js";
import { ModelReference } from "./model_reference.js";
import { StandardSqlDataType, StandardSqlField } from "./standard_sql.js";
import { TableReference } from "./table_reference.js";

export const protobufPackage = "google.cloud.bigquery.v2";

/** Remote Model Info */
export interface RemoteModelInfo {
  /** Output only. The endpoint for remote model. */
  endpoint?:
    | string
    | undefined;
  /** Output only. The remote service type for remote model. */
  remoteServiceType?:
    | RemoteModelInfo_RemoteServiceType
    | undefined;
  /**
   * Output only. Fully qualified name of the user-provided connection object of
   * the remote model. Format:
   * ```"projects/{project_id}/locations/{location_id}/connections/{connection_id}"```
   */
  connection: string;
  /**
   * Output only. Max number of rows in each batch sent to the remote service.
   * If unset, the number of rows in each batch is set dynamically.
   */
  maxBatchingRows: Long;
  /** Output only. The model version for LLM. */
  remoteModelVersion: string;
  /**
   * Output only. The name of the speech recognizer to use for speech
   * recognition. The expected format is
   * `projects/{project}/locations/{location}/recognizers/{recognizer}`.
   * Customers can specify this field at model creation. If not specified, a
   * default recognizer `projects/{model
   * project}/locations/global/recognizers/_` will be used. See more details at
   * [recognizers](https://cloud.google.com/speech-to-text/v2/docs/reference/rest/v2/projects.locations.recognizers)
   */
  speechRecognizer: string;
}

/** Supported service type for remote model. */
export enum RemoteModelInfo_RemoteServiceType {
  /** REMOTE_SERVICE_TYPE_UNSPECIFIED - Unspecified remote service type. */
  REMOTE_SERVICE_TYPE_UNSPECIFIED = 0,
  /**
   * CLOUD_AI_TRANSLATE_V3 - V3 Cloud AI Translation API. See more details at [Cloud Translation API]
   * (https://cloud.google.com/translate/docs/reference/rest).
   */
  CLOUD_AI_TRANSLATE_V3 = 1,
  /**
   * CLOUD_AI_VISION_V1 - V1 Cloud AI Vision API See more details at [Cloud Vision API]
   * (https://cloud.google.com/vision/docs/reference/rest).
   */
  CLOUD_AI_VISION_V1 = 2,
  /**
   * CLOUD_AI_NATURAL_LANGUAGE_V1 - V1 Cloud AI Natural Language API. See more details at [REST Resource:
   * documents](https://cloud.google.com/natural-language/docs/reference/rest/v1/documents).
   */
  CLOUD_AI_NATURAL_LANGUAGE_V1 = 3,
  /**
   * CLOUD_AI_SPEECH_TO_TEXT_V2 - V2 Speech-to-Text API. See more details at [Google Cloud Speech-to-Text
   * V2 API](https://cloud.google.com/speech-to-text/v2/docs)
   */
  CLOUD_AI_SPEECH_TO_TEXT_V2 = 7,
  UNRECOGNIZED = -1,
}

export function remoteModelInfo_RemoteServiceTypeFromJSON(object: any): RemoteModelInfo_RemoteServiceType {
  switch (object) {
    case 0:
    case "REMOTE_SERVICE_TYPE_UNSPECIFIED":
      return RemoteModelInfo_RemoteServiceType.REMOTE_SERVICE_TYPE_UNSPECIFIED;
    case 1:
    case "CLOUD_AI_TRANSLATE_V3":
      return RemoteModelInfo_RemoteServiceType.CLOUD_AI_TRANSLATE_V3;
    case 2:
    case "CLOUD_AI_VISION_V1":
      return RemoteModelInfo_RemoteServiceType.CLOUD_AI_VISION_V1;
    case 3:
    case "CLOUD_AI_NATURAL_LANGUAGE_V1":
      return RemoteModelInfo_RemoteServiceType.CLOUD_AI_NATURAL_LANGUAGE_V1;
    case 7:
    case "CLOUD_AI_SPEECH_TO_TEXT_V2":
      return RemoteModelInfo_RemoteServiceType.CLOUD_AI_SPEECH_TO_TEXT_V2;
    case -1:
    case "UNRECOGNIZED":
    default:
      return RemoteModelInfo_RemoteServiceType.UNRECOGNIZED;
  }
}

export function remoteModelInfo_RemoteServiceTypeToJSON(object: RemoteModelInfo_RemoteServiceType): string {
  switch (object) {
    case RemoteModelInfo_RemoteServiceType.REMOTE_SERVICE_TYPE_UNSPECIFIED:
      return "REMOTE_SERVICE_TYPE_UNSPECIFIED";
    case RemoteModelInfo_RemoteServiceType.CLOUD_AI_TRANSLATE_V3:
      return "CLOUD_AI_TRANSLATE_V3";
    case RemoteModelInfo_RemoteServiceType.CLOUD_AI_VISION_V1:
      return "CLOUD_AI_VISION_V1";
    case RemoteModelInfo_RemoteServiceType.CLOUD_AI_NATURAL_LANGUAGE_V1:
      return "CLOUD_AI_NATURAL_LANGUAGE_V1";
    case RemoteModelInfo_RemoteServiceType.CLOUD_AI_SPEECH_TO_TEXT_V2:
      return "CLOUD_AI_SPEECH_TO_TEXT_V2";
    case RemoteModelInfo_RemoteServiceType.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/** Information about a single transform column. */
export interface TransformColumn {
  /** Output only. Name of the column. */
  name: string;
  /** Output only. Data type of the column after the transform. */
  type:
    | StandardSqlDataType
    | undefined;
  /** Output only. The SQL expression used in the column transform. */
  transformSql: string;
}

export interface Model {
  /** Output only. A hash of this resource. */
  etag: string;
  /** Required. Unique identifier for this model. */
  modelReference:
    | ModelReference
    | undefined;
  /**
   * Output only. The time when this model was created, in millisecs since the
   * epoch.
   */
  creationTime: Long;
  /**
   * Output only. The time when this model was last modified, in millisecs since
   * the epoch.
   */
  lastModifiedTime: Long;
  /** Optional. A user-friendly description of this model. */
  description: string;
  /** Optional. A descriptive name for this model. */
  friendlyName: string;
  /**
   * The labels associated with this model. You can use these to organize
   * and group your models. Label keys and values can be no longer
   * than 63 characters, can only contain lowercase letters, numeric
   * characters, underscores and dashes. International characters are allowed.
   * Label values are optional. Label keys must start with a letter and each
   * label in the list must have a different key.
   */
  labels: { [key: string]: string };
  /**
   * Optional. The time when this model expires, in milliseconds since the
   * epoch. If not present, the model will persist indefinitely. Expired models
   * will be deleted and their storage reclaimed.  The defaultTableExpirationMs
   * property of the encapsulating dataset can be used to set a default
   * expirationTime on newly created models.
   */
  expirationTime: Long;
  /**
   * Output only. The geographic location where the model resides. This value
   * is inherited from the dataset.
   */
  location: string;
  /**
   * Custom encryption configuration (e.g., Cloud KMS keys). This shows the
   * encryption configuration of the model data while stored in BigQuery
   * storage. This field can be used with PatchModel to update encryption key
   * for an already encrypted model.
   */
  encryptionConfiguration:
    | EncryptionConfiguration
    | undefined;
  /** Output only. Type of the model resource. */
  modelType: Model_ModelType;
  /** Information for all training runs in increasing order of start_time. */
  trainingRuns: Model_TrainingRun[];
  /**
   * Output only. Input feature columns for the model inference. If the model is
   * trained with TRANSFORM clause, these are the input of the TRANSFORM clause.
   */
  featureColumns: StandardSqlField[];
  /**
   * Output only. Label columns that were used to train this model.
   * The output of the model will have a "predicted_" prefix to these columns.
   */
  labelColumns: StandardSqlField[];
  /**
   * Output only. This field will be populated if a TRANSFORM clause was used to
   * train a model. TRANSFORM clause (if used) takes feature_columns as input
   * and outputs transform_columns. transform_columns then are used to train the
   * model.
   */
  transformColumns: TransformColumn[];
  /** Output only. All hyperparameter search spaces in this model. */
  hparamSearchSpaces:
    | Model_HparamSearchSpaces
    | undefined;
  /**
   * Output only. The default trial_id to use in TVFs when the trial_id is not
   * passed in. For single-objective [hyperparameter
   * tuning](https://cloud.google.com/bigquery-ml/docs/reference/standard-sql/bigqueryml-syntax-hp-tuning-overview)
   * models, this is the best trial ID. For multi-objective [hyperparameter
   * tuning](https://cloud.google.com/bigquery-ml/docs/reference/standard-sql/bigqueryml-syntax-hp-tuning-overview)
   * models, this is the smallest trial ID among all Pareto optimal trials.
   */
  defaultTrialId: Long;
  /**
   * Output only. Trials of a [hyperparameter
   * tuning](https://cloud.google.com/bigquery-ml/docs/reference/standard-sql/bigqueryml-syntax-hp-tuning-overview)
   * model sorted by trial_id.
   */
  hparamTrials: Model_HparamTuningTrial[];
  /**
   * Output only. For single-objective [hyperparameter
   * tuning](https://cloud.google.com/bigquery-ml/docs/reference/standard-sql/bigqueryml-syntax-hp-tuning-overview)
   * models, it only contains the best trial. For multi-objective
   * [hyperparameter
   * tuning](https://cloud.google.com/bigquery-ml/docs/reference/standard-sql/bigqueryml-syntax-hp-tuning-overview)
   * models, it contains all Pareto optimal trials sorted by trial_id.
   */
  optimalTrialIds: Long[];
  /** Output only. Remote model info */
  remoteModelInfo: RemoteModelInfo | undefined;
}

/** Indicates the type of the Model. */
export enum Model_ModelType {
  /** MODEL_TYPE_UNSPECIFIED - Default value. */
  MODEL_TYPE_UNSPECIFIED = 0,
  /** LINEAR_REGRESSION - Linear regression model. */
  LINEAR_REGRESSION = 1,
  /** LOGISTIC_REGRESSION - Logistic regression based classification model. */
  LOGISTIC_REGRESSION = 2,
  /** KMEANS - K-means clustering model. */
  KMEANS = 3,
  /** MATRIX_FACTORIZATION - Matrix factorization model. */
  MATRIX_FACTORIZATION = 4,
  /** DNN_CLASSIFIER - DNN classifier model. */
  DNN_CLASSIFIER = 5,
  /** TENSORFLOW - An imported TensorFlow model. */
  TENSORFLOW = 6,
  /** DNN_REGRESSOR - DNN regressor model. */
  DNN_REGRESSOR = 7,
  /** XGBOOST - An imported XGBoost model. */
  XGBOOST = 8,
  /** BOOSTED_TREE_REGRESSOR - Boosted tree regressor model. */
  BOOSTED_TREE_REGRESSOR = 9,
  /** BOOSTED_TREE_CLASSIFIER - Boosted tree classifier model. */
  BOOSTED_TREE_CLASSIFIER = 10,
  /** ARIMA - ARIMA model. */
  ARIMA = 11,
  /** AUTOML_REGRESSOR - AutoML Tables regression model. */
  AUTOML_REGRESSOR = 12,
  /** AUTOML_CLASSIFIER - AutoML Tables classification model. */
  AUTOML_CLASSIFIER = 13,
  /** PCA - Prinpical Component Analysis model. */
  PCA = 14,
  /** DNN_LINEAR_COMBINED_CLASSIFIER - Wide-and-deep classifier model. */
  DNN_LINEAR_COMBINED_CLASSIFIER = 16,
  /** DNN_LINEAR_COMBINED_REGRESSOR - Wide-and-deep regressor model. */
  DNN_LINEAR_COMBINED_REGRESSOR = 17,
  /** AUTOENCODER - Autoencoder model. */
  AUTOENCODER = 18,
  /** ARIMA_PLUS - New name for the ARIMA model. */
  ARIMA_PLUS = 19,
  /** ARIMA_PLUS_XREG - ARIMA with external regressors. */
  ARIMA_PLUS_XREG = 23,
  /** RANDOM_FOREST_REGRESSOR - Random forest regressor model. */
  RANDOM_FOREST_REGRESSOR = 24,
  /** RANDOM_FOREST_CLASSIFIER - Random forest classifier model. */
  RANDOM_FOREST_CLASSIFIER = 25,
  /** TENSORFLOW_LITE - An imported TensorFlow Lite model. */
  TENSORFLOW_LITE = 26,
  /** ONNX - An imported ONNX model. */
  ONNX = 28,
  /**
   * TRANSFORM_ONLY - Model to capture the columns and logic in the TRANSFORM clause along with
   * statistics useful for ML analytic functions.
   */
  TRANSFORM_ONLY = 29,
  UNRECOGNIZED = -1,
}

export function model_ModelTypeFromJSON(object: any): Model_ModelType {
  switch (object) {
    case 0:
    case "MODEL_TYPE_UNSPECIFIED":
      return Model_ModelType.MODEL_TYPE_UNSPECIFIED;
    case 1:
    case "LINEAR_REGRESSION":
      return Model_ModelType.LINEAR_REGRESSION;
    case 2:
    case "LOGISTIC_REGRESSION":
      return Model_ModelType.LOGISTIC_REGRESSION;
    case 3:
    case "KMEANS":
      return Model_ModelType.KMEANS;
    case 4:
    case "MATRIX_FACTORIZATION":
      return Model_ModelType.MATRIX_FACTORIZATION;
    case 5:
    case "DNN_CLASSIFIER":
      return Model_ModelType.DNN_CLASSIFIER;
    case 6:
    case "TENSORFLOW":
      return Model_ModelType.TENSORFLOW;
    case 7:
    case "DNN_REGRESSOR":
      return Model_ModelType.DNN_REGRESSOR;
    case 8:
    case "XGBOOST":
      return Model_ModelType.XGBOOST;
    case 9:
    case "BOOSTED_TREE_REGRESSOR":
      return Model_ModelType.BOOSTED_TREE_REGRESSOR;
    case 10:
    case "BOOSTED_TREE_CLASSIFIER":
      return Model_ModelType.BOOSTED_TREE_CLASSIFIER;
    case 11:
    case "ARIMA":
      return Model_ModelType.ARIMA;
    case 12:
    case "AUTOML_REGRESSOR":
      return Model_ModelType.AUTOML_REGRESSOR;
    case 13:
    case "AUTOML_CLASSIFIER":
      return Model_ModelType.AUTOML_CLASSIFIER;
    case 14:
    case "PCA":
      return Model_ModelType.PCA;
    case 16:
    case "DNN_LINEAR_COMBINED_CLASSIFIER":
      return Model_ModelType.DNN_LINEAR_COMBINED_CLASSIFIER;
    case 17:
    case "DNN_LINEAR_COMBINED_REGRESSOR":
      return Model_ModelType.DNN_LINEAR_COMBINED_REGRESSOR;
    case 18:
    case "AUTOENCODER":
      return Model_ModelType.AUTOENCODER;
    case 19:
    case "ARIMA_PLUS":
      return Model_ModelType.ARIMA_PLUS;
    case 23:
    case "ARIMA_PLUS_XREG":
      return Model_ModelType.ARIMA_PLUS_XREG;
    case 24:
    case "RANDOM_FOREST_REGRESSOR":
      return Model_ModelType.RANDOM_FOREST_REGRESSOR;
    case 25:
    case "RANDOM_FOREST_CLASSIFIER":
      return Model_ModelType.RANDOM_FOREST_CLASSIFIER;
    case 26:
    case "TENSORFLOW_LITE":
      return Model_ModelType.TENSORFLOW_LITE;
    case 28:
    case "ONNX":
      return Model_ModelType.ONNX;
    case 29:
    case "TRANSFORM_ONLY":
      return Model_ModelType.TRANSFORM_ONLY;
    case -1:
    case "UNRECOGNIZED":
    default:
      return Model_ModelType.UNRECOGNIZED;
  }
}

export function model_ModelTypeToJSON(object: Model_ModelType): string {
  switch (object) {
    case Model_ModelType.MODEL_TYPE_UNSPECIFIED:
      return "MODEL_TYPE_UNSPECIFIED";
    case Model_ModelType.LINEAR_REGRESSION:
      return "LINEAR_REGRESSION";
    case Model_ModelType.LOGISTIC_REGRESSION:
      return "LOGISTIC_REGRESSION";
    case Model_ModelType.KMEANS:
      return "KMEANS";
    case Model_ModelType.MATRIX_FACTORIZATION:
      return "MATRIX_FACTORIZATION";
    case Model_ModelType.DNN_CLASSIFIER:
      return "DNN_CLASSIFIER";
    case Model_ModelType.TENSORFLOW:
      return "TENSORFLOW";
    case Model_ModelType.DNN_REGRESSOR:
      return "DNN_REGRESSOR";
    case Model_ModelType.XGBOOST:
      return "XGBOOST";
    case Model_ModelType.BOOSTED_TREE_REGRESSOR:
      return "BOOSTED_TREE_REGRESSOR";
    case Model_ModelType.BOOSTED_TREE_CLASSIFIER:
      return "BOOSTED_TREE_CLASSIFIER";
    case Model_ModelType.ARIMA:
      return "ARIMA";
    case Model_ModelType.AUTOML_REGRESSOR:
      return "AUTOML_REGRESSOR";
    case Model_ModelType.AUTOML_CLASSIFIER:
      return "AUTOML_CLASSIFIER";
    case Model_ModelType.PCA:
      return "PCA";
    case Model_ModelType.DNN_LINEAR_COMBINED_CLASSIFIER:
      return "DNN_LINEAR_COMBINED_CLASSIFIER";
    case Model_ModelType.DNN_LINEAR_COMBINED_REGRESSOR:
      return "DNN_LINEAR_COMBINED_REGRESSOR";
    case Model_ModelType.AUTOENCODER:
      return "AUTOENCODER";
    case Model_ModelType.ARIMA_PLUS:
      return "ARIMA_PLUS";
    case Model_ModelType.ARIMA_PLUS_XREG:
      return "ARIMA_PLUS_XREG";
    case Model_ModelType.RANDOM_FOREST_REGRESSOR:
      return "RANDOM_FOREST_REGRESSOR";
    case Model_ModelType.RANDOM_FOREST_CLASSIFIER:
      return "RANDOM_FOREST_CLASSIFIER";
    case Model_ModelType.TENSORFLOW_LITE:
      return "TENSORFLOW_LITE";
    case Model_ModelType.ONNX:
      return "ONNX";
    case Model_ModelType.TRANSFORM_ONLY:
      return "TRANSFORM_ONLY";
    case Model_ModelType.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/** Loss metric to evaluate model training performance. */
export enum Model_LossType {
  /** LOSS_TYPE_UNSPECIFIED - Default value. */
  LOSS_TYPE_UNSPECIFIED = 0,
  /** MEAN_SQUARED_LOSS - Mean squared loss, used for linear regression. */
  MEAN_SQUARED_LOSS = 1,
  /** MEAN_LOG_LOSS - Mean log loss, used for logistic regression. */
  MEAN_LOG_LOSS = 2,
  UNRECOGNIZED = -1,
}

export function model_LossTypeFromJSON(object: any): Model_LossType {
  switch (object) {
    case 0:
    case "LOSS_TYPE_UNSPECIFIED":
      return Model_LossType.LOSS_TYPE_UNSPECIFIED;
    case 1:
    case "MEAN_SQUARED_LOSS":
      return Model_LossType.MEAN_SQUARED_LOSS;
    case 2:
    case "MEAN_LOG_LOSS":
      return Model_LossType.MEAN_LOG_LOSS;
    case -1:
    case "UNRECOGNIZED":
    default:
      return Model_LossType.UNRECOGNIZED;
  }
}

export function model_LossTypeToJSON(object: Model_LossType): string {
  switch (object) {
    case Model_LossType.LOSS_TYPE_UNSPECIFIED:
      return "LOSS_TYPE_UNSPECIFIED";
    case Model_LossType.MEAN_SQUARED_LOSS:
      return "MEAN_SQUARED_LOSS";
    case Model_LossType.MEAN_LOG_LOSS:
      return "MEAN_LOG_LOSS";
    case Model_LossType.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/** Distance metric used to compute the distance between two points. */
export enum Model_DistanceType {
  /** DISTANCE_TYPE_UNSPECIFIED - Default value. */
  DISTANCE_TYPE_UNSPECIFIED = 0,
  /** EUCLIDEAN - Eculidean distance. */
  EUCLIDEAN = 1,
  /** COSINE - Cosine distance. */
  COSINE = 2,
  UNRECOGNIZED = -1,
}

export function model_DistanceTypeFromJSON(object: any): Model_DistanceType {
  switch (object) {
    case 0:
    case "DISTANCE_TYPE_UNSPECIFIED":
      return Model_DistanceType.DISTANCE_TYPE_UNSPECIFIED;
    case 1:
    case "EUCLIDEAN":
      return Model_DistanceType.EUCLIDEAN;
    case 2:
    case "COSINE":
      return Model_DistanceType.COSINE;
    case -1:
    case "UNRECOGNIZED":
    default:
      return Model_DistanceType.UNRECOGNIZED;
  }
}

export function model_DistanceTypeToJSON(object: Model_DistanceType): string {
  switch (object) {
    case Model_DistanceType.DISTANCE_TYPE_UNSPECIFIED:
      return "DISTANCE_TYPE_UNSPECIFIED";
    case Model_DistanceType.EUCLIDEAN:
      return "EUCLIDEAN";
    case Model_DistanceType.COSINE:
      return "COSINE";
    case Model_DistanceType.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/** Indicates the method to split input data into multiple tables. */
export enum Model_DataSplitMethod {
  /** DATA_SPLIT_METHOD_UNSPECIFIED - Default value. */
  DATA_SPLIT_METHOD_UNSPECIFIED = 0,
  /** RANDOM - Splits data randomly. */
  RANDOM = 1,
  /** CUSTOM - Splits data with the user provided tags. */
  CUSTOM = 2,
  /** SEQUENTIAL - Splits data sequentially. */
  SEQUENTIAL = 3,
  /** NO_SPLIT - Data split will be skipped. */
  NO_SPLIT = 4,
  /**
   * AUTO_SPLIT - Splits data automatically: Uses NO_SPLIT if the data size is small.
   * Otherwise uses RANDOM.
   */
  AUTO_SPLIT = 5,
  UNRECOGNIZED = -1,
}

export function model_DataSplitMethodFromJSON(object: any): Model_DataSplitMethod {
  switch (object) {
    case 0:
    case "DATA_SPLIT_METHOD_UNSPECIFIED":
      return Model_DataSplitMethod.DATA_SPLIT_METHOD_UNSPECIFIED;
    case 1:
    case "RANDOM":
      return Model_DataSplitMethod.RANDOM;
    case 2:
    case "CUSTOM":
      return Model_DataSplitMethod.CUSTOM;
    case 3:
    case "SEQUENTIAL":
      return Model_DataSplitMethod.SEQUENTIAL;
    case 4:
    case "NO_SPLIT":
      return Model_DataSplitMethod.NO_SPLIT;
    case 5:
    case "AUTO_SPLIT":
      return Model_DataSplitMethod.AUTO_SPLIT;
    case -1:
    case "UNRECOGNIZED":
    default:
      return Model_DataSplitMethod.UNRECOGNIZED;
  }
}

export function model_DataSplitMethodToJSON(object: Model_DataSplitMethod): string {
  switch (object) {
    case Model_DataSplitMethod.DATA_SPLIT_METHOD_UNSPECIFIED:
      return "DATA_SPLIT_METHOD_UNSPECIFIED";
    case Model_DataSplitMethod.RANDOM:
      return "RANDOM";
    case Model_DataSplitMethod.CUSTOM:
      return "CUSTOM";
    case Model_DataSplitMethod.SEQUENTIAL:
      return "SEQUENTIAL";
    case Model_DataSplitMethod.NO_SPLIT:
      return "NO_SPLIT";
    case Model_DataSplitMethod.AUTO_SPLIT:
      return "AUTO_SPLIT";
    case Model_DataSplitMethod.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/** Type of supported data frequency for time series forecasting models. */
export enum Model_DataFrequency {
  /** DATA_FREQUENCY_UNSPECIFIED - Default value. */
  DATA_FREQUENCY_UNSPECIFIED = 0,
  /** AUTO_FREQUENCY - Automatically inferred from timestamps. */
  AUTO_FREQUENCY = 1,
  /** YEARLY - Yearly data. */
  YEARLY = 2,
  /** QUARTERLY - Quarterly data. */
  QUARTERLY = 3,
  /** MONTHLY - Monthly data. */
  MONTHLY = 4,
  /** WEEKLY - Weekly data. */
  WEEKLY = 5,
  /** DAILY - Daily data. */
  DAILY = 6,
  /** HOURLY - Hourly data. */
  HOURLY = 7,
  /** PER_MINUTE - Per-minute data. */
  PER_MINUTE = 8,
  UNRECOGNIZED = -1,
}

export function model_DataFrequencyFromJSON(object: any): Model_DataFrequency {
  switch (object) {
    case 0:
    case "DATA_FREQUENCY_UNSPECIFIED":
      return Model_DataFrequency.DATA_FREQUENCY_UNSPECIFIED;
    case 1:
    case "AUTO_FREQUENCY":
      return Model_DataFrequency.AUTO_FREQUENCY;
    case 2:
    case "YEARLY":
      return Model_DataFrequency.YEARLY;
    case 3:
    case "QUARTERLY":
      return Model_DataFrequency.QUARTERLY;
    case 4:
    case "MONTHLY":
      return Model_DataFrequency.MONTHLY;
    case 5:
    case "WEEKLY":
      return Model_DataFrequency.WEEKLY;
    case 6:
    case "DAILY":
      return Model_DataFrequency.DAILY;
    case 7:
    case "HOURLY":
      return Model_DataFrequency.HOURLY;
    case 8:
    case "PER_MINUTE":
      return Model_DataFrequency.PER_MINUTE;
    case -1:
    case "UNRECOGNIZED":
    default:
      return Model_DataFrequency.UNRECOGNIZED;
  }
}

export function model_DataFrequencyToJSON(object: Model_DataFrequency): string {
  switch (object) {
    case Model_DataFrequency.DATA_FREQUENCY_UNSPECIFIED:
      return "DATA_FREQUENCY_UNSPECIFIED";
    case Model_DataFrequency.AUTO_FREQUENCY:
      return "AUTO_FREQUENCY";
    case Model_DataFrequency.YEARLY:
      return "YEARLY";
    case Model_DataFrequency.QUARTERLY:
      return "QUARTERLY";
    case Model_DataFrequency.MONTHLY:
      return "MONTHLY";
    case Model_DataFrequency.WEEKLY:
      return "WEEKLY";
    case Model_DataFrequency.DAILY:
      return "DAILY";
    case Model_DataFrequency.HOURLY:
      return "HOURLY";
    case Model_DataFrequency.PER_MINUTE:
      return "PER_MINUTE";
    case Model_DataFrequency.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/** Type of supported holiday regions for time series forecasting models. */
export enum Model_HolidayRegion {
  /** HOLIDAY_REGION_UNSPECIFIED - Holiday region unspecified. */
  HOLIDAY_REGION_UNSPECIFIED = 0,
  /** GLOBAL - Global. */
  GLOBAL = 1,
  /** NA - North America. */
  NA = 2,
  /**
   * JAPAC - Japan and Asia Pacific: Korea, Greater China, India, Australia, and New
   * Zealand.
   */
  JAPAC = 3,
  /** EMEA - Europe, the Middle East and Africa. */
  EMEA = 4,
  /** LAC - Latin America and the Caribbean. */
  LAC = 5,
  /** AE - United Arab Emirates */
  AE = 6,
  /** AR - Argentina */
  AR = 7,
  /** AT - Austria */
  AT = 8,
  /** AU - Australia */
  AU = 9,
  /** BE - Belgium */
  BE = 10,
  /** BR - Brazil */
  BR = 11,
  /** CA - Canada */
  CA = 12,
  /** CH - Switzerland */
  CH = 13,
  /** CL - Chile */
  CL = 14,
  /** CN - China */
  CN = 15,
  /** CO - Colombia */
  CO = 16,
  /** CS - Czechoslovakia */
  CS = 17,
  /** CZ - Czech Republic */
  CZ = 18,
  /** DE - Germany */
  DE = 19,
  /** DK - Denmark */
  DK = 20,
  /** DZ - Algeria */
  DZ = 21,
  /** EC - Ecuador */
  EC = 22,
  /** EE - Estonia */
  EE = 23,
  /** EG - Egypt */
  EG = 24,
  /** ES - Spain */
  ES = 25,
  /** FI - Finland */
  FI = 26,
  /** FR - France */
  FR = 27,
  /** GB - Great Britain (United Kingdom) */
  GB = 28,
  /** GR - Greece */
  GR = 29,
  /** HK - Hong Kong */
  HK = 30,
  /** HU - Hungary */
  HU = 31,
  /** ID - Indonesia */
  ID = 32,
  /** IE - Ireland */
  IE = 33,
  /** IL - Israel */
  IL = 34,
  /** IN - India */
  IN = 35,
  /** IR - Iran */
  IR = 36,
  /** IT - Italy */
  IT = 37,
  /** JP - Japan */
  JP = 38,
  /** KR - Korea (South) */
  KR = 39,
  /** LV - Latvia */
  LV = 40,
  /** MA - Morocco */
  MA = 41,
  /** MX - Mexico */
  MX = 42,
  /** MY - Malaysia */
  MY = 43,
  /** NG - Nigeria */
  NG = 44,
  /** NL - Netherlands */
  NL = 45,
  /** NO - Norway */
  NO = 46,
  /** NZ - New Zealand */
  NZ = 47,
  /** PE - Peru */
  PE = 48,
  /** PH - Philippines */
  PH = 49,
  /** PK - Pakistan */
  PK = 50,
  /** PL - Poland */
  PL = 51,
  /** PT - Portugal */
  PT = 52,
  /** RO - Romania */
  RO = 53,
  /** RS - Serbia */
  RS = 54,
  /** RU - Russian Federation */
  RU = 55,
  /** SA - Saudi Arabia */
  SA = 56,
  /** SE - Sweden */
  SE = 57,
  /** SG - Singapore */
  SG = 58,
  /** SI - Slovenia */
  SI = 59,
  /** SK - Slovakia */
  SK = 60,
  /** TH - Thailand */
  TH = 61,
  /** TR - Turkey */
  TR = 62,
  /** TW - Taiwan */
  TW = 63,
  /** UA - Ukraine */
  UA = 64,
  /** US - United States */
  US = 65,
  /** VE - Venezuela */
  VE = 66,
  /** VN - Viet Nam */
  VN = 67,
  /** ZA - South Africa */
  ZA = 68,
  UNRECOGNIZED = -1,
}

export function model_HolidayRegionFromJSON(object: any): Model_HolidayRegion {
  switch (object) {
    case 0:
    case "HOLIDAY_REGION_UNSPECIFIED":
      return Model_HolidayRegion.HOLIDAY_REGION_UNSPECIFIED;
    case 1:
    case "GLOBAL":
      return Model_HolidayRegion.GLOBAL;
    case 2:
    case "NA":
      return Model_HolidayRegion.NA;
    case 3:
    case "JAPAC":
      return Model_HolidayRegion.JAPAC;
    case 4:
    case "EMEA":
      return Model_HolidayRegion.EMEA;
    case 5:
    case "LAC":
      return Model_HolidayRegion.LAC;
    case 6:
    case "AE":
      return Model_HolidayRegion.AE;
    case 7:
    case "AR":
      return Model_HolidayRegion.AR;
    case 8:
    case "AT":
      return Model_HolidayRegion.AT;
    case 9:
    case "AU":
      return Model_HolidayRegion.AU;
    case 10:
    case "BE":
      return Model_HolidayRegion.BE;
    case 11:
    case "BR":
      return Model_HolidayRegion.BR;
    case 12:
    case "CA":
      return Model_HolidayRegion.CA;
    case 13:
    case "CH":
      return Model_HolidayRegion.CH;
    case 14:
    case "CL":
      return Model_HolidayRegion.CL;
    case 15:
    case "CN":
      return Model_HolidayRegion.CN;
    case 16:
    case "CO":
      return Model_HolidayRegion.CO;
    case 17:
    case "CS":
      return Model_HolidayRegion.CS;
    case 18:
    case "CZ":
      return Model_HolidayRegion.CZ;
    case 19:
    case "DE":
      return Model_HolidayRegion.DE;
    case 20:
    case "DK":
      return Model_HolidayRegion.DK;
    case 21:
    case "DZ":
      return Model_HolidayRegion.DZ;
    case 22:
    case "EC":
      return Model_HolidayRegion.EC;
    case 23:
    case "EE":
      return Model_HolidayRegion.EE;
    case 24:
    case "EG":
      return Model_HolidayRegion.EG;
    case 25:
    case "ES":
      return Model_HolidayRegion.ES;
    case 26:
    case "FI":
      return Model_HolidayRegion.FI;
    case 27:
    case "FR":
      return Model_HolidayRegion.FR;
    case 28:
    case "GB":
      return Model_HolidayRegion.GB;
    case 29:
    case "GR":
      return Model_HolidayRegion.GR;
    case 30:
    case "HK":
      return Model_HolidayRegion.HK;
    case 31:
    case "HU":
      return Model_HolidayRegion.HU;
    case 32:
    case "ID":
      return Model_HolidayRegion.ID;
    case 33:
    case "IE":
      return Model_HolidayRegion.IE;
    case 34:
    case "IL":
      return Model_HolidayRegion.IL;
    case 35:
    case "IN":
      return Model_HolidayRegion.IN;
    case 36:
    case "IR":
      return Model_HolidayRegion.IR;
    case 37:
    case "IT":
      return Model_HolidayRegion.IT;
    case 38:
    case "JP":
      return Model_HolidayRegion.JP;
    case 39:
    case "KR":
      return Model_HolidayRegion.KR;
    case 40:
    case "LV":
      return Model_HolidayRegion.LV;
    case 41:
    case "MA":
      return Model_HolidayRegion.MA;
    case 42:
    case "MX":
      return Model_HolidayRegion.MX;
    case 43:
    case "MY":
      return Model_HolidayRegion.MY;
    case 44:
    case "NG":
      return Model_HolidayRegion.NG;
    case 45:
    case "NL":
      return Model_HolidayRegion.NL;
    case 46:
    case "NO":
      return Model_HolidayRegion.NO;
    case 47:
    case "NZ":
      return Model_HolidayRegion.NZ;
    case 48:
    case "PE":
      return Model_HolidayRegion.PE;
    case 49:
    case "PH":
      return Model_HolidayRegion.PH;
    case 50:
    case "PK":
      return Model_HolidayRegion.PK;
    case 51:
    case "PL":
      return Model_HolidayRegion.PL;
    case 52:
    case "PT":
      return Model_HolidayRegion.PT;
    case 53:
    case "RO":
      return Model_HolidayRegion.RO;
    case 54:
    case "RS":
      return Model_HolidayRegion.RS;
    case 55:
    case "RU":
      return Model_HolidayRegion.RU;
    case 56:
    case "SA":
      return Model_HolidayRegion.SA;
    case 57:
    case "SE":
      return Model_HolidayRegion.SE;
    case 58:
    case "SG":
      return Model_HolidayRegion.SG;
    case 59:
    case "SI":
      return Model_HolidayRegion.SI;
    case 60:
    case "SK":
      return Model_HolidayRegion.SK;
    case 61:
    case "TH":
      return Model_HolidayRegion.TH;
    case 62:
    case "TR":
      return Model_HolidayRegion.TR;
    case 63:
    case "TW":
      return Model_HolidayRegion.TW;
    case 64:
    case "UA":
      return Model_HolidayRegion.UA;
    case 65:
    case "US":
      return Model_HolidayRegion.US;
    case 66:
    case "VE":
      return Model_HolidayRegion.VE;
    case 67:
    case "VN":
      return Model_HolidayRegion.VN;
    case 68:
    case "ZA":
      return Model_HolidayRegion.ZA;
    case -1:
    case "UNRECOGNIZED":
    default:
      return Model_HolidayRegion.UNRECOGNIZED;
  }
}

export function model_HolidayRegionToJSON(object: Model_HolidayRegion): string {
  switch (object) {
    case Model_HolidayRegion.HOLIDAY_REGION_UNSPECIFIED:
      return "HOLIDAY_REGION_UNSPECIFIED";
    case Model_HolidayRegion.GLOBAL:
      return "GLOBAL";
    case Model_HolidayRegion.NA:
      return "NA";
    case Model_HolidayRegion.JAPAC:
      return "JAPAC";
    case Model_HolidayRegion.EMEA:
      return "EMEA";
    case Model_HolidayRegion.LAC:
      return "LAC";
    case Model_HolidayRegion.AE:
      return "AE";
    case Model_HolidayRegion.AR:
      return "AR";
    case Model_HolidayRegion.AT:
      return "AT";
    case Model_HolidayRegion.AU:
      return "AU";
    case Model_HolidayRegion.BE:
      return "BE";
    case Model_HolidayRegion.BR:
      return "BR";
    case Model_HolidayRegion.CA:
      return "CA";
    case Model_HolidayRegion.CH:
      return "CH";
    case Model_HolidayRegion.CL:
      return "CL";
    case Model_HolidayRegion.CN:
      return "CN";
    case Model_HolidayRegion.CO:
      return "CO";
    case Model_HolidayRegion.CS:
      return "CS";
    case Model_HolidayRegion.CZ:
      return "CZ";
    case Model_HolidayRegion.DE:
      return "DE";
    case Model_HolidayRegion.DK:
      return "DK";
    case Model_HolidayRegion.DZ:
      return "DZ";
    case Model_HolidayRegion.EC:
      return "EC";
    case Model_HolidayRegion.EE:
      return "EE";
    case Model_HolidayRegion.EG:
      return "EG";
    case Model_HolidayRegion.ES:
      return "ES";
    case Model_HolidayRegion.FI:
      return "FI";
    case Model_HolidayRegion.FR:
      return "FR";
    case Model_HolidayRegion.GB:
      return "GB";
    case Model_HolidayRegion.GR:
      return "GR";
    case Model_HolidayRegion.HK:
      return "HK";
    case Model_HolidayRegion.HU:
      return "HU";
    case Model_HolidayRegion.ID:
      return "ID";
    case Model_HolidayRegion.IE:
      return "IE";
    case Model_HolidayRegion.IL:
      return "IL";
    case Model_HolidayRegion.IN:
      return "IN";
    case Model_HolidayRegion.IR:
      return "IR";
    case Model_HolidayRegion.IT:
      return "IT";
    case Model_HolidayRegion.JP:
      return "JP";
    case Model_HolidayRegion.KR:
      return "KR";
    case Model_HolidayRegion.LV:
      return "LV";
    case Model_HolidayRegion.MA:
      return "MA";
    case Model_HolidayRegion.MX:
      return "MX";
    case Model_HolidayRegion.MY:
      return "MY";
    case Model_HolidayRegion.NG:
      return "NG";
    case Model_HolidayRegion.NL:
      return "NL";
    case Model_HolidayRegion.NO:
      return "NO";
    case Model_HolidayRegion.NZ:
      return "NZ";
    case Model_HolidayRegion.PE:
      return "PE";
    case Model_HolidayRegion.PH:
      return "PH";
    case Model_HolidayRegion.PK:
      return "PK";
    case Model_HolidayRegion.PL:
      return "PL";
    case Model_HolidayRegion.PT:
      return "PT";
    case Model_HolidayRegion.RO:
      return "RO";
    case Model_HolidayRegion.RS:
      return "RS";
    case Model_HolidayRegion.RU:
      return "RU";
    case Model_HolidayRegion.SA:
      return "SA";
    case Model_HolidayRegion.SE:
      return "SE";
    case Model_HolidayRegion.SG:
      return "SG";
    case Model_HolidayRegion.SI:
      return "SI";
    case Model_HolidayRegion.SK:
      return "SK";
    case Model_HolidayRegion.TH:
      return "TH";
    case Model_HolidayRegion.TR:
      return "TR";
    case Model_HolidayRegion.TW:
      return "TW";
    case Model_HolidayRegion.UA:
      return "UA";
    case Model_HolidayRegion.US:
      return "US";
    case Model_HolidayRegion.VE:
      return "VE";
    case Model_HolidayRegion.VN:
      return "VN";
    case Model_HolidayRegion.ZA:
      return "ZA";
    case Model_HolidayRegion.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/**
 * Enums for color space, used for processing images in Object Table.
 * See more details at
 * https://www.tensorflow.org/io/tutorials/colorspace.
 */
export enum Model_ColorSpace {
  /** COLOR_SPACE_UNSPECIFIED - Unspecified color space */
  COLOR_SPACE_UNSPECIFIED = 0,
  /** RGB - RGB */
  RGB = 1,
  /** HSV - HSV */
  HSV = 2,
  /** YIQ - YIQ */
  YIQ = 3,
  /** YUV - YUV */
  YUV = 4,
  /** GRAYSCALE - GRAYSCALE */
  GRAYSCALE = 5,
  UNRECOGNIZED = -1,
}

export function model_ColorSpaceFromJSON(object: any): Model_ColorSpace {
  switch (object) {
    case 0:
    case "COLOR_SPACE_UNSPECIFIED":
      return Model_ColorSpace.COLOR_SPACE_UNSPECIFIED;
    case 1:
    case "RGB":
      return Model_ColorSpace.RGB;
    case 2:
    case "HSV":
      return Model_ColorSpace.HSV;
    case 3:
    case "YIQ":
      return Model_ColorSpace.YIQ;
    case 4:
    case "YUV":
      return Model_ColorSpace.YUV;
    case 5:
    case "GRAYSCALE":
      return Model_ColorSpace.GRAYSCALE;
    case -1:
    case "UNRECOGNIZED":
    default:
      return Model_ColorSpace.UNRECOGNIZED;
  }
}

export function model_ColorSpaceToJSON(object: Model_ColorSpace): string {
  switch (object) {
    case Model_ColorSpace.COLOR_SPACE_UNSPECIFIED:
      return "COLOR_SPACE_UNSPECIFIED";
    case Model_ColorSpace.RGB:
      return "RGB";
    case Model_ColorSpace.HSV:
      return "HSV";
    case Model_ColorSpace.YIQ:
      return "YIQ";
    case Model_ColorSpace.YUV:
      return "YUV";
    case Model_ColorSpace.GRAYSCALE:
      return "GRAYSCALE";
    case Model_ColorSpace.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/** Indicates the learning rate optimization strategy to use. */
export enum Model_LearnRateStrategy {
  /** LEARN_RATE_STRATEGY_UNSPECIFIED - Default value. */
  LEARN_RATE_STRATEGY_UNSPECIFIED = 0,
  /** LINE_SEARCH - Use line search to determine learning rate. */
  LINE_SEARCH = 1,
  /** CONSTANT - Use a constant learning rate. */
  CONSTANT = 2,
  UNRECOGNIZED = -1,
}

export function model_LearnRateStrategyFromJSON(object: any): Model_LearnRateStrategy {
  switch (object) {
    case 0:
    case "LEARN_RATE_STRATEGY_UNSPECIFIED":
      return Model_LearnRateStrategy.LEARN_RATE_STRATEGY_UNSPECIFIED;
    case 1:
    case "LINE_SEARCH":
      return Model_LearnRateStrategy.LINE_SEARCH;
    case 2:
    case "CONSTANT":
      return Model_LearnRateStrategy.CONSTANT;
    case -1:
    case "UNRECOGNIZED":
    default:
      return Model_LearnRateStrategy.UNRECOGNIZED;
  }
}

export function model_LearnRateStrategyToJSON(object: Model_LearnRateStrategy): string {
  switch (object) {
    case Model_LearnRateStrategy.LEARN_RATE_STRATEGY_UNSPECIFIED:
      return "LEARN_RATE_STRATEGY_UNSPECIFIED";
    case Model_LearnRateStrategy.LINE_SEARCH:
      return "LINE_SEARCH";
    case Model_LearnRateStrategy.CONSTANT:
      return "CONSTANT";
    case Model_LearnRateStrategy.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/** Indicates the optimization strategy used for training. */
export enum Model_OptimizationStrategy {
  /** OPTIMIZATION_STRATEGY_UNSPECIFIED - Default value. */
  OPTIMIZATION_STRATEGY_UNSPECIFIED = 0,
  /** BATCH_GRADIENT_DESCENT - Uses an iterative batch gradient descent algorithm. */
  BATCH_GRADIENT_DESCENT = 1,
  /** NORMAL_EQUATION - Uses a normal equation to solve linear regression problem. */
  NORMAL_EQUATION = 2,
  UNRECOGNIZED = -1,
}

export function model_OptimizationStrategyFromJSON(object: any): Model_OptimizationStrategy {
  switch (object) {
    case 0:
    case "OPTIMIZATION_STRATEGY_UNSPECIFIED":
      return Model_OptimizationStrategy.OPTIMIZATION_STRATEGY_UNSPECIFIED;
    case 1:
    case "BATCH_GRADIENT_DESCENT":
      return Model_OptimizationStrategy.BATCH_GRADIENT_DESCENT;
    case 2:
    case "NORMAL_EQUATION":
      return Model_OptimizationStrategy.NORMAL_EQUATION;
    case -1:
    case "UNRECOGNIZED":
    default:
      return Model_OptimizationStrategy.UNRECOGNIZED;
  }
}

export function model_OptimizationStrategyToJSON(object: Model_OptimizationStrategy): string {
  switch (object) {
    case Model_OptimizationStrategy.OPTIMIZATION_STRATEGY_UNSPECIFIED:
      return "OPTIMIZATION_STRATEGY_UNSPECIFIED";
    case Model_OptimizationStrategy.BATCH_GRADIENT_DESCENT:
      return "BATCH_GRADIENT_DESCENT";
    case Model_OptimizationStrategy.NORMAL_EQUATION:
      return "NORMAL_EQUATION";
    case Model_OptimizationStrategy.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/** Indicates the training algorithm to use for matrix factorization models. */
export enum Model_FeedbackType {
  /** FEEDBACK_TYPE_UNSPECIFIED - Default value. */
  FEEDBACK_TYPE_UNSPECIFIED = 0,
  /** IMPLICIT - Use weighted-als for implicit feedback problems. */
  IMPLICIT = 1,
  /** EXPLICIT - Use nonweighted-als for explicit feedback problems. */
  EXPLICIT = 2,
  UNRECOGNIZED = -1,
}

export function model_FeedbackTypeFromJSON(object: any): Model_FeedbackType {
  switch (object) {
    case 0:
    case "FEEDBACK_TYPE_UNSPECIFIED":
      return Model_FeedbackType.FEEDBACK_TYPE_UNSPECIFIED;
    case 1:
    case "IMPLICIT":
      return Model_FeedbackType.IMPLICIT;
    case 2:
    case "EXPLICIT":
      return Model_FeedbackType.EXPLICIT;
    case -1:
    case "UNRECOGNIZED":
    default:
      return Model_FeedbackType.UNRECOGNIZED;
  }
}

export function model_FeedbackTypeToJSON(object: Model_FeedbackType): string {
  switch (object) {
    case Model_FeedbackType.FEEDBACK_TYPE_UNSPECIFIED:
      return "FEEDBACK_TYPE_UNSPECIFIED";
    case Model_FeedbackType.IMPLICIT:
      return "IMPLICIT";
    case Model_FeedbackType.EXPLICIT:
      return "EXPLICIT";
    case Model_FeedbackType.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/** Enums for seasonal period. */
export interface Model_SeasonalPeriod {
}

/** Seasonal period type. */
export enum Model_SeasonalPeriod_SeasonalPeriodType {
  /** SEASONAL_PERIOD_TYPE_UNSPECIFIED - Unspecified seasonal period. */
  SEASONAL_PERIOD_TYPE_UNSPECIFIED = 0,
  /** NO_SEASONALITY - No seasonality */
  NO_SEASONALITY = 1,
  /** DAILY - Daily period, 24 hours. */
  DAILY = 2,
  /** WEEKLY - Weekly period, 7 days. */
  WEEKLY = 3,
  /** MONTHLY - Monthly period, 30 days or irregular. */
  MONTHLY = 4,
  /** QUARTERLY - Quarterly period, 90 days or irregular. */
  QUARTERLY = 5,
  /** YEARLY - Yearly period, 365 days or irregular. */
  YEARLY = 6,
  UNRECOGNIZED = -1,
}

export function model_SeasonalPeriod_SeasonalPeriodTypeFromJSON(object: any): Model_SeasonalPeriod_SeasonalPeriodType {
  switch (object) {
    case 0:
    case "SEASONAL_PERIOD_TYPE_UNSPECIFIED":
      return Model_SeasonalPeriod_SeasonalPeriodType.SEASONAL_PERIOD_TYPE_UNSPECIFIED;
    case 1:
    case "NO_SEASONALITY":
      return Model_SeasonalPeriod_SeasonalPeriodType.NO_SEASONALITY;
    case 2:
    case "DAILY":
      return Model_SeasonalPeriod_SeasonalPeriodType.DAILY;
    case 3:
    case "WEEKLY":
      return Model_SeasonalPeriod_SeasonalPeriodType.WEEKLY;
    case 4:
    case "MONTHLY":
      return Model_SeasonalPeriod_SeasonalPeriodType.MONTHLY;
    case 5:
    case "QUARTERLY":
      return Model_SeasonalPeriod_SeasonalPeriodType.QUARTERLY;
    case 6:
    case "YEARLY":
      return Model_SeasonalPeriod_SeasonalPeriodType.YEARLY;
    case -1:
    case "UNRECOGNIZED":
    default:
      return Model_SeasonalPeriod_SeasonalPeriodType.UNRECOGNIZED;
  }
}

export function model_SeasonalPeriod_SeasonalPeriodTypeToJSON(object: Model_SeasonalPeriod_SeasonalPeriodType): string {
  switch (object) {
    case Model_SeasonalPeriod_SeasonalPeriodType.SEASONAL_PERIOD_TYPE_UNSPECIFIED:
      return "SEASONAL_PERIOD_TYPE_UNSPECIFIED";
    case Model_SeasonalPeriod_SeasonalPeriodType.NO_SEASONALITY:
      return "NO_SEASONALITY";
    case Model_SeasonalPeriod_SeasonalPeriodType.DAILY:
      return "DAILY";
    case Model_SeasonalPeriod_SeasonalPeriodType.WEEKLY:
      return "WEEKLY";
    case Model_SeasonalPeriod_SeasonalPeriodType.MONTHLY:
      return "MONTHLY";
    case Model_SeasonalPeriod_SeasonalPeriodType.QUARTERLY:
      return "QUARTERLY";
    case Model_SeasonalPeriod_SeasonalPeriodType.YEARLY:
      return "YEARLY";
    case Model_SeasonalPeriod_SeasonalPeriodType.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/** Enums for kmeans model type. */
export interface Model_KmeansEnums {
}

/**
 * Indicates the method used to initialize the centroids for KMeans
 * clustering algorithm.
 */
export enum Model_KmeansEnums_KmeansInitializationMethod {
  /** KMEANS_INITIALIZATION_METHOD_UNSPECIFIED - Unspecified initialization method. */
  KMEANS_INITIALIZATION_METHOD_UNSPECIFIED = 0,
  /** RANDOM - Initializes the centroids randomly. */
  RANDOM = 1,
  /**
   * CUSTOM - Initializes the centroids using data specified in
   * kmeans_initialization_column.
   */
  CUSTOM = 2,
  /** KMEANS_PLUS_PLUS - Initializes with kmeans++. */
  KMEANS_PLUS_PLUS = 3,
  UNRECOGNIZED = -1,
}

export function model_KmeansEnums_KmeansInitializationMethodFromJSON(
  object: any,
): Model_KmeansEnums_KmeansInitializationMethod {
  switch (object) {
    case 0:
    case "KMEANS_INITIALIZATION_METHOD_UNSPECIFIED":
      return Model_KmeansEnums_KmeansInitializationMethod.KMEANS_INITIALIZATION_METHOD_UNSPECIFIED;
    case 1:
    case "RANDOM":
      return Model_KmeansEnums_KmeansInitializationMethod.RANDOM;
    case 2:
    case "CUSTOM":
      return Model_KmeansEnums_KmeansInitializationMethod.CUSTOM;
    case 3:
    case "KMEANS_PLUS_PLUS":
      return Model_KmeansEnums_KmeansInitializationMethod.KMEANS_PLUS_PLUS;
    case -1:
    case "UNRECOGNIZED":
    default:
      return Model_KmeansEnums_KmeansInitializationMethod.UNRECOGNIZED;
  }
}

export function model_KmeansEnums_KmeansInitializationMethodToJSON(
  object: Model_KmeansEnums_KmeansInitializationMethod,
): string {
  switch (object) {
    case Model_KmeansEnums_KmeansInitializationMethod.KMEANS_INITIALIZATION_METHOD_UNSPECIFIED:
      return "KMEANS_INITIALIZATION_METHOD_UNSPECIFIED";
    case Model_KmeansEnums_KmeansInitializationMethod.RANDOM:
      return "RANDOM";
    case Model_KmeansEnums_KmeansInitializationMethod.CUSTOM:
      return "CUSTOM";
    case Model_KmeansEnums_KmeansInitializationMethod.KMEANS_PLUS_PLUS:
      return "KMEANS_PLUS_PLUS";
    case Model_KmeansEnums_KmeansInitializationMethod.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/** Enums for XGBoost model type. */
export interface Model_BoostedTreeOptionEnums {
}

/** Booster types supported. Refer to booster parameter in XGBoost. */
export enum Model_BoostedTreeOptionEnums_BoosterType {
  /** BOOSTER_TYPE_UNSPECIFIED - Unspecified booster type. */
  BOOSTER_TYPE_UNSPECIFIED = 0,
  /** GBTREE - Gbtree booster. */
  GBTREE = 1,
  /** DART - Dart booster. */
  DART = 2,
  UNRECOGNIZED = -1,
}

export function model_BoostedTreeOptionEnums_BoosterTypeFromJSON(
  object: any,
): Model_BoostedTreeOptionEnums_BoosterType {
  switch (object) {
    case 0:
    case "BOOSTER_TYPE_UNSPECIFIED":
      return Model_BoostedTreeOptionEnums_BoosterType.BOOSTER_TYPE_UNSPECIFIED;
    case 1:
    case "GBTREE":
      return Model_BoostedTreeOptionEnums_BoosterType.GBTREE;
    case 2:
    case "DART":
      return Model_BoostedTreeOptionEnums_BoosterType.DART;
    case -1:
    case "UNRECOGNIZED":
    default:
      return Model_BoostedTreeOptionEnums_BoosterType.UNRECOGNIZED;
  }
}

export function model_BoostedTreeOptionEnums_BoosterTypeToJSON(
  object: Model_BoostedTreeOptionEnums_BoosterType,
): string {
  switch (object) {
    case Model_BoostedTreeOptionEnums_BoosterType.BOOSTER_TYPE_UNSPECIFIED:
      return "BOOSTER_TYPE_UNSPECIFIED";
    case Model_BoostedTreeOptionEnums_BoosterType.GBTREE:
      return "GBTREE";
    case Model_BoostedTreeOptionEnums_BoosterType.DART:
      return "DART";
    case Model_BoostedTreeOptionEnums_BoosterType.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/**
 * Type of normalization algorithm for boosted tree models using dart
 * booster. Refer to normalize_type in XGBoost.
 */
export enum Model_BoostedTreeOptionEnums_DartNormalizeType {
  /** DART_NORMALIZE_TYPE_UNSPECIFIED - Unspecified dart normalize type. */
  DART_NORMALIZE_TYPE_UNSPECIFIED = 0,
  /** TREE - New trees have the same weight of each of dropped trees. */
  TREE = 1,
  /** FOREST - New trees have the same weight of sum of dropped trees. */
  FOREST = 2,
  UNRECOGNIZED = -1,
}

export function model_BoostedTreeOptionEnums_DartNormalizeTypeFromJSON(
  object: any,
): Model_BoostedTreeOptionEnums_DartNormalizeType {
  switch (object) {
    case 0:
    case "DART_NORMALIZE_TYPE_UNSPECIFIED":
      return Model_BoostedTreeOptionEnums_DartNormalizeType.DART_NORMALIZE_TYPE_UNSPECIFIED;
    case 1:
    case "TREE":
      return Model_BoostedTreeOptionEnums_DartNormalizeType.TREE;
    case 2:
    case "FOREST":
      return Model_BoostedTreeOptionEnums_DartNormalizeType.FOREST;
    case -1:
    case "UNRECOGNIZED":
    default:
      return Model_BoostedTreeOptionEnums_DartNormalizeType.UNRECOGNIZED;
  }
}

export function model_BoostedTreeOptionEnums_DartNormalizeTypeToJSON(
  object: Model_BoostedTreeOptionEnums_DartNormalizeType,
): string {
  switch (object) {
    case Model_BoostedTreeOptionEnums_DartNormalizeType.DART_NORMALIZE_TYPE_UNSPECIFIED:
      return "DART_NORMALIZE_TYPE_UNSPECIFIED";
    case Model_BoostedTreeOptionEnums_DartNormalizeType.TREE:
      return "TREE";
    case Model_BoostedTreeOptionEnums_DartNormalizeType.FOREST:
      return "FOREST";
    case Model_BoostedTreeOptionEnums_DartNormalizeType.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/**
 * Tree construction algorithm used in boosted tree models.
 * Refer to tree_method in XGBoost.
 */
export enum Model_BoostedTreeOptionEnums_TreeMethod {
  /** TREE_METHOD_UNSPECIFIED - Unspecified tree method. */
  TREE_METHOD_UNSPECIFIED = 0,
  /** AUTO - Use heuristic to choose the fastest method. */
  AUTO = 1,
  /** EXACT - Exact greedy algorithm. */
  EXACT = 2,
  /**
   * APPROX - Approximate greedy algorithm using quantile sketch and gradient
   * histogram.
   */
  APPROX = 3,
  /** HIST - Fast histogram optimized approximate greedy algorithm. */
  HIST = 4,
  UNRECOGNIZED = -1,
}

export function model_BoostedTreeOptionEnums_TreeMethodFromJSON(object: any): Model_BoostedTreeOptionEnums_TreeMethod {
  switch (object) {
    case 0:
    case "TREE_METHOD_UNSPECIFIED":
      return Model_BoostedTreeOptionEnums_TreeMethod.TREE_METHOD_UNSPECIFIED;
    case 1:
    case "AUTO":
      return Model_BoostedTreeOptionEnums_TreeMethod.AUTO;
    case 2:
    case "EXACT":
      return Model_BoostedTreeOptionEnums_TreeMethod.EXACT;
    case 3:
    case "APPROX":
      return Model_BoostedTreeOptionEnums_TreeMethod.APPROX;
    case 4:
    case "HIST":
      return Model_BoostedTreeOptionEnums_TreeMethod.HIST;
    case -1:
    case "UNRECOGNIZED":
    default:
      return Model_BoostedTreeOptionEnums_TreeMethod.UNRECOGNIZED;
  }
}

export function model_BoostedTreeOptionEnums_TreeMethodToJSON(object: Model_BoostedTreeOptionEnums_TreeMethod): string {
  switch (object) {
    case Model_BoostedTreeOptionEnums_TreeMethod.TREE_METHOD_UNSPECIFIED:
      return "TREE_METHOD_UNSPECIFIED";
    case Model_BoostedTreeOptionEnums_TreeMethod.AUTO:
      return "AUTO";
    case Model_BoostedTreeOptionEnums_TreeMethod.EXACT:
      return "EXACT";
    case Model_BoostedTreeOptionEnums_TreeMethod.APPROX:
      return "APPROX";
    case Model_BoostedTreeOptionEnums_TreeMethod.HIST:
      return "HIST";
    case Model_BoostedTreeOptionEnums_TreeMethod.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/** Enums for hyperparameter tuning. */
export interface Model_HparamTuningEnums {
}

/** Available evaluation metrics used as hyperparameter tuning objectives. */
export enum Model_HparamTuningEnums_HparamTuningObjective {
  /** HPARAM_TUNING_OBJECTIVE_UNSPECIFIED - Unspecified evaluation metric. */
  HPARAM_TUNING_OBJECTIVE_UNSPECIFIED = 0,
  /**
   * MEAN_ABSOLUTE_ERROR - Mean absolute error.
   * mean_absolute_error = AVG(ABS(label - predicted))
   */
  MEAN_ABSOLUTE_ERROR = 1,
  /**
   * MEAN_SQUARED_ERROR - Mean squared error.
   * mean_squared_error = AVG(POW(label - predicted, 2))
   */
  MEAN_SQUARED_ERROR = 2,
  /**
   * MEAN_SQUARED_LOG_ERROR - Mean squared log error.
   * mean_squared_log_error = AVG(POW(LN(1 + label) - LN(1 + predicted), 2))
   */
  MEAN_SQUARED_LOG_ERROR = 3,
  /**
   * MEDIAN_ABSOLUTE_ERROR - Mean absolute error.
   * median_absolute_error = APPROX_QUANTILES(absolute_error, 2)[OFFSET(1)]
   */
  MEDIAN_ABSOLUTE_ERROR = 4,
  /**
   * R_SQUARED - R^2 score. This corresponds to r2_score in ML.EVALUATE.
   * r_squared = 1 - SUM(squared_error)/(COUNT(label)*VAR_POP(label))
   */
  R_SQUARED = 5,
  /**
   * EXPLAINED_VARIANCE - Explained variance.
   * explained_variance = 1 - VAR_POP(label_error)/VAR_POP(label)
   */
  EXPLAINED_VARIANCE = 6,
  /**
   * PRECISION - Precision is the fraction of actual positive predictions that had
   * positive actual labels. For multiclass this is a macro-averaged metric
   * treating each class as a binary classifier.
   */
  PRECISION = 7,
  /**
   * RECALL - Recall is the fraction of actual positive labels that were given a
   * positive prediction. For multiclass this is a macro-averaged metric.
   */
  RECALL = 8,
  /**
   * ACCURACY - Accuracy is the fraction of predictions given the correct label. For
   * multiclass this is a globally micro-averaged metric.
   */
  ACCURACY = 9,
  /**
   * F1_SCORE - The F1 score is an average of recall and precision. For multiclass this
   * is a macro-averaged metric.
   */
  F1_SCORE = 10,
  /** LOG_LOSS - Logorithmic Loss. For multiclass this is a macro-averaged metric. */
  LOG_LOSS = 11,
  /**
   * ROC_AUC - Area Under an ROC Curve. For multiclass this is a macro-averaged
   * metric.
   */
  ROC_AUC = 12,
  /** DAVIES_BOULDIN_INDEX - Davies-Bouldin Index. */
  DAVIES_BOULDIN_INDEX = 13,
  /** MEAN_AVERAGE_PRECISION - Mean Average Precision. */
  MEAN_AVERAGE_PRECISION = 14,
  /** NORMALIZED_DISCOUNTED_CUMULATIVE_GAIN - Normalized Discounted Cumulative Gain. */
  NORMALIZED_DISCOUNTED_CUMULATIVE_GAIN = 15,
  /** AVERAGE_RANK - Average Rank. */
  AVERAGE_RANK = 16,
  UNRECOGNIZED = -1,
}

export function model_HparamTuningEnums_HparamTuningObjectiveFromJSON(
  object: any,
): Model_HparamTuningEnums_HparamTuningObjective {
  switch (object) {
    case 0:
    case "HPARAM_TUNING_OBJECTIVE_UNSPECIFIED":
      return Model_HparamTuningEnums_HparamTuningObjective.HPARAM_TUNING_OBJECTIVE_UNSPECIFIED;
    case 1:
    case "MEAN_ABSOLUTE_ERROR":
      return Model_HparamTuningEnums_HparamTuningObjective.MEAN_ABSOLUTE_ERROR;
    case 2:
    case "MEAN_SQUARED_ERROR":
      return Model_HparamTuningEnums_HparamTuningObjective.MEAN_SQUARED_ERROR;
    case 3:
    case "MEAN_SQUARED_LOG_ERROR":
      return Model_HparamTuningEnums_HparamTuningObjective.MEAN_SQUARED_LOG_ERROR;
    case 4:
    case "MEDIAN_ABSOLUTE_ERROR":
      return Model_HparamTuningEnums_HparamTuningObjective.MEDIAN_ABSOLUTE_ERROR;
    case 5:
    case "R_SQUARED":
      return Model_HparamTuningEnums_HparamTuningObjective.R_SQUARED;
    case 6:
    case "EXPLAINED_VARIANCE":
      return Model_HparamTuningEnums_HparamTuningObjective.EXPLAINED_VARIANCE;
    case 7:
    case "PRECISION":
      return Model_HparamTuningEnums_HparamTuningObjective.PRECISION;
    case 8:
    case "RECALL":
      return Model_HparamTuningEnums_HparamTuningObjective.RECALL;
    case 9:
    case "ACCURACY":
      return Model_HparamTuningEnums_HparamTuningObjective.ACCURACY;
    case 10:
    case "F1_SCORE":
      return Model_HparamTuningEnums_HparamTuningObjective.F1_SCORE;
    case 11:
    case "LOG_LOSS":
      return Model_HparamTuningEnums_HparamTuningObjective.LOG_LOSS;
    case 12:
    case "ROC_AUC":
      return Model_HparamTuningEnums_HparamTuningObjective.ROC_AUC;
    case 13:
    case "DAVIES_BOULDIN_INDEX":
      return Model_HparamTuningEnums_HparamTuningObjective.DAVIES_BOULDIN_INDEX;
    case 14:
    case "MEAN_AVERAGE_PRECISION":
      return Model_HparamTuningEnums_HparamTuningObjective.MEAN_AVERAGE_PRECISION;
    case 15:
    case "NORMALIZED_DISCOUNTED_CUMULATIVE_GAIN":
      return Model_HparamTuningEnums_HparamTuningObjective.NORMALIZED_DISCOUNTED_CUMULATIVE_GAIN;
    case 16:
    case "AVERAGE_RANK":
      return Model_HparamTuningEnums_HparamTuningObjective.AVERAGE_RANK;
    case -1:
    case "UNRECOGNIZED":
    default:
      return Model_HparamTuningEnums_HparamTuningObjective.UNRECOGNIZED;
  }
}

export function model_HparamTuningEnums_HparamTuningObjectiveToJSON(
  object: Model_HparamTuningEnums_HparamTuningObjective,
): string {
  switch (object) {
    case Model_HparamTuningEnums_HparamTuningObjective.HPARAM_TUNING_OBJECTIVE_UNSPECIFIED:
      return "HPARAM_TUNING_OBJECTIVE_UNSPECIFIED";
    case Model_HparamTuningEnums_HparamTuningObjective.MEAN_ABSOLUTE_ERROR:
      return "MEAN_ABSOLUTE_ERROR";
    case Model_HparamTuningEnums_HparamTuningObjective.MEAN_SQUARED_ERROR:
      return "MEAN_SQUARED_ERROR";
    case Model_HparamTuningEnums_HparamTuningObjective.MEAN_SQUARED_LOG_ERROR:
      return "MEAN_SQUARED_LOG_ERROR";
    case Model_HparamTuningEnums_HparamTuningObjective.MEDIAN_ABSOLUTE_ERROR:
      return "MEDIAN_ABSOLUTE_ERROR";
    case Model_HparamTuningEnums_HparamTuningObjective.R_SQUARED:
      return "R_SQUARED";
    case Model_HparamTuningEnums_HparamTuningObjective.EXPLAINED_VARIANCE:
      return "EXPLAINED_VARIANCE";
    case Model_HparamTuningEnums_HparamTuningObjective.PRECISION:
      return "PRECISION";
    case Model_HparamTuningEnums_HparamTuningObjective.RECALL:
      return "RECALL";
    case Model_HparamTuningEnums_HparamTuningObjective.ACCURACY:
      return "ACCURACY";
    case Model_HparamTuningEnums_HparamTuningObjective.F1_SCORE:
      return "F1_SCORE";
    case Model_HparamTuningEnums_HparamTuningObjective.LOG_LOSS:
      return "LOG_LOSS";
    case Model_HparamTuningEnums_HparamTuningObjective.ROC_AUC:
      return "ROC_AUC";
    case Model_HparamTuningEnums_HparamTuningObjective.DAVIES_BOULDIN_INDEX:
      return "DAVIES_BOULDIN_INDEX";
    case Model_HparamTuningEnums_HparamTuningObjective.MEAN_AVERAGE_PRECISION:
      return "MEAN_AVERAGE_PRECISION";
    case Model_HparamTuningEnums_HparamTuningObjective.NORMALIZED_DISCOUNTED_CUMULATIVE_GAIN:
      return "NORMALIZED_DISCOUNTED_CUMULATIVE_GAIN";
    case Model_HparamTuningEnums_HparamTuningObjective.AVERAGE_RANK:
      return "AVERAGE_RANK";
    case Model_HparamTuningEnums_HparamTuningObjective.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/**
 * Evaluation metrics for regression and explicit feedback type matrix
 * factorization models.
 */
export interface Model_RegressionMetrics {
  /** Mean absolute error. */
  meanAbsoluteError:
    | number
    | undefined;
  /** Mean squared error. */
  meanSquaredError:
    | number
    | undefined;
  /** Mean squared log error. */
  meanSquaredLogError:
    | number
    | undefined;
  /** Median absolute error. */
  medianAbsoluteError:
    | number
    | undefined;
  /** R^2 score. This corresponds to r2_score in ML.EVALUATE. */
  rSquared: number | undefined;
}

/**
 * Aggregate metrics for classification/classifier models. For multi-class
 * models, the metrics are either macro-averaged or micro-averaged. When
 * macro-averaged, the metrics are calculated for each label and then an
 * unweighted average is taken of those values. When micro-averaged, the
 * metric is calculated globally by counting the total number of correctly
 * predicted rows.
 */
export interface Model_AggregateClassificationMetrics {
  /**
   * Precision is the fraction of actual positive predictions that had
   * positive actual labels. For multiclass this is a macro-averaged
   * metric treating each class as a binary classifier.
   */
  precision:
    | number
    | undefined;
  /**
   * Recall is the fraction of actual positive labels that were given a
   * positive prediction. For multiclass this is a macro-averaged metric.
   */
  recall:
    | number
    | undefined;
  /**
   * Accuracy is the fraction of predictions given the correct label. For
   * multiclass this is a micro-averaged metric.
   */
  accuracy:
    | number
    | undefined;
  /**
   * Threshold at which the metrics are computed. For binary
   * classification models this is the positive class threshold.
   * For multi-class classfication models this is the confidence
   * threshold.
   */
  threshold:
    | number
    | undefined;
  /**
   * The F1 score is an average of recall and precision. For multiclass
   * this is a macro-averaged metric.
   */
  f1Score:
    | number
    | undefined;
  /** Logarithmic Loss. For multiclass this is a macro-averaged metric. */
  logLoss:
    | number
    | undefined;
  /**
   * Area Under a ROC Curve. For multiclass this is a macro-averaged
   * metric.
   */
  rocAuc: number | undefined;
}

/** Evaluation metrics for binary classification/classifier models. */
export interface Model_BinaryClassificationMetrics {
  /** Aggregate classification metrics. */
  aggregateClassificationMetrics:
    | Model_AggregateClassificationMetrics
    | undefined;
  /** Binary confusion matrix at multiple thresholds. */
  binaryConfusionMatrixList: Model_BinaryClassificationMetrics_BinaryConfusionMatrix[];
  /** Label representing the positive class. */
  positiveLabel: string;
  /** Label representing the negative class. */
  negativeLabel: string;
}

/** Confusion matrix for binary classification models. */
export interface Model_BinaryClassificationMetrics_BinaryConfusionMatrix {
  /** Threshold value used when computing each of the following metric. */
  positiveClassThreshold:
    | number
    | undefined;
  /** Number of true samples predicted as true. */
  truePositives:
    | Long
    | undefined;
  /** Number of false samples predicted as true. */
  falsePositives:
    | Long
    | undefined;
  /** Number of true samples predicted as false. */
  trueNegatives:
    | Long
    | undefined;
  /** Number of false samples predicted as false. */
  falseNegatives:
    | Long
    | undefined;
  /**
   * The fraction of actual positive predictions that had positive actual
   * labels.
   */
  precision:
    | number
    | undefined;
  /**
   * The fraction of actual positive labels that were given a positive
   * prediction.
   */
  recall:
    | number
    | undefined;
  /** The equally weighted average of recall and precision. */
  f1Score:
    | number
    | undefined;
  /** The fraction of predictions given the correct label. */
  accuracy: number | undefined;
}

/** Evaluation metrics for multi-class classification/classifier models. */
export interface Model_MultiClassClassificationMetrics {
  /** Aggregate classification metrics. */
  aggregateClassificationMetrics:
    | Model_AggregateClassificationMetrics
    | undefined;
  /** Confusion matrix at different thresholds. */
  confusionMatrixList: Model_MultiClassClassificationMetrics_ConfusionMatrix[];
}

/** Confusion matrix for multi-class classification models. */
export interface Model_MultiClassClassificationMetrics_ConfusionMatrix {
  /**
   * Confidence threshold used when computing the entries of the
   * confusion matrix.
   */
  confidenceThreshold:
    | number
    | undefined;
  /** One row per actual label. */
  rows: Model_MultiClassClassificationMetrics_ConfusionMatrix_Row[];
}

/** A single entry in the confusion matrix. */
export interface Model_MultiClassClassificationMetrics_ConfusionMatrix_Entry {
  /**
   * The predicted label. For confidence_threshold > 0, we will
   * also add an entry indicating the number of items under the
   * confidence threshold.
   */
  predictedLabel: string;
  /** Number of items being predicted as this label. */
  itemCount: Long | undefined;
}

/** A single row in the confusion matrix. */
export interface Model_MultiClassClassificationMetrics_ConfusionMatrix_Row {
  /** The original label of this row. */
  actualLabel: string;
  /** Info describing predicted label distribution. */
  entries: Model_MultiClassClassificationMetrics_ConfusionMatrix_Entry[];
}

/** Evaluation metrics for clustering models. */
export interface Model_ClusteringMetrics {
  /** Davies-Bouldin index. */
  daviesBouldinIndex:
    | number
    | undefined;
  /** Mean of squared distances between each sample to its cluster centroid. */
  meanSquaredDistance:
    | number
    | undefined;
  /** Information for all clusters. */
  clusters: Model_ClusteringMetrics_Cluster[];
}

/** Message containing the information about one cluster. */
export interface Model_ClusteringMetrics_Cluster {
  /** Centroid id. */
  centroidId: Long;
  /** Values of highly variant features for this cluster. */
  featureValues: Model_ClusteringMetrics_Cluster_FeatureValue[];
  /** Count of training data rows that were assigned to this cluster. */
  count: Long | undefined;
}

/** Representative value of a single feature within the cluster. */
export interface Model_ClusteringMetrics_Cluster_FeatureValue {
  /** The feature column name. */
  featureColumn: string;
  /**
   * The numerical feature value. This is the centroid value for this
   * feature.
   */
  numericalValue?:
    | number
    | undefined;
  /** The categorical feature value. */
  categoricalValue?: Model_ClusteringMetrics_Cluster_FeatureValue_CategoricalValue | undefined;
}

/** Representative value of a categorical feature. */
export interface Model_ClusteringMetrics_Cluster_FeatureValue_CategoricalValue {
  /**
   * Counts of all categories for the categorical feature. If there are
   * more than ten categories, we return top ten (by count) and return
   * one more CategoryCount with category "_OTHER_" and count as
   * aggregate counts of remaining categories.
   */
  categoryCounts: Model_ClusteringMetrics_Cluster_FeatureValue_CategoricalValue_CategoryCount[];
}

/** Represents the count of a single category within the cluster. */
export interface Model_ClusteringMetrics_Cluster_FeatureValue_CategoricalValue_CategoryCount {
  /** The name of category. */
  category: string;
  /**
   * The count of training samples matching the category within the
   * cluster.
   */
  count: Long | undefined;
}

/**
 * Evaluation metrics used by weighted-ALS models specified by
 * feedback_type=implicit.
 */
export interface Model_RankingMetrics {
  /**
   * Calculates a precision per user for all the items by ranking them and
   * then averages all the precisions across all the users.
   */
  meanAveragePrecision:
    | number
    | undefined;
  /**
   * Similar to the mean squared error computed in regression and explicit
   * recommendation models except instead of computing the rating directly,
   * the output from evaluate is computed against a preference which is 1 or 0
   * depending on if the rating exists or not.
   */
  meanSquaredError:
    | number
    | undefined;
  /**
   * A metric to determine the goodness of a ranking calculated from the
   * predicted confidence by comparing it to an ideal rank measured by the
   * original ratings.
   */
  normalizedDiscountedCumulativeGain:
    | number
    | undefined;
  /**
   * Determines the goodness of a ranking by computing the percentile rank
   * from the predicted confidence and dividing it by the original rank.
   */
  averageRank: number | undefined;
}

/** Model evaluation metrics for ARIMA forecasting models. */
export interface Model_ArimaForecastingMetrics {
  /**
   * Repeated as there can be many metric sets (one for each model) in
   * auto-arima and the large-scale case.
   */
  arimaSingleModelForecastingMetrics: Model_ArimaForecastingMetrics_ArimaSingleModelForecastingMetrics[];
}

/** Model evaluation metrics for a single ARIMA forecasting model. */
export interface Model_ArimaForecastingMetrics_ArimaSingleModelForecastingMetrics {
  /** Non-seasonal order. */
  nonSeasonalOrder:
    | Model_ArimaOrder
    | undefined;
  /** Arima fitting metrics. */
  arimaFittingMetrics:
    | Model_ArimaFittingMetrics
    | undefined;
  /**
   * Is arima model fitted with drift or not. It is always false when d
   * is not 1.
   */
  hasDrift:
    | boolean
    | undefined;
  /**
   * The time_series_id value for this time series. It will be one of
   * the unique values from the time_series_id_column specified during
   * ARIMA model training. Only present when time_series_id_column
   * training option was used.
   */
  timeSeriesId: string;
  /**
   * The tuple of time_series_ids identifying this time series. It will
   * be one of the unique tuples of values present in the
   * time_series_id_columns specified during ARIMA model training. Only
   * present when time_series_id_columns training option was used and
   * the order of values here are same as the order of
   * time_series_id_columns.
   */
  timeSeriesIds: string[];
  /**
   * Seasonal periods. Repeated because multiple periods are supported
   * for one time series.
   */
  seasonalPeriods: Model_SeasonalPeriod_SeasonalPeriodType[];
  /** If true, holiday_effect is a part of time series decomposition result. */
  hasHolidayEffect:
    | boolean
    | undefined;
  /** If true, spikes_and_dips is a part of time series decomposition result. */
  hasSpikesAndDips:
    | boolean
    | undefined;
  /** If true, step_changes is a part of time series decomposition result. */
  hasStepChanges: boolean | undefined;
}

/** Model evaluation metrics for dimensionality reduction models. */
export interface Model_DimensionalityReductionMetrics {
  /**
   * Total percentage of variance explained by the selected principal
   * components.
   */
  totalExplainedVarianceRatio: number | undefined;
}

/**
 * Evaluation metrics of a model. These are either computed on all training
 * data or just the eval data based on whether eval data was used during
 * training. These are not present for imported models.
 */
export interface Model_EvaluationMetrics {
  /**
   * Populated for regression models and explicit feedback type matrix
   * factorization models.
   */
  regressionMetrics?:
    | Model_RegressionMetrics
    | undefined;
  /** Populated for binary classification/classifier models. */
  binaryClassificationMetrics?:
    | Model_BinaryClassificationMetrics
    | undefined;
  /** Populated for multi-class classification/classifier models. */
  multiClassClassificationMetrics?:
    | Model_MultiClassClassificationMetrics
    | undefined;
  /** Populated for clustering models. */
  clusteringMetrics?:
    | Model_ClusteringMetrics
    | undefined;
  /** Populated for implicit feedback type matrix factorization models. */
  rankingMetrics?:
    | Model_RankingMetrics
    | undefined;
  /** Populated for ARIMA models. */
  arimaForecastingMetrics?:
    | Model_ArimaForecastingMetrics
    | undefined;
  /**
   * Evaluation metrics when the model is a dimensionality reduction model,
   * which currently includes PCA.
   */
  dimensionalityReductionMetrics?: Model_DimensionalityReductionMetrics | undefined;
}

/**
 * Data split result. This contains references to the training and evaluation
 * data tables that were used to train the model.
 */
export interface Model_DataSplitResult {
  /** Table reference of the training data after split. */
  trainingTable:
    | TableReference
    | undefined;
  /** Table reference of the evaluation data after split. */
  evaluationTable:
    | TableReference
    | undefined;
  /** Table reference of the test data after split. */
  testTable: TableReference | undefined;
}

/** Arima order, can be used for both non-seasonal and seasonal parts. */
export interface Model_ArimaOrder {
  /** Order of the autoregressive part. */
  p:
    | Long
    | undefined;
  /** Order of the differencing part. */
  d:
    | Long
    | undefined;
  /** Order of the moving-average part. */
  q: Long | undefined;
}

/** ARIMA model fitting metrics. */
export interface Model_ArimaFittingMetrics {
  /** Log-likelihood. */
  logLikelihood:
    | number
    | undefined;
  /** AIC. */
  aic:
    | number
    | undefined;
  /** Variance. */
  variance: number | undefined;
}

/**
 * Global explanations containing the top most important features
 * after training.
 */
export interface Model_GlobalExplanation {
  /**
   * A list of the top global explanations. Sorted by absolute value of
   * attribution in descending order.
   */
  explanations: Model_GlobalExplanation_Explanation[];
  /**
   * Class label for this set of global explanations. Will be empty/null for
   * binary logistic and linear regression models. Sorted alphabetically in
   * descending order.
   */
  classLabel: string;
}

/** Explanation for a single feature. */
export interface Model_GlobalExplanation_Explanation {
  /**
   * The full feature name. For non-numerical features, will be formatted
   * like `<column_name>.<encoded_feature_name>`. Overall size of feature
   * name will always be truncated to first 120 characters.
   */
  featureName: string;
  /** Attribution of feature. */
  attribution: number | undefined;
}

/** Encoding methods for categorical features. */
export interface Model_CategoryEncodingMethod {
}

/** Supported encoding methods for categorical features. */
export enum Model_CategoryEncodingMethod_EncodingMethod {
  /** ENCODING_METHOD_UNSPECIFIED - Unspecified encoding method. */
  ENCODING_METHOD_UNSPECIFIED = 0,
  /** ONE_HOT_ENCODING - Applies one-hot encoding. */
  ONE_HOT_ENCODING = 1,
  /** LABEL_ENCODING - Applies label encoding. */
  LABEL_ENCODING = 2,
  /** DUMMY_ENCODING - Applies dummy encoding. */
  DUMMY_ENCODING = 3,
  UNRECOGNIZED = -1,
}

export function model_CategoryEncodingMethod_EncodingMethodFromJSON(
  object: any,
): Model_CategoryEncodingMethod_EncodingMethod {
  switch (object) {
    case 0:
    case "ENCODING_METHOD_UNSPECIFIED":
      return Model_CategoryEncodingMethod_EncodingMethod.ENCODING_METHOD_UNSPECIFIED;
    case 1:
    case "ONE_HOT_ENCODING":
      return Model_CategoryEncodingMethod_EncodingMethod.ONE_HOT_ENCODING;
    case 2:
    case "LABEL_ENCODING":
      return Model_CategoryEncodingMethod_EncodingMethod.LABEL_ENCODING;
    case 3:
    case "DUMMY_ENCODING":
      return Model_CategoryEncodingMethod_EncodingMethod.DUMMY_ENCODING;
    case -1:
    case "UNRECOGNIZED":
    default:
      return Model_CategoryEncodingMethod_EncodingMethod.UNRECOGNIZED;
  }
}

export function model_CategoryEncodingMethod_EncodingMethodToJSON(
  object: Model_CategoryEncodingMethod_EncodingMethod,
): string {
  switch (object) {
    case Model_CategoryEncodingMethod_EncodingMethod.ENCODING_METHOD_UNSPECIFIED:
      return "ENCODING_METHOD_UNSPECIFIED";
    case Model_CategoryEncodingMethod_EncodingMethod.ONE_HOT_ENCODING:
      return "ONE_HOT_ENCODING";
    case Model_CategoryEncodingMethod_EncodingMethod.LABEL_ENCODING:
      return "LABEL_ENCODING";
    case Model_CategoryEncodingMethod_EncodingMethod.DUMMY_ENCODING:
      return "DUMMY_ENCODING";
    case Model_CategoryEncodingMethod_EncodingMethod.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/** PCA solver options. */
export interface Model_PcaSolverOptionEnums {
}

/** Enums for supported PCA solvers. */
export enum Model_PcaSolverOptionEnums_PcaSolver {
  /** UNSPECIFIED - Default value. */
  UNSPECIFIED = 0,
  /** FULL - Full eigen-decoposition. */
  FULL = 1,
  /** RANDOMIZED - Randomized SVD. */
  RANDOMIZED = 2,
  /** AUTO - Auto. */
  AUTO = 3,
  UNRECOGNIZED = -1,
}

export function model_PcaSolverOptionEnums_PcaSolverFromJSON(object: any): Model_PcaSolverOptionEnums_PcaSolver {
  switch (object) {
    case 0:
    case "UNSPECIFIED":
      return Model_PcaSolverOptionEnums_PcaSolver.UNSPECIFIED;
    case 1:
    case "FULL":
      return Model_PcaSolverOptionEnums_PcaSolver.FULL;
    case 2:
    case "RANDOMIZED":
      return Model_PcaSolverOptionEnums_PcaSolver.RANDOMIZED;
    case 3:
    case "AUTO":
      return Model_PcaSolverOptionEnums_PcaSolver.AUTO;
    case -1:
    case "UNRECOGNIZED":
    default:
      return Model_PcaSolverOptionEnums_PcaSolver.UNRECOGNIZED;
  }
}

export function model_PcaSolverOptionEnums_PcaSolverToJSON(object: Model_PcaSolverOptionEnums_PcaSolver): string {
  switch (object) {
    case Model_PcaSolverOptionEnums_PcaSolver.UNSPECIFIED:
      return "UNSPECIFIED";
    case Model_PcaSolverOptionEnums_PcaSolver.FULL:
      return "FULL";
    case Model_PcaSolverOptionEnums_PcaSolver.RANDOMIZED:
      return "RANDOMIZED";
    case Model_PcaSolverOptionEnums_PcaSolver.AUTO:
      return "AUTO";
    case Model_PcaSolverOptionEnums_PcaSolver.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/** Model registry options. */
export interface Model_ModelRegistryOptionEnums {
}

/** Enums for supported model registries. */
export enum Model_ModelRegistryOptionEnums_ModelRegistry {
  /** MODEL_REGISTRY_UNSPECIFIED - Default value. */
  MODEL_REGISTRY_UNSPECIFIED = 0,
  /** VERTEX_AI - Vertex AI. */
  VERTEX_AI = 1,
  UNRECOGNIZED = -1,
}

export function model_ModelRegistryOptionEnums_ModelRegistryFromJSON(
  object: any,
): Model_ModelRegistryOptionEnums_ModelRegistry {
  switch (object) {
    case 0:
    case "MODEL_REGISTRY_UNSPECIFIED":
      return Model_ModelRegistryOptionEnums_ModelRegistry.MODEL_REGISTRY_UNSPECIFIED;
    case 1:
    case "VERTEX_AI":
      return Model_ModelRegistryOptionEnums_ModelRegistry.VERTEX_AI;
    case -1:
    case "UNRECOGNIZED":
    default:
      return Model_ModelRegistryOptionEnums_ModelRegistry.UNRECOGNIZED;
  }
}

export function model_ModelRegistryOptionEnums_ModelRegistryToJSON(
  object: Model_ModelRegistryOptionEnums_ModelRegistry,
): string {
  switch (object) {
    case Model_ModelRegistryOptionEnums_ModelRegistry.MODEL_REGISTRY_UNSPECIFIED:
      return "MODEL_REGISTRY_UNSPECIFIED";
    case Model_ModelRegistryOptionEnums_ModelRegistry.VERTEX_AI:
      return "VERTEX_AI";
    case Model_ModelRegistryOptionEnums_ModelRegistry.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/** Information about a single training query run for the model. */
export interface Model_TrainingRun {
  /**
   * Output only. Options that were used for this training run, includes
   * user specified and default options that were used.
   */
  trainingOptions:
    | Model_TrainingRun_TrainingOptions
    | undefined;
  /** Output only. The start time of this training run. */
  startTime:
    | Date
    | undefined;
  /**
   * Output only. Output of each iteration run, results.size() <=
   * max_iterations.
   */
  results: Model_TrainingRun_IterationResult[];
  /**
   * Output only. The evaluation metrics over training/eval data that were
   * computed at the end of training.
   */
  evaluationMetrics:
    | Model_EvaluationMetrics
    | undefined;
  /**
   * Output only. Data split result of the training run. Only set when the
   * input data is actually split.
   */
  dataSplitResult:
    | Model_DataSplitResult
    | undefined;
  /**
   * Output only. Global explanation contains the explanation of top features
   * on the model level. Applies to both regression and classification models.
   */
  modelLevelGlobalExplanation:
    | Model_GlobalExplanation
    | undefined;
  /**
   * Output only. Global explanation contains the explanation of top features
   * on the class level. Applies to classification models only.
   */
  classLevelGlobalExplanations: Model_GlobalExplanation[];
  /**
   * The model id in the [Vertex AI Model
   * Registry](https://cloud.google.com/vertex-ai/docs/model-registry/introduction)
   * for this training run.
   */
  vertexAiModelId: string;
  /**
   * Output only. The model version in the [Vertex AI Model
   * Registry](https://cloud.google.com/vertex-ai/docs/model-registry/introduction)
   * for this training run.
   */
  vertexAiModelVersion: string;
}

/** Options used in model training. */
export interface Model_TrainingRun_TrainingOptions {
  /**
   * The maximum number of iterations in training. Used only for iterative
   * training algorithms.
   */
  maxIterations: Long;
  /** Type of loss function used during training run. */
  lossType: Model_LossType;
  /** Learning rate in training. Used only for iterative training algorithms. */
  learnRate: number;
  /** L1 regularization coefficient. */
  l1Regularization:
    | number
    | undefined;
  /** L2 regularization coefficient. */
  l2Regularization:
    | number
    | undefined;
  /**
   * When early_stop is true, stops training when accuracy improvement is
   * less than 'min_relative_progress'. Used only for iterative training
   * algorithms.
   */
  minRelativeProgress:
    | number
    | undefined;
  /** Whether to train a model from the last checkpoint. */
  warmStart:
    | boolean
    | undefined;
  /**
   * Whether to stop early when the loss doesn't improve significantly
   * any more (compared to min_relative_progress). Used only for iterative
   * training algorithms.
   */
  earlyStop:
    | boolean
    | undefined;
  /** Name of input label columns in training data. */
  inputLabelColumns: string[];
  /** The data split type for training and evaluation, e.g. RANDOM. */
  dataSplitMethod: Model_DataSplitMethod;
  /**
   * The fraction of evaluation data over the whole input data. The rest
   * of data will be used as training data. The format should be double.
   * Accurate to two decimal places.
   * Default value is 0.2.
   */
  dataSplitEvalFraction: number;
  /**
   * The column to split data with. This column won't be used as a
   * feature.
   * 1. When data_split_method is CUSTOM, the corresponding column should
   * be boolean. The rows with true value tag are eval data, and the false
   * are training data.
   * 2. When data_split_method is SEQ, the first DATA_SPLIT_EVAL_FRACTION
   * rows (from smallest to largest) in the corresponding column are used
   * as training data, and the rest are eval data. It respects the order
   * in Orderable data types:
   * https://cloud.google.com/bigquery/docs/reference/standard-sql/data-types#data-type-properties
   */
  dataSplitColumn: string;
  /** The strategy to determine learn rate for the current iteration. */
  learnRateStrategy: Model_LearnRateStrategy;
  /**
   * Specifies the initial learning rate for the line search learn rate
   * strategy.
   */
  initialLearnRate: number;
  /**
   * Weights associated with each label class, for rebalancing the
   * training data. Only applicable for classification models.
   */
  labelClassWeights: { [key: string]: number };
  /** User column specified for matrix factorization models. */
  userColumn: string;
  /** Item column specified for matrix factorization models. */
  itemColumn: string;
  /** Distance type for clustering models. */
  distanceType: Model_DistanceType;
  /** Number of clusters for clustering models. */
  numClusters: Long;
  /**
   * Google Cloud Storage URI from which the model was imported. Only
   * applicable for imported models.
   */
  modelUri: string;
  /** Optimization strategy for training linear regression models. */
  optimizationStrategy: Model_OptimizationStrategy;
  /** Hidden units for dnn models. */
  hiddenUnits: Long[];
  /** Batch size for dnn models. */
  batchSize: Long;
  /** Dropout probability for dnn models. */
  dropout:
    | number
    | undefined;
  /** Maximum depth of a tree for boosted tree models. */
  maxTreeDepth: Long;
  /**
   * Subsample fraction of the training data to grow tree to prevent
   * overfitting for boosted tree models.
   */
  subsample: number;
  /** Minimum split loss for boosted tree models. */
  minSplitLoss:
    | number
    | undefined;
  /** Booster type for boosted tree models. */
  boosterType: Model_BoostedTreeOptionEnums_BoosterType;
  /**
   * Number of parallel trees constructed during each iteration for boosted
   * tree models.
   */
  numParallelTree:
    | Long
    | undefined;
  /**
   * Type of normalization algorithm for boosted tree models using
   * dart booster.
   */
  dartNormalizeType: Model_BoostedTreeOptionEnums_DartNormalizeType;
  /** Tree construction algorithm for boosted tree models. */
  treeMethod: Model_BoostedTreeOptionEnums_TreeMethod;
  /**
   * Minimum sum of instance weight needed in a child for boosted tree
   * models.
   */
  minTreeChildWeight:
    | Long
    | undefined;
  /**
   * Subsample ratio of columns when constructing each tree for boosted tree
   * models.
   */
  colsampleBytree:
    | number
    | undefined;
  /** Subsample ratio of columns for each level for boosted tree models. */
  colsampleBylevel:
    | number
    | undefined;
  /**
   * Subsample ratio of columns for each node(split) for boosted tree
   * models.
   */
  colsampleBynode:
    | number
    | undefined;
  /** Num factors specified for matrix factorization models. */
  numFactors: Long;
  /**
   * Feedback type that specifies which algorithm to run for matrix
   * factorization.
   */
  feedbackType: Model_FeedbackType;
  /**
   * Hyperparameter for matrix factoration when implicit feedback type is
   * specified.
   */
  walsAlpha:
    | number
    | undefined;
  /** The method used to initialize the centroids for kmeans algorithm. */
  kmeansInitializationMethod: Model_KmeansEnums_KmeansInitializationMethod;
  /**
   * The column used to provide the initial centroids for kmeans algorithm
   * when kmeans_initialization_method is CUSTOM.
   */
  kmeansInitializationColumn: string;
  /** Column to be designated as time series timestamp for ARIMA model. */
  timeSeriesTimestampColumn: string;
  /** Column to be designated as time series data for ARIMA model. */
  timeSeriesDataColumn: string;
  /** Whether to enable auto ARIMA or not. */
  autoArima:
    | boolean
    | undefined;
  /**
   * A specification of the non-seasonal part of the ARIMA model: the three
   * components (p, d, q) are the AR order, the degree of differencing, and
   * the MA order.
   */
  nonSeasonalOrder:
    | Model_ArimaOrder
    | undefined;
  /** The data frequency of a time series. */
  dataFrequency: Model_DataFrequency;
  /**
   * Whether or not p-value test should be computed for this model. Only
   * available for linear and logistic regression models.
   */
  calculatePValues:
    | boolean
    | undefined;
  /** Include drift when fitting an ARIMA model. */
  includeDrift:
    | boolean
    | undefined;
  /**
   * The geographical region based on which the holidays are considered in
   * time series modeling. If a valid value is specified, then holiday
   * effects modeling is enabled.
   */
  holidayRegion: Model_HolidayRegion;
  /** A list of geographical regions that are used for time series modeling. */
  holidayRegions: Model_HolidayRegion[];
  /** The time series id column that was used during ARIMA model training. */
  timeSeriesIdColumn: string;
  /** The time series id columns that were used during ARIMA model training. */
  timeSeriesIdColumns: string[];
  /** The number of periods ahead that need to be forecasted. */
  horizon: Long;
  /** The max value of the sum of non-seasonal p and q. */
  autoArimaMaxOrder: Long;
  /** The min value of the sum of non-seasonal p and q. */
  autoArimaMinOrder: Long;
  /** Number of trials to run this hyperparameter tuning job. */
  numTrials: Long;
  /** Maximum number of trials to run in parallel. */
  maxParallelTrials: Long;
  /** The target evaluation metrics to optimize the hyperparameters for. */
  hparamTuningObjectives: Model_HparamTuningEnums_HparamTuningObjective[];
  /** If true, perform decompose time series and save the results. */
  decomposeTimeSeries:
    | boolean
    | undefined;
  /** If true, clean spikes and dips in the input time series. */
  cleanSpikesAndDips:
    | boolean
    | undefined;
  /**
   * If true, detect step changes and make data adjustment in the input time
   * series.
   */
  adjustStepChanges:
    | boolean
    | undefined;
  /** If true, enable global explanation during training. */
  enableGlobalExplain:
    | boolean
    | undefined;
  /** Number of paths for the sampled Shapley explain method. */
  sampledShapleyNumPaths: Long;
  /** Number of integral steps for the integrated gradients explain method. */
  integratedGradientsNumSteps: Long;
  /** Categorical feature encoding method. */
  categoryEncodingMethod: Model_CategoryEncodingMethod_EncodingMethod;
  /**
   * Based on the selected TF version, the corresponding docker image is
   * used to train external models.
   */
  tfVersion: string;
  /**
   * Enums for color space, used for processing images in Object Table.
   * See more details at
   * https://www.tensorflow.org/io/tutorials/colorspace.
   */
  colorSpace: Model_ColorSpace;
  /**
   * Name of the instance weight column for training data.
   * This column isn't be used as a feature.
   */
  instanceWeightColumn: string;
  /**
   * Smoothing window size for the trend component. When a positive value is
   * specified, a center moving average smoothing is applied on the history
   * trend. When the smoothing window is out of the boundary at the
   * beginning or the end of the trend, the first element or the last
   * element is padded to fill the smoothing window before the average is
   * applied.
   */
  trendSmoothingWindowSize: Long;
  /**
   * The fraction of the interpolated length of the time series that's used
   * to model the time series trend component. All of the time points of the
   * time series are used to model the non-trend component. This training
   * option accelerates modeling training without sacrificing much
   * forecasting accuracy. You can use this option with
   * `minTimeSeriesLength` but not with `maxTimeSeriesLength`.
   */
  timeSeriesLengthFraction: number;
  /**
   * The minimum number of time points in a time series that are used in
   * modeling the trend component of the time series. If you use this option
   * you must also set the `timeSeriesLengthFraction` option. This training
   * option ensures that enough time points are available when you use
   * `timeSeriesLengthFraction` in trend modeling. This is particularly
   * important when forecasting multiple time series in a single query using
   * `timeSeriesIdColumn`. If the total number of time points is less than
   * the `minTimeSeriesLength` value, then the query uses all available time
   * points.
   */
  minTimeSeriesLength: Long;
  /**
   * The maximum number of time points in a time series that can be used in
   * modeling the trend component of the time series. Don't use this option
   * with the `timeSeriesLengthFraction` or `minTimeSeriesLength` options.
   */
  maxTimeSeriesLength: Long;
  /** User-selected XGBoost versions for training of XGBoost models. */
  xgboostVersion: string;
  /**
   * Whether to use approximate feature contribution method in XGBoost model
   * explanation for global explain.
   */
  approxGlobalFeatureContrib:
    | boolean
    | undefined;
  /** Whether the model should include intercept during model training. */
  fitIntercept:
    | boolean
    | undefined;
  /**
   * Number of principal components to keep in the PCA model. Must be <= the
   * number of features.
   */
  numPrincipalComponents: Long;
  /**
   * The minimum ratio of cumulative explained variance that needs to be
   * given by the PCA model.
   */
  pcaExplainedVarianceRatio: number;
  /**
   * If true, scale the feature values by dividing the feature standard
   * deviation. Currently only apply to PCA.
   */
  scaleFeatures:
    | boolean
    | undefined;
  /** The solver for PCA. */
  pcaSolver: Model_PcaSolverOptionEnums_PcaSolver;
  /**
   * Whether to calculate class weights automatically based on the
   * popularity of each label.
   */
  autoClassWeights:
    | boolean
    | undefined;
  /** Activation function of the neural nets. */
  activationFn: string;
  /** Optimizer used for training the neural nets. */
  optimizer: string;
  /** Budget in hours for AutoML training. */
  budgetHours: number;
  /** Whether to standardize numerical features. Default to true. */
  standardizeFeatures:
    | boolean
    | undefined;
  /** L1 regularization coefficient to activations. */
  l1RegActivation: number;
  /** The model registry. */
  modelRegistry: Model_ModelRegistryOptionEnums_ModelRegistry;
  /**
   * The version aliases to apply in Vertex AI model registry. Always
   * overwrite if the version aliases exists in a existing model.
   */
  vertexAiModelVersionAliases: string[];
}

export interface Model_TrainingRun_TrainingOptions_LabelClassWeightsEntry {
  key: string;
  value: number;
}

/** Information about a single iteration of the training run. */
export interface Model_TrainingRun_IterationResult {
  /** Index of the iteration, 0 based. */
  index:
    | number
    | undefined;
  /** Time taken to run the iteration in milliseconds. */
  durationMs:
    | Long
    | undefined;
  /** Loss computed on the training data at the end of iteration. */
  trainingLoss:
    | number
    | undefined;
  /** Loss computed on the eval data at the end of iteration. */
  evalLoss:
    | number
    | undefined;
  /** Learn rate used for this iteration. */
  learnRate: number;
  /** Information about top clusters for clustering models. */
  clusterInfos: Model_TrainingRun_IterationResult_ClusterInfo[];
  /** Arima result. */
  arimaResult:
    | Model_TrainingRun_IterationResult_ArimaResult
    | undefined;
  /** The information of the principal components. */
  principalComponentInfos: Model_TrainingRun_IterationResult_PrincipalComponentInfo[];
}

/** Information about a single cluster for clustering model. */
export interface Model_TrainingRun_IterationResult_ClusterInfo {
  /** Centroid id. */
  centroidId: Long;
  /**
   * Cluster radius, the average distance from centroid
   * to each point assigned to the cluster.
   */
  clusterRadius:
    | number
    | undefined;
  /** Cluster size, the total number of points assigned to the cluster. */
  clusterSize: Long | undefined;
}

/**
 * (Auto-)arima fitting result. Wrap everything in ArimaResult for easier
 * refactoring if we want to use model-specific iteration results.
 */
export interface Model_TrainingRun_IterationResult_ArimaResult {
  /**
   * This message is repeated because there are multiple arima models
   * fitted in auto-arima. For non-auto-arima model, its size is one.
   */
  arimaModelInfo: Model_TrainingRun_IterationResult_ArimaResult_ArimaModelInfo[];
  /**
   * Seasonal periods. Repeated because multiple periods are supported for
   * one time series.
   */
  seasonalPeriods: Model_SeasonalPeriod_SeasonalPeriodType[];
}

/** Arima coefficients. */
export interface Model_TrainingRun_IterationResult_ArimaResult_ArimaCoefficients {
  /** Auto-regressive coefficients, an array of double. */
  autoRegressiveCoefficients: number[];
  /** Moving-average coefficients, an array of double. */
  movingAverageCoefficients: number[];
  /** Intercept coefficient, just a double not an array. */
  interceptCoefficient: number | undefined;
}

/** Arima model information. */
export interface Model_TrainingRun_IterationResult_ArimaResult_ArimaModelInfo {
  /** Non-seasonal order. */
  nonSeasonalOrder:
    | Model_ArimaOrder
    | undefined;
  /** Arima coefficients. */
  arimaCoefficients:
    | Model_TrainingRun_IterationResult_ArimaResult_ArimaCoefficients
    | undefined;
  /** Arima fitting metrics. */
  arimaFittingMetrics:
    | Model_ArimaFittingMetrics
    | undefined;
  /**
   * Whether Arima model fitted with drift or not. It is always false
   * when d is not 1.
   */
  hasDrift:
    | boolean
    | undefined;
  /**
   * The time_series_id value for this time series. It will be one of
   * the unique values from the time_series_id_column specified during
   * ARIMA model training. Only present when time_series_id_column
   * training option was used.
   */
  timeSeriesId: string;
  /**
   * The tuple of time_series_ids identifying this time series. It will
   * be one of the unique tuples of values present in the
   * time_series_id_columns specified during ARIMA model training. Only
   * present when time_series_id_columns training option was used and
   * the order of values here are same as the order of
   * time_series_id_columns.
   */
  timeSeriesIds: string[];
  /**
   * Seasonal periods. Repeated because multiple periods are supported
   * for one time series.
   */
  seasonalPeriods: Model_SeasonalPeriod_SeasonalPeriodType[];
  /**
   * If true, holiday_effect is a part of time series decomposition
   * result.
   */
  hasHolidayEffect:
    | boolean
    | undefined;
  /**
   * If true, spikes_and_dips is a part of time series decomposition
   * result.
   */
  hasSpikesAndDips:
    | boolean
    | undefined;
  /**
   * If true, step_changes is a part of time series decomposition
   * result.
   */
  hasStepChanges: boolean | undefined;
}

/**
 * Principal component infos, used only for eigen decomposition based
 * models, e.g., PCA. Ordered by explained_variance in the descending
 * order.
 */
export interface Model_TrainingRun_IterationResult_PrincipalComponentInfo {
  /** Id of the principal component. */
  principalComponentId:
    | Long
    | undefined;
  /**
   * Explained variance by this principal component, which is simply the
   * eigenvalue.
   */
  explainedVariance:
    | number
    | undefined;
  /** Explained_variance over the total explained variance. */
  explainedVarianceRatio:
    | number
    | undefined;
  /**
   * The explained_variance is pre-ordered in the descending order to
   * compute the cumulative explained variance ratio.
   */
  cumulativeExplainedVarianceRatio: number | undefined;
}

/** Search space for a double hyperparameter. */
export interface Model_DoubleHparamSearchSpace {
  /** Range of the double hyperparameter. */
  range?:
    | Model_DoubleHparamSearchSpace_DoubleRange
    | undefined;
  /** Candidates of the double hyperparameter. */
  candidates?: Model_DoubleHparamSearchSpace_DoubleCandidates | undefined;
}

/** Range of a double hyperparameter. */
export interface Model_DoubleHparamSearchSpace_DoubleRange {
  /** Min value of the double parameter. */
  min:
    | number
    | undefined;
  /** Max value of the double parameter. */
  max: number | undefined;
}

/** Discrete candidates of a double hyperparameter. */
export interface Model_DoubleHparamSearchSpace_DoubleCandidates {
  /** Candidates for the double parameter in increasing order. */
  candidates: number[];
}

/** Search space for an int hyperparameter. */
export interface Model_IntHparamSearchSpace {
  /** Range of the int hyperparameter. */
  range?:
    | Model_IntHparamSearchSpace_IntRange
    | undefined;
  /** Candidates of the int hyperparameter. */
  candidates?: Model_IntHparamSearchSpace_IntCandidates | undefined;
}

/** Range of an int hyperparameter. */
export interface Model_IntHparamSearchSpace_IntRange {
  /** Min value of the int parameter. */
  min:
    | Long
    | undefined;
  /** Max value of the int parameter. */
  max: Long | undefined;
}

/** Discrete candidates of an int hyperparameter. */
export interface Model_IntHparamSearchSpace_IntCandidates {
  /** Candidates for the int parameter in increasing order. */
  candidates: Long[];
}

/** Search space for string and enum. */
export interface Model_StringHparamSearchSpace {
  /** Canididates for the string or enum parameter in lower case. */
  candidates: string[];
}

/** Search space for int array. */
export interface Model_IntArrayHparamSearchSpace {
  /** Candidates for the int array parameter. */
  candidates: Model_IntArrayHparamSearchSpace_IntArray[];
}

/** An array of int. */
export interface Model_IntArrayHparamSearchSpace_IntArray {
  /** Elements in the int array. */
  elements: Long[];
}

/**
 * Hyperparameter search spaces.
 * These should be a subset of training_options.
 */
export interface Model_HparamSearchSpaces {
  /** Learning rate of training jobs. */
  learnRate:
    | Model_DoubleHparamSearchSpace
    | undefined;
  /** L1 regularization coefficient. */
  l1Reg:
    | Model_DoubleHparamSearchSpace
    | undefined;
  /** L2 regularization coefficient. */
  l2Reg:
    | Model_DoubleHparamSearchSpace
    | undefined;
  /** Number of clusters for k-means. */
  numClusters:
    | Model_IntHparamSearchSpace
    | undefined;
  /** Number of latent factors to train on. */
  numFactors:
    | Model_IntHparamSearchSpace
    | undefined;
  /** Hidden units for neural network models. */
  hiddenUnits:
    | Model_IntArrayHparamSearchSpace
    | undefined;
  /** Mini batch sample size. */
  batchSize:
    | Model_IntHparamSearchSpace
    | undefined;
  /**
   * Dropout probability for dnn model training and boosted tree models
   * using dart booster.
   */
  dropout:
    | Model_DoubleHparamSearchSpace
    | undefined;
  /** Maximum depth of a tree for boosted tree models. */
  maxTreeDepth:
    | Model_IntHparamSearchSpace
    | undefined;
  /**
   * Subsample the training data to grow tree to prevent overfitting for
   * boosted tree models.
   */
  subsample:
    | Model_DoubleHparamSearchSpace
    | undefined;
  /** Minimum split loss for boosted tree models. */
  minSplitLoss:
    | Model_DoubleHparamSearchSpace
    | undefined;
  /**
   * Hyperparameter for matrix factoration when implicit feedback type is
   * specified.
   */
  walsAlpha:
    | Model_DoubleHparamSearchSpace
    | undefined;
  /** Booster type for boosted tree models. */
  boosterType:
    | Model_StringHparamSearchSpace
    | undefined;
  /** Number of parallel trees for boosted tree models. */
  numParallelTree:
    | Model_IntHparamSearchSpace
    | undefined;
  /** Dart normalization type for boosted tree models. */
  dartNormalizeType:
    | Model_StringHparamSearchSpace
    | undefined;
  /** Tree construction algorithm for boosted tree models. */
  treeMethod:
    | Model_StringHparamSearchSpace
    | undefined;
  /** Minimum sum of instance weight needed in a child for boosted tree models. */
  minTreeChildWeight:
    | Model_IntHparamSearchSpace
    | undefined;
  /**
   * Subsample ratio of columns when constructing each tree for boosted tree
   * models.
   */
  colsampleBytree:
    | Model_DoubleHparamSearchSpace
    | undefined;
  /** Subsample ratio of columns for each level for boosted tree models. */
  colsampleBylevel:
    | Model_DoubleHparamSearchSpace
    | undefined;
  /** Subsample ratio of columns for each node(split) for boosted tree models. */
  colsampleBynode:
    | Model_DoubleHparamSearchSpace
    | undefined;
  /** Activation functions of neural network models. */
  activationFn:
    | Model_StringHparamSearchSpace
    | undefined;
  /** Optimizer of TF models. */
  optimizer: Model_StringHparamSearchSpace | undefined;
}

/**
 * Training info of a trial in [hyperparameter
 * tuning](https://cloud.google.com/bigquery-ml/docs/reference/standard-sql/bigqueryml-syntax-hp-tuning-overview)
 * models.
 */
export interface Model_HparamTuningTrial {
  /** 1-based index of the trial. */
  trialId: Long;
  /** Starting time of the trial. */
  startTimeMs: Long;
  /** Ending time of the trial. */
  endTimeMs: Long;
  /** The hyperprameters selected for this trial. */
  hparams:
    | Model_TrainingRun_TrainingOptions
    | undefined;
  /**
   * Evaluation metrics of this trial calculated on the test data.
   * Empty in Job API.
   */
  evaluationMetrics:
    | Model_EvaluationMetrics
    | undefined;
  /** The status of the trial. */
  status: Model_HparamTuningTrial_TrialStatus;
  /** Error message for FAILED and INFEASIBLE trial. */
  errorMessage: string;
  /** Loss computed on the training data at the end of trial. */
  trainingLoss:
    | number
    | undefined;
  /** Loss computed on the eval data at the end of trial. */
  evalLoss:
    | number
    | undefined;
  /**
   * Hyperparameter tuning evaluation metrics of this trial calculated on the
   * eval data. Unlike evaluation_metrics, only the fields corresponding to
   * the hparam_tuning_objectives are set.
   */
  hparamTuningEvaluationMetrics: Model_EvaluationMetrics | undefined;
}

/** Current status of the trial. */
export enum Model_HparamTuningTrial_TrialStatus {
  /** TRIAL_STATUS_UNSPECIFIED - Default value. */
  TRIAL_STATUS_UNSPECIFIED = 0,
  /** NOT_STARTED - Scheduled but not started. */
  NOT_STARTED = 1,
  /** RUNNING - Running state. */
  RUNNING = 2,
  /** SUCCEEDED - The trial succeeded. */
  SUCCEEDED = 3,
  /** FAILED - The trial failed. */
  FAILED = 4,
  /** INFEASIBLE - The trial is infeasible due to the invalid params. */
  INFEASIBLE = 5,
  /** STOPPED_EARLY - Trial stopped early because it's not promising. */
  STOPPED_EARLY = 6,
  UNRECOGNIZED = -1,
}

export function model_HparamTuningTrial_TrialStatusFromJSON(object: any): Model_HparamTuningTrial_TrialStatus {
  switch (object) {
    case 0:
    case "TRIAL_STATUS_UNSPECIFIED":
      return Model_HparamTuningTrial_TrialStatus.TRIAL_STATUS_UNSPECIFIED;
    case 1:
    case "NOT_STARTED":
      return Model_HparamTuningTrial_TrialStatus.NOT_STARTED;
    case 2:
    case "RUNNING":
      return Model_HparamTuningTrial_TrialStatus.RUNNING;
    case 3:
    case "SUCCEEDED":
      return Model_HparamTuningTrial_TrialStatus.SUCCEEDED;
    case 4:
    case "FAILED":
      return Model_HparamTuningTrial_TrialStatus.FAILED;
    case 5:
    case "INFEASIBLE":
      return Model_HparamTuningTrial_TrialStatus.INFEASIBLE;
    case 6:
    case "STOPPED_EARLY":
      return Model_HparamTuningTrial_TrialStatus.STOPPED_EARLY;
    case -1:
    case "UNRECOGNIZED":
    default:
      return Model_HparamTuningTrial_TrialStatus.UNRECOGNIZED;
  }
}

export function model_HparamTuningTrial_TrialStatusToJSON(object: Model_HparamTuningTrial_TrialStatus): string {
  switch (object) {
    case Model_HparamTuningTrial_TrialStatus.TRIAL_STATUS_UNSPECIFIED:
      return "TRIAL_STATUS_UNSPECIFIED";
    case Model_HparamTuningTrial_TrialStatus.NOT_STARTED:
      return "NOT_STARTED";
    case Model_HparamTuningTrial_TrialStatus.RUNNING:
      return "RUNNING";
    case Model_HparamTuningTrial_TrialStatus.SUCCEEDED:
      return "SUCCEEDED";
    case Model_HparamTuningTrial_TrialStatus.FAILED:
      return "FAILED";
    case Model_HparamTuningTrial_TrialStatus.INFEASIBLE:
      return "INFEASIBLE";
    case Model_HparamTuningTrial_TrialStatus.STOPPED_EARLY:
      return "STOPPED_EARLY";
    case Model_HparamTuningTrial_TrialStatus.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

export interface Model_LabelsEntry {
  key: string;
  value: string;
}

/** Request format for getting information about a BigQuery ML model. */
export interface GetModelRequest {
  /** Required. Project ID of the requested model. */
  projectId: string;
  /** Required. Dataset ID of the requested model. */
  datasetId: string;
  /** Required. Model ID of the requested model. */
  modelId: string;
}

export interface PatchModelRequest {
  /** Required. Project ID of the model to patch. */
  projectId: string;
  /** Required. Dataset ID of the model to patch. */
  datasetId: string;
  /** Required. Model ID of the model to patch. */
  modelId: string;
  /**
   * Required. Patched model.
   * Follows RFC5789 patch semantics. Missing fields are not updated.
   * To clear a field, explicitly set to default value.
   */
  model: Model | undefined;
}

/** Request format for deleting BigQuery ML models. */
export interface DeleteModelRequest {
  /** Required. Project ID of the model to delete. */
  projectId: string;
  /** Required. Dataset ID of the model to delete. */
  datasetId: string;
  /** Required. Model ID of the model to delete. */
  modelId: string;
}

/** Request format for listing BigQuery ML models. */
export interface ListModelsRequest {
  /** Required. Project ID of the models to list. */
  projectId: string;
  /** Required. Dataset ID of the models to list. */
  datasetId: string;
  /**
   * The maximum number of results to return in a single response page.
   * Leverage the page tokens to iterate through the entire collection.
   */
  maxResults:
    | number
    | undefined;
  /**
   * Page token, returned by a previous call to request the next page of
   * results
   */
  pageToken: string;
}

/** Response format for a single page when listing BigQuery ML models. */
export interface ListModelsResponse {
  /**
   * Models in the requested dataset. Only the following fields are populated:
   * model_reference, model_type, creation_time, last_modified_time and
   * labels.
   */
  models: Model[];
  /** A token to request the next page of results. */
  nextPageToken: string;
}

function createBaseRemoteModelInfo(): RemoteModelInfo {
  return {
    endpoint: undefined,
    remoteServiceType: undefined,
    connection: "",
    maxBatchingRows: Long.ZERO,
    remoteModelVersion: "",
    speechRecognizer: "",
  };
}

export const RemoteModelInfo: MessageFns<RemoteModelInfo> = {
  encode(message: RemoteModelInfo, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.endpoint !== undefined) {
      writer.uint32(10).string(message.endpoint);
    }
    if (message.remoteServiceType !== undefined) {
      writer.uint32(16).int32(message.remoteServiceType);
    }
    if (message.connection !== "") {
      writer.uint32(26).string(message.connection);
    }
    if (!message.maxBatchingRows.equals(Long.ZERO)) {
      writer.uint32(32).int64(message.maxBatchingRows.toString());
    }
    if (message.remoteModelVersion !== "") {
      writer.uint32(42).string(message.remoteModelVersion);
    }
    if (message.speechRecognizer !== "") {
      writer.uint32(58).string(message.speechRecognizer);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): RemoteModelInfo {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseRemoteModelInfo();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.endpoint = reader.string();
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.remoteServiceType = reader.int32() as any;
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.connection = reader.string();
          continue;
        case 4:
          if (tag !== 32) {
            break;
          }

          message.maxBatchingRows = Long.fromString(reader.int64().toString());
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.remoteModelVersion = reader.string();
          continue;
        case 7:
          if (tag !== 58) {
            break;
          }

          message.speechRecognizer = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): RemoteModelInfo {
    return {
      endpoint: isSet(object.endpoint) ? globalThis.String(object.endpoint) : undefined,
      remoteServiceType: isSet(object.remoteServiceType)
        ? remoteModelInfo_RemoteServiceTypeFromJSON(object.remoteServiceType)
        : undefined,
      connection: isSet(object.connection) ? globalThis.String(object.connection) : "",
      maxBatchingRows: isSet(object.maxBatchingRows) ? Long.fromValue(object.maxBatchingRows) : Long.ZERO,
      remoteModelVersion: isSet(object.remoteModelVersion) ? globalThis.String(object.remoteModelVersion) : "",
      speechRecognizer: isSet(object.speechRecognizer) ? globalThis.String(object.speechRecognizer) : "",
    };
  },

  toJSON(message: RemoteModelInfo): unknown {
    const obj: any = {};
    if (message.endpoint !== undefined) {
      obj.endpoint = message.endpoint;
    }
    if (message.remoteServiceType !== undefined) {
      obj.remoteServiceType = remoteModelInfo_RemoteServiceTypeToJSON(message.remoteServiceType);
    }
    if (message.connection !== "") {
      obj.connection = message.connection;
    }
    if (!message.maxBatchingRows.equals(Long.ZERO)) {
      obj.maxBatchingRows = (message.maxBatchingRows || Long.ZERO).toString();
    }
    if (message.remoteModelVersion !== "") {
      obj.remoteModelVersion = message.remoteModelVersion;
    }
    if (message.speechRecognizer !== "") {
      obj.speechRecognizer = message.speechRecognizer;
    }
    return obj;
  },

  create(base?: DeepPartial<RemoteModelInfo>): RemoteModelInfo {
    return RemoteModelInfo.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<RemoteModelInfo>): RemoteModelInfo {
    const message = createBaseRemoteModelInfo();
    message.endpoint = object.endpoint ?? undefined;
    message.remoteServiceType = object.remoteServiceType ?? undefined;
    message.connection = object.connection ?? "";
    message.maxBatchingRows = (object.maxBatchingRows !== undefined && object.maxBatchingRows !== null)
      ? Long.fromValue(object.maxBatchingRows)
      : Long.ZERO;
    message.remoteModelVersion = object.remoteModelVersion ?? "";
    message.speechRecognizer = object.speechRecognizer ?? "";
    return message;
  },
};

function createBaseTransformColumn(): TransformColumn {
  return { name: "", type: undefined, transformSql: "" };
}

export const TransformColumn: MessageFns<TransformColumn> = {
  encode(message: TransformColumn, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    if (message.type !== undefined) {
      StandardSqlDataType.encode(message.type, writer.uint32(18).fork()).join();
    }
    if (message.transformSql !== "") {
      writer.uint32(26).string(message.transformSql);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): TransformColumn {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseTransformColumn();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.type = StandardSqlDataType.decode(reader, reader.uint32());
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.transformSql = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): TransformColumn {
    return {
      name: isSet(object.name) ? globalThis.String(object.name) : "",
      type: isSet(object.type) ? StandardSqlDataType.fromJSON(object.type) : undefined,
      transformSql: isSet(object.transformSql) ? globalThis.String(object.transformSql) : "",
    };
  },

  toJSON(message: TransformColumn): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    if (message.type !== undefined) {
      obj.type = StandardSqlDataType.toJSON(message.type);
    }
    if (message.transformSql !== "") {
      obj.transformSql = message.transformSql;
    }
    return obj;
  },

  create(base?: DeepPartial<TransformColumn>): TransformColumn {
    return TransformColumn.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<TransformColumn>): TransformColumn {
    const message = createBaseTransformColumn();
    message.name = object.name ?? "";
    message.type = (object.type !== undefined && object.type !== null)
      ? StandardSqlDataType.fromPartial(object.type)
      : undefined;
    message.transformSql = object.transformSql ?? "";
    return message;
  },
};

function createBaseModel(): Model {
  return {
    etag: "",
    modelReference: undefined,
    creationTime: Long.ZERO,
    lastModifiedTime: Long.ZERO,
    description: "",
    friendlyName: "",
    labels: {},
    expirationTime: Long.ZERO,
    location: "",
    encryptionConfiguration: undefined,
    modelType: 0,
    trainingRuns: [],
    featureColumns: [],
    labelColumns: [],
    transformColumns: [],
    hparamSearchSpaces: undefined,
    defaultTrialId: Long.ZERO,
    hparamTrials: [],
    optimalTrialIds: [],
    remoteModelInfo: undefined,
  };
}

export const Model: MessageFns<Model> = {
  encode(message: Model, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.etag !== "") {
      writer.uint32(10).string(message.etag);
    }
    if (message.modelReference !== undefined) {
      ModelReference.encode(message.modelReference, writer.uint32(18).fork()).join();
    }
    if (!message.creationTime.equals(Long.ZERO)) {
      writer.uint32(40).int64(message.creationTime.toString());
    }
    if (!message.lastModifiedTime.equals(Long.ZERO)) {
      writer.uint32(48).int64(message.lastModifiedTime.toString());
    }
    if (message.description !== "") {
      writer.uint32(98).string(message.description);
    }
    if (message.friendlyName !== "") {
      writer.uint32(114).string(message.friendlyName);
    }
    Object.entries(message.labels).forEach(([key, value]) => {
      Model_LabelsEntry.encode({ key: key as any, value }, writer.uint32(122).fork()).join();
    });
    if (!message.expirationTime.equals(Long.ZERO)) {
      writer.uint32(128).int64(message.expirationTime.toString());
    }
    if (message.location !== "") {
      writer.uint32(106).string(message.location);
    }
    if (message.encryptionConfiguration !== undefined) {
      EncryptionConfiguration.encode(message.encryptionConfiguration, writer.uint32(138).fork()).join();
    }
    if (message.modelType !== 0) {
      writer.uint32(56).int32(message.modelType);
    }
    for (const v of message.trainingRuns) {
      Model_TrainingRun.encode(v!, writer.uint32(74).fork()).join();
    }
    for (const v of message.featureColumns) {
      StandardSqlField.encode(v!, writer.uint32(82).fork()).join();
    }
    for (const v of message.labelColumns) {
      StandardSqlField.encode(v!, writer.uint32(90).fork()).join();
    }
    for (const v of message.transformColumns) {
      TransformColumn.encode(v!, writer.uint32(210).fork()).join();
    }
    if (message.hparamSearchSpaces !== undefined) {
      Model_HparamSearchSpaces.encode(message.hparamSearchSpaces, writer.uint32(146).fork()).join();
    }
    if (!message.defaultTrialId.equals(Long.ZERO)) {
      writer.uint32(168).int64(message.defaultTrialId.toString());
    }
    for (const v of message.hparamTrials) {
      Model_HparamTuningTrial.encode(v!, writer.uint32(162).fork()).join();
    }
    writer.uint32(178).fork();
    for (const v of message.optimalTrialIds) {
      writer.int64(v.toString());
    }
    writer.join();
    if (message.remoteModelInfo !== undefined) {
      RemoteModelInfo.encode(message.remoteModelInfo, writer.uint32(202).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Model {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseModel();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.etag = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.modelReference = ModelReference.decode(reader, reader.uint32());
          continue;
        case 5:
          if (tag !== 40) {
            break;
          }

          message.creationTime = Long.fromString(reader.int64().toString());
          continue;
        case 6:
          if (tag !== 48) {
            break;
          }

          message.lastModifiedTime = Long.fromString(reader.int64().toString());
          continue;
        case 12:
          if (tag !== 98) {
            break;
          }

          message.description = reader.string();
          continue;
        case 14:
          if (tag !== 114) {
            break;
          }

          message.friendlyName = reader.string();
          continue;
        case 15:
          if (tag !== 122) {
            break;
          }

          const entry15 = Model_LabelsEntry.decode(reader, reader.uint32());
          if (entry15.value !== undefined) {
            message.labels[entry15.key] = entry15.value;
          }
          continue;
        case 16:
          if (tag !== 128) {
            break;
          }

          message.expirationTime = Long.fromString(reader.int64().toString());
          continue;
        case 13:
          if (tag !== 106) {
            break;
          }

          message.location = reader.string();
          continue;
        case 17:
          if (tag !== 138) {
            break;
          }

          message.encryptionConfiguration = EncryptionConfiguration.decode(reader, reader.uint32());
          continue;
        case 7:
          if (tag !== 56) {
            break;
          }

          message.modelType = reader.int32() as any;
          continue;
        case 9:
          if (tag !== 74) {
            break;
          }

          message.trainingRuns.push(Model_TrainingRun.decode(reader, reader.uint32()));
          continue;
        case 10:
          if (tag !== 82) {
            break;
          }

          message.featureColumns.push(StandardSqlField.decode(reader, reader.uint32()));
          continue;
        case 11:
          if (tag !== 90) {
            break;
          }

          message.labelColumns.push(StandardSqlField.decode(reader, reader.uint32()));
          continue;
        case 26:
          if (tag !== 210) {
            break;
          }

          message.transformColumns.push(TransformColumn.decode(reader, reader.uint32()));
          continue;
        case 18:
          if (tag !== 146) {
            break;
          }

          message.hparamSearchSpaces = Model_HparamSearchSpaces.decode(reader, reader.uint32());
          continue;
        case 21:
          if (tag !== 168) {
            break;
          }

          message.defaultTrialId = Long.fromString(reader.int64().toString());
          continue;
        case 20:
          if (tag !== 162) {
            break;
          }

          message.hparamTrials.push(Model_HparamTuningTrial.decode(reader, reader.uint32()));
          continue;
        case 22:
          if (tag === 176) {
            message.optimalTrialIds.push(Long.fromString(reader.int64().toString()));

            continue;
          }

          if (tag === 178) {
            const end2 = reader.uint32() + reader.pos;
            while (reader.pos < end2) {
              message.optimalTrialIds.push(Long.fromString(reader.int64().toString()));
            }

            continue;
          }

          break;
        case 25:
          if (tag !== 202) {
            break;
          }

          message.remoteModelInfo = RemoteModelInfo.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Model {
    return {
      etag: isSet(object.etag) ? globalThis.String(object.etag) : "",
      modelReference: isSet(object.modelReference) ? ModelReference.fromJSON(object.modelReference) : undefined,
      creationTime: isSet(object.creationTime) ? Long.fromValue(object.creationTime) : Long.ZERO,
      lastModifiedTime: isSet(object.lastModifiedTime) ? Long.fromValue(object.lastModifiedTime) : Long.ZERO,
      description: isSet(object.description) ? globalThis.String(object.description) : "",
      friendlyName: isSet(object.friendlyName) ? globalThis.String(object.friendlyName) : "",
      labels: isObject(object.labels)
        ? Object.entries(object.labels).reduce<{ [key: string]: string }>((acc, [key, value]) => {
          acc[key] = String(value);
          return acc;
        }, {})
        : {},
      expirationTime: isSet(object.expirationTime) ? Long.fromValue(object.expirationTime) : Long.ZERO,
      location: isSet(object.location) ? globalThis.String(object.location) : "",
      encryptionConfiguration: isSet(object.encryptionConfiguration)
        ? EncryptionConfiguration.fromJSON(object.encryptionConfiguration)
        : undefined,
      modelType: isSet(object.modelType) ? model_ModelTypeFromJSON(object.modelType) : 0,
      trainingRuns: globalThis.Array.isArray(object?.trainingRuns)
        ? object.trainingRuns.map((e: any) => Model_TrainingRun.fromJSON(e))
        : [],
      featureColumns: globalThis.Array.isArray(object?.featureColumns)
        ? object.featureColumns.map((e: any) => StandardSqlField.fromJSON(e))
        : [],
      labelColumns: globalThis.Array.isArray(object?.labelColumns)
        ? object.labelColumns.map((e: any) => StandardSqlField.fromJSON(e))
        : [],
      transformColumns: globalThis.Array.isArray(object?.transformColumns)
        ? object.transformColumns.map((e: any) => TransformColumn.fromJSON(e))
        : [],
      hparamSearchSpaces: isSet(object.hparamSearchSpaces)
        ? Model_HparamSearchSpaces.fromJSON(object.hparamSearchSpaces)
        : undefined,
      defaultTrialId: isSet(object.defaultTrialId) ? Long.fromValue(object.defaultTrialId) : Long.ZERO,
      hparamTrials: globalThis.Array.isArray(object?.hparamTrials)
        ? object.hparamTrials.map((e: any) => Model_HparamTuningTrial.fromJSON(e))
        : [],
      optimalTrialIds: globalThis.Array.isArray(object?.optimalTrialIds)
        ? object.optimalTrialIds.map((e: any) => Long.fromValue(e))
        : [],
      remoteModelInfo: isSet(object.remoteModelInfo) ? RemoteModelInfo.fromJSON(object.remoteModelInfo) : undefined,
    };
  },

  toJSON(message: Model): unknown {
    const obj: any = {};
    if (message.etag !== "") {
      obj.etag = message.etag;
    }
    if (message.modelReference !== undefined) {
      obj.modelReference = ModelReference.toJSON(message.modelReference);
    }
    if (!message.creationTime.equals(Long.ZERO)) {
      obj.creationTime = (message.creationTime || Long.ZERO).toString();
    }
    if (!message.lastModifiedTime.equals(Long.ZERO)) {
      obj.lastModifiedTime = (message.lastModifiedTime || Long.ZERO).toString();
    }
    if (message.description !== "") {
      obj.description = message.description;
    }
    if (message.friendlyName !== "") {
      obj.friendlyName = message.friendlyName;
    }
    if (message.labels) {
      const entries = Object.entries(message.labels);
      if (entries.length > 0) {
        obj.labels = {};
        entries.forEach(([k, v]) => {
          obj.labels[k] = v;
        });
      }
    }
    if (!message.expirationTime.equals(Long.ZERO)) {
      obj.expirationTime = (message.expirationTime || Long.ZERO).toString();
    }
    if (message.location !== "") {
      obj.location = message.location;
    }
    if (message.encryptionConfiguration !== undefined) {
      obj.encryptionConfiguration = EncryptionConfiguration.toJSON(message.encryptionConfiguration);
    }
    if (message.modelType !== 0) {
      obj.modelType = model_ModelTypeToJSON(message.modelType);
    }
    if (message.trainingRuns?.length) {
      obj.trainingRuns = message.trainingRuns.map((e) => Model_TrainingRun.toJSON(e));
    }
    if (message.featureColumns?.length) {
      obj.featureColumns = message.featureColumns.map((e) => StandardSqlField.toJSON(e));
    }
    if (message.labelColumns?.length) {
      obj.labelColumns = message.labelColumns.map((e) => StandardSqlField.toJSON(e));
    }
    if (message.transformColumns?.length) {
      obj.transformColumns = message.transformColumns.map((e) => TransformColumn.toJSON(e));
    }
    if (message.hparamSearchSpaces !== undefined) {
      obj.hparamSearchSpaces = Model_HparamSearchSpaces.toJSON(message.hparamSearchSpaces);
    }
    if (!message.defaultTrialId.equals(Long.ZERO)) {
      obj.defaultTrialId = (message.defaultTrialId || Long.ZERO).toString();
    }
    if (message.hparamTrials?.length) {
      obj.hparamTrials = message.hparamTrials.map((e) => Model_HparamTuningTrial.toJSON(e));
    }
    if (message.optimalTrialIds?.length) {
      obj.optimalTrialIds = message.optimalTrialIds.map((e) => (e || Long.ZERO).toString());
    }
    if (message.remoteModelInfo !== undefined) {
      obj.remoteModelInfo = RemoteModelInfo.toJSON(message.remoteModelInfo);
    }
    return obj;
  },

  create(base?: DeepPartial<Model>): Model {
    return Model.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<Model>): Model {
    const message = createBaseModel();
    message.etag = object.etag ?? "";
    message.modelReference = (object.modelReference !== undefined && object.modelReference !== null)
      ? ModelReference.fromPartial(object.modelReference)
      : undefined;
    message.creationTime = (object.creationTime !== undefined && object.creationTime !== null)
      ? Long.fromValue(object.creationTime)
      : Long.ZERO;
    message.lastModifiedTime = (object.lastModifiedTime !== undefined && object.lastModifiedTime !== null)
      ? Long.fromValue(object.lastModifiedTime)
      : Long.ZERO;
    message.description = object.description ?? "";
    message.friendlyName = object.friendlyName ?? "";
    message.labels = Object.entries(object.labels ?? {}).reduce<{ [key: string]: string }>((acc, [key, value]) => {
      if (value !== undefined) {
        acc[key] = globalThis.String(value);
      }
      return acc;
    }, {});
    message.expirationTime = (object.expirationTime !== undefined && object.expirationTime !== null)
      ? Long.fromValue(object.expirationTime)
      : Long.ZERO;
    message.location = object.location ?? "";
    message.encryptionConfiguration =
      (object.encryptionConfiguration !== undefined && object.encryptionConfiguration !== null)
        ? EncryptionConfiguration.fromPartial(object.encryptionConfiguration)
        : undefined;
    message.modelType = object.modelType ?? 0;
    message.trainingRuns = object.trainingRuns?.map((e) => Model_TrainingRun.fromPartial(e)) || [];
    message.featureColumns = object.featureColumns?.map((e) => StandardSqlField.fromPartial(e)) || [];
    message.labelColumns = object.labelColumns?.map((e) => StandardSqlField.fromPartial(e)) || [];
    message.transformColumns = object.transformColumns?.map((e) => TransformColumn.fromPartial(e)) || [];
    message.hparamSearchSpaces = (object.hparamSearchSpaces !== undefined && object.hparamSearchSpaces !== null)
      ? Model_HparamSearchSpaces.fromPartial(object.hparamSearchSpaces)
      : undefined;
    message.defaultTrialId = (object.defaultTrialId !== undefined && object.defaultTrialId !== null)
      ? Long.fromValue(object.defaultTrialId)
      : Long.ZERO;
    message.hparamTrials = object.hparamTrials?.map((e) => Model_HparamTuningTrial.fromPartial(e)) || [];
    message.optimalTrialIds = object.optimalTrialIds?.map((e) => Long.fromValue(e)) || [];
    message.remoteModelInfo = (object.remoteModelInfo !== undefined && object.remoteModelInfo !== null)
      ? RemoteModelInfo.fromPartial(object.remoteModelInfo)
      : undefined;
    return message;
  },
};

function createBaseModel_SeasonalPeriod(): Model_SeasonalPeriod {
  return {};
}

export const Model_SeasonalPeriod: MessageFns<Model_SeasonalPeriod> = {
  encode(_: Model_SeasonalPeriod, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Model_SeasonalPeriod {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseModel_SeasonalPeriod();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(_: any): Model_SeasonalPeriod {
    return {};
  },

  toJSON(_: Model_SeasonalPeriod): unknown {
    const obj: any = {};
    return obj;
  },

  create(base?: DeepPartial<Model_SeasonalPeriod>): Model_SeasonalPeriod {
    return Model_SeasonalPeriod.fromPartial(base ?? {});
  },
  fromPartial(_: DeepPartial<Model_SeasonalPeriod>): Model_SeasonalPeriod {
    const message = createBaseModel_SeasonalPeriod();
    return message;
  },
};

function createBaseModel_KmeansEnums(): Model_KmeansEnums {
  return {};
}

export const Model_KmeansEnums: MessageFns<Model_KmeansEnums> = {
  encode(_: Model_KmeansEnums, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Model_KmeansEnums {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseModel_KmeansEnums();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(_: any): Model_KmeansEnums {
    return {};
  },

  toJSON(_: Model_KmeansEnums): unknown {
    const obj: any = {};
    return obj;
  },

  create(base?: DeepPartial<Model_KmeansEnums>): Model_KmeansEnums {
    return Model_KmeansEnums.fromPartial(base ?? {});
  },
  fromPartial(_: DeepPartial<Model_KmeansEnums>): Model_KmeansEnums {
    const message = createBaseModel_KmeansEnums();
    return message;
  },
};

function createBaseModel_BoostedTreeOptionEnums(): Model_BoostedTreeOptionEnums {
  return {};
}

export const Model_BoostedTreeOptionEnums: MessageFns<Model_BoostedTreeOptionEnums> = {
  encode(_: Model_BoostedTreeOptionEnums, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Model_BoostedTreeOptionEnums {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseModel_BoostedTreeOptionEnums();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(_: any): Model_BoostedTreeOptionEnums {
    return {};
  },

  toJSON(_: Model_BoostedTreeOptionEnums): unknown {
    const obj: any = {};
    return obj;
  },

  create(base?: DeepPartial<Model_BoostedTreeOptionEnums>): Model_BoostedTreeOptionEnums {
    return Model_BoostedTreeOptionEnums.fromPartial(base ?? {});
  },
  fromPartial(_: DeepPartial<Model_BoostedTreeOptionEnums>): Model_BoostedTreeOptionEnums {
    const message = createBaseModel_BoostedTreeOptionEnums();
    return message;
  },
};

function createBaseModel_HparamTuningEnums(): Model_HparamTuningEnums {
  return {};
}

export const Model_HparamTuningEnums: MessageFns<Model_HparamTuningEnums> = {
  encode(_: Model_HparamTuningEnums, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Model_HparamTuningEnums {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseModel_HparamTuningEnums();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(_: any): Model_HparamTuningEnums {
    return {};
  },

  toJSON(_: Model_HparamTuningEnums): unknown {
    const obj: any = {};
    return obj;
  },

  create(base?: DeepPartial<Model_HparamTuningEnums>): Model_HparamTuningEnums {
    return Model_HparamTuningEnums.fromPartial(base ?? {});
  },
  fromPartial(_: DeepPartial<Model_HparamTuningEnums>): Model_HparamTuningEnums {
    const message = createBaseModel_HparamTuningEnums();
    return message;
  },
};

function createBaseModel_RegressionMetrics(): Model_RegressionMetrics {
  return {
    meanAbsoluteError: undefined,
    meanSquaredError: undefined,
    meanSquaredLogError: undefined,
    medianAbsoluteError: undefined,
    rSquared: undefined,
  };
}

export const Model_RegressionMetrics: MessageFns<Model_RegressionMetrics> = {
  encode(message: Model_RegressionMetrics, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.meanAbsoluteError !== undefined) {
      DoubleValue.encode({ value: message.meanAbsoluteError! }, writer.uint32(10).fork()).join();
    }
    if (message.meanSquaredError !== undefined) {
      DoubleValue.encode({ value: message.meanSquaredError! }, writer.uint32(18).fork()).join();
    }
    if (message.meanSquaredLogError !== undefined) {
      DoubleValue.encode({ value: message.meanSquaredLogError! }, writer.uint32(26).fork()).join();
    }
    if (message.medianAbsoluteError !== undefined) {
      DoubleValue.encode({ value: message.medianAbsoluteError! }, writer.uint32(34).fork()).join();
    }
    if (message.rSquared !== undefined) {
      DoubleValue.encode({ value: message.rSquared! }, writer.uint32(42).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Model_RegressionMetrics {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseModel_RegressionMetrics();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.meanAbsoluteError = DoubleValue.decode(reader, reader.uint32()).value;
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.meanSquaredError = DoubleValue.decode(reader, reader.uint32()).value;
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.meanSquaredLogError = DoubleValue.decode(reader, reader.uint32()).value;
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.medianAbsoluteError = DoubleValue.decode(reader, reader.uint32()).value;
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.rSquared = DoubleValue.decode(reader, reader.uint32()).value;
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Model_RegressionMetrics {
    return {
      meanAbsoluteError: isSet(object.meanAbsoluteError) ? Number(object.meanAbsoluteError) : undefined,
      meanSquaredError: isSet(object.meanSquaredError) ? Number(object.meanSquaredError) : undefined,
      meanSquaredLogError: isSet(object.meanSquaredLogError) ? Number(object.meanSquaredLogError) : undefined,
      medianAbsoluteError: isSet(object.medianAbsoluteError) ? Number(object.medianAbsoluteError) : undefined,
      rSquared: isSet(object.rSquared) ? Number(object.rSquared) : undefined,
    };
  },

  toJSON(message: Model_RegressionMetrics): unknown {
    const obj: any = {};
    if (message.meanAbsoluteError !== undefined) {
      obj.meanAbsoluteError = message.meanAbsoluteError;
    }
    if (message.meanSquaredError !== undefined) {
      obj.meanSquaredError = message.meanSquaredError;
    }
    if (message.meanSquaredLogError !== undefined) {
      obj.meanSquaredLogError = message.meanSquaredLogError;
    }
    if (message.medianAbsoluteError !== undefined) {
      obj.medianAbsoluteError = message.medianAbsoluteError;
    }
    if (message.rSquared !== undefined) {
      obj.rSquared = message.rSquared;
    }
    return obj;
  },

  create(base?: DeepPartial<Model_RegressionMetrics>): Model_RegressionMetrics {
    return Model_RegressionMetrics.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<Model_RegressionMetrics>): Model_RegressionMetrics {
    const message = createBaseModel_RegressionMetrics();
    message.meanAbsoluteError = object.meanAbsoluteError ?? undefined;
    message.meanSquaredError = object.meanSquaredError ?? undefined;
    message.meanSquaredLogError = object.meanSquaredLogError ?? undefined;
    message.medianAbsoluteError = object.medianAbsoluteError ?? undefined;
    message.rSquared = object.rSquared ?? undefined;
    return message;
  },
};

function createBaseModel_AggregateClassificationMetrics(): Model_AggregateClassificationMetrics {
  return {
    precision: undefined,
    recall: undefined,
    accuracy: undefined,
    threshold: undefined,
    f1Score: undefined,
    logLoss: undefined,
    rocAuc: undefined,
  };
}

export const Model_AggregateClassificationMetrics: MessageFns<Model_AggregateClassificationMetrics> = {
  encode(message: Model_AggregateClassificationMetrics, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.precision !== undefined) {
      DoubleValue.encode({ value: message.precision! }, writer.uint32(10).fork()).join();
    }
    if (message.recall !== undefined) {
      DoubleValue.encode({ value: message.recall! }, writer.uint32(18).fork()).join();
    }
    if (message.accuracy !== undefined) {
      DoubleValue.encode({ value: message.accuracy! }, writer.uint32(26).fork()).join();
    }
    if (message.threshold !== undefined) {
      DoubleValue.encode({ value: message.threshold! }, writer.uint32(34).fork()).join();
    }
    if (message.f1Score !== undefined) {
      DoubleValue.encode({ value: message.f1Score! }, writer.uint32(42).fork()).join();
    }
    if (message.logLoss !== undefined) {
      DoubleValue.encode({ value: message.logLoss! }, writer.uint32(50).fork()).join();
    }
    if (message.rocAuc !== undefined) {
      DoubleValue.encode({ value: message.rocAuc! }, writer.uint32(58).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Model_AggregateClassificationMetrics {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseModel_AggregateClassificationMetrics();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.precision = DoubleValue.decode(reader, reader.uint32()).value;
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.recall = DoubleValue.decode(reader, reader.uint32()).value;
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.accuracy = DoubleValue.decode(reader, reader.uint32()).value;
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.threshold = DoubleValue.decode(reader, reader.uint32()).value;
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.f1Score = DoubleValue.decode(reader, reader.uint32()).value;
          continue;
        case 6:
          if (tag !== 50) {
            break;
          }

          message.logLoss = DoubleValue.decode(reader, reader.uint32()).value;
          continue;
        case 7:
          if (tag !== 58) {
            break;
          }

          message.rocAuc = DoubleValue.decode(reader, reader.uint32()).value;
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Model_AggregateClassificationMetrics {
    return {
      precision: isSet(object.precision) ? Number(object.precision) : undefined,
      recall: isSet(object.recall) ? Number(object.recall) : undefined,
      accuracy: isSet(object.accuracy) ? Number(object.accuracy) : undefined,
      threshold: isSet(object.threshold) ? Number(object.threshold) : undefined,
      f1Score: isSet(object.f1Score) ? Number(object.f1Score) : undefined,
      logLoss: isSet(object.logLoss) ? Number(object.logLoss) : undefined,
      rocAuc: isSet(object.rocAuc) ? Number(object.rocAuc) : undefined,
    };
  },

  toJSON(message: Model_AggregateClassificationMetrics): unknown {
    const obj: any = {};
    if (message.precision !== undefined) {
      obj.precision = message.precision;
    }
    if (message.recall !== undefined) {
      obj.recall = message.recall;
    }
    if (message.accuracy !== undefined) {
      obj.accuracy = message.accuracy;
    }
    if (message.threshold !== undefined) {
      obj.threshold = message.threshold;
    }
    if (message.f1Score !== undefined) {
      obj.f1Score = message.f1Score;
    }
    if (message.logLoss !== undefined) {
      obj.logLoss = message.logLoss;
    }
    if (message.rocAuc !== undefined) {
      obj.rocAuc = message.rocAuc;
    }
    return obj;
  },

  create(base?: DeepPartial<Model_AggregateClassificationMetrics>): Model_AggregateClassificationMetrics {
    return Model_AggregateClassificationMetrics.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<Model_AggregateClassificationMetrics>): Model_AggregateClassificationMetrics {
    const message = createBaseModel_AggregateClassificationMetrics();
    message.precision = object.precision ?? undefined;
    message.recall = object.recall ?? undefined;
    message.accuracy = object.accuracy ?? undefined;
    message.threshold = object.threshold ?? undefined;
    message.f1Score = object.f1Score ?? undefined;
    message.logLoss = object.logLoss ?? undefined;
    message.rocAuc = object.rocAuc ?? undefined;
    return message;
  },
};

function createBaseModel_BinaryClassificationMetrics(): Model_BinaryClassificationMetrics {
  return {
    aggregateClassificationMetrics: undefined,
    binaryConfusionMatrixList: [],
    positiveLabel: "",
    negativeLabel: "",
  };
}

export const Model_BinaryClassificationMetrics: MessageFns<Model_BinaryClassificationMetrics> = {
  encode(message: Model_BinaryClassificationMetrics, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.aggregateClassificationMetrics !== undefined) {
      Model_AggregateClassificationMetrics.encode(message.aggregateClassificationMetrics, writer.uint32(10).fork())
        .join();
    }
    for (const v of message.binaryConfusionMatrixList) {
      Model_BinaryClassificationMetrics_BinaryConfusionMatrix.encode(v!, writer.uint32(18).fork()).join();
    }
    if (message.positiveLabel !== "") {
      writer.uint32(26).string(message.positiveLabel);
    }
    if (message.negativeLabel !== "") {
      writer.uint32(34).string(message.negativeLabel);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Model_BinaryClassificationMetrics {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseModel_BinaryClassificationMetrics();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.aggregateClassificationMetrics = Model_AggregateClassificationMetrics.decode(reader, reader.uint32());
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.binaryConfusionMatrixList.push(
            Model_BinaryClassificationMetrics_BinaryConfusionMatrix.decode(reader, reader.uint32()),
          );
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.positiveLabel = reader.string();
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.negativeLabel = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Model_BinaryClassificationMetrics {
    return {
      aggregateClassificationMetrics: isSet(object.aggregateClassificationMetrics)
        ? Model_AggregateClassificationMetrics.fromJSON(object.aggregateClassificationMetrics)
        : undefined,
      binaryConfusionMatrixList: globalThis.Array.isArray(object?.binaryConfusionMatrixList)
        ? object.binaryConfusionMatrixList.map((e: any) =>
          Model_BinaryClassificationMetrics_BinaryConfusionMatrix.fromJSON(e)
        )
        : [],
      positiveLabel: isSet(object.positiveLabel) ? globalThis.String(object.positiveLabel) : "",
      negativeLabel: isSet(object.negativeLabel) ? globalThis.String(object.negativeLabel) : "",
    };
  },

  toJSON(message: Model_BinaryClassificationMetrics): unknown {
    const obj: any = {};
    if (message.aggregateClassificationMetrics !== undefined) {
      obj.aggregateClassificationMetrics = Model_AggregateClassificationMetrics.toJSON(
        message.aggregateClassificationMetrics,
      );
    }
    if (message.binaryConfusionMatrixList?.length) {
      obj.binaryConfusionMatrixList = message.binaryConfusionMatrixList.map((e) =>
        Model_BinaryClassificationMetrics_BinaryConfusionMatrix.toJSON(e)
      );
    }
    if (message.positiveLabel !== "") {
      obj.positiveLabel = message.positiveLabel;
    }
    if (message.negativeLabel !== "") {
      obj.negativeLabel = message.negativeLabel;
    }
    return obj;
  },

  create(base?: DeepPartial<Model_BinaryClassificationMetrics>): Model_BinaryClassificationMetrics {
    return Model_BinaryClassificationMetrics.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<Model_BinaryClassificationMetrics>): Model_BinaryClassificationMetrics {
    const message = createBaseModel_BinaryClassificationMetrics();
    message.aggregateClassificationMetrics =
      (object.aggregateClassificationMetrics !== undefined && object.aggregateClassificationMetrics !== null)
        ? Model_AggregateClassificationMetrics.fromPartial(object.aggregateClassificationMetrics)
        : undefined;
    message.binaryConfusionMatrixList =
      object.binaryConfusionMatrixList?.map((e) =>
        Model_BinaryClassificationMetrics_BinaryConfusionMatrix.fromPartial(e)
      ) || [];
    message.positiveLabel = object.positiveLabel ?? "";
    message.negativeLabel = object.negativeLabel ?? "";
    return message;
  },
};

function createBaseModel_BinaryClassificationMetrics_BinaryConfusionMatrix(): Model_BinaryClassificationMetrics_BinaryConfusionMatrix {
  return {
    positiveClassThreshold: undefined,
    truePositives: undefined,
    falsePositives: undefined,
    trueNegatives: undefined,
    falseNegatives: undefined,
    precision: undefined,
    recall: undefined,
    f1Score: undefined,
    accuracy: undefined,
  };
}

export const Model_BinaryClassificationMetrics_BinaryConfusionMatrix: MessageFns<
  Model_BinaryClassificationMetrics_BinaryConfusionMatrix
> = {
  encode(
    message: Model_BinaryClassificationMetrics_BinaryConfusionMatrix,
    writer: BinaryWriter = new BinaryWriter(),
  ): BinaryWriter {
    if (message.positiveClassThreshold !== undefined) {
      DoubleValue.encode({ value: message.positiveClassThreshold! }, writer.uint32(10).fork()).join();
    }
    if (message.truePositives !== undefined) {
      Int64Value.encode({ value: message.truePositives! }, writer.uint32(18).fork()).join();
    }
    if (message.falsePositives !== undefined) {
      Int64Value.encode({ value: message.falsePositives! }, writer.uint32(26).fork()).join();
    }
    if (message.trueNegatives !== undefined) {
      Int64Value.encode({ value: message.trueNegatives! }, writer.uint32(34).fork()).join();
    }
    if (message.falseNegatives !== undefined) {
      Int64Value.encode({ value: message.falseNegatives! }, writer.uint32(42).fork()).join();
    }
    if (message.precision !== undefined) {
      DoubleValue.encode({ value: message.precision! }, writer.uint32(50).fork()).join();
    }
    if (message.recall !== undefined) {
      DoubleValue.encode({ value: message.recall! }, writer.uint32(58).fork()).join();
    }
    if (message.f1Score !== undefined) {
      DoubleValue.encode({ value: message.f1Score! }, writer.uint32(66).fork()).join();
    }
    if (message.accuracy !== undefined) {
      DoubleValue.encode({ value: message.accuracy! }, writer.uint32(74).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Model_BinaryClassificationMetrics_BinaryConfusionMatrix {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseModel_BinaryClassificationMetrics_BinaryConfusionMatrix();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.positiveClassThreshold = DoubleValue.decode(reader, reader.uint32()).value;
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.truePositives = Int64Value.decode(reader, reader.uint32()).value;
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.falsePositives = Int64Value.decode(reader, reader.uint32()).value;
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.trueNegatives = Int64Value.decode(reader, reader.uint32()).value;
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.falseNegatives = Int64Value.decode(reader, reader.uint32()).value;
          continue;
        case 6:
          if (tag !== 50) {
            break;
          }

          message.precision = DoubleValue.decode(reader, reader.uint32()).value;
          continue;
        case 7:
          if (tag !== 58) {
            break;
          }

          message.recall = DoubleValue.decode(reader, reader.uint32()).value;
          continue;
        case 8:
          if (tag !== 66) {
            break;
          }

          message.f1Score = DoubleValue.decode(reader, reader.uint32()).value;
          continue;
        case 9:
          if (tag !== 74) {
            break;
          }

          message.accuracy = DoubleValue.decode(reader, reader.uint32()).value;
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Model_BinaryClassificationMetrics_BinaryConfusionMatrix {
    return {
      positiveClassThreshold: isSet(object.positiveClassThreshold) ? Number(object.positiveClassThreshold) : undefined,
      truePositives: isSet(object.truePositives) ? Long.fromValue(object.truePositives) : undefined,
      falsePositives: isSet(object.falsePositives) ? Long.fromValue(object.falsePositives) : undefined,
      trueNegatives: isSet(object.trueNegatives) ? Long.fromValue(object.trueNegatives) : undefined,
      falseNegatives: isSet(object.falseNegatives) ? Long.fromValue(object.falseNegatives) : undefined,
      precision: isSet(object.precision) ? Number(object.precision) : undefined,
      recall: isSet(object.recall) ? Number(object.recall) : undefined,
      f1Score: isSet(object.f1Score) ? Number(object.f1Score) : undefined,
      accuracy: isSet(object.accuracy) ? Number(object.accuracy) : undefined,
    };
  },

  toJSON(message: Model_BinaryClassificationMetrics_BinaryConfusionMatrix): unknown {
    const obj: any = {};
    if (message.positiveClassThreshold !== undefined) {
      obj.positiveClassThreshold = message.positiveClassThreshold;
    }
    if (message.truePositives !== undefined) {
      obj.truePositives = message.truePositives;
    }
    if (message.falsePositives !== undefined) {
      obj.falsePositives = message.falsePositives;
    }
    if (message.trueNegatives !== undefined) {
      obj.trueNegatives = message.trueNegatives;
    }
    if (message.falseNegatives !== undefined) {
      obj.falseNegatives = message.falseNegatives;
    }
    if (message.precision !== undefined) {
      obj.precision = message.precision;
    }
    if (message.recall !== undefined) {
      obj.recall = message.recall;
    }
    if (message.f1Score !== undefined) {
      obj.f1Score = message.f1Score;
    }
    if (message.accuracy !== undefined) {
      obj.accuracy = message.accuracy;
    }
    return obj;
  },

  create(
    base?: DeepPartial<Model_BinaryClassificationMetrics_BinaryConfusionMatrix>,
  ): Model_BinaryClassificationMetrics_BinaryConfusionMatrix {
    return Model_BinaryClassificationMetrics_BinaryConfusionMatrix.fromPartial(base ?? {});
  },
  fromPartial(
    object: DeepPartial<Model_BinaryClassificationMetrics_BinaryConfusionMatrix>,
  ): Model_BinaryClassificationMetrics_BinaryConfusionMatrix {
    const message = createBaseModel_BinaryClassificationMetrics_BinaryConfusionMatrix();
    message.positiveClassThreshold = object.positiveClassThreshold ?? undefined;
    message.truePositives = (object.truePositives !== undefined && object.truePositives !== null)
      ? Long.fromValue(object.truePositives)
      : undefined;
    message.falsePositives = (object.falsePositives !== undefined && object.falsePositives !== null)
      ? Long.fromValue(object.falsePositives)
      : undefined;
    message.trueNegatives = (object.trueNegatives !== undefined && object.trueNegatives !== null)
      ? Long.fromValue(object.trueNegatives)
      : undefined;
    message.falseNegatives = (object.falseNegatives !== undefined && object.falseNegatives !== null)
      ? Long.fromValue(object.falseNegatives)
      : undefined;
    message.precision = object.precision ?? undefined;
    message.recall = object.recall ?? undefined;
    message.f1Score = object.f1Score ?? undefined;
    message.accuracy = object.accuracy ?? undefined;
    return message;
  },
};

function createBaseModel_MultiClassClassificationMetrics(): Model_MultiClassClassificationMetrics {
  return { aggregateClassificationMetrics: undefined, confusionMatrixList: [] };
}

export const Model_MultiClassClassificationMetrics: MessageFns<Model_MultiClassClassificationMetrics> = {
  encode(message: Model_MultiClassClassificationMetrics, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.aggregateClassificationMetrics !== undefined) {
      Model_AggregateClassificationMetrics.encode(message.aggregateClassificationMetrics, writer.uint32(10).fork())
        .join();
    }
    for (const v of message.confusionMatrixList) {
      Model_MultiClassClassificationMetrics_ConfusionMatrix.encode(v!, writer.uint32(18).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Model_MultiClassClassificationMetrics {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseModel_MultiClassClassificationMetrics();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.aggregateClassificationMetrics = Model_AggregateClassificationMetrics.decode(reader, reader.uint32());
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.confusionMatrixList.push(
            Model_MultiClassClassificationMetrics_ConfusionMatrix.decode(reader, reader.uint32()),
          );
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Model_MultiClassClassificationMetrics {
    return {
      aggregateClassificationMetrics: isSet(object.aggregateClassificationMetrics)
        ? Model_AggregateClassificationMetrics.fromJSON(object.aggregateClassificationMetrics)
        : undefined,
      confusionMatrixList: globalThis.Array.isArray(object?.confusionMatrixList)
        ? object.confusionMatrixList.map((e: any) => Model_MultiClassClassificationMetrics_ConfusionMatrix.fromJSON(e))
        : [],
    };
  },

  toJSON(message: Model_MultiClassClassificationMetrics): unknown {
    const obj: any = {};
    if (message.aggregateClassificationMetrics !== undefined) {
      obj.aggregateClassificationMetrics = Model_AggregateClassificationMetrics.toJSON(
        message.aggregateClassificationMetrics,
      );
    }
    if (message.confusionMatrixList?.length) {
      obj.confusionMatrixList = message.confusionMatrixList.map((e) =>
        Model_MultiClassClassificationMetrics_ConfusionMatrix.toJSON(e)
      );
    }
    return obj;
  },

  create(base?: DeepPartial<Model_MultiClassClassificationMetrics>): Model_MultiClassClassificationMetrics {
    return Model_MultiClassClassificationMetrics.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<Model_MultiClassClassificationMetrics>): Model_MultiClassClassificationMetrics {
    const message = createBaseModel_MultiClassClassificationMetrics();
    message.aggregateClassificationMetrics =
      (object.aggregateClassificationMetrics !== undefined && object.aggregateClassificationMetrics !== null)
        ? Model_AggregateClassificationMetrics.fromPartial(object.aggregateClassificationMetrics)
        : undefined;
    message.confusionMatrixList =
      object.confusionMatrixList?.map((e) => Model_MultiClassClassificationMetrics_ConfusionMatrix.fromPartial(e)) ||
      [];
    return message;
  },
};

function createBaseModel_MultiClassClassificationMetrics_ConfusionMatrix(): Model_MultiClassClassificationMetrics_ConfusionMatrix {
  return { confidenceThreshold: undefined, rows: [] };
}

export const Model_MultiClassClassificationMetrics_ConfusionMatrix: MessageFns<
  Model_MultiClassClassificationMetrics_ConfusionMatrix
> = {
  encode(
    message: Model_MultiClassClassificationMetrics_ConfusionMatrix,
    writer: BinaryWriter = new BinaryWriter(),
  ): BinaryWriter {
    if (message.confidenceThreshold !== undefined) {
      DoubleValue.encode({ value: message.confidenceThreshold! }, writer.uint32(10).fork()).join();
    }
    for (const v of message.rows) {
      Model_MultiClassClassificationMetrics_ConfusionMatrix_Row.encode(v!, writer.uint32(18).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Model_MultiClassClassificationMetrics_ConfusionMatrix {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseModel_MultiClassClassificationMetrics_ConfusionMatrix();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.confidenceThreshold = DoubleValue.decode(reader, reader.uint32()).value;
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.rows.push(Model_MultiClassClassificationMetrics_ConfusionMatrix_Row.decode(reader, reader.uint32()));
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Model_MultiClassClassificationMetrics_ConfusionMatrix {
    return {
      confidenceThreshold: isSet(object.confidenceThreshold) ? Number(object.confidenceThreshold) : undefined,
      rows: globalThis.Array.isArray(object?.rows)
        ? object.rows.map((e: any) => Model_MultiClassClassificationMetrics_ConfusionMatrix_Row.fromJSON(e))
        : [],
    };
  },

  toJSON(message: Model_MultiClassClassificationMetrics_ConfusionMatrix): unknown {
    const obj: any = {};
    if (message.confidenceThreshold !== undefined) {
      obj.confidenceThreshold = message.confidenceThreshold;
    }
    if (message.rows?.length) {
      obj.rows = message.rows.map((e) => Model_MultiClassClassificationMetrics_ConfusionMatrix_Row.toJSON(e));
    }
    return obj;
  },

  create(
    base?: DeepPartial<Model_MultiClassClassificationMetrics_ConfusionMatrix>,
  ): Model_MultiClassClassificationMetrics_ConfusionMatrix {
    return Model_MultiClassClassificationMetrics_ConfusionMatrix.fromPartial(base ?? {});
  },
  fromPartial(
    object: DeepPartial<Model_MultiClassClassificationMetrics_ConfusionMatrix>,
  ): Model_MultiClassClassificationMetrics_ConfusionMatrix {
    const message = createBaseModel_MultiClassClassificationMetrics_ConfusionMatrix();
    message.confidenceThreshold = object.confidenceThreshold ?? undefined;
    message.rows = object.rows?.map((e) => Model_MultiClassClassificationMetrics_ConfusionMatrix_Row.fromPartial(e)) ||
      [];
    return message;
  },
};

function createBaseModel_MultiClassClassificationMetrics_ConfusionMatrix_Entry(): Model_MultiClassClassificationMetrics_ConfusionMatrix_Entry {
  return { predictedLabel: "", itemCount: undefined };
}

export const Model_MultiClassClassificationMetrics_ConfusionMatrix_Entry: MessageFns<
  Model_MultiClassClassificationMetrics_ConfusionMatrix_Entry
> = {
  encode(
    message: Model_MultiClassClassificationMetrics_ConfusionMatrix_Entry,
    writer: BinaryWriter = new BinaryWriter(),
  ): BinaryWriter {
    if (message.predictedLabel !== "") {
      writer.uint32(10).string(message.predictedLabel);
    }
    if (message.itemCount !== undefined) {
      Int64Value.encode({ value: message.itemCount! }, writer.uint32(18).fork()).join();
    }
    return writer;
  },

  decode(
    input: BinaryReader | Uint8Array,
    length?: number,
  ): Model_MultiClassClassificationMetrics_ConfusionMatrix_Entry {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseModel_MultiClassClassificationMetrics_ConfusionMatrix_Entry();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.predictedLabel = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.itemCount = Int64Value.decode(reader, reader.uint32()).value;
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Model_MultiClassClassificationMetrics_ConfusionMatrix_Entry {
    return {
      predictedLabel: isSet(object.predictedLabel) ? globalThis.String(object.predictedLabel) : "",
      itemCount: isSet(object.itemCount) ? Long.fromValue(object.itemCount) : undefined,
    };
  },

  toJSON(message: Model_MultiClassClassificationMetrics_ConfusionMatrix_Entry): unknown {
    const obj: any = {};
    if (message.predictedLabel !== "") {
      obj.predictedLabel = message.predictedLabel;
    }
    if (message.itemCount !== undefined) {
      obj.itemCount = message.itemCount;
    }
    return obj;
  },

  create(
    base?: DeepPartial<Model_MultiClassClassificationMetrics_ConfusionMatrix_Entry>,
  ): Model_MultiClassClassificationMetrics_ConfusionMatrix_Entry {
    return Model_MultiClassClassificationMetrics_ConfusionMatrix_Entry.fromPartial(base ?? {});
  },
  fromPartial(
    object: DeepPartial<Model_MultiClassClassificationMetrics_ConfusionMatrix_Entry>,
  ): Model_MultiClassClassificationMetrics_ConfusionMatrix_Entry {
    const message = createBaseModel_MultiClassClassificationMetrics_ConfusionMatrix_Entry();
    message.predictedLabel = object.predictedLabel ?? "";
    message.itemCount = (object.itemCount !== undefined && object.itemCount !== null)
      ? Long.fromValue(object.itemCount)
      : undefined;
    return message;
  },
};

function createBaseModel_MultiClassClassificationMetrics_ConfusionMatrix_Row(): Model_MultiClassClassificationMetrics_ConfusionMatrix_Row {
  return { actualLabel: "", entries: [] };
}

export const Model_MultiClassClassificationMetrics_ConfusionMatrix_Row: MessageFns<
  Model_MultiClassClassificationMetrics_ConfusionMatrix_Row
> = {
  encode(
    message: Model_MultiClassClassificationMetrics_ConfusionMatrix_Row,
    writer: BinaryWriter = new BinaryWriter(),
  ): BinaryWriter {
    if (message.actualLabel !== "") {
      writer.uint32(10).string(message.actualLabel);
    }
    for (const v of message.entries) {
      Model_MultiClassClassificationMetrics_ConfusionMatrix_Entry.encode(v!, writer.uint32(18).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Model_MultiClassClassificationMetrics_ConfusionMatrix_Row {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseModel_MultiClassClassificationMetrics_ConfusionMatrix_Row();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.actualLabel = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.entries.push(
            Model_MultiClassClassificationMetrics_ConfusionMatrix_Entry.decode(reader, reader.uint32()),
          );
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Model_MultiClassClassificationMetrics_ConfusionMatrix_Row {
    return {
      actualLabel: isSet(object.actualLabel) ? globalThis.String(object.actualLabel) : "",
      entries: globalThis.Array.isArray(object?.entries)
        ? object.entries.map((e: any) => Model_MultiClassClassificationMetrics_ConfusionMatrix_Entry.fromJSON(e))
        : [],
    };
  },

  toJSON(message: Model_MultiClassClassificationMetrics_ConfusionMatrix_Row): unknown {
    const obj: any = {};
    if (message.actualLabel !== "") {
      obj.actualLabel = message.actualLabel;
    }
    if (message.entries?.length) {
      obj.entries = message.entries.map((e) => Model_MultiClassClassificationMetrics_ConfusionMatrix_Entry.toJSON(e));
    }
    return obj;
  },

  create(
    base?: DeepPartial<Model_MultiClassClassificationMetrics_ConfusionMatrix_Row>,
  ): Model_MultiClassClassificationMetrics_ConfusionMatrix_Row {
    return Model_MultiClassClassificationMetrics_ConfusionMatrix_Row.fromPartial(base ?? {});
  },
  fromPartial(
    object: DeepPartial<Model_MultiClassClassificationMetrics_ConfusionMatrix_Row>,
  ): Model_MultiClassClassificationMetrics_ConfusionMatrix_Row {
    const message = createBaseModel_MultiClassClassificationMetrics_ConfusionMatrix_Row();
    message.actualLabel = object.actualLabel ?? "";
    message.entries =
      object.entries?.map((e) => Model_MultiClassClassificationMetrics_ConfusionMatrix_Entry.fromPartial(e)) || [];
    return message;
  },
};

function createBaseModel_ClusteringMetrics(): Model_ClusteringMetrics {
  return { daviesBouldinIndex: undefined, meanSquaredDistance: undefined, clusters: [] };
}

export const Model_ClusteringMetrics: MessageFns<Model_ClusteringMetrics> = {
  encode(message: Model_ClusteringMetrics, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.daviesBouldinIndex !== undefined) {
      DoubleValue.encode({ value: message.daviesBouldinIndex! }, writer.uint32(10).fork()).join();
    }
    if (message.meanSquaredDistance !== undefined) {
      DoubleValue.encode({ value: message.meanSquaredDistance! }, writer.uint32(18).fork()).join();
    }
    for (const v of message.clusters) {
      Model_ClusteringMetrics_Cluster.encode(v!, writer.uint32(26).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Model_ClusteringMetrics {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseModel_ClusteringMetrics();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.daviesBouldinIndex = DoubleValue.decode(reader, reader.uint32()).value;
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.meanSquaredDistance = DoubleValue.decode(reader, reader.uint32()).value;
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.clusters.push(Model_ClusteringMetrics_Cluster.decode(reader, reader.uint32()));
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Model_ClusteringMetrics {
    return {
      daviesBouldinIndex: isSet(object.daviesBouldinIndex) ? Number(object.daviesBouldinIndex) : undefined,
      meanSquaredDistance: isSet(object.meanSquaredDistance) ? Number(object.meanSquaredDistance) : undefined,
      clusters: globalThis.Array.isArray(object?.clusters)
        ? object.clusters.map((e: any) => Model_ClusteringMetrics_Cluster.fromJSON(e))
        : [],
    };
  },

  toJSON(message: Model_ClusteringMetrics): unknown {
    const obj: any = {};
    if (message.daviesBouldinIndex !== undefined) {
      obj.daviesBouldinIndex = message.daviesBouldinIndex;
    }
    if (message.meanSquaredDistance !== undefined) {
      obj.meanSquaredDistance = message.meanSquaredDistance;
    }
    if (message.clusters?.length) {
      obj.clusters = message.clusters.map((e) => Model_ClusteringMetrics_Cluster.toJSON(e));
    }
    return obj;
  },

  create(base?: DeepPartial<Model_ClusteringMetrics>): Model_ClusteringMetrics {
    return Model_ClusteringMetrics.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<Model_ClusteringMetrics>): Model_ClusteringMetrics {
    const message = createBaseModel_ClusteringMetrics();
    message.daviesBouldinIndex = object.daviesBouldinIndex ?? undefined;
    message.meanSquaredDistance = object.meanSquaredDistance ?? undefined;
    message.clusters = object.clusters?.map((e) => Model_ClusteringMetrics_Cluster.fromPartial(e)) || [];
    return message;
  },
};

function createBaseModel_ClusteringMetrics_Cluster(): Model_ClusteringMetrics_Cluster {
  return { centroidId: Long.ZERO, featureValues: [], count: undefined };
}

export const Model_ClusteringMetrics_Cluster: MessageFns<Model_ClusteringMetrics_Cluster> = {
  encode(message: Model_ClusteringMetrics_Cluster, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (!message.centroidId.equals(Long.ZERO)) {
      writer.uint32(8).int64(message.centroidId.toString());
    }
    for (const v of message.featureValues) {
      Model_ClusteringMetrics_Cluster_FeatureValue.encode(v!, writer.uint32(18).fork()).join();
    }
    if (message.count !== undefined) {
      Int64Value.encode({ value: message.count! }, writer.uint32(26).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Model_ClusteringMetrics_Cluster {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseModel_ClusteringMetrics_Cluster();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 8) {
            break;
          }

          message.centroidId = Long.fromString(reader.int64().toString());
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.featureValues.push(Model_ClusteringMetrics_Cluster_FeatureValue.decode(reader, reader.uint32()));
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.count = Int64Value.decode(reader, reader.uint32()).value;
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Model_ClusteringMetrics_Cluster {
    return {
      centroidId: isSet(object.centroidId) ? Long.fromValue(object.centroidId) : Long.ZERO,
      featureValues: globalThis.Array.isArray(object?.featureValues)
        ? object.featureValues.map((e: any) => Model_ClusteringMetrics_Cluster_FeatureValue.fromJSON(e))
        : [],
      count: isSet(object.count) ? Long.fromValue(object.count) : undefined,
    };
  },

  toJSON(message: Model_ClusteringMetrics_Cluster): unknown {
    const obj: any = {};
    if (!message.centroidId.equals(Long.ZERO)) {
      obj.centroidId = (message.centroidId || Long.ZERO).toString();
    }
    if (message.featureValues?.length) {
      obj.featureValues = message.featureValues.map((e) => Model_ClusteringMetrics_Cluster_FeatureValue.toJSON(e));
    }
    if (message.count !== undefined) {
      obj.count = message.count;
    }
    return obj;
  },

  create(base?: DeepPartial<Model_ClusteringMetrics_Cluster>): Model_ClusteringMetrics_Cluster {
    return Model_ClusteringMetrics_Cluster.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<Model_ClusteringMetrics_Cluster>): Model_ClusteringMetrics_Cluster {
    const message = createBaseModel_ClusteringMetrics_Cluster();
    message.centroidId = (object.centroidId !== undefined && object.centroidId !== null)
      ? Long.fromValue(object.centroidId)
      : Long.ZERO;
    message.featureValues =
      object.featureValues?.map((e) => Model_ClusteringMetrics_Cluster_FeatureValue.fromPartial(e)) || [];
    message.count = (object.count !== undefined && object.count !== null) ? Long.fromValue(object.count) : undefined;
    return message;
  },
};

function createBaseModel_ClusteringMetrics_Cluster_FeatureValue(): Model_ClusteringMetrics_Cluster_FeatureValue {
  return { featureColumn: "", numericalValue: undefined, categoricalValue: undefined };
}

export const Model_ClusteringMetrics_Cluster_FeatureValue: MessageFns<Model_ClusteringMetrics_Cluster_FeatureValue> = {
  encode(
    message: Model_ClusteringMetrics_Cluster_FeatureValue,
    writer: BinaryWriter = new BinaryWriter(),
  ): BinaryWriter {
    if (message.featureColumn !== "") {
      writer.uint32(10).string(message.featureColumn);
    }
    if (message.numericalValue !== undefined) {
      DoubleValue.encode({ value: message.numericalValue! }, writer.uint32(18).fork()).join();
    }
    if (message.categoricalValue !== undefined) {
      Model_ClusteringMetrics_Cluster_FeatureValue_CategoricalValue.encode(
        message.categoricalValue,
        writer.uint32(26).fork(),
      ).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Model_ClusteringMetrics_Cluster_FeatureValue {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseModel_ClusteringMetrics_Cluster_FeatureValue();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.featureColumn = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.numericalValue = DoubleValue.decode(reader, reader.uint32()).value;
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.categoricalValue = Model_ClusteringMetrics_Cluster_FeatureValue_CategoricalValue.decode(
            reader,
            reader.uint32(),
          );
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Model_ClusteringMetrics_Cluster_FeatureValue {
    return {
      featureColumn: isSet(object.featureColumn) ? globalThis.String(object.featureColumn) : "",
      numericalValue: isSet(object.numericalValue) ? Number(object.numericalValue) : undefined,
      categoricalValue: isSet(object.categoricalValue)
        ? Model_ClusteringMetrics_Cluster_FeatureValue_CategoricalValue.fromJSON(object.categoricalValue)
        : undefined,
    };
  },

  toJSON(message: Model_ClusteringMetrics_Cluster_FeatureValue): unknown {
    const obj: any = {};
    if (message.featureColumn !== "") {
      obj.featureColumn = message.featureColumn;
    }
    if (message.numericalValue !== undefined) {
      obj.numericalValue = message.numericalValue;
    }
    if (message.categoricalValue !== undefined) {
      obj.categoricalValue = Model_ClusteringMetrics_Cluster_FeatureValue_CategoricalValue.toJSON(
        message.categoricalValue,
      );
    }
    return obj;
  },

  create(
    base?: DeepPartial<Model_ClusteringMetrics_Cluster_FeatureValue>,
  ): Model_ClusteringMetrics_Cluster_FeatureValue {
    return Model_ClusteringMetrics_Cluster_FeatureValue.fromPartial(base ?? {});
  },
  fromPartial(
    object: DeepPartial<Model_ClusteringMetrics_Cluster_FeatureValue>,
  ): Model_ClusteringMetrics_Cluster_FeatureValue {
    const message = createBaseModel_ClusteringMetrics_Cluster_FeatureValue();
    message.featureColumn = object.featureColumn ?? "";
    message.numericalValue = object.numericalValue ?? undefined;
    message.categoricalValue = (object.categoricalValue !== undefined && object.categoricalValue !== null)
      ? Model_ClusteringMetrics_Cluster_FeatureValue_CategoricalValue.fromPartial(object.categoricalValue)
      : undefined;
    return message;
  },
};

function createBaseModel_ClusteringMetrics_Cluster_FeatureValue_CategoricalValue(): Model_ClusteringMetrics_Cluster_FeatureValue_CategoricalValue {
  return { categoryCounts: [] };
}

export const Model_ClusteringMetrics_Cluster_FeatureValue_CategoricalValue: MessageFns<
  Model_ClusteringMetrics_Cluster_FeatureValue_CategoricalValue
> = {
  encode(
    message: Model_ClusteringMetrics_Cluster_FeatureValue_CategoricalValue,
    writer: BinaryWriter = new BinaryWriter(),
  ): BinaryWriter {
    for (const v of message.categoryCounts) {
      Model_ClusteringMetrics_Cluster_FeatureValue_CategoricalValue_CategoryCount.encode(v!, writer.uint32(10).fork())
        .join();
    }
    return writer;
  },

  decode(
    input: BinaryReader | Uint8Array,
    length?: number,
  ): Model_ClusteringMetrics_Cluster_FeatureValue_CategoricalValue {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseModel_ClusteringMetrics_Cluster_FeatureValue_CategoricalValue();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.categoryCounts.push(
            Model_ClusteringMetrics_Cluster_FeatureValue_CategoricalValue_CategoryCount.decode(reader, reader.uint32()),
          );
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Model_ClusteringMetrics_Cluster_FeatureValue_CategoricalValue {
    return {
      categoryCounts: globalThis.Array.isArray(object?.categoryCounts)
        ? object.categoryCounts.map((e: any) =>
          Model_ClusteringMetrics_Cluster_FeatureValue_CategoricalValue_CategoryCount.fromJSON(e)
        )
        : [],
    };
  },

  toJSON(message: Model_ClusteringMetrics_Cluster_FeatureValue_CategoricalValue): unknown {
    const obj: any = {};
    if (message.categoryCounts?.length) {
      obj.categoryCounts = message.categoryCounts.map((e) =>
        Model_ClusteringMetrics_Cluster_FeatureValue_CategoricalValue_CategoryCount.toJSON(e)
      );
    }
    return obj;
  },

  create(
    base?: DeepPartial<Model_ClusteringMetrics_Cluster_FeatureValue_CategoricalValue>,
  ): Model_ClusteringMetrics_Cluster_FeatureValue_CategoricalValue {
    return Model_ClusteringMetrics_Cluster_FeatureValue_CategoricalValue.fromPartial(base ?? {});
  },
  fromPartial(
    object: DeepPartial<Model_ClusteringMetrics_Cluster_FeatureValue_CategoricalValue>,
  ): Model_ClusteringMetrics_Cluster_FeatureValue_CategoricalValue {
    const message = createBaseModel_ClusteringMetrics_Cluster_FeatureValue_CategoricalValue();
    message.categoryCounts =
      object.categoryCounts?.map((e) =>
        Model_ClusteringMetrics_Cluster_FeatureValue_CategoricalValue_CategoryCount.fromPartial(e)
      ) || [];
    return message;
  },
};

function createBaseModel_ClusteringMetrics_Cluster_FeatureValue_CategoricalValue_CategoryCount(): Model_ClusteringMetrics_Cluster_FeatureValue_CategoricalValue_CategoryCount {
  return { category: "", count: undefined };
}

export const Model_ClusteringMetrics_Cluster_FeatureValue_CategoricalValue_CategoryCount: MessageFns<
  Model_ClusteringMetrics_Cluster_FeatureValue_CategoricalValue_CategoryCount
> = {
  encode(
    message: Model_ClusteringMetrics_Cluster_FeatureValue_CategoricalValue_CategoryCount,
    writer: BinaryWriter = new BinaryWriter(),
  ): BinaryWriter {
    if (message.category !== "") {
      writer.uint32(10).string(message.category);
    }
    if (message.count !== undefined) {
      Int64Value.encode({ value: message.count! }, writer.uint32(18).fork()).join();
    }
    return writer;
  },

  decode(
    input: BinaryReader | Uint8Array,
    length?: number,
  ): Model_ClusteringMetrics_Cluster_FeatureValue_CategoricalValue_CategoryCount {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseModel_ClusteringMetrics_Cluster_FeatureValue_CategoricalValue_CategoryCount();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.category = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.count = Int64Value.decode(reader, reader.uint32()).value;
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Model_ClusteringMetrics_Cluster_FeatureValue_CategoricalValue_CategoryCount {
    return {
      category: isSet(object.category) ? globalThis.String(object.category) : "",
      count: isSet(object.count) ? Long.fromValue(object.count) : undefined,
    };
  },

  toJSON(message: Model_ClusteringMetrics_Cluster_FeatureValue_CategoricalValue_CategoryCount): unknown {
    const obj: any = {};
    if (message.category !== "") {
      obj.category = message.category;
    }
    if (message.count !== undefined) {
      obj.count = message.count;
    }
    return obj;
  },

  create(
    base?: DeepPartial<Model_ClusteringMetrics_Cluster_FeatureValue_CategoricalValue_CategoryCount>,
  ): Model_ClusteringMetrics_Cluster_FeatureValue_CategoricalValue_CategoryCount {
    return Model_ClusteringMetrics_Cluster_FeatureValue_CategoricalValue_CategoryCount.fromPartial(base ?? {});
  },
  fromPartial(
    object: DeepPartial<Model_ClusteringMetrics_Cluster_FeatureValue_CategoricalValue_CategoryCount>,
  ): Model_ClusteringMetrics_Cluster_FeatureValue_CategoricalValue_CategoryCount {
    const message = createBaseModel_ClusteringMetrics_Cluster_FeatureValue_CategoricalValue_CategoryCount();
    message.category = object.category ?? "";
    message.count = (object.count !== undefined && object.count !== null) ? Long.fromValue(object.count) : undefined;
    return message;
  },
};

function createBaseModel_RankingMetrics(): Model_RankingMetrics {
  return {
    meanAveragePrecision: undefined,
    meanSquaredError: undefined,
    normalizedDiscountedCumulativeGain: undefined,
    averageRank: undefined,
  };
}

export const Model_RankingMetrics: MessageFns<Model_RankingMetrics> = {
  encode(message: Model_RankingMetrics, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.meanAveragePrecision !== undefined) {
      DoubleValue.encode({ value: message.meanAveragePrecision! }, writer.uint32(10).fork()).join();
    }
    if (message.meanSquaredError !== undefined) {
      DoubleValue.encode({ value: message.meanSquaredError! }, writer.uint32(18).fork()).join();
    }
    if (message.normalizedDiscountedCumulativeGain !== undefined) {
      DoubleValue.encode({ value: message.normalizedDiscountedCumulativeGain! }, writer.uint32(26).fork()).join();
    }
    if (message.averageRank !== undefined) {
      DoubleValue.encode({ value: message.averageRank! }, writer.uint32(34).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Model_RankingMetrics {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseModel_RankingMetrics();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.meanAveragePrecision = DoubleValue.decode(reader, reader.uint32()).value;
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.meanSquaredError = DoubleValue.decode(reader, reader.uint32()).value;
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.normalizedDiscountedCumulativeGain = DoubleValue.decode(reader, reader.uint32()).value;
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.averageRank = DoubleValue.decode(reader, reader.uint32()).value;
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Model_RankingMetrics {
    return {
      meanAveragePrecision: isSet(object.meanAveragePrecision) ? Number(object.meanAveragePrecision) : undefined,
      meanSquaredError: isSet(object.meanSquaredError) ? Number(object.meanSquaredError) : undefined,
      normalizedDiscountedCumulativeGain: isSet(object.normalizedDiscountedCumulativeGain)
        ? Number(object.normalizedDiscountedCumulativeGain)
        : undefined,
      averageRank: isSet(object.averageRank) ? Number(object.averageRank) : undefined,
    };
  },

  toJSON(message: Model_RankingMetrics): unknown {
    const obj: any = {};
    if (message.meanAveragePrecision !== undefined) {
      obj.meanAveragePrecision = message.meanAveragePrecision;
    }
    if (message.meanSquaredError !== undefined) {
      obj.meanSquaredError = message.meanSquaredError;
    }
    if (message.normalizedDiscountedCumulativeGain !== undefined) {
      obj.normalizedDiscountedCumulativeGain = message.normalizedDiscountedCumulativeGain;
    }
    if (message.averageRank !== undefined) {
      obj.averageRank = message.averageRank;
    }
    return obj;
  },

  create(base?: DeepPartial<Model_RankingMetrics>): Model_RankingMetrics {
    return Model_RankingMetrics.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<Model_RankingMetrics>): Model_RankingMetrics {
    const message = createBaseModel_RankingMetrics();
    message.meanAveragePrecision = object.meanAveragePrecision ?? undefined;
    message.meanSquaredError = object.meanSquaredError ?? undefined;
    message.normalizedDiscountedCumulativeGain = object.normalizedDiscountedCumulativeGain ?? undefined;
    message.averageRank = object.averageRank ?? undefined;
    return message;
  },
};

function createBaseModel_ArimaForecastingMetrics(): Model_ArimaForecastingMetrics {
  return { arimaSingleModelForecastingMetrics: [] };
}

export const Model_ArimaForecastingMetrics: MessageFns<Model_ArimaForecastingMetrics> = {
  encode(message: Model_ArimaForecastingMetrics, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.arimaSingleModelForecastingMetrics) {
      Model_ArimaForecastingMetrics_ArimaSingleModelForecastingMetrics.encode(v!, writer.uint32(50).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Model_ArimaForecastingMetrics {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseModel_ArimaForecastingMetrics();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 6:
          if (tag !== 50) {
            break;
          }

          message.arimaSingleModelForecastingMetrics.push(
            Model_ArimaForecastingMetrics_ArimaSingleModelForecastingMetrics.decode(reader, reader.uint32()),
          );
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Model_ArimaForecastingMetrics {
    return {
      arimaSingleModelForecastingMetrics: globalThis.Array.isArray(object?.arimaSingleModelForecastingMetrics)
        ? object.arimaSingleModelForecastingMetrics.map((e: any) =>
          Model_ArimaForecastingMetrics_ArimaSingleModelForecastingMetrics.fromJSON(e)
        )
        : [],
    };
  },

  toJSON(message: Model_ArimaForecastingMetrics): unknown {
    const obj: any = {};
    if (message.arimaSingleModelForecastingMetrics?.length) {
      obj.arimaSingleModelForecastingMetrics = message.arimaSingleModelForecastingMetrics.map((e) =>
        Model_ArimaForecastingMetrics_ArimaSingleModelForecastingMetrics.toJSON(e)
      );
    }
    return obj;
  },

  create(base?: DeepPartial<Model_ArimaForecastingMetrics>): Model_ArimaForecastingMetrics {
    return Model_ArimaForecastingMetrics.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<Model_ArimaForecastingMetrics>): Model_ArimaForecastingMetrics {
    const message = createBaseModel_ArimaForecastingMetrics();
    message.arimaSingleModelForecastingMetrics =
      object.arimaSingleModelForecastingMetrics?.map((e) =>
        Model_ArimaForecastingMetrics_ArimaSingleModelForecastingMetrics.fromPartial(e)
      ) || [];
    return message;
  },
};

function createBaseModel_ArimaForecastingMetrics_ArimaSingleModelForecastingMetrics(): Model_ArimaForecastingMetrics_ArimaSingleModelForecastingMetrics {
  return {
    nonSeasonalOrder: undefined,
    arimaFittingMetrics: undefined,
    hasDrift: undefined,
    timeSeriesId: "",
    timeSeriesIds: [],
    seasonalPeriods: [],
    hasHolidayEffect: undefined,
    hasSpikesAndDips: undefined,
    hasStepChanges: undefined,
  };
}

export const Model_ArimaForecastingMetrics_ArimaSingleModelForecastingMetrics: MessageFns<
  Model_ArimaForecastingMetrics_ArimaSingleModelForecastingMetrics
> = {
  encode(
    message: Model_ArimaForecastingMetrics_ArimaSingleModelForecastingMetrics,
    writer: BinaryWriter = new BinaryWriter(),
  ): BinaryWriter {
    if (message.nonSeasonalOrder !== undefined) {
      Model_ArimaOrder.encode(message.nonSeasonalOrder, writer.uint32(10).fork()).join();
    }
    if (message.arimaFittingMetrics !== undefined) {
      Model_ArimaFittingMetrics.encode(message.arimaFittingMetrics, writer.uint32(18).fork()).join();
    }
    if (message.hasDrift !== undefined) {
      BoolValue.encode({ value: message.hasDrift! }, writer.uint32(26).fork()).join();
    }
    if (message.timeSeriesId !== "") {
      writer.uint32(34).string(message.timeSeriesId);
    }
    for (const v of message.timeSeriesIds) {
      writer.uint32(74).string(v!);
    }
    writer.uint32(42).fork();
    for (const v of message.seasonalPeriods) {
      writer.int32(v);
    }
    writer.join();
    if (message.hasHolidayEffect !== undefined) {
      BoolValue.encode({ value: message.hasHolidayEffect! }, writer.uint32(50).fork()).join();
    }
    if (message.hasSpikesAndDips !== undefined) {
      BoolValue.encode({ value: message.hasSpikesAndDips! }, writer.uint32(58).fork()).join();
    }
    if (message.hasStepChanges !== undefined) {
      BoolValue.encode({ value: message.hasStepChanges! }, writer.uint32(66).fork()).join();
    }
    return writer;
  },

  decode(
    input: BinaryReader | Uint8Array,
    length?: number,
  ): Model_ArimaForecastingMetrics_ArimaSingleModelForecastingMetrics {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseModel_ArimaForecastingMetrics_ArimaSingleModelForecastingMetrics();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.nonSeasonalOrder = Model_ArimaOrder.decode(reader, reader.uint32());
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.arimaFittingMetrics = Model_ArimaFittingMetrics.decode(reader, reader.uint32());
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.hasDrift = BoolValue.decode(reader, reader.uint32()).value;
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.timeSeriesId = reader.string();
          continue;
        case 9:
          if (tag !== 74) {
            break;
          }

          message.timeSeriesIds.push(reader.string());
          continue;
        case 5:
          if (tag === 40) {
            message.seasonalPeriods.push(reader.int32() as any);

            continue;
          }

          if (tag === 42) {
            const end2 = reader.uint32() + reader.pos;
            while (reader.pos < end2) {
              message.seasonalPeriods.push(reader.int32() as any);
            }

            continue;
          }

          break;
        case 6:
          if (tag !== 50) {
            break;
          }

          message.hasHolidayEffect = BoolValue.decode(reader, reader.uint32()).value;
          continue;
        case 7:
          if (tag !== 58) {
            break;
          }

          message.hasSpikesAndDips = BoolValue.decode(reader, reader.uint32()).value;
          continue;
        case 8:
          if (tag !== 66) {
            break;
          }

          message.hasStepChanges = BoolValue.decode(reader, reader.uint32()).value;
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Model_ArimaForecastingMetrics_ArimaSingleModelForecastingMetrics {
    return {
      nonSeasonalOrder: isSet(object.nonSeasonalOrder) ? Model_ArimaOrder.fromJSON(object.nonSeasonalOrder) : undefined,
      arimaFittingMetrics: isSet(object.arimaFittingMetrics)
        ? Model_ArimaFittingMetrics.fromJSON(object.arimaFittingMetrics)
        : undefined,
      hasDrift: isSet(object.hasDrift) ? Boolean(object.hasDrift) : undefined,
      timeSeriesId: isSet(object.timeSeriesId) ? globalThis.String(object.timeSeriesId) : "",
      timeSeriesIds: globalThis.Array.isArray(object?.timeSeriesIds)
        ? object.timeSeriesIds.map((e: any) => globalThis.String(e))
        : [],
      seasonalPeriods: globalThis.Array.isArray(object?.seasonalPeriods)
        ? object.seasonalPeriods.map((e: any) => model_SeasonalPeriod_SeasonalPeriodTypeFromJSON(e))
        : [],
      hasHolidayEffect: isSet(object.hasHolidayEffect) ? Boolean(object.hasHolidayEffect) : undefined,
      hasSpikesAndDips: isSet(object.hasSpikesAndDips) ? Boolean(object.hasSpikesAndDips) : undefined,
      hasStepChanges: isSet(object.hasStepChanges) ? Boolean(object.hasStepChanges) : undefined,
    };
  },

  toJSON(message: Model_ArimaForecastingMetrics_ArimaSingleModelForecastingMetrics): unknown {
    const obj: any = {};
    if (message.nonSeasonalOrder !== undefined) {
      obj.nonSeasonalOrder = Model_ArimaOrder.toJSON(message.nonSeasonalOrder);
    }
    if (message.arimaFittingMetrics !== undefined) {
      obj.arimaFittingMetrics = Model_ArimaFittingMetrics.toJSON(message.arimaFittingMetrics);
    }
    if (message.hasDrift !== undefined) {
      obj.hasDrift = message.hasDrift;
    }
    if (message.timeSeriesId !== "") {
      obj.timeSeriesId = message.timeSeriesId;
    }
    if (message.timeSeriesIds?.length) {
      obj.timeSeriesIds = message.timeSeriesIds;
    }
    if (message.seasonalPeriods?.length) {
      obj.seasonalPeriods = message.seasonalPeriods.map((e) => model_SeasonalPeriod_SeasonalPeriodTypeToJSON(e));
    }
    if (message.hasHolidayEffect !== undefined) {
      obj.hasHolidayEffect = message.hasHolidayEffect;
    }
    if (message.hasSpikesAndDips !== undefined) {
      obj.hasSpikesAndDips = message.hasSpikesAndDips;
    }
    if (message.hasStepChanges !== undefined) {
      obj.hasStepChanges = message.hasStepChanges;
    }
    return obj;
  },

  create(
    base?: DeepPartial<Model_ArimaForecastingMetrics_ArimaSingleModelForecastingMetrics>,
  ): Model_ArimaForecastingMetrics_ArimaSingleModelForecastingMetrics {
    return Model_ArimaForecastingMetrics_ArimaSingleModelForecastingMetrics.fromPartial(base ?? {});
  },
  fromPartial(
    object: DeepPartial<Model_ArimaForecastingMetrics_ArimaSingleModelForecastingMetrics>,
  ): Model_ArimaForecastingMetrics_ArimaSingleModelForecastingMetrics {
    const message = createBaseModel_ArimaForecastingMetrics_ArimaSingleModelForecastingMetrics();
    message.nonSeasonalOrder = (object.nonSeasonalOrder !== undefined && object.nonSeasonalOrder !== null)
      ? Model_ArimaOrder.fromPartial(object.nonSeasonalOrder)
      : undefined;
    message.arimaFittingMetrics = (object.arimaFittingMetrics !== undefined && object.arimaFittingMetrics !== null)
      ? Model_ArimaFittingMetrics.fromPartial(object.arimaFittingMetrics)
      : undefined;
    message.hasDrift = object.hasDrift ?? undefined;
    message.timeSeriesId = object.timeSeriesId ?? "";
    message.timeSeriesIds = object.timeSeriesIds?.map((e) => e) || [];
    message.seasonalPeriods = object.seasonalPeriods?.map((e) => e) || [];
    message.hasHolidayEffect = object.hasHolidayEffect ?? undefined;
    message.hasSpikesAndDips = object.hasSpikesAndDips ?? undefined;
    message.hasStepChanges = object.hasStepChanges ?? undefined;
    return message;
  },
};

function createBaseModel_DimensionalityReductionMetrics(): Model_DimensionalityReductionMetrics {
  return { totalExplainedVarianceRatio: undefined };
}

export const Model_DimensionalityReductionMetrics: MessageFns<Model_DimensionalityReductionMetrics> = {
  encode(message: Model_DimensionalityReductionMetrics, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.totalExplainedVarianceRatio !== undefined) {
      DoubleValue.encode({ value: message.totalExplainedVarianceRatio! }, writer.uint32(10).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Model_DimensionalityReductionMetrics {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseModel_DimensionalityReductionMetrics();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.totalExplainedVarianceRatio = DoubleValue.decode(reader, reader.uint32()).value;
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Model_DimensionalityReductionMetrics {
    return {
      totalExplainedVarianceRatio: isSet(object.totalExplainedVarianceRatio)
        ? Number(object.totalExplainedVarianceRatio)
        : undefined,
    };
  },

  toJSON(message: Model_DimensionalityReductionMetrics): unknown {
    const obj: any = {};
    if (message.totalExplainedVarianceRatio !== undefined) {
      obj.totalExplainedVarianceRatio = message.totalExplainedVarianceRatio;
    }
    return obj;
  },

  create(base?: DeepPartial<Model_DimensionalityReductionMetrics>): Model_DimensionalityReductionMetrics {
    return Model_DimensionalityReductionMetrics.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<Model_DimensionalityReductionMetrics>): Model_DimensionalityReductionMetrics {
    const message = createBaseModel_DimensionalityReductionMetrics();
    message.totalExplainedVarianceRatio = object.totalExplainedVarianceRatio ?? undefined;
    return message;
  },
};

function createBaseModel_EvaluationMetrics(): Model_EvaluationMetrics {
  return {
    regressionMetrics: undefined,
    binaryClassificationMetrics: undefined,
    multiClassClassificationMetrics: undefined,
    clusteringMetrics: undefined,
    rankingMetrics: undefined,
    arimaForecastingMetrics: undefined,
    dimensionalityReductionMetrics: undefined,
  };
}

export const Model_EvaluationMetrics: MessageFns<Model_EvaluationMetrics> = {
  encode(message: Model_EvaluationMetrics, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.regressionMetrics !== undefined) {
      Model_RegressionMetrics.encode(message.regressionMetrics, writer.uint32(10).fork()).join();
    }
    if (message.binaryClassificationMetrics !== undefined) {
      Model_BinaryClassificationMetrics.encode(message.binaryClassificationMetrics, writer.uint32(18).fork()).join();
    }
    if (message.multiClassClassificationMetrics !== undefined) {
      Model_MultiClassClassificationMetrics.encode(message.multiClassClassificationMetrics, writer.uint32(26).fork())
        .join();
    }
    if (message.clusteringMetrics !== undefined) {
      Model_ClusteringMetrics.encode(message.clusteringMetrics, writer.uint32(34).fork()).join();
    }
    if (message.rankingMetrics !== undefined) {
      Model_RankingMetrics.encode(message.rankingMetrics, writer.uint32(42).fork()).join();
    }
    if (message.arimaForecastingMetrics !== undefined) {
      Model_ArimaForecastingMetrics.encode(message.arimaForecastingMetrics, writer.uint32(50).fork()).join();
    }
    if (message.dimensionalityReductionMetrics !== undefined) {
      Model_DimensionalityReductionMetrics.encode(message.dimensionalityReductionMetrics, writer.uint32(58).fork())
        .join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Model_EvaluationMetrics {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseModel_EvaluationMetrics();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.regressionMetrics = Model_RegressionMetrics.decode(reader, reader.uint32());
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.binaryClassificationMetrics = Model_BinaryClassificationMetrics.decode(reader, reader.uint32());
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.multiClassClassificationMetrics = Model_MultiClassClassificationMetrics.decode(
            reader,
            reader.uint32(),
          );
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.clusteringMetrics = Model_ClusteringMetrics.decode(reader, reader.uint32());
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.rankingMetrics = Model_RankingMetrics.decode(reader, reader.uint32());
          continue;
        case 6:
          if (tag !== 50) {
            break;
          }

          message.arimaForecastingMetrics = Model_ArimaForecastingMetrics.decode(reader, reader.uint32());
          continue;
        case 7:
          if (tag !== 58) {
            break;
          }

          message.dimensionalityReductionMetrics = Model_DimensionalityReductionMetrics.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Model_EvaluationMetrics {
    return {
      regressionMetrics: isSet(object.regressionMetrics)
        ? Model_RegressionMetrics.fromJSON(object.regressionMetrics)
        : undefined,
      binaryClassificationMetrics: isSet(object.binaryClassificationMetrics)
        ? Model_BinaryClassificationMetrics.fromJSON(object.binaryClassificationMetrics)
        : undefined,
      multiClassClassificationMetrics: isSet(object.multiClassClassificationMetrics)
        ? Model_MultiClassClassificationMetrics.fromJSON(object.multiClassClassificationMetrics)
        : undefined,
      clusteringMetrics: isSet(object.clusteringMetrics)
        ? Model_ClusteringMetrics.fromJSON(object.clusteringMetrics)
        : undefined,
      rankingMetrics: isSet(object.rankingMetrics) ? Model_RankingMetrics.fromJSON(object.rankingMetrics) : undefined,
      arimaForecastingMetrics: isSet(object.arimaForecastingMetrics)
        ? Model_ArimaForecastingMetrics.fromJSON(object.arimaForecastingMetrics)
        : undefined,
      dimensionalityReductionMetrics: isSet(object.dimensionalityReductionMetrics)
        ? Model_DimensionalityReductionMetrics.fromJSON(object.dimensionalityReductionMetrics)
        : undefined,
    };
  },

  toJSON(message: Model_EvaluationMetrics): unknown {
    const obj: any = {};
    if (message.regressionMetrics !== undefined) {
      obj.regressionMetrics = Model_RegressionMetrics.toJSON(message.regressionMetrics);
    }
    if (message.binaryClassificationMetrics !== undefined) {
      obj.binaryClassificationMetrics = Model_BinaryClassificationMetrics.toJSON(message.binaryClassificationMetrics);
    }
    if (message.multiClassClassificationMetrics !== undefined) {
      obj.multiClassClassificationMetrics = Model_MultiClassClassificationMetrics.toJSON(
        message.multiClassClassificationMetrics,
      );
    }
    if (message.clusteringMetrics !== undefined) {
      obj.clusteringMetrics = Model_ClusteringMetrics.toJSON(message.clusteringMetrics);
    }
    if (message.rankingMetrics !== undefined) {
      obj.rankingMetrics = Model_RankingMetrics.toJSON(message.rankingMetrics);
    }
    if (message.arimaForecastingMetrics !== undefined) {
      obj.arimaForecastingMetrics = Model_ArimaForecastingMetrics.toJSON(message.arimaForecastingMetrics);
    }
    if (message.dimensionalityReductionMetrics !== undefined) {
      obj.dimensionalityReductionMetrics = Model_DimensionalityReductionMetrics.toJSON(
        message.dimensionalityReductionMetrics,
      );
    }
    return obj;
  },

  create(base?: DeepPartial<Model_EvaluationMetrics>): Model_EvaluationMetrics {
    return Model_EvaluationMetrics.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<Model_EvaluationMetrics>): Model_EvaluationMetrics {
    const message = createBaseModel_EvaluationMetrics();
    message.regressionMetrics = (object.regressionMetrics !== undefined && object.regressionMetrics !== null)
      ? Model_RegressionMetrics.fromPartial(object.regressionMetrics)
      : undefined;
    message.binaryClassificationMetrics =
      (object.binaryClassificationMetrics !== undefined && object.binaryClassificationMetrics !== null)
        ? Model_BinaryClassificationMetrics.fromPartial(object.binaryClassificationMetrics)
        : undefined;
    message.multiClassClassificationMetrics =
      (object.multiClassClassificationMetrics !== undefined && object.multiClassClassificationMetrics !== null)
        ? Model_MultiClassClassificationMetrics.fromPartial(object.multiClassClassificationMetrics)
        : undefined;
    message.clusteringMetrics = (object.clusteringMetrics !== undefined && object.clusteringMetrics !== null)
      ? Model_ClusteringMetrics.fromPartial(object.clusteringMetrics)
      : undefined;
    message.rankingMetrics = (object.rankingMetrics !== undefined && object.rankingMetrics !== null)
      ? Model_RankingMetrics.fromPartial(object.rankingMetrics)
      : undefined;
    message.arimaForecastingMetrics =
      (object.arimaForecastingMetrics !== undefined && object.arimaForecastingMetrics !== null)
        ? Model_ArimaForecastingMetrics.fromPartial(object.arimaForecastingMetrics)
        : undefined;
    message.dimensionalityReductionMetrics =
      (object.dimensionalityReductionMetrics !== undefined && object.dimensionalityReductionMetrics !== null)
        ? Model_DimensionalityReductionMetrics.fromPartial(object.dimensionalityReductionMetrics)
        : undefined;
    return message;
  },
};

function createBaseModel_DataSplitResult(): Model_DataSplitResult {
  return { trainingTable: undefined, evaluationTable: undefined, testTable: undefined };
}

export const Model_DataSplitResult: MessageFns<Model_DataSplitResult> = {
  encode(message: Model_DataSplitResult, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.trainingTable !== undefined) {
      TableReference.encode(message.trainingTable, writer.uint32(10).fork()).join();
    }
    if (message.evaluationTable !== undefined) {
      TableReference.encode(message.evaluationTable, writer.uint32(18).fork()).join();
    }
    if (message.testTable !== undefined) {
      TableReference.encode(message.testTable, writer.uint32(26).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Model_DataSplitResult {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseModel_DataSplitResult();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.trainingTable = TableReference.decode(reader, reader.uint32());
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.evaluationTable = TableReference.decode(reader, reader.uint32());
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.testTable = TableReference.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Model_DataSplitResult {
    return {
      trainingTable: isSet(object.trainingTable) ? TableReference.fromJSON(object.trainingTable) : undefined,
      evaluationTable: isSet(object.evaluationTable) ? TableReference.fromJSON(object.evaluationTable) : undefined,
      testTable: isSet(object.testTable) ? TableReference.fromJSON(object.testTable) : undefined,
    };
  },

  toJSON(message: Model_DataSplitResult): unknown {
    const obj: any = {};
    if (message.trainingTable !== undefined) {
      obj.trainingTable = TableReference.toJSON(message.trainingTable);
    }
    if (message.evaluationTable !== undefined) {
      obj.evaluationTable = TableReference.toJSON(message.evaluationTable);
    }
    if (message.testTable !== undefined) {
      obj.testTable = TableReference.toJSON(message.testTable);
    }
    return obj;
  },

  create(base?: DeepPartial<Model_DataSplitResult>): Model_DataSplitResult {
    return Model_DataSplitResult.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<Model_DataSplitResult>): Model_DataSplitResult {
    const message = createBaseModel_DataSplitResult();
    message.trainingTable = (object.trainingTable !== undefined && object.trainingTable !== null)
      ? TableReference.fromPartial(object.trainingTable)
      : undefined;
    message.evaluationTable = (object.evaluationTable !== undefined && object.evaluationTable !== null)
      ? TableReference.fromPartial(object.evaluationTable)
      : undefined;
    message.testTable = (object.testTable !== undefined && object.testTable !== null)
      ? TableReference.fromPartial(object.testTable)
      : undefined;
    return message;
  },
};

function createBaseModel_ArimaOrder(): Model_ArimaOrder {
  return { p: undefined, d: undefined, q: undefined };
}

export const Model_ArimaOrder: MessageFns<Model_ArimaOrder> = {
  encode(message: Model_ArimaOrder, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.p !== undefined) {
      Int64Value.encode({ value: message.p! }, writer.uint32(10).fork()).join();
    }
    if (message.d !== undefined) {
      Int64Value.encode({ value: message.d! }, writer.uint32(18).fork()).join();
    }
    if (message.q !== undefined) {
      Int64Value.encode({ value: message.q! }, writer.uint32(26).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Model_ArimaOrder {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseModel_ArimaOrder();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.p = Int64Value.decode(reader, reader.uint32()).value;
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.d = Int64Value.decode(reader, reader.uint32()).value;
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.q = Int64Value.decode(reader, reader.uint32()).value;
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Model_ArimaOrder {
    return {
      p: isSet(object.p) ? Long.fromValue(object.p) : undefined,
      d: isSet(object.d) ? Long.fromValue(object.d) : undefined,
      q: isSet(object.q) ? Long.fromValue(object.q) : undefined,
    };
  },

  toJSON(message: Model_ArimaOrder): unknown {
    const obj: any = {};
    if (message.p !== undefined) {
      obj.p = message.p;
    }
    if (message.d !== undefined) {
      obj.d = message.d;
    }
    if (message.q !== undefined) {
      obj.q = message.q;
    }
    return obj;
  },

  create(base?: DeepPartial<Model_ArimaOrder>): Model_ArimaOrder {
    return Model_ArimaOrder.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<Model_ArimaOrder>): Model_ArimaOrder {
    const message = createBaseModel_ArimaOrder();
    message.p = (object.p !== undefined && object.p !== null) ? Long.fromValue(object.p) : undefined;
    message.d = (object.d !== undefined && object.d !== null) ? Long.fromValue(object.d) : undefined;
    message.q = (object.q !== undefined && object.q !== null) ? Long.fromValue(object.q) : undefined;
    return message;
  },
};

function createBaseModel_ArimaFittingMetrics(): Model_ArimaFittingMetrics {
  return { logLikelihood: undefined, aic: undefined, variance: undefined };
}

export const Model_ArimaFittingMetrics: MessageFns<Model_ArimaFittingMetrics> = {
  encode(message: Model_ArimaFittingMetrics, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.logLikelihood !== undefined) {
      DoubleValue.encode({ value: message.logLikelihood! }, writer.uint32(10).fork()).join();
    }
    if (message.aic !== undefined) {
      DoubleValue.encode({ value: message.aic! }, writer.uint32(18).fork()).join();
    }
    if (message.variance !== undefined) {
      DoubleValue.encode({ value: message.variance! }, writer.uint32(26).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Model_ArimaFittingMetrics {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseModel_ArimaFittingMetrics();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.logLikelihood = DoubleValue.decode(reader, reader.uint32()).value;
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.aic = DoubleValue.decode(reader, reader.uint32()).value;
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.variance = DoubleValue.decode(reader, reader.uint32()).value;
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Model_ArimaFittingMetrics {
    return {
      logLikelihood: isSet(object.logLikelihood) ? Number(object.logLikelihood) : undefined,
      aic: isSet(object.aic) ? Number(object.aic) : undefined,
      variance: isSet(object.variance) ? Number(object.variance) : undefined,
    };
  },

  toJSON(message: Model_ArimaFittingMetrics): unknown {
    const obj: any = {};
    if (message.logLikelihood !== undefined) {
      obj.logLikelihood = message.logLikelihood;
    }
    if (message.aic !== undefined) {
      obj.aic = message.aic;
    }
    if (message.variance !== undefined) {
      obj.variance = message.variance;
    }
    return obj;
  },

  create(base?: DeepPartial<Model_ArimaFittingMetrics>): Model_ArimaFittingMetrics {
    return Model_ArimaFittingMetrics.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<Model_ArimaFittingMetrics>): Model_ArimaFittingMetrics {
    const message = createBaseModel_ArimaFittingMetrics();
    message.logLikelihood = object.logLikelihood ?? undefined;
    message.aic = object.aic ?? undefined;
    message.variance = object.variance ?? undefined;
    return message;
  },
};

function createBaseModel_GlobalExplanation(): Model_GlobalExplanation {
  return { explanations: [], classLabel: "" };
}

export const Model_GlobalExplanation: MessageFns<Model_GlobalExplanation> = {
  encode(message: Model_GlobalExplanation, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.explanations) {
      Model_GlobalExplanation_Explanation.encode(v!, writer.uint32(10).fork()).join();
    }
    if (message.classLabel !== "") {
      writer.uint32(18).string(message.classLabel);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Model_GlobalExplanation {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseModel_GlobalExplanation();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.explanations.push(Model_GlobalExplanation_Explanation.decode(reader, reader.uint32()));
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.classLabel = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Model_GlobalExplanation {
    return {
      explanations: globalThis.Array.isArray(object?.explanations)
        ? object.explanations.map((e: any) => Model_GlobalExplanation_Explanation.fromJSON(e))
        : [],
      classLabel: isSet(object.classLabel) ? globalThis.String(object.classLabel) : "",
    };
  },

  toJSON(message: Model_GlobalExplanation): unknown {
    const obj: any = {};
    if (message.explanations?.length) {
      obj.explanations = message.explanations.map((e) => Model_GlobalExplanation_Explanation.toJSON(e));
    }
    if (message.classLabel !== "") {
      obj.classLabel = message.classLabel;
    }
    return obj;
  },

  create(base?: DeepPartial<Model_GlobalExplanation>): Model_GlobalExplanation {
    return Model_GlobalExplanation.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<Model_GlobalExplanation>): Model_GlobalExplanation {
    const message = createBaseModel_GlobalExplanation();
    message.explanations = object.explanations?.map((e) => Model_GlobalExplanation_Explanation.fromPartial(e)) || [];
    message.classLabel = object.classLabel ?? "";
    return message;
  },
};

function createBaseModel_GlobalExplanation_Explanation(): Model_GlobalExplanation_Explanation {
  return { featureName: "", attribution: undefined };
}

export const Model_GlobalExplanation_Explanation: MessageFns<Model_GlobalExplanation_Explanation> = {
  encode(message: Model_GlobalExplanation_Explanation, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.featureName !== "") {
      writer.uint32(10).string(message.featureName);
    }
    if (message.attribution !== undefined) {
      DoubleValue.encode({ value: message.attribution! }, writer.uint32(18).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Model_GlobalExplanation_Explanation {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseModel_GlobalExplanation_Explanation();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.featureName = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.attribution = DoubleValue.decode(reader, reader.uint32()).value;
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Model_GlobalExplanation_Explanation {
    return {
      featureName: isSet(object.featureName) ? globalThis.String(object.featureName) : "",
      attribution: isSet(object.attribution) ? Number(object.attribution) : undefined,
    };
  },

  toJSON(message: Model_GlobalExplanation_Explanation): unknown {
    const obj: any = {};
    if (message.featureName !== "") {
      obj.featureName = message.featureName;
    }
    if (message.attribution !== undefined) {
      obj.attribution = message.attribution;
    }
    return obj;
  },

  create(base?: DeepPartial<Model_GlobalExplanation_Explanation>): Model_GlobalExplanation_Explanation {
    return Model_GlobalExplanation_Explanation.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<Model_GlobalExplanation_Explanation>): Model_GlobalExplanation_Explanation {
    const message = createBaseModel_GlobalExplanation_Explanation();
    message.featureName = object.featureName ?? "";
    message.attribution = object.attribution ?? undefined;
    return message;
  },
};

function createBaseModel_CategoryEncodingMethod(): Model_CategoryEncodingMethod {
  return {};
}

export const Model_CategoryEncodingMethod: MessageFns<Model_CategoryEncodingMethod> = {
  encode(_: Model_CategoryEncodingMethod, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Model_CategoryEncodingMethod {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseModel_CategoryEncodingMethod();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(_: any): Model_CategoryEncodingMethod {
    return {};
  },

  toJSON(_: Model_CategoryEncodingMethod): unknown {
    const obj: any = {};
    return obj;
  },

  create(base?: DeepPartial<Model_CategoryEncodingMethod>): Model_CategoryEncodingMethod {
    return Model_CategoryEncodingMethod.fromPartial(base ?? {});
  },
  fromPartial(_: DeepPartial<Model_CategoryEncodingMethod>): Model_CategoryEncodingMethod {
    const message = createBaseModel_CategoryEncodingMethod();
    return message;
  },
};

function createBaseModel_PcaSolverOptionEnums(): Model_PcaSolverOptionEnums {
  return {};
}

export const Model_PcaSolverOptionEnums: MessageFns<Model_PcaSolverOptionEnums> = {
  encode(_: Model_PcaSolverOptionEnums, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Model_PcaSolverOptionEnums {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseModel_PcaSolverOptionEnums();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(_: any): Model_PcaSolverOptionEnums {
    return {};
  },

  toJSON(_: Model_PcaSolverOptionEnums): unknown {
    const obj: any = {};
    return obj;
  },

  create(base?: DeepPartial<Model_PcaSolverOptionEnums>): Model_PcaSolverOptionEnums {
    return Model_PcaSolverOptionEnums.fromPartial(base ?? {});
  },
  fromPartial(_: DeepPartial<Model_PcaSolverOptionEnums>): Model_PcaSolverOptionEnums {
    const message = createBaseModel_PcaSolverOptionEnums();
    return message;
  },
};

function createBaseModel_ModelRegistryOptionEnums(): Model_ModelRegistryOptionEnums {
  return {};
}

export const Model_ModelRegistryOptionEnums: MessageFns<Model_ModelRegistryOptionEnums> = {
  encode(_: Model_ModelRegistryOptionEnums, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Model_ModelRegistryOptionEnums {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseModel_ModelRegistryOptionEnums();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(_: any): Model_ModelRegistryOptionEnums {
    return {};
  },

  toJSON(_: Model_ModelRegistryOptionEnums): unknown {
    const obj: any = {};
    return obj;
  },

  create(base?: DeepPartial<Model_ModelRegistryOptionEnums>): Model_ModelRegistryOptionEnums {
    return Model_ModelRegistryOptionEnums.fromPartial(base ?? {});
  },
  fromPartial(_: DeepPartial<Model_ModelRegistryOptionEnums>): Model_ModelRegistryOptionEnums {
    const message = createBaseModel_ModelRegistryOptionEnums();
    return message;
  },
};

function createBaseModel_TrainingRun(): Model_TrainingRun {
  return {
    trainingOptions: undefined,
    startTime: undefined,
    results: [],
    evaluationMetrics: undefined,
    dataSplitResult: undefined,
    modelLevelGlobalExplanation: undefined,
    classLevelGlobalExplanations: [],
    vertexAiModelId: "",
    vertexAiModelVersion: "",
  };
}

export const Model_TrainingRun: MessageFns<Model_TrainingRun> = {
  encode(message: Model_TrainingRun, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.trainingOptions !== undefined) {
      Model_TrainingRun_TrainingOptions.encode(message.trainingOptions, writer.uint32(10).fork()).join();
    }
    if (message.startTime !== undefined) {
      Timestamp.encode(toTimestamp(message.startTime), writer.uint32(66).fork()).join();
    }
    for (const v of message.results) {
      Model_TrainingRun_IterationResult.encode(v!, writer.uint32(50).fork()).join();
    }
    if (message.evaluationMetrics !== undefined) {
      Model_EvaluationMetrics.encode(message.evaluationMetrics, writer.uint32(58).fork()).join();
    }
    if (message.dataSplitResult !== undefined) {
      Model_DataSplitResult.encode(message.dataSplitResult, writer.uint32(74).fork()).join();
    }
    if (message.modelLevelGlobalExplanation !== undefined) {
      Model_GlobalExplanation.encode(message.modelLevelGlobalExplanation, writer.uint32(90).fork()).join();
    }
    for (const v of message.classLevelGlobalExplanations) {
      Model_GlobalExplanation.encode(v!, writer.uint32(98).fork()).join();
    }
    if (message.vertexAiModelId !== "") {
      writer.uint32(114).string(message.vertexAiModelId);
    }
    if (message.vertexAiModelVersion !== "") {
      writer.uint32(122).string(message.vertexAiModelVersion);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Model_TrainingRun {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseModel_TrainingRun();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.trainingOptions = Model_TrainingRun_TrainingOptions.decode(reader, reader.uint32());
          continue;
        case 8:
          if (tag !== 66) {
            break;
          }

          message.startTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        case 6:
          if (tag !== 50) {
            break;
          }

          message.results.push(Model_TrainingRun_IterationResult.decode(reader, reader.uint32()));
          continue;
        case 7:
          if (tag !== 58) {
            break;
          }

          message.evaluationMetrics = Model_EvaluationMetrics.decode(reader, reader.uint32());
          continue;
        case 9:
          if (tag !== 74) {
            break;
          }

          message.dataSplitResult = Model_DataSplitResult.decode(reader, reader.uint32());
          continue;
        case 11:
          if (tag !== 90) {
            break;
          }

          message.modelLevelGlobalExplanation = Model_GlobalExplanation.decode(reader, reader.uint32());
          continue;
        case 12:
          if (tag !== 98) {
            break;
          }

          message.classLevelGlobalExplanations.push(Model_GlobalExplanation.decode(reader, reader.uint32()));
          continue;
        case 14:
          if (tag !== 114) {
            break;
          }

          message.vertexAiModelId = reader.string();
          continue;
        case 15:
          if (tag !== 122) {
            break;
          }

          message.vertexAiModelVersion = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Model_TrainingRun {
    return {
      trainingOptions: isSet(object.trainingOptions)
        ? Model_TrainingRun_TrainingOptions.fromJSON(object.trainingOptions)
        : undefined,
      startTime: isSet(object.startTime) ? fromJsonTimestamp(object.startTime) : undefined,
      results: globalThis.Array.isArray(object?.results)
        ? object.results.map((e: any) => Model_TrainingRun_IterationResult.fromJSON(e))
        : [],
      evaluationMetrics: isSet(object.evaluationMetrics)
        ? Model_EvaluationMetrics.fromJSON(object.evaluationMetrics)
        : undefined,
      dataSplitResult: isSet(object.dataSplitResult)
        ? Model_DataSplitResult.fromJSON(object.dataSplitResult)
        : undefined,
      modelLevelGlobalExplanation: isSet(object.modelLevelGlobalExplanation)
        ? Model_GlobalExplanation.fromJSON(object.modelLevelGlobalExplanation)
        : undefined,
      classLevelGlobalExplanations: globalThis.Array.isArray(object?.classLevelGlobalExplanations)
        ? object.classLevelGlobalExplanations.map((e: any) => Model_GlobalExplanation.fromJSON(e))
        : [],
      vertexAiModelId: isSet(object.vertexAiModelId) ? globalThis.String(object.vertexAiModelId) : "",
      vertexAiModelVersion: isSet(object.vertexAiModelVersion) ? globalThis.String(object.vertexAiModelVersion) : "",
    };
  },

  toJSON(message: Model_TrainingRun): unknown {
    const obj: any = {};
    if (message.trainingOptions !== undefined) {
      obj.trainingOptions = Model_TrainingRun_TrainingOptions.toJSON(message.trainingOptions);
    }
    if (message.startTime !== undefined) {
      obj.startTime = message.startTime.toISOString();
    }
    if (message.results?.length) {
      obj.results = message.results.map((e) => Model_TrainingRun_IterationResult.toJSON(e));
    }
    if (message.evaluationMetrics !== undefined) {
      obj.evaluationMetrics = Model_EvaluationMetrics.toJSON(message.evaluationMetrics);
    }
    if (message.dataSplitResult !== undefined) {
      obj.dataSplitResult = Model_DataSplitResult.toJSON(message.dataSplitResult);
    }
    if (message.modelLevelGlobalExplanation !== undefined) {
      obj.modelLevelGlobalExplanation = Model_GlobalExplanation.toJSON(message.modelLevelGlobalExplanation);
    }
    if (message.classLevelGlobalExplanations?.length) {
      obj.classLevelGlobalExplanations = message.classLevelGlobalExplanations.map((e) =>
        Model_GlobalExplanation.toJSON(e)
      );
    }
    if (message.vertexAiModelId !== "") {
      obj.vertexAiModelId = message.vertexAiModelId;
    }
    if (message.vertexAiModelVersion !== "") {
      obj.vertexAiModelVersion = message.vertexAiModelVersion;
    }
    return obj;
  },

  create(base?: DeepPartial<Model_TrainingRun>): Model_TrainingRun {
    return Model_TrainingRun.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<Model_TrainingRun>): Model_TrainingRun {
    const message = createBaseModel_TrainingRun();
    message.trainingOptions = (object.trainingOptions !== undefined && object.trainingOptions !== null)
      ? Model_TrainingRun_TrainingOptions.fromPartial(object.trainingOptions)
      : undefined;
    message.startTime = object.startTime ?? undefined;
    message.results = object.results?.map((e) => Model_TrainingRun_IterationResult.fromPartial(e)) || [];
    message.evaluationMetrics = (object.evaluationMetrics !== undefined && object.evaluationMetrics !== null)
      ? Model_EvaluationMetrics.fromPartial(object.evaluationMetrics)
      : undefined;
    message.dataSplitResult = (object.dataSplitResult !== undefined && object.dataSplitResult !== null)
      ? Model_DataSplitResult.fromPartial(object.dataSplitResult)
      : undefined;
    message.modelLevelGlobalExplanation =
      (object.modelLevelGlobalExplanation !== undefined && object.modelLevelGlobalExplanation !== null)
        ? Model_GlobalExplanation.fromPartial(object.modelLevelGlobalExplanation)
        : undefined;
    message.classLevelGlobalExplanations =
      object.classLevelGlobalExplanations?.map((e) => Model_GlobalExplanation.fromPartial(e)) || [];
    message.vertexAiModelId = object.vertexAiModelId ?? "";
    message.vertexAiModelVersion = object.vertexAiModelVersion ?? "";
    return message;
  },
};

function createBaseModel_TrainingRun_TrainingOptions(): Model_TrainingRun_TrainingOptions {
  return {
    maxIterations: Long.ZERO,
    lossType: 0,
    learnRate: 0,
    l1Regularization: undefined,
    l2Regularization: undefined,
    minRelativeProgress: undefined,
    warmStart: undefined,
    earlyStop: undefined,
    inputLabelColumns: [],
    dataSplitMethod: 0,
    dataSplitEvalFraction: 0,
    dataSplitColumn: "",
    learnRateStrategy: 0,
    initialLearnRate: 0,
    labelClassWeights: {},
    userColumn: "",
    itemColumn: "",
    distanceType: 0,
    numClusters: Long.ZERO,
    modelUri: "",
    optimizationStrategy: 0,
    hiddenUnits: [],
    batchSize: Long.ZERO,
    dropout: undefined,
    maxTreeDepth: Long.ZERO,
    subsample: 0,
    minSplitLoss: undefined,
    boosterType: 0,
    numParallelTree: undefined,
    dartNormalizeType: 0,
    treeMethod: 0,
    minTreeChildWeight: undefined,
    colsampleBytree: undefined,
    colsampleBylevel: undefined,
    colsampleBynode: undefined,
    numFactors: Long.ZERO,
    feedbackType: 0,
    walsAlpha: undefined,
    kmeansInitializationMethod: 0,
    kmeansInitializationColumn: "",
    timeSeriesTimestampColumn: "",
    timeSeriesDataColumn: "",
    autoArima: undefined,
    nonSeasonalOrder: undefined,
    dataFrequency: 0,
    calculatePValues: undefined,
    includeDrift: undefined,
    holidayRegion: 0,
    holidayRegions: [],
    timeSeriesIdColumn: "",
    timeSeriesIdColumns: [],
    horizon: Long.ZERO,
    autoArimaMaxOrder: Long.ZERO,
    autoArimaMinOrder: Long.ZERO,
    numTrials: Long.ZERO,
    maxParallelTrials: Long.ZERO,
    hparamTuningObjectives: [],
    decomposeTimeSeries: undefined,
    cleanSpikesAndDips: undefined,
    adjustStepChanges: undefined,
    enableGlobalExplain: undefined,
    sampledShapleyNumPaths: Long.ZERO,
    integratedGradientsNumSteps: Long.ZERO,
    categoryEncodingMethod: 0,
    tfVersion: "",
    colorSpace: 0,
    instanceWeightColumn: "",
    trendSmoothingWindowSize: Long.ZERO,
    timeSeriesLengthFraction: 0,
    minTimeSeriesLength: Long.ZERO,
    maxTimeSeriesLength: Long.ZERO,
    xgboostVersion: "",
    approxGlobalFeatureContrib: undefined,
    fitIntercept: undefined,
    numPrincipalComponents: Long.ZERO,
    pcaExplainedVarianceRatio: 0,
    scaleFeatures: undefined,
    pcaSolver: 0,
    autoClassWeights: undefined,
    activationFn: "",
    optimizer: "",
    budgetHours: 0,
    standardizeFeatures: undefined,
    l1RegActivation: 0,
    modelRegistry: 0,
    vertexAiModelVersionAliases: [],
  };
}

export const Model_TrainingRun_TrainingOptions: MessageFns<Model_TrainingRun_TrainingOptions> = {
  encode(message: Model_TrainingRun_TrainingOptions, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (!message.maxIterations.equals(Long.ZERO)) {
      writer.uint32(8).int64(message.maxIterations.toString());
    }
    if (message.lossType !== 0) {
      writer.uint32(16).int32(message.lossType);
    }
    if (message.learnRate !== 0) {
      writer.uint32(25).double(message.learnRate);
    }
    if (message.l1Regularization !== undefined) {
      DoubleValue.encode({ value: message.l1Regularization! }, writer.uint32(34).fork()).join();
    }
    if (message.l2Regularization !== undefined) {
      DoubleValue.encode({ value: message.l2Regularization! }, writer.uint32(42).fork()).join();
    }
    if (message.minRelativeProgress !== undefined) {
      DoubleValue.encode({ value: message.minRelativeProgress! }, writer.uint32(50).fork()).join();
    }
    if (message.warmStart !== undefined) {
      BoolValue.encode({ value: message.warmStart! }, writer.uint32(58).fork()).join();
    }
    if (message.earlyStop !== undefined) {
      BoolValue.encode({ value: message.earlyStop! }, writer.uint32(66).fork()).join();
    }
    for (const v of message.inputLabelColumns) {
      writer.uint32(74).string(v!);
    }
    if (message.dataSplitMethod !== 0) {
      writer.uint32(80).int32(message.dataSplitMethod);
    }
    if (message.dataSplitEvalFraction !== 0) {
      writer.uint32(89).double(message.dataSplitEvalFraction);
    }
    if (message.dataSplitColumn !== "") {
      writer.uint32(98).string(message.dataSplitColumn);
    }
    if (message.learnRateStrategy !== 0) {
      writer.uint32(104).int32(message.learnRateStrategy);
    }
    if (message.initialLearnRate !== 0) {
      writer.uint32(129).double(message.initialLearnRate);
    }
    Object.entries(message.labelClassWeights).forEach(([key, value]) => {
      Model_TrainingRun_TrainingOptions_LabelClassWeightsEntry.encode(
        { key: key as any, value },
        writer.uint32(138).fork(),
      ).join();
    });
    if (message.userColumn !== "") {
      writer.uint32(146).string(message.userColumn);
    }
    if (message.itemColumn !== "") {
      writer.uint32(154).string(message.itemColumn);
    }
    if (message.distanceType !== 0) {
      writer.uint32(160).int32(message.distanceType);
    }
    if (!message.numClusters.equals(Long.ZERO)) {
      writer.uint32(168).int64(message.numClusters.toString());
    }
    if (message.modelUri !== "") {
      writer.uint32(178).string(message.modelUri);
    }
    if (message.optimizationStrategy !== 0) {
      writer.uint32(184).int32(message.optimizationStrategy);
    }
    writer.uint32(194).fork();
    for (const v of message.hiddenUnits) {
      writer.int64(v.toString());
    }
    writer.join();
    if (!message.batchSize.equals(Long.ZERO)) {
      writer.uint32(200).int64(message.batchSize.toString());
    }
    if (message.dropout !== undefined) {
      DoubleValue.encode({ value: message.dropout! }, writer.uint32(210).fork()).join();
    }
    if (!message.maxTreeDepth.equals(Long.ZERO)) {
      writer.uint32(216).int64(message.maxTreeDepth.toString());
    }
    if (message.subsample !== 0) {
      writer.uint32(225).double(message.subsample);
    }
    if (message.minSplitLoss !== undefined) {
      DoubleValue.encode({ value: message.minSplitLoss! }, writer.uint32(234).fork()).join();
    }
    if (message.boosterType !== 0) {
      writer.uint32(480).int32(message.boosterType);
    }
    if (message.numParallelTree !== undefined) {
      Int64Value.encode({ value: message.numParallelTree! }, writer.uint32(490).fork()).join();
    }
    if (message.dartNormalizeType !== 0) {
      writer.uint32(496).int32(message.dartNormalizeType);
    }
    if (message.treeMethod !== 0) {
      writer.uint32(504).int32(message.treeMethod);
    }
    if (message.minTreeChildWeight !== undefined) {
      Int64Value.encode({ value: message.minTreeChildWeight! }, writer.uint32(514).fork()).join();
    }
    if (message.colsampleBytree !== undefined) {
      DoubleValue.encode({ value: message.colsampleBytree! }, writer.uint32(522).fork()).join();
    }
    if (message.colsampleBylevel !== undefined) {
      DoubleValue.encode({ value: message.colsampleBylevel! }, writer.uint32(530).fork()).join();
    }
    if (message.colsampleBynode !== undefined) {
      DoubleValue.encode({ value: message.colsampleBynode! }, writer.uint32(538).fork()).join();
    }
    if (!message.numFactors.equals(Long.ZERO)) {
      writer.uint32(240).int64(message.numFactors.toString());
    }
    if (message.feedbackType !== 0) {
      writer.uint32(248).int32(message.feedbackType);
    }
    if (message.walsAlpha !== undefined) {
      DoubleValue.encode({ value: message.walsAlpha! }, writer.uint32(258).fork()).join();
    }
    if (message.kmeansInitializationMethod !== 0) {
      writer.uint32(264).int32(message.kmeansInitializationMethod);
    }
    if (message.kmeansInitializationColumn !== "") {
      writer.uint32(274).string(message.kmeansInitializationColumn);
    }
    if (message.timeSeriesTimestampColumn !== "") {
      writer.uint32(282).string(message.timeSeriesTimestampColumn);
    }
    if (message.timeSeriesDataColumn !== "") {
      writer.uint32(290).string(message.timeSeriesDataColumn);
    }
    if (message.autoArima !== undefined) {
      BoolValue.encode({ value: message.autoArima! }, writer.uint32(298).fork()).join();
    }
    if (message.nonSeasonalOrder !== undefined) {
      Model_ArimaOrder.encode(message.nonSeasonalOrder, writer.uint32(306).fork()).join();
    }
    if (message.dataFrequency !== 0) {
      writer.uint32(312).int32(message.dataFrequency);
    }
    if (message.calculatePValues !== undefined) {
      BoolValue.encode({ value: message.calculatePValues! }, writer.uint32(322).fork()).join();
    }
    if (message.includeDrift !== undefined) {
      BoolValue.encode({ value: message.includeDrift! }, writer.uint32(330).fork()).join();
    }
    if (message.holidayRegion !== 0) {
      writer.uint32(336).int32(message.holidayRegion);
    }
    writer.uint32(570).fork();
    for (const v of message.holidayRegions) {
      writer.int32(v);
    }
    writer.join();
    if (message.timeSeriesIdColumn !== "") {
      writer.uint32(346).string(message.timeSeriesIdColumn);
    }
    for (const v of message.timeSeriesIdColumns) {
      writer.uint32(410).string(v!);
    }
    if (!message.horizon.equals(Long.ZERO)) {
      writer.uint32(352).int64(message.horizon.toString());
    }
    if (!message.autoArimaMaxOrder.equals(Long.ZERO)) {
      writer.uint32(368).int64(message.autoArimaMaxOrder.toString());
    }
    if (!message.autoArimaMinOrder.equals(Long.ZERO)) {
      writer.uint32(664).int64(message.autoArimaMinOrder.toString());
    }
    if (!message.numTrials.equals(Long.ZERO)) {
      writer.uint32(376).int64(message.numTrials.toString());
    }
    if (!message.maxParallelTrials.equals(Long.ZERO)) {
      writer.uint32(384).int64(message.maxParallelTrials.toString());
    }
    writer.uint32(434).fork();
    for (const v of message.hparamTuningObjectives) {
      writer.int32(v);
    }
    writer.join();
    if (message.decomposeTimeSeries !== undefined) {
      BoolValue.encode({ value: message.decomposeTimeSeries! }, writer.uint32(402).fork()).join();
    }
    if (message.cleanSpikesAndDips !== undefined) {
      BoolValue.encode({ value: message.cleanSpikesAndDips! }, writer.uint32(418).fork()).join();
    }
    if (message.adjustStepChanges !== undefined) {
      BoolValue.encode({ value: message.adjustStepChanges! }, writer.uint32(426).fork()).join();
    }
    if (message.enableGlobalExplain !== undefined) {
      BoolValue.encode({ value: message.enableGlobalExplain! }, writer.uint32(442).fork()).join();
    }
    if (!message.sampledShapleyNumPaths.equals(Long.ZERO)) {
      writer.uint32(448).int64(message.sampledShapleyNumPaths.toString());
    }
    if (!message.integratedGradientsNumSteps.equals(Long.ZERO)) {
      writer.uint32(456).int64(message.integratedGradientsNumSteps.toString());
    }
    if (message.categoryEncodingMethod !== 0) {
      writer.uint32(464).int32(message.categoryEncodingMethod);
    }
    if (message.tfVersion !== "") {
      writer.uint32(562).string(message.tfVersion);
    }
    if (message.colorSpace !== 0) {
      writer.uint32(576).int32(message.colorSpace);
    }
    if (message.instanceWeightColumn !== "") {
      writer.uint32(586).string(message.instanceWeightColumn);
    }
    if (!message.trendSmoothingWindowSize.equals(Long.ZERO)) {
      writer.uint32(592).int64(message.trendSmoothingWindowSize.toString());
    }
    if (message.timeSeriesLengthFraction !== 0) {
      writer.uint32(601).double(message.timeSeriesLengthFraction);
    }
    if (!message.minTimeSeriesLength.equals(Long.ZERO)) {
      writer.uint32(608).int64(message.minTimeSeriesLength.toString());
    }
    if (!message.maxTimeSeriesLength.equals(Long.ZERO)) {
      writer.uint32(616).int64(message.maxTimeSeriesLength.toString());
    }
    if (message.xgboostVersion !== "") {
      writer.uint32(626).string(message.xgboostVersion);
    }
    if (message.approxGlobalFeatureContrib !== undefined) {
      BoolValue.encode({ value: message.approxGlobalFeatureContrib! }, writer.uint32(674).fork()).join();
    }
    if (message.fitIntercept !== undefined) {
      BoolValue.encode({ value: message.fitIntercept! }, writer.uint32(682).fork()).join();
    }
    if (!message.numPrincipalComponents.equals(Long.ZERO)) {
      writer.uint32(688).int64(message.numPrincipalComponents.toString());
    }
    if (message.pcaExplainedVarianceRatio !== 0) {
      writer.uint32(697).double(message.pcaExplainedVarianceRatio);
    }
    if (message.scaleFeatures !== undefined) {
      BoolValue.encode({ value: message.scaleFeatures! }, writer.uint32(706).fork()).join();
    }
    if (message.pcaSolver !== 0) {
      writer.uint32(712).int32(message.pcaSolver);
    }
    if (message.autoClassWeights !== undefined) {
      BoolValue.encode({ value: message.autoClassWeights! }, writer.uint32(722).fork()).join();
    }
    if (message.activationFn !== "") {
      writer.uint32(730).string(message.activationFn);
    }
    if (message.optimizer !== "") {
      writer.uint32(738).string(message.optimizer);
    }
    if (message.budgetHours !== 0) {
      writer.uint32(745).double(message.budgetHours);
    }
    if (message.standardizeFeatures !== undefined) {
      BoolValue.encode({ value: message.standardizeFeatures! }, writer.uint32(754).fork()).join();
    }
    if (message.l1RegActivation !== 0) {
      writer.uint32(761).double(message.l1RegActivation);
    }
    if (message.modelRegistry !== 0) {
      writer.uint32(768).int32(message.modelRegistry);
    }
    for (const v of message.vertexAiModelVersionAliases) {
      writer.uint32(778).string(v!);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Model_TrainingRun_TrainingOptions {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseModel_TrainingRun_TrainingOptions();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 8) {
            break;
          }

          message.maxIterations = Long.fromString(reader.int64().toString());
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.lossType = reader.int32() as any;
          continue;
        case 3:
          if (tag !== 25) {
            break;
          }

          message.learnRate = reader.double();
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.l1Regularization = DoubleValue.decode(reader, reader.uint32()).value;
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.l2Regularization = DoubleValue.decode(reader, reader.uint32()).value;
          continue;
        case 6:
          if (tag !== 50) {
            break;
          }

          message.minRelativeProgress = DoubleValue.decode(reader, reader.uint32()).value;
          continue;
        case 7:
          if (tag !== 58) {
            break;
          }

          message.warmStart = BoolValue.decode(reader, reader.uint32()).value;
          continue;
        case 8:
          if (tag !== 66) {
            break;
          }

          message.earlyStop = BoolValue.decode(reader, reader.uint32()).value;
          continue;
        case 9:
          if (tag !== 74) {
            break;
          }

          message.inputLabelColumns.push(reader.string());
          continue;
        case 10:
          if (tag !== 80) {
            break;
          }

          message.dataSplitMethod = reader.int32() as any;
          continue;
        case 11:
          if (tag !== 89) {
            break;
          }

          message.dataSplitEvalFraction = reader.double();
          continue;
        case 12:
          if (tag !== 98) {
            break;
          }

          message.dataSplitColumn = reader.string();
          continue;
        case 13:
          if (tag !== 104) {
            break;
          }

          message.learnRateStrategy = reader.int32() as any;
          continue;
        case 16:
          if (tag !== 129) {
            break;
          }

          message.initialLearnRate = reader.double();
          continue;
        case 17:
          if (tag !== 138) {
            break;
          }

          const entry17 = Model_TrainingRun_TrainingOptions_LabelClassWeightsEntry.decode(reader, reader.uint32());
          if (entry17.value !== undefined) {
            message.labelClassWeights[entry17.key] = entry17.value;
          }
          continue;
        case 18:
          if (tag !== 146) {
            break;
          }

          message.userColumn = reader.string();
          continue;
        case 19:
          if (tag !== 154) {
            break;
          }

          message.itemColumn = reader.string();
          continue;
        case 20:
          if (tag !== 160) {
            break;
          }

          message.distanceType = reader.int32() as any;
          continue;
        case 21:
          if (tag !== 168) {
            break;
          }

          message.numClusters = Long.fromString(reader.int64().toString());
          continue;
        case 22:
          if (tag !== 178) {
            break;
          }

          message.modelUri = reader.string();
          continue;
        case 23:
          if (tag !== 184) {
            break;
          }

          message.optimizationStrategy = reader.int32() as any;
          continue;
        case 24:
          if (tag === 192) {
            message.hiddenUnits.push(Long.fromString(reader.int64().toString()));

            continue;
          }

          if (tag === 194) {
            const end2 = reader.uint32() + reader.pos;
            while (reader.pos < end2) {
              message.hiddenUnits.push(Long.fromString(reader.int64().toString()));
            }

            continue;
          }

          break;
        case 25:
          if (tag !== 200) {
            break;
          }

          message.batchSize = Long.fromString(reader.int64().toString());
          continue;
        case 26:
          if (tag !== 210) {
            break;
          }

          message.dropout = DoubleValue.decode(reader, reader.uint32()).value;
          continue;
        case 27:
          if (tag !== 216) {
            break;
          }

          message.maxTreeDepth = Long.fromString(reader.int64().toString());
          continue;
        case 28:
          if (tag !== 225) {
            break;
          }

          message.subsample = reader.double();
          continue;
        case 29:
          if (tag !== 234) {
            break;
          }

          message.minSplitLoss = DoubleValue.decode(reader, reader.uint32()).value;
          continue;
        case 60:
          if (tag !== 480) {
            break;
          }

          message.boosterType = reader.int32() as any;
          continue;
        case 61:
          if (tag !== 490) {
            break;
          }

          message.numParallelTree = Int64Value.decode(reader, reader.uint32()).value;
          continue;
        case 62:
          if (tag !== 496) {
            break;
          }

          message.dartNormalizeType = reader.int32() as any;
          continue;
        case 63:
          if (tag !== 504) {
            break;
          }

          message.treeMethod = reader.int32() as any;
          continue;
        case 64:
          if (tag !== 514) {
            break;
          }

          message.minTreeChildWeight = Int64Value.decode(reader, reader.uint32()).value;
          continue;
        case 65:
          if (tag !== 522) {
            break;
          }

          message.colsampleBytree = DoubleValue.decode(reader, reader.uint32()).value;
          continue;
        case 66:
          if (tag !== 530) {
            break;
          }

          message.colsampleBylevel = DoubleValue.decode(reader, reader.uint32()).value;
          continue;
        case 67:
          if (tag !== 538) {
            break;
          }

          message.colsampleBynode = DoubleValue.decode(reader, reader.uint32()).value;
          continue;
        case 30:
          if (tag !== 240) {
            break;
          }

          message.numFactors = Long.fromString(reader.int64().toString());
          continue;
        case 31:
          if (tag !== 248) {
            break;
          }

          message.feedbackType = reader.int32() as any;
          continue;
        case 32:
          if (tag !== 258) {
            break;
          }

          message.walsAlpha = DoubleValue.decode(reader, reader.uint32()).value;
          continue;
        case 33:
          if (tag !== 264) {
            break;
          }

          message.kmeansInitializationMethod = reader.int32() as any;
          continue;
        case 34:
          if (tag !== 274) {
            break;
          }

          message.kmeansInitializationColumn = reader.string();
          continue;
        case 35:
          if (tag !== 282) {
            break;
          }

          message.timeSeriesTimestampColumn = reader.string();
          continue;
        case 36:
          if (tag !== 290) {
            break;
          }

          message.timeSeriesDataColumn = reader.string();
          continue;
        case 37:
          if (tag !== 298) {
            break;
          }

          message.autoArima = BoolValue.decode(reader, reader.uint32()).value;
          continue;
        case 38:
          if (tag !== 306) {
            break;
          }

          message.nonSeasonalOrder = Model_ArimaOrder.decode(reader, reader.uint32());
          continue;
        case 39:
          if (tag !== 312) {
            break;
          }

          message.dataFrequency = reader.int32() as any;
          continue;
        case 40:
          if (tag !== 322) {
            break;
          }

          message.calculatePValues = BoolValue.decode(reader, reader.uint32()).value;
          continue;
        case 41:
          if (tag !== 330) {
            break;
          }

          message.includeDrift = BoolValue.decode(reader, reader.uint32()).value;
          continue;
        case 42:
          if (tag !== 336) {
            break;
          }

          message.holidayRegion = reader.int32() as any;
          continue;
        case 71:
          if (tag === 568) {
            message.holidayRegions.push(reader.int32() as any);

            continue;
          }

          if (tag === 570) {
            const end2 = reader.uint32() + reader.pos;
            while (reader.pos < end2) {
              message.holidayRegions.push(reader.int32() as any);
            }

            continue;
          }

          break;
        case 43:
          if (tag !== 346) {
            break;
          }

          message.timeSeriesIdColumn = reader.string();
          continue;
        case 51:
          if (tag !== 410) {
            break;
          }

          message.timeSeriesIdColumns.push(reader.string());
          continue;
        case 44:
          if (tag !== 352) {
            break;
          }

          message.horizon = Long.fromString(reader.int64().toString());
          continue;
        case 46:
          if (tag !== 368) {
            break;
          }

          message.autoArimaMaxOrder = Long.fromString(reader.int64().toString());
          continue;
        case 83:
          if (tag !== 664) {
            break;
          }

          message.autoArimaMinOrder = Long.fromString(reader.int64().toString());
          continue;
        case 47:
          if (tag !== 376) {
            break;
          }

          message.numTrials = Long.fromString(reader.int64().toString());
          continue;
        case 48:
          if (tag !== 384) {
            break;
          }

          message.maxParallelTrials = Long.fromString(reader.int64().toString());
          continue;
        case 54:
          if (tag === 432) {
            message.hparamTuningObjectives.push(reader.int32() as any);

            continue;
          }

          if (tag === 434) {
            const end2 = reader.uint32() + reader.pos;
            while (reader.pos < end2) {
              message.hparamTuningObjectives.push(reader.int32() as any);
            }

            continue;
          }

          break;
        case 50:
          if (tag !== 402) {
            break;
          }

          message.decomposeTimeSeries = BoolValue.decode(reader, reader.uint32()).value;
          continue;
        case 52:
          if (tag !== 418) {
            break;
          }

          message.cleanSpikesAndDips = BoolValue.decode(reader, reader.uint32()).value;
          continue;
        case 53:
          if (tag !== 426) {
            break;
          }

          message.adjustStepChanges = BoolValue.decode(reader, reader.uint32()).value;
          continue;
        case 55:
          if (tag !== 442) {
            break;
          }

          message.enableGlobalExplain = BoolValue.decode(reader, reader.uint32()).value;
          continue;
        case 56:
          if (tag !== 448) {
            break;
          }

          message.sampledShapleyNumPaths = Long.fromString(reader.int64().toString());
          continue;
        case 57:
          if (tag !== 456) {
            break;
          }

          message.integratedGradientsNumSteps = Long.fromString(reader.int64().toString());
          continue;
        case 58:
          if (tag !== 464) {
            break;
          }

          message.categoryEncodingMethod = reader.int32() as any;
          continue;
        case 70:
          if (tag !== 562) {
            break;
          }

          message.tfVersion = reader.string();
          continue;
        case 72:
          if (tag !== 576) {
            break;
          }

          message.colorSpace = reader.int32() as any;
          continue;
        case 73:
          if (tag !== 586) {
            break;
          }

          message.instanceWeightColumn = reader.string();
          continue;
        case 74:
          if (tag !== 592) {
            break;
          }

          message.trendSmoothingWindowSize = Long.fromString(reader.int64().toString());
          continue;
        case 75:
          if (tag !== 601) {
            break;
          }

          message.timeSeriesLengthFraction = reader.double();
          continue;
        case 76:
          if (tag !== 608) {
            break;
          }

          message.minTimeSeriesLength = Long.fromString(reader.int64().toString());
          continue;
        case 77:
          if (tag !== 616) {
            break;
          }

          message.maxTimeSeriesLength = Long.fromString(reader.int64().toString());
          continue;
        case 78:
          if (tag !== 626) {
            break;
          }

          message.xgboostVersion = reader.string();
          continue;
        case 84:
          if (tag !== 674) {
            break;
          }

          message.approxGlobalFeatureContrib = BoolValue.decode(reader, reader.uint32()).value;
          continue;
        case 85:
          if (tag !== 682) {
            break;
          }

          message.fitIntercept = BoolValue.decode(reader, reader.uint32()).value;
          continue;
        case 86:
          if (tag !== 688) {
            break;
          }

          message.numPrincipalComponents = Long.fromString(reader.int64().toString());
          continue;
        case 87:
          if (tag !== 697) {
            break;
          }

          message.pcaExplainedVarianceRatio = reader.double();
          continue;
        case 88:
          if (tag !== 706) {
            break;
          }

          message.scaleFeatures = BoolValue.decode(reader, reader.uint32()).value;
          continue;
        case 89:
          if (tag !== 712) {
            break;
          }

          message.pcaSolver = reader.int32() as any;
          continue;
        case 90:
          if (tag !== 722) {
            break;
          }

          message.autoClassWeights = BoolValue.decode(reader, reader.uint32()).value;
          continue;
        case 91:
          if (tag !== 730) {
            break;
          }

          message.activationFn = reader.string();
          continue;
        case 92:
          if (tag !== 738) {
            break;
          }

          message.optimizer = reader.string();
          continue;
        case 93:
          if (tag !== 745) {
            break;
          }

          message.budgetHours = reader.double();
          continue;
        case 94:
          if (tag !== 754) {
            break;
          }

          message.standardizeFeatures = BoolValue.decode(reader, reader.uint32()).value;
          continue;
        case 95:
          if (tag !== 761) {
            break;
          }

          message.l1RegActivation = reader.double();
          continue;
        case 96:
          if (tag !== 768) {
            break;
          }

          message.modelRegistry = reader.int32() as any;
          continue;
        case 97:
          if (tag !== 778) {
            break;
          }

          message.vertexAiModelVersionAliases.push(reader.string());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Model_TrainingRun_TrainingOptions {
    return {
      maxIterations: isSet(object.maxIterations) ? Long.fromValue(object.maxIterations) : Long.ZERO,
      lossType: isSet(object.lossType) ? model_LossTypeFromJSON(object.lossType) : 0,
      learnRate: isSet(object.learnRate) ? globalThis.Number(object.learnRate) : 0,
      l1Regularization: isSet(object.l1Regularization) ? Number(object.l1Regularization) : undefined,
      l2Regularization: isSet(object.l2Regularization) ? Number(object.l2Regularization) : undefined,
      minRelativeProgress: isSet(object.minRelativeProgress) ? Number(object.minRelativeProgress) : undefined,
      warmStart: isSet(object.warmStart) ? Boolean(object.warmStart) : undefined,
      earlyStop: isSet(object.earlyStop) ? Boolean(object.earlyStop) : undefined,
      inputLabelColumns: globalThis.Array.isArray(object?.inputLabelColumns)
        ? object.inputLabelColumns.map((e: any) => globalThis.String(e))
        : [],
      dataSplitMethod: isSet(object.dataSplitMethod) ? model_DataSplitMethodFromJSON(object.dataSplitMethod) : 0,
      dataSplitEvalFraction: isSet(object.dataSplitEvalFraction) ? globalThis.Number(object.dataSplitEvalFraction) : 0,
      dataSplitColumn: isSet(object.dataSplitColumn) ? globalThis.String(object.dataSplitColumn) : "",
      learnRateStrategy: isSet(object.learnRateStrategy)
        ? model_LearnRateStrategyFromJSON(object.learnRateStrategy)
        : 0,
      initialLearnRate: isSet(object.initialLearnRate) ? globalThis.Number(object.initialLearnRate) : 0,
      labelClassWeights: isObject(object.labelClassWeights)
        ? Object.entries(object.labelClassWeights).reduce<{ [key: string]: number }>((acc, [key, value]) => {
          acc[key] = Number(value);
          return acc;
        }, {})
        : {},
      userColumn: isSet(object.userColumn) ? globalThis.String(object.userColumn) : "",
      itemColumn: isSet(object.itemColumn) ? globalThis.String(object.itemColumn) : "",
      distanceType: isSet(object.distanceType) ? model_DistanceTypeFromJSON(object.distanceType) : 0,
      numClusters: isSet(object.numClusters) ? Long.fromValue(object.numClusters) : Long.ZERO,
      modelUri: isSet(object.modelUri) ? globalThis.String(object.modelUri) : "",
      optimizationStrategy: isSet(object.optimizationStrategy)
        ? model_OptimizationStrategyFromJSON(object.optimizationStrategy)
        : 0,
      hiddenUnits: globalThis.Array.isArray(object?.hiddenUnits)
        ? object.hiddenUnits.map((e: any) => Long.fromValue(e))
        : [],
      batchSize: isSet(object.batchSize) ? Long.fromValue(object.batchSize) : Long.ZERO,
      dropout: isSet(object.dropout) ? Number(object.dropout) : undefined,
      maxTreeDepth: isSet(object.maxTreeDepth) ? Long.fromValue(object.maxTreeDepth) : Long.ZERO,
      subsample: isSet(object.subsample) ? globalThis.Number(object.subsample) : 0,
      minSplitLoss: isSet(object.minSplitLoss) ? Number(object.minSplitLoss) : undefined,
      boosterType: isSet(object.boosterType) ? model_BoostedTreeOptionEnums_BoosterTypeFromJSON(object.boosterType) : 0,
      numParallelTree: isSet(object.numParallelTree) ? Long.fromValue(object.numParallelTree) : undefined,
      dartNormalizeType: isSet(object.dartNormalizeType)
        ? model_BoostedTreeOptionEnums_DartNormalizeTypeFromJSON(object.dartNormalizeType)
        : 0,
      treeMethod: isSet(object.treeMethod) ? model_BoostedTreeOptionEnums_TreeMethodFromJSON(object.treeMethod) : 0,
      minTreeChildWeight: isSet(object.minTreeChildWeight) ? Long.fromValue(object.minTreeChildWeight) : undefined,
      colsampleBytree: isSet(object.colsampleBytree) ? Number(object.colsampleBytree) : undefined,
      colsampleBylevel: isSet(object.colsampleBylevel) ? Number(object.colsampleBylevel) : undefined,
      colsampleBynode: isSet(object.colsampleBynode) ? Number(object.colsampleBynode) : undefined,
      numFactors: isSet(object.numFactors) ? Long.fromValue(object.numFactors) : Long.ZERO,
      feedbackType: isSet(object.feedbackType) ? model_FeedbackTypeFromJSON(object.feedbackType) : 0,
      walsAlpha: isSet(object.walsAlpha) ? Number(object.walsAlpha) : undefined,
      kmeansInitializationMethod: isSet(object.kmeansInitializationMethod)
        ? model_KmeansEnums_KmeansInitializationMethodFromJSON(object.kmeansInitializationMethod)
        : 0,
      kmeansInitializationColumn: isSet(object.kmeansInitializationColumn)
        ? globalThis.String(object.kmeansInitializationColumn)
        : "",
      timeSeriesTimestampColumn: isSet(object.timeSeriesTimestampColumn)
        ? globalThis.String(object.timeSeriesTimestampColumn)
        : "",
      timeSeriesDataColumn: isSet(object.timeSeriesDataColumn) ? globalThis.String(object.timeSeriesDataColumn) : "",
      autoArima: isSet(object.autoArima) ? Boolean(object.autoArima) : undefined,
      nonSeasonalOrder: isSet(object.nonSeasonalOrder) ? Model_ArimaOrder.fromJSON(object.nonSeasonalOrder) : undefined,
      dataFrequency: isSet(object.dataFrequency) ? model_DataFrequencyFromJSON(object.dataFrequency) : 0,
      calculatePValues: isSet(object.calculatePValues) ? Boolean(object.calculatePValues) : undefined,
      includeDrift: isSet(object.includeDrift) ? Boolean(object.includeDrift) : undefined,
      holidayRegion: isSet(object.holidayRegion) ? model_HolidayRegionFromJSON(object.holidayRegion) : 0,
      holidayRegions: globalThis.Array.isArray(object?.holidayRegions)
        ? object.holidayRegions.map((e: any) => model_HolidayRegionFromJSON(e))
        : [],
      timeSeriesIdColumn: isSet(object.timeSeriesIdColumn) ? globalThis.String(object.timeSeriesIdColumn) : "",
      timeSeriesIdColumns: globalThis.Array.isArray(object?.timeSeriesIdColumns)
        ? object.timeSeriesIdColumns.map((e: any) => globalThis.String(e))
        : [],
      horizon: isSet(object.horizon) ? Long.fromValue(object.horizon) : Long.ZERO,
      autoArimaMaxOrder: isSet(object.autoArimaMaxOrder) ? Long.fromValue(object.autoArimaMaxOrder) : Long.ZERO,
      autoArimaMinOrder: isSet(object.autoArimaMinOrder) ? Long.fromValue(object.autoArimaMinOrder) : Long.ZERO,
      numTrials: isSet(object.numTrials) ? Long.fromValue(object.numTrials) : Long.ZERO,
      maxParallelTrials: isSet(object.maxParallelTrials) ? Long.fromValue(object.maxParallelTrials) : Long.ZERO,
      hparamTuningObjectives: globalThis.Array.isArray(object?.hparamTuningObjectives)
        ? object.hparamTuningObjectives.map((e: any) => model_HparamTuningEnums_HparamTuningObjectiveFromJSON(e))
        : [],
      decomposeTimeSeries: isSet(object.decomposeTimeSeries) ? Boolean(object.decomposeTimeSeries) : undefined,
      cleanSpikesAndDips: isSet(object.cleanSpikesAndDips) ? Boolean(object.cleanSpikesAndDips) : undefined,
      adjustStepChanges: isSet(object.adjustStepChanges) ? Boolean(object.adjustStepChanges) : undefined,
      enableGlobalExplain: isSet(object.enableGlobalExplain) ? Boolean(object.enableGlobalExplain) : undefined,
      sampledShapleyNumPaths: isSet(object.sampledShapleyNumPaths)
        ? Long.fromValue(object.sampledShapleyNumPaths)
        : Long.ZERO,
      integratedGradientsNumSteps: isSet(object.integratedGradientsNumSteps)
        ? Long.fromValue(object.integratedGradientsNumSteps)
        : Long.ZERO,
      categoryEncodingMethod: isSet(object.categoryEncodingMethod)
        ? model_CategoryEncodingMethod_EncodingMethodFromJSON(object.categoryEncodingMethod)
        : 0,
      tfVersion: isSet(object.tfVersion) ? globalThis.String(object.tfVersion) : "",
      colorSpace: isSet(object.colorSpace) ? model_ColorSpaceFromJSON(object.colorSpace) : 0,
      instanceWeightColumn: isSet(object.instanceWeightColumn) ? globalThis.String(object.instanceWeightColumn) : "",
      trendSmoothingWindowSize: isSet(object.trendSmoothingWindowSize)
        ? Long.fromValue(object.trendSmoothingWindowSize)
        : Long.ZERO,
      timeSeriesLengthFraction: isSet(object.timeSeriesLengthFraction)
        ? globalThis.Number(object.timeSeriesLengthFraction)
        : 0,
      minTimeSeriesLength: isSet(object.minTimeSeriesLength) ? Long.fromValue(object.minTimeSeriesLength) : Long.ZERO,
      maxTimeSeriesLength: isSet(object.maxTimeSeriesLength) ? Long.fromValue(object.maxTimeSeriesLength) : Long.ZERO,
      xgboostVersion: isSet(object.xgboostVersion) ? globalThis.String(object.xgboostVersion) : "",
      approxGlobalFeatureContrib: isSet(object.approxGlobalFeatureContrib)
        ? Boolean(object.approxGlobalFeatureContrib)
        : undefined,
      fitIntercept: isSet(object.fitIntercept) ? Boolean(object.fitIntercept) : undefined,
      numPrincipalComponents: isSet(object.numPrincipalComponents)
        ? Long.fromValue(object.numPrincipalComponents)
        : Long.ZERO,
      pcaExplainedVarianceRatio: isSet(object.pcaExplainedVarianceRatio)
        ? globalThis.Number(object.pcaExplainedVarianceRatio)
        : 0,
      scaleFeatures: isSet(object.scaleFeatures) ? Boolean(object.scaleFeatures) : undefined,
      pcaSolver: isSet(object.pcaSolver) ? model_PcaSolverOptionEnums_PcaSolverFromJSON(object.pcaSolver) : 0,
      autoClassWeights: isSet(object.autoClassWeights) ? Boolean(object.autoClassWeights) : undefined,
      activationFn: isSet(object.activationFn) ? globalThis.String(object.activationFn) : "",
      optimizer: isSet(object.optimizer) ? globalThis.String(object.optimizer) : "",
      budgetHours: isSet(object.budgetHours) ? globalThis.Number(object.budgetHours) : 0,
      standardizeFeatures: isSet(object.standardizeFeatures) ? Boolean(object.standardizeFeatures) : undefined,
      l1RegActivation: isSet(object.l1RegActivation) ? globalThis.Number(object.l1RegActivation) : 0,
      modelRegistry: isSet(object.modelRegistry)
        ? model_ModelRegistryOptionEnums_ModelRegistryFromJSON(object.modelRegistry)
        : 0,
      vertexAiModelVersionAliases: globalThis.Array.isArray(object?.vertexAiModelVersionAliases)
        ? object.vertexAiModelVersionAliases.map((e: any) => globalThis.String(e))
        : [],
    };
  },

  toJSON(message: Model_TrainingRun_TrainingOptions): unknown {
    const obj: any = {};
    if (!message.maxIterations.equals(Long.ZERO)) {
      obj.maxIterations = (message.maxIterations || Long.ZERO).toString();
    }
    if (message.lossType !== 0) {
      obj.lossType = model_LossTypeToJSON(message.lossType);
    }
    if (message.learnRate !== 0) {
      obj.learnRate = message.learnRate;
    }
    if (message.l1Regularization !== undefined) {
      obj.l1Regularization = message.l1Regularization;
    }
    if (message.l2Regularization !== undefined) {
      obj.l2Regularization = message.l2Regularization;
    }
    if (message.minRelativeProgress !== undefined) {
      obj.minRelativeProgress = message.minRelativeProgress;
    }
    if (message.warmStart !== undefined) {
      obj.warmStart = message.warmStart;
    }
    if (message.earlyStop !== undefined) {
      obj.earlyStop = message.earlyStop;
    }
    if (message.inputLabelColumns?.length) {
      obj.inputLabelColumns = message.inputLabelColumns;
    }
    if (message.dataSplitMethod !== 0) {
      obj.dataSplitMethod = model_DataSplitMethodToJSON(message.dataSplitMethod);
    }
    if (message.dataSplitEvalFraction !== 0) {
      obj.dataSplitEvalFraction = message.dataSplitEvalFraction;
    }
    if (message.dataSplitColumn !== "") {
      obj.dataSplitColumn = message.dataSplitColumn;
    }
    if (message.learnRateStrategy !== 0) {
      obj.learnRateStrategy = model_LearnRateStrategyToJSON(message.learnRateStrategy);
    }
    if (message.initialLearnRate !== 0) {
      obj.initialLearnRate = message.initialLearnRate;
    }
    if (message.labelClassWeights) {
      const entries = Object.entries(message.labelClassWeights);
      if (entries.length > 0) {
        obj.labelClassWeights = {};
        entries.forEach(([k, v]) => {
          obj.labelClassWeights[k] = v;
        });
      }
    }
    if (message.userColumn !== "") {
      obj.userColumn = message.userColumn;
    }
    if (message.itemColumn !== "") {
      obj.itemColumn = message.itemColumn;
    }
    if (message.distanceType !== 0) {
      obj.distanceType = model_DistanceTypeToJSON(message.distanceType);
    }
    if (!message.numClusters.equals(Long.ZERO)) {
      obj.numClusters = (message.numClusters || Long.ZERO).toString();
    }
    if (message.modelUri !== "") {
      obj.modelUri = message.modelUri;
    }
    if (message.optimizationStrategy !== 0) {
      obj.optimizationStrategy = model_OptimizationStrategyToJSON(message.optimizationStrategy);
    }
    if (message.hiddenUnits?.length) {
      obj.hiddenUnits = message.hiddenUnits.map((e) => (e || Long.ZERO).toString());
    }
    if (!message.batchSize.equals(Long.ZERO)) {
      obj.batchSize = (message.batchSize || Long.ZERO).toString();
    }
    if (message.dropout !== undefined) {
      obj.dropout = message.dropout;
    }
    if (!message.maxTreeDepth.equals(Long.ZERO)) {
      obj.maxTreeDepth = (message.maxTreeDepth || Long.ZERO).toString();
    }
    if (message.subsample !== 0) {
      obj.subsample = message.subsample;
    }
    if (message.minSplitLoss !== undefined) {
      obj.minSplitLoss = message.minSplitLoss;
    }
    if (message.boosterType !== 0) {
      obj.boosterType = model_BoostedTreeOptionEnums_BoosterTypeToJSON(message.boosterType);
    }
    if (message.numParallelTree !== undefined) {
      obj.numParallelTree = message.numParallelTree;
    }
    if (message.dartNormalizeType !== 0) {
      obj.dartNormalizeType = model_BoostedTreeOptionEnums_DartNormalizeTypeToJSON(message.dartNormalizeType);
    }
    if (message.treeMethod !== 0) {
      obj.treeMethod = model_BoostedTreeOptionEnums_TreeMethodToJSON(message.treeMethod);
    }
    if (message.minTreeChildWeight !== undefined) {
      obj.minTreeChildWeight = message.minTreeChildWeight;
    }
    if (message.colsampleBytree !== undefined) {
      obj.colsampleBytree = message.colsampleBytree;
    }
    if (message.colsampleBylevel !== undefined) {
      obj.colsampleBylevel = message.colsampleBylevel;
    }
    if (message.colsampleBynode !== undefined) {
      obj.colsampleBynode = message.colsampleBynode;
    }
    if (!message.numFactors.equals(Long.ZERO)) {
      obj.numFactors = (message.numFactors || Long.ZERO).toString();
    }
    if (message.feedbackType !== 0) {
      obj.feedbackType = model_FeedbackTypeToJSON(message.feedbackType);
    }
    if (message.walsAlpha !== undefined) {
      obj.walsAlpha = message.walsAlpha;
    }
    if (message.kmeansInitializationMethod !== 0) {
      obj.kmeansInitializationMethod = model_KmeansEnums_KmeansInitializationMethodToJSON(
        message.kmeansInitializationMethod,
      );
    }
    if (message.kmeansInitializationColumn !== "") {
      obj.kmeansInitializationColumn = message.kmeansInitializationColumn;
    }
    if (message.timeSeriesTimestampColumn !== "") {
      obj.timeSeriesTimestampColumn = message.timeSeriesTimestampColumn;
    }
    if (message.timeSeriesDataColumn !== "") {
      obj.timeSeriesDataColumn = message.timeSeriesDataColumn;
    }
    if (message.autoArima !== undefined) {
      obj.autoArima = message.autoArima;
    }
    if (message.nonSeasonalOrder !== undefined) {
      obj.nonSeasonalOrder = Model_ArimaOrder.toJSON(message.nonSeasonalOrder);
    }
    if (message.dataFrequency !== 0) {
      obj.dataFrequency = model_DataFrequencyToJSON(message.dataFrequency);
    }
    if (message.calculatePValues !== undefined) {
      obj.calculatePValues = message.calculatePValues;
    }
    if (message.includeDrift !== undefined) {
      obj.includeDrift = message.includeDrift;
    }
    if (message.holidayRegion !== 0) {
      obj.holidayRegion = model_HolidayRegionToJSON(message.holidayRegion);
    }
    if (message.holidayRegions?.length) {
      obj.holidayRegions = message.holidayRegions.map((e) => model_HolidayRegionToJSON(e));
    }
    if (message.timeSeriesIdColumn !== "") {
      obj.timeSeriesIdColumn = message.timeSeriesIdColumn;
    }
    if (message.timeSeriesIdColumns?.length) {
      obj.timeSeriesIdColumns = message.timeSeriesIdColumns;
    }
    if (!message.horizon.equals(Long.ZERO)) {
      obj.horizon = (message.horizon || Long.ZERO).toString();
    }
    if (!message.autoArimaMaxOrder.equals(Long.ZERO)) {
      obj.autoArimaMaxOrder = (message.autoArimaMaxOrder || Long.ZERO).toString();
    }
    if (!message.autoArimaMinOrder.equals(Long.ZERO)) {
      obj.autoArimaMinOrder = (message.autoArimaMinOrder || Long.ZERO).toString();
    }
    if (!message.numTrials.equals(Long.ZERO)) {
      obj.numTrials = (message.numTrials || Long.ZERO).toString();
    }
    if (!message.maxParallelTrials.equals(Long.ZERO)) {
      obj.maxParallelTrials = (message.maxParallelTrials || Long.ZERO).toString();
    }
    if (message.hparamTuningObjectives?.length) {
      obj.hparamTuningObjectives = message.hparamTuningObjectives.map((e) =>
        model_HparamTuningEnums_HparamTuningObjectiveToJSON(e)
      );
    }
    if (message.decomposeTimeSeries !== undefined) {
      obj.decomposeTimeSeries = message.decomposeTimeSeries;
    }
    if (message.cleanSpikesAndDips !== undefined) {
      obj.cleanSpikesAndDips = message.cleanSpikesAndDips;
    }
    if (message.adjustStepChanges !== undefined) {
      obj.adjustStepChanges = message.adjustStepChanges;
    }
    if (message.enableGlobalExplain !== undefined) {
      obj.enableGlobalExplain = message.enableGlobalExplain;
    }
    if (!message.sampledShapleyNumPaths.equals(Long.ZERO)) {
      obj.sampledShapleyNumPaths = (message.sampledShapleyNumPaths || Long.ZERO).toString();
    }
    if (!message.integratedGradientsNumSteps.equals(Long.ZERO)) {
      obj.integratedGradientsNumSteps = (message.integratedGradientsNumSteps || Long.ZERO).toString();
    }
    if (message.categoryEncodingMethod !== 0) {
      obj.categoryEncodingMethod = model_CategoryEncodingMethod_EncodingMethodToJSON(message.categoryEncodingMethod);
    }
    if (message.tfVersion !== "") {
      obj.tfVersion = message.tfVersion;
    }
    if (message.colorSpace !== 0) {
      obj.colorSpace = model_ColorSpaceToJSON(message.colorSpace);
    }
    if (message.instanceWeightColumn !== "") {
      obj.instanceWeightColumn = message.instanceWeightColumn;
    }
    if (!message.trendSmoothingWindowSize.equals(Long.ZERO)) {
      obj.trendSmoothingWindowSize = (message.trendSmoothingWindowSize || Long.ZERO).toString();
    }
    if (message.timeSeriesLengthFraction !== 0) {
      obj.timeSeriesLengthFraction = message.timeSeriesLengthFraction;
    }
    if (!message.minTimeSeriesLength.equals(Long.ZERO)) {
      obj.minTimeSeriesLength = (message.minTimeSeriesLength || Long.ZERO).toString();
    }
    if (!message.maxTimeSeriesLength.equals(Long.ZERO)) {
      obj.maxTimeSeriesLength = (message.maxTimeSeriesLength || Long.ZERO).toString();
    }
    if (message.xgboostVersion !== "") {
      obj.xgboostVersion = message.xgboostVersion;
    }
    if (message.approxGlobalFeatureContrib !== undefined) {
      obj.approxGlobalFeatureContrib = message.approxGlobalFeatureContrib;
    }
    if (message.fitIntercept !== undefined) {
      obj.fitIntercept = message.fitIntercept;
    }
    if (!message.numPrincipalComponents.equals(Long.ZERO)) {
      obj.numPrincipalComponents = (message.numPrincipalComponents || Long.ZERO).toString();
    }
    if (message.pcaExplainedVarianceRatio !== 0) {
      obj.pcaExplainedVarianceRatio = message.pcaExplainedVarianceRatio;
    }
    if (message.scaleFeatures !== undefined) {
      obj.scaleFeatures = message.scaleFeatures;
    }
    if (message.pcaSolver !== 0) {
      obj.pcaSolver = model_PcaSolverOptionEnums_PcaSolverToJSON(message.pcaSolver);
    }
    if (message.autoClassWeights !== undefined) {
      obj.autoClassWeights = message.autoClassWeights;
    }
    if (message.activationFn !== "") {
      obj.activationFn = message.activationFn;
    }
    if (message.optimizer !== "") {
      obj.optimizer = message.optimizer;
    }
    if (message.budgetHours !== 0) {
      obj.budgetHours = message.budgetHours;
    }
    if (message.standardizeFeatures !== undefined) {
      obj.standardizeFeatures = message.standardizeFeatures;
    }
    if (message.l1RegActivation !== 0) {
      obj.l1RegActivation = message.l1RegActivation;
    }
    if (message.modelRegistry !== 0) {
      obj.modelRegistry = model_ModelRegistryOptionEnums_ModelRegistryToJSON(message.modelRegistry);
    }
    if (message.vertexAiModelVersionAliases?.length) {
      obj.vertexAiModelVersionAliases = message.vertexAiModelVersionAliases;
    }
    return obj;
  },

  create(base?: DeepPartial<Model_TrainingRun_TrainingOptions>): Model_TrainingRun_TrainingOptions {
    return Model_TrainingRun_TrainingOptions.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<Model_TrainingRun_TrainingOptions>): Model_TrainingRun_TrainingOptions {
    const message = createBaseModel_TrainingRun_TrainingOptions();
    message.maxIterations = (object.maxIterations !== undefined && object.maxIterations !== null)
      ? Long.fromValue(object.maxIterations)
      : Long.ZERO;
    message.lossType = object.lossType ?? 0;
    message.learnRate = object.learnRate ?? 0;
    message.l1Regularization = object.l1Regularization ?? undefined;
    message.l2Regularization = object.l2Regularization ?? undefined;
    message.minRelativeProgress = object.minRelativeProgress ?? undefined;
    message.warmStart = object.warmStart ?? undefined;
    message.earlyStop = object.earlyStop ?? undefined;
    message.inputLabelColumns = object.inputLabelColumns?.map((e) => e) || [];
    message.dataSplitMethod = object.dataSplitMethod ?? 0;
    message.dataSplitEvalFraction = object.dataSplitEvalFraction ?? 0;
    message.dataSplitColumn = object.dataSplitColumn ?? "";
    message.learnRateStrategy = object.learnRateStrategy ?? 0;
    message.initialLearnRate = object.initialLearnRate ?? 0;
    message.labelClassWeights = Object.entries(object.labelClassWeights ?? {}).reduce<{ [key: string]: number }>(
      (acc, [key, value]) => {
        if (value !== undefined) {
          acc[key] = globalThis.Number(value);
        }
        return acc;
      },
      {},
    );
    message.userColumn = object.userColumn ?? "";
    message.itemColumn = object.itemColumn ?? "";
    message.distanceType = object.distanceType ?? 0;
    message.numClusters = (object.numClusters !== undefined && object.numClusters !== null)
      ? Long.fromValue(object.numClusters)
      : Long.ZERO;
    message.modelUri = object.modelUri ?? "";
    message.optimizationStrategy = object.optimizationStrategy ?? 0;
    message.hiddenUnits = object.hiddenUnits?.map((e) => Long.fromValue(e)) || [];
    message.batchSize = (object.batchSize !== undefined && object.batchSize !== null)
      ? Long.fromValue(object.batchSize)
      : Long.ZERO;
    message.dropout = object.dropout ?? undefined;
    message.maxTreeDepth = (object.maxTreeDepth !== undefined && object.maxTreeDepth !== null)
      ? Long.fromValue(object.maxTreeDepth)
      : Long.ZERO;
    message.subsample = object.subsample ?? 0;
    message.minSplitLoss = object.minSplitLoss ?? undefined;
    message.boosterType = object.boosterType ?? 0;
    message.numParallelTree = (object.numParallelTree !== undefined && object.numParallelTree !== null)
      ? Long.fromValue(object.numParallelTree)
      : undefined;
    message.dartNormalizeType = object.dartNormalizeType ?? 0;
    message.treeMethod = object.treeMethod ?? 0;
    message.minTreeChildWeight = (object.minTreeChildWeight !== undefined && object.minTreeChildWeight !== null)
      ? Long.fromValue(object.minTreeChildWeight)
      : undefined;
    message.colsampleBytree = object.colsampleBytree ?? undefined;
    message.colsampleBylevel = object.colsampleBylevel ?? undefined;
    message.colsampleBynode = object.colsampleBynode ?? undefined;
    message.numFactors = (object.numFactors !== undefined && object.numFactors !== null)
      ? Long.fromValue(object.numFactors)
      : Long.ZERO;
    message.feedbackType = object.feedbackType ?? 0;
    message.walsAlpha = object.walsAlpha ?? undefined;
    message.kmeansInitializationMethod = object.kmeansInitializationMethod ?? 0;
    message.kmeansInitializationColumn = object.kmeansInitializationColumn ?? "";
    message.timeSeriesTimestampColumn = object.timeSeriesTimestampColumn ?? "";
    message.timeSeriesDataColumn = object.timeSeriesDataColumn ?? "";
    message.autoArima = object.autoArima ?? undefined;
    message.nonSeasonalOrder = (object.nonSeasonalOrder !== undefined && object.nonSeasonalOrder !== null)
      ? Model_ArimaOrder.fromPartial(object.nonSeasonalOrder)
      : undefined;
    message.dataFrequency = object.dataFrequency ?? 0;
    message.calculatePValues = object.calculatePValues ?? undefined;
    message.includeDrift = object.includeDrift ?? undefined;
    message.holidayRegion = object.holidayRegion ?? 0;
    message.holidayRegions = object.holidayRegions?.map((e) => e) || [];
    message.timeSeriesIdColumn = object.timeSeriesIdColumn ?? "";
    message.timeSeriesIdColumns = object.timeSeriesIdColumns?.map((e) => e) || [];
    message.horizon = (object.horizon !== undefined && object.horizon !== null)
      ? Long.fromValue(object.horizon)
      : Long.ZERO;
    message.autoArimaMaxOrder = (object.autoArimaMaxOrder !== undefined && object.autoArimaMaxOrder !== null)
      ? Long.fromValue(object.autoArimaMaxOrder)
      : Long.ZERO;
    message.autoArimaMinOrder = (object.autoArimaMinOrder !== undefined && object.autoArimaMinOrder !== null)
      ? Long.fromValue(object.autoArimaMinOrder)
      : Long.ZERO;
    message.numTrials = (object.numTrials !== undefined && object.numTrials !== null)
      ? Long.fromValue(object.numTrials)
      : Long.ZERO;
    message.maxParallelTrials = (object.maxParallelTrials !== undefined && object.maxParallelTrials !== null)
      ? Long.fromValue(object.maxParallelTrials)
      : Long.ZERO;
    message.hparamTuningObjectives = object.hparamTuningObjectives?.map((e) => e) || [];
    message.decomposeTimeSeries = object.decomposeTimeSeries ?? undefined;
    message.cleanSpikesAndDips = object.cleanSpikesAndDips ?? undefined;
    message.adjustStepChanges = object.adjustStepChanges ?? undefined;
    message.enableGlobalExplain = object.enableGlobalExplain ?? undefined;
    message.sampledShapleyNumPaths =
      (object.sampledShapleyNumPaths !== undefined && object.sampledShapleyNumPaths !== null)
        ? Long.fromValue(object.sampledShapleyNumPaths)
        : Long.ZERO;
    message.integratedGradientsNumSteps =
      (object.integratedGradientsNumSteps !== undefined && object.integratedGradientsNumSteps !== null)
        ? Long.fromValue(object.integratedGradientsNumSteps)
        : Long.ZERO;
    message.categoryEncodingMethod = object.categoryEncodingMethod ?? 0;
    message.tfVersion = object.tfVersion ?? "";
    message.colorSpace = object.colorSpace ?? 0;
    message.instanceWeightColumn = object.instanceWeightColumn ?? "";
    message.trendSmoothingWindowSize =
      (object.trendSmoothingWindowSize !== undefined && object.trendSmoothingWindowSize !== null)
        ? Long.fromValue(object.trendSmoothingWindowSize)
        : Long.ZERO;
    message.timeSeriesLengthFraction = object.timeSeriesLengthFraction ?? 0;
    message.minTimeSeriesLength = (object.minTimeSeriesLength !== undefined && object.minTimeSeriesLength !== null)
      ? Long.fromValue(object.minTimeSeriesLength)
      : Long.ZERO;
    message.maxTimeSeriesLength = (object.maxTimeSeriesLength !== undefined && object.maxTimeSeriesLength !== null)
      ? Long.fromValue(object.maxTimeSeriesLength)
      : Long.ZERO;
    message.xgboostVersion = object.xgboostVersion ?? "";
    message.approxGlobalFeatureContrib = object.approxGlobalFeatureContrib ?? undefined;
    message.fitIntercept = object.fitIntercept ?? undefined;
    message.numPrincipalComponents =
      (object.numPrincipalComponents !== undefined && object.numPrincipalComponents !== null)
        ? Long.fromValue(object.numPrincipalComponents)
        : Long.ZERO;
    message.pcaExplainedVarianceRatio = object.pcaExplainedVarianceRatio ?? 0;
    message.scaleFeatures = object.scaleFeatures ?? undefined;
    message.pcaSolver = object.pcaSolver ?? 0;
    message.autoClassWeights = object.autoClassWeights ?? undefined;
    message.activationFn = object.activationFn ?? "";
    message.optimizer = object.optimizer ?? "";
    message.budgetHours = object.budgetHours ?? 0;
    message.standardizeFeatures = object.standardizeFeatures ?? undefined;
    message.l1RegActivation = object.l1RegActivation ?? 0;
    message.modelRegistry = object.modelRegistry ?? 0;
    message.vertexAiModelVersionAliases = object.vertexAiModelVersionAliases?.map((e) => e) || [];
    return message;
  },
};

function createBaseModel_TrainingRun_TrainingOptions_LabelClassWeightsEntry(): Model_TrainingRun_TrainingOptions_LabelClassWeightsEntry {
  return { key: "", value: 0 };
}

export const Model_TrainingRun_TrainingOptions_LabelClassWeightsEntry: MessageFns<
  Model_TrainingRun_TrainingOptions_LabelClassWeightsEntry
> = {
  encode(
    message: Model_TrainingRun_TrainingOptions_LabelClassWeightsEntry,
    writer: BinaryWriter = new BinaryWriter(),
  ): BinaryWriter {
    if (message.key !== "") {
      writer.uint32(10).string(message.key);
    }
    if (message.value !== 0) {
      writer.uint32(17).double(message.value);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Model_TrainingRun_TrainingOptions_LabelClassWeightsEntry {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseModel_TrainingRun_TrainingOptions_LabelClassWeightsEntry();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.key = reader.string();
          continue;
        case 2:
          if (tag !== 17) {
            break;
          }

          message.value = reader.double();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Model_TrainingRun_TrainingOptions_LabelClassWeightsEntry {
    return {
      key: isSet(object.key) ? globalThis.String(object.key) : "",
      value: isSet(object.value) ? globalThis.Number(object.value) : 0,
    };
  },

  toJSON(message: Model_TrainingRun_TrainingOptions_LabelClassWeightsEntry): unknown {
    const obj: any = {};
    if (message.key !== "") {
      obj.key = message.key;
    }
    if (message.value !== 0) {
      obj.value = message.value;
    }
    return obj;
  },

  create(
    base?: DeepPartial<Model_TrainingRun_TrainingOptions_LabelClassWeightsEntry>,
  ): Model_TrainingRun_TrainingOptions_LabelClassWeightsEntry {
    return Model_TrainingRun_TrainingOptions_LabelClassWeightsEntry.fromPartial(base ?? {});
  },
  fromPartial(
    object: DeepPartial<Model_TrainingRun_TrainingOptions_LabelClassWeightsEntry>,
  ): Model_TrainingRun_TrainingOptions_LabelClassWeightsEntry {
    const message = createBaseModel_TrainingRun_TrainingOptions_LabelClassWeightsEntry();
    message.key = object.key ?? "";
    message.value = object.value ?? 0;
    return message;
  },
};

function createBaseModel_TrainingRun_IterationResult(): Model_TrainingRun_IterationResult {
  return {
    index: undefined,
    durationMs: undefined,
    trainingLoss: undefined,
    evalLoss: undefined,
    learnRate: 0,
    clusterInfos: [],
    arimaResult: undefined,
    principalComponentInfos: [],
  };
}

export const Model_TrainingRun_IterationResult: MessageFns<Model_TrainingRun_IterationResult> = {
  encode(message: Model_TrainingRun_IterationResult, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.index !== undefined) {
      Int32Value.encode({ value: message.index! }, writer.uint32(10).fork()).join();
    }
    if (message.durationMs !== undefined) {
      Int64Value.encode({ value: message.durationMs! }, writer.uint32(34).fork()).join();
    }
    if (message.trainingLoss !== undefined) {
      DoubleValue.encode({ value: message.trainingLoss! }, writer.uint32(42).fork()).join();
    }
    if (message.evalLoss !== undefined) {
      DoubleValue.encode({ value: message.evalLoss! }, writer.uint32(50).fork()).join();
    }
    if (message.learnRate !== 0) {
      writer.uint32(57).double(message.learnRate);
    }
    for (const v of message.clusterInfos) {
      Model_TrainingRun_IterationResult_ClusterInfo.encode(v!, writer.uint32(66).fork()).join();
    }
    if (message.arimaResult !== undefined) {
      Model_TrainingRun_IterationResult_ArimaResult.encode(message.arimaResult, writer.uint32(74).fork()).join();
    }
    for (const v of message.principalComponentInfos) {
      Model_TrainingRun_IterationResult_PrincipalComponentInfo.encode(v!, writer.uint32(82).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Model_TrainingRun_IterationResult {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseModel_TrainingRun_IterationResult();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.index = Int32Value.decode(reader, reader.uint32()).value;
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.durationMs = Int64Value.decode(reader, reader.uint32()).value;
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.trainingLoss = DoubleValue.decode(reader, reader.uint32()).value;
          continue;
        case 6:
          if (tag !== 50) {
            break;
          }

          message.evalLoss = DoubleValue.decode(reader, reader.uint32()).value;
          continue;
        case 7:
          if (tag !== 57) {
            break;
          }

          message.learnRate = reader.double();
          continue;
        case 8:
          if (tag !== 66) {
            break;
          }

          message.clusterInfos.push(Model_TrainingRun_IterationResult_ClusterInfo.decode(reader, reader.uint32()));
          continue;
        case 9:
          if (tag !== 74) {
            break;
          }

          message.arimaResult = Model_TrainingRun_IterationResult_ArimaResult.decode(reader, reader.uint32());
          continue;
        case 10:
          if (tag !== 82) {
            break;
          }

          message.principalComponentInfos.push(
            Model_TrainingRun_IterationResult_PrincipalComponentInfo.decode(reader, reader.uint32()),
          );
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Model_TrainingRun_IterationResult {
    return {
      index: isSet(object.index) ? Number(object.index) : undefined,
      durationMs: isSet(object.durationMs) ? Long.fromValue(object.durationMs) : undefined,
      trainingLoss: isSet(object.trainingLoss) ? Number(object.trainingLoss) : undefined,
      evalLoss: isSet(object.evalLoss) ? Number(object.evalLoss) : undefined,
      learnRate: isSet(object.learnRate) ? globalThis.Number(object.learnRate) : 0,
      clusterInfos: globalThis.Array.isArray(object?.clusterInfos)
        ? object.clusterInfos.map((e: any) => Model_TrainingRun_IterationResult_ClusterInfo.fromJSON(e))
        : [],
      arimaResult: isSet(object.arimaResult)
        ? Model_TrainingRun_IterationResult_ArimaResult.fromJSON(object.arimaResult)
        : undefined,
      principalComponentInfos: globalThis.Array.isArray(object?.principalComponentInfos)
        ? object.principalComponentInfos.map((e: any) =>
          Model_TrainingRun_IterationResult_PrincipalComponentInfo.fromJSON(e)
        )
        : [],
    };
  },

  toJSON(message: Model_TrainingRun_IterationResult): unknown {
    const obj: any = {};
    if (message.index !== undefined) {
      obj.index = message.index;
    }
    if (message.durationMs !== undefined) {
      obj.durationMs = message.durationMs;
    }
    if (message.trainingLoss !== undefined) {
      obj.trainingLoss = message.trainingLoss;
    }
    if (message.evalLoss !== undefined) {
      obj.evalLoss = message.evalLoss;
    }
    if (message.learnRate !== 0) {
      obj.learnRate = message.learnRate;
    }
    if (message.clusterInfos?.length) {
      obj.clusterInfos = message.clusterInfos.map((e) => Model_TrainingRun_IterationResult_ClusterInfo.toJSON(e));
    }
    if (message.arimaResult !== undefined) {
      obj.arimaResult = Model_TrainingRun_IterationResult_ArimaResult.toJSON(message.arimaResult);
    }
    if (message.principalComponentInfos?.length) {
      obj.principalComponentInfos = message.principalComponentInfos.map((e) =>
        Model_TrainingRun_IterationResult_PrincipalComponentInfo.toJSON(e)
      );
    }
    return obj;
  },

  create(base?: DeepPartial<Model_TrainingRun_IterationResult>): Model_TrainingRun_IterationResult {
    return Model_TrainingRun_IterationResult.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<Model_TrainingRun_IterationResult>): Model_TrainingRun_IterationResult {
    const message = createBaseModel_TrainingRun_IterationResult();
    message.index = object.index ?? undefined;
    message.durationMs = (object.durationMs !== undefined && object.durationMs !== null)
      ? Long.fromValue(object.durationMs)
      : undefined;
    message.trainingLoss = object.trainingLoss ?? undefined;
    message.evalLoss = object.evalLoss ?? undefined;
    message.learnRate = object.learnRate ?? 0;
    message.clusterInfos =
      object.clusterInfos?.map((e) => Model_TrainingRun_IterationResult_ClusterInfo.fromPartial(e)) || [];
    message.arimaResult = (object.arimaResult !== undefined && object.arimaResult !== null)
      ? Model_TrainingRun_IterationResult_ArimaResult.fromPartial(object.arimaResult)
      : undefined;
    message.principalComponentInfos =
      object.principalComponentInfos?.map((e) =>
        Model_TrainingRun_IterationResult_PrincipalComponentInfo.fromPartial(e)
      ) || [];
    return message;
  },
};

function createBaseModel_TrainingRun_IterationResult_ClusterInfo(): Model_TrainingRun_IterationResult_ClusterInfo {
  return { centroidId: Long.ZERO, clusterRadius: undefined, clusterSize: undefined };
}

export const Model_TrainingRun_IterationResult_ClusterInfo: MessageFns<Model_TrainingRun_IterationResult_ClusterInfo> =
  {
    encode(
      message: Model_TrainingRun_IterationResult_ClusterInfo,
      writer: BinaryWriter = new BinaryWriter(),
    ): BinaryWriter {
      if (!message.centroidId.equals(Long.ZERO)) {
        writer.uint32(8).int64(message.centroidId.toString());
      }
      if (message.clusterRadius !== undefined) {
        DoubleValue.encode({ value: message.clusterRadius! }, writer.uint32(18).fork()).join();
      }
      if (message.clusterSize !== undefined) {
        Int64Value.encode({ value: message.clusterSize! }, writer.uint32(26).fork()).join();
      }
      return writer;
    },

    decode(input: BinaryReader | Uint8Array, length?: number): Model_TrainingRun_IterationResult_ClusterInfo {
      const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
      let end = length === undefined ? reader.len : reader.pos + length;
      const message = createBaseModel_TrainingRun_IterationResult_ClusterInfo();
      while (reader.pos < end) {
        const tag = reader.uint32();
        switch (tag >>> 3) {
          case 1:
            if (tag !== 8) {
              break;
            }

            message.centroidId = Long.fromString(reader.int64().toString());
            continue;
          case 2:
            if (tag !== 18) {
              break;
            }

            message.clusterRadius = DoubleValue.decode(reader, reader.uint32()).value;
            continue;
          case 3:
            if (tag !== 26) {
              break;
            }

            message.clusterSize = Int64Value.decode(reader, reader.uint32()).value;
            continue;
        }
        if ((tag & 7) === 4 || tag === 0) {
          break;
        }
        reader.skip(tag & 7);
      }
      return message;
    },

    fromJSON(object: any): Model_TrainingRun_IterationResult_ClusterInfo {
      return {
        centroidId: isSet(object.centroidId) ? Long.fromValue(object.centroidId) : Long.ZERO,
        clusterRadius: isSet(object.clusterRadius) ? Number(object.clusterRadius) : undefined,
        clusterSize: isSet(object.clusterSize) ? Long.fromValue(object.clusterSize) : undefined,
      };
    },

    toJSON(message: Model_TrainingRun_IterationResult_ClusterInfo): unknown {
      const obj: any = {};
      if (!message.centroidId.equals(Long.ZERO)) {
        obj.centroidId = (message.centroidId || Long.ZERO).toString();
      }
      if (message.clusterRadius !== undefined) {
        obj.clusterRadius = message.clusterRadius;
      }
      if (message.clusterSize !== undefined) {
        obj.clusterSize = message.clusterSize;
      }
      return obj;
    },

    create(
      base?: DeepPartial<Model_TrainingRun_IterationResult_ClusterInfo>,
    ): Model_TrainingRun_IterationResult_ClusterInfo {
      return Model_TrainingRun_IterationResult_ClusterInfo.fromPartial(base ?? {});
    },
    fromPartial(
      object: DeepPartial<Model_TrainingRun_IterationResult_ClusterInfo>,
    ): Model_TrainingRun_IterationResult_ClusterInfo {
      const message = createBaseModel_TrainingRun_IterationResult_ClusterInfo();
      message.centroidId = (object.centroidId !== undefined && object.centroidId !== null)
        ? Long.fromValue(object.centroidId)
        : Long.ZERO;
      message.clusterRadius = object.clusterRadius ?? undefined;
      message.clusterSize = (object.clusterSize !== undefined && object.clusterSize !== null)
        ? Long.fromValue(object.clusterSize)
        : undefined;
      return message;
    },
  };

function createBaseModel_TrainingRun_IterationResult_ArimaResult(): Model_TrainingRun_IterationResult_ArimaResult {
  return { arimaModelInfo: [], seasonalPeriods: [] };
}

export const Model_TrainingRun_IterationResult_ArimaResult: MessageFns<Model_TrainingRun_IterationResult_ArimaResult> =
  {
    encode(
      message: Model_TrainingRun_IterationResult_ArimaResult,
      writer: BinaryWriter = new BinaryWriter(),
    ): BinaryWriter {
      for (const v of message.arimaModelInfo) {
        Model_TrainingRun_IterationResult_ArimaResult_ArimaModelInfo.encode(v!, writer.uint32(10).fork()).join();
      }
      writer.uint32(18).fork();
      for (const v of message.seasonalPeriods) {
        writer.int32(v);
      }
      writer.join();
      return writer;
    },

    decode(input: BinaryReader | Uint8Array, length?: number): Model_TrainingRun_IterationResult_ArimaResult {
      const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
      let end = length === undefined ? reader.len : reader.pos + length;
      const message = createBaseModel_TrainingRun_IterationResult_ArimaResult();
      while (reader.pos < end) {
        const tag = reader.uint32();
        switch (tag >>> 3) {
          case 1:
            if (tag !== 10) {
              break;
            }

            message.arimaModelInfo.push(
              Model_TrainingRun_IterationResult_ArimaResult_ArimaModelInfo.decode(reader, reader.uint32()),
            );
            continue;
          case 2:
            if (tag === 16) {
              message.seasonalPeriods.push(reader.int32() as any);

              continue;
            }

            if (tag === 18) {
              const end2 = reader.uint32() + reader.pos;
              while (reader.pos < end2) {
                message.seasonalPeriods.push(reader.int32() as any);
              }

              continue;
            }

            break;
        }
        if ((tag & 7) === 4 || tag === 0) {
          break;
        }
        reader.skip(tag & 7);
      }
      return message;
    },

    fromJSON(object: any): Model_TrainingRun_IterationResult_ArimaResult {
      return {
        arimaModelInfo: globalThis.Array.isArray(object?.arimaModelInfo)
          ? object.arimaModelInfo.map((e: any) =>
            Model_TrainingRun_IterationResult_ArimaResult_ArimaModelInfo.fromJSON(e)
          )
          : [],
        seasonalPeriods: globalThis.Array.isArray(object?.seasonalPeriods)
          ? object.seasonalPeriods.map((e: any) => model_SeasonalPeriod_SeasonalPeriodTypeFromJSON(e))
          : [],
      };
    },

    toJSON(message: Model_TrainingRun_IterationResult_ArimaResult): unknown {
      const obj: any = {};
      if (message.arimaModelInfo?.length) {
        obj.arimaModelInfo = message.arimaModelInfo.map((e) =>
          Model_TrainingRun_IterationResult_ArimaResult_ArimaModelInfo.toJSON(e)
        );
      }
      if (message.seasonalPeriods?.length) {
        obj.seasonalPeriods = message.seasonalPeriods.map((e) => model_SeasonalPeriod_SeasonalPeriodTypeToJSON(e));
      }
      return obj;
    },

    create(
      base?: DeepPartial<Model_TrainingRun_IterationResult_ArimaResult>,
    ): Model_TrainingRun_IterationResult_ArimaResult {
      return Model_TrainingRun_IterationResult_ArimaResult.fromPartial(base ?? {});
    },
    fromPartial(
      object: DeepPartial<Model_TrainingRun_IterationResult_ArimaResult>,
    ): Model_TrainingRun_IterationResult_ArimaResult {
      const message = createBaseModel_TrainingRun_IterationResult_ArimaResult();
      message.arimaModelInfo =
        object.arimaModelInfo?.map((e) =>
          Model_TrainingRun_IterationResult_ArimaResult_ArimaModelInfo.fromPartial(e)
        ) || [];
      message.seasonalPeriods = object.seasonalPeriods?.map((e) => e) || [];
      return message;
    },
  };

function createBaseModel_TrainingRun_IterationResult_ArimaResult_ArimaCoefficients(): Model_TrainingRun_IterationResult_ArimaResult_ArimaCoefficients {
  return { autoRegressiveCoefficients: [], movingAverageCoefficients: [], interceptCoefficient: undefined };
}

export const Model_TrainingRun_IterationResult_ArimaResult_ArimaCoefficients: MessageFns<
  Model_TrainingRun_IterationResult_ArimaResult_ArimaCoefficients
> = {
  encode(
    message: Model_TrainingRun_IterationResult_ArimaResult_ArimaCoefficients,
    writer: BinaryWriter = new BinaryWriter(),
  ): BinaryWriter {
    writer.uint32(10).fork();
    for (const v of message.autoRegressiveCoefficients) {
      writer.double(v);
    }
    writer.join();
    writer.uint32(18).fork();
    for (const v of message.movingAverageCoefficients) {
      writer.double(v);
    }
    writer.join();
    if (message.interceptCoefficient !== undefined) {
      DoubleValue.encode({ value: message.interceptCoefficient! }, writer.uint32(26).fork()).join();
    }
    return writer;
  },

  decode(
    input: BinaryReader | Uint8Array,
    length?: number,
  ): Model_TrainingRun_IterationResult_ArimaResult_ArimaCoefficients {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseModel_TrainingRun_IterationResult_ArimaResult_ArimaCoefficients();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag === 9) {
            message.autoRegressiveCoefficients.push(reader.double());

            continue;
          }

          if (tag === 10) {
            const end2 = reader.uint32() + reader.pos;
            while (reader.pos < end2) {
              message.autoRegressiveCoefficients.push(reader.double());
            }

            continue;
          }

          break;
        case 2:
          if (tag === 17) {
            message.movingAverageCoefficients.push(reader.double());

            continue;
          }

          if (tag === 18) {
            const end2 = reader.uint32() + reader.pos;
            while (reader.pos < end2) {
              message.movingAverageCoefficients.push(reader.double());
            }

            continue;
          }

          break;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.interceptCoefficient = DoubleValue.decode(reader, reader.uint32()).value;
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Model_TrainingRun_IterationResult_ArimaResult_ArimaCoefficients {
    return {
      autoRegressiveCoefficients: globalThis.Array.isArray(object?.autoRegressiveCoefficients)
        ? object.autoRegressiveCoefficients.map((e: any) => globalThis.Number(e))
        : [],
      movingAverageCoefficients: globalThis.Array.isArray(object?.movingAverageCoefficients)
        ? object.movingAverageCoefficients.map((e: any) => globalThis.Number(e))
        : [],
      interceptCoefficient: isSet(object.interceptCoefficient) ? Number(object.interceptCoefficient) : undefined,
    };
  },

  toJSON(message: Model_TrainingRun_IterationResult_ArimaResult_ArimaCoefficients): unknown {
    const obj: any = {};
    if (message.autoRegressiveCoefficients?.length) {
      obj.autoRegressiveCoefficients = message.autoRegressiveCoefficients;
    }
    if (message.movingAverageCoefficients?.length) {
      obj.movingAverageCoefficients = message.movingAverageCoefficients;
    }
    if (message.interceptCoefficient !== undefined) {
      obj.interceptCoefficient = message.interceptCoefficient;
    }
    return obj;
  },

  create(
    base?: DeepPartial<Model_TrainingRun_IterationResult_ArimaResult_ArimaCoefficients>,
  ): Model_TrainingRun_IterationResult_ArimaResult_ArimaCoefficients {
    return Model_TrainingRun_IterationResult_ArimaResult_ArimaCoefficients.fromPartial(base ?? {});
  },
  fromPartial(
    object: DeepPartial<Model_TrainingRun_IterationResult_ArimaResult_ArimaCoefficients>,
  ): Model_TrainingRun_IterationResult_ArimaResult_ArimaCoefficients {
    const message = createBaseModel_TrainingRun_IterationResult_ArimaResult_ArimaCoefficients();
    message.autoRegressiveCoefficients = object.autoRegressiveCoefficients?.map((e) => e) || [];
    message.movingAverageCoefficients = object.movingAverageCoefficients?.map((e) => e) || [];
    message.interceptCoefficient = object.interceptCoefficient ?? undefined;
    return message;
  },
};

function createBaseModel_TrainingRun_IterationResult_ArimaResult_ArimaModelInfo(): Model_TrainingRun_IterationResult_ArimaResult_ArimaModelInfo {
  return {
    nonSeasonalOrder: undefined,
    arimaCoefficients: undefined,
    arimaFittingMetrics: undefined,
    hasDrift: undefined,
    timeSeriesId: "",
    timeSeriesIds: [],
    seasonalPeriods: [],
    hasHolidayEffect: undefined,
    hasSpikesAndDips: undefined,
    hasStepChanges: undefined,
  };
}

export const Model_TrainingRun_IterationResult_ArimaResult_ArimaModelInfo: MessageFns<
  Model_TrainingRun_IterationResult_ArimaResult_ArimaModelInfo
> = {
  encode(
    message: Model_TrainingRun_IterationResult_ArimaResult_ArimaModelInfo,
    writer: BinaryWriter = new BinaryWriter(),
  ): BinaryWriter {
    if (message.nonSeasonalOrder !== undefined) {
      Model_ArimaOrder.encode(message.nonSeasonalOrder, writer.uint32(10).fork()).join();
    }
    if (message.arimaCoefficients !== undefined) {
      Model_TrainingRun_IterationResult_ArimaResult_ArimaCoefficients.encode(
        message.arimaCoefficients,
        writer.uint32(18).fork(),
      ).join();
    }
    if (message.arimaFittingMetrics !== undefined) {
      Model_ArimaFittingMetrics.encode(message.arimaFittingMetrics, writer.uint32(26).fork()).join();
    }
    if (message.hasDrift !== undefined) {
      BoolValue.encode({ value: message.hasDrift! }, writer.uint32(34).fork()).join();
    }
    if (message.timeSeriesId !== "") {
      writer.uint32(42).string(message.timeSeriesId);
    }
    for (const v of message.timeSeriesIds) {
      writer.uint32(82).string(v!);
    }
    writer.uint32(50).fork();
    for (const v of message.seasonalPeriods) {
      writer.int32(v);
    }
    writer.join();
    if (message.hasHolidayEffect !== undefined) {
      BoolValue.encode({ value: message.hasHolidayEffect! }, writer.uint32(58).fork()).join();
    }
    if (message.hasSpikesAndDips !== undefined) {
      BoolValue.encode({ value: message.hasSpikesAndDips! }, writer.uint32(66).fork()).join();
    }
    if (message.hasStepChanges !== undefined) {
      BoolValue.encode({ value: message.hasStepChanges! }, writer.uint32(74).fork()).join();
    }
    return writer;
  },

  decode(
    input: BinaryReader | Uint8Array,
    length?: number,
  ): Model_TrainingRun_IterationResult_ArimaResult_ArimaModelInfo {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseModel_TrainingRun_IterationResult_ArimaResult_ArimaModelInfo();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.nonSeasonalOrder = Model_ArimaOrder.decode(reader, reader.uint32());
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.arimaCoefficients = Model_TrainingRun_IterationResult_ArimaResult_ArimaCoefficients.decode(
            reader,
            reader.uint32(),
          );
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.arimaFittingMetrics = Model_ArimaFittingMetrics.decode(reader, reader.uint32());
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.hasDrift = BoolValue.decode(reader, reader.uint32()).value;
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.timeSeriesId = reader.string();
          continue;
        case 10:
          if (tag !== 82) {
            break;
          }

          message.timeSeriesIds.push(reader.string());
          continue;
        case 6:
          if (tag === 48) {
            message.seasonalPeriods.push(reader.int32() as any);

            continue;
          }

          if (tag === 50) {
            const end2 = reader.uint32() + reader.pos;
            while (reader.pos < end2) {
              message.seasonalPeriods.push(reader.int32() as any);
            }

            continue;
          }

          break;
        case 7:
          if (tag !== 58) {
            break;
          }

          message.hasHolidayEffect = BoolValue.decode(reader, reader.uint32()).value;
          continue;
        case 8:
          if (tag !== 66) {
            break;
          }

          message.hasSpikesAndDips = BoolValue.decode(reader, reader.uint32()).value;
          continue;
        case 9:
          if (tag !== 74) {
            break;
          }

          message.hasStepChanges = BoolValue.decode(reader, reader.uint32()).value;
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Model_TrainingRun_IterationResult_ArimaResult_ArimaModelInfo {
    return {
      nonSeasonalOrder: isSet(object.nonSeasonalOrder) ? Model_ArimaOrder.fromJSON(object.nonSeasonalOrder) : undefined,
      arimaCoefficients: isSet(object.arimaCoefficients)
        ? Model_TrainingRun_IterationResult_ArimaResult_ArimaCoefficients.fromJSON(object.arimaCoefficients)
        : undefined,
      arimaFittingMetrics: isSet(object.arimaFittingMetrics)
        ? Model_ArimaFittingMetrics.fromJSON(object.arimaFittingMetrics)
        : undefined,
      hasDrift: isSet(object.hasDrift) ? Boolean(object.hasDrift) : undefined,
      timeSeriesId: isSet(object.timeSeriesId) ? globalThis.String(object.timeSeriesId) : "",
      timeSeriesIds: globalThis.Array.isArray(object?.timeSeriesIds)
        ? object.timeSeriesIds.map((e: any) => globalThis.String(e))
        : [],
      seasonalPeriods: globalThis.Array.isArray(object?.seasonalPeriods)
        ? object.seasonalPeriods.map((e: any) => model_SeasonalPeriod_SeasonalPeriodTypeFromJSON(e))
        : [],
      hasHolidayEffect: isSet(object.hasHolidayEffect) ? Boolean(object.hasHolidayEffect) : undefined,
      hasSpikesAndDips: isSet(object.hasSpikesAndDips) ? Boolean(object.hasSpikesAndDips) : undefined,
      hasStepChanges: isSet(object.hasStepChanges) ? Boolean(object.hasStepChanges) : undefined,
    };
  },

  toJSON(message: Model_TrainingRun_IterationResult_ArimaResult_ArimaModelInfo): unknown {
    const obj: any = {};
    if (message.nonSeasonalOrder !== undefined) {
      obj.nonSeasonalOrder = Model_ArimaOrder.toJSON(message.nonSeasonalOrder);
    }
    if (message.arimaCoefficients !== undefined) {
      obj.arimaCoefficients = Model_TrainingRun_IterationResult_ArimaResult_ArimaCoefficients.toJSON(
        message.arimaCoefficients,
      );
    }
    if (message.arimaFittingMetrics !== undefined) {
      obj.arimaFittingMetrics = Model_ArimaFittingMetrics.toJSON(message.arimaFittingMetrics);
    }
    if (message.hasDrift !== undefined) {
      obj.hasDrift = message.hasDrift;
    }
    if (message.timeSeriesId !== "") {
      obj.timeSeriesId = message.timeSeriesId;
    }
    if (message.timeSeriesIds?.length) {
      obj.timeSeriesIds = message.timeSeriesIds;
    }
    if (message.seasonalPeriods?.length) {
      obj.seasonalPeriods = message.seasonalPeriods.map((e) => model_SeasonalPeriod_SeasonalPeriodTypeToJSON(e));
    }
    if (message.hasHolidayEffect !== undefined) {
      obj.hasHolidayEffect = message.hasHolidayEffect;
    }
    if (message.hasSpikesAndDips !== undefined) {
      obj.hasSpikesAndDips = message.hasSpikesAndDips;
    }
    if (message.hasStepChanges !== undefined) {
      obj.hasStepChanges = message.hasStepChanges;
    }
    return obj;
  },

  create(
    base?: DeepPartial<Model_TrainingRun_IterationResult_ArimaResult_ArimaModelInfo>,
  ): Model_TrainingRun_IterationResult_ArimaResult_ArimaModelInfo {
    return Model_TrainingRun_IterationResult_ArimaResult_ArimaModelInfo.fromPartial(base ?? {});
  },
  fromPartial(
    object: DeepPartial<Model_TrainingRun_IterationResult_ArimaResult_ArimaModelInfo>,
  ): Model_TrainingRun_IterationResult_ArimaResult_ArimaModelInfo {
    const message = createBaseModel_TrainingRun_IterationResult_ArimaResult_ArimaModelInfo();
    message.nonSeasonalOrder = (object.nonSeasonalOrder !== undefined && object.nonSeasonalOrder !== null)
      ? Model_ArimaOrder.fromPartial(object.nonSeasonalOrder)
      : undefined;
    message.arimaCoefficients = (object.arimaCoefficients !== undefined && object.arimaCoefficients !== null)
      ? Model_TrainingRun_IterationResult_ArimaResult_ArimaCoefficients.fromPartial(object.arimaCoefficients)
      : undefined;
    message.arimaFittingMetrics = (object.arimaFittingMetrics !== undefined && object.arimaFittingMetrics !== null)
      ? Model_ArimaFittingMetrics.fromPartial(object.arimaFittingMetrics)
      : undefined;
    message.hasDrift = object.hasDrift ?? undefined;
    message.timeSeriesId = object.timeSeriesId ?? "";
    message.timeSeriesIds = object.timeSeriesIds?.map((e) => e) || [];
    message.seasonalPeriods = object.seasonalPeriods?.map((e) => e) || [];
    message.hasHolidayEffect = object.hasHolidayEffect ?? undefined;
    message.hasSpikesAndDips = object.hasSpikesAndDips ?? undefined;
    message.hasStepChanges = object.hasStepChanges ?? undefined;
    return message;
  },
};

function createBaseModel_TrainingRun_IterationResult_PrincipalComponentInfo(): Model_TrainingRun_IterationResult_PrincipalComponentInfo {
  return {
    principalComponentId: undefined,
    explainedVariance: undefined,
    explainedVarianceRatio: undefined,
    cumulativeExplainedVarianceRatio: undefined,
  };
}

export const Model_TrainingRun_IterationResult_PrincipalComponentInfo: MessageFns<
  Model_TrainingRun_IterationResult_PrincipalComponentInfo
> = {
  encode(
    message: Model_TrainingRun_IterationResult_PrincipalComponentInfo,
    writer: BinaryWriter = new BinaryWriter(),
  ): BinaryWriter {
    if (message.principalComponentId !== undefined) {
      Int64Value.encode({ value: message.principalComponentId! }, writer.uint32(10).fork()).join();
    }
    if (message.explainedVariance !== undefined) {
      DoubleValue.encode({ value: message.explainedVariance! }, writer.uint32(18).fork()).join();
    }
    if (message.explainedVarianceRatio !== undefined) {
      DoubleValue.encode({ value: message.explainedVarianceRatio! }, writer.uint32(26).fork()).join();
    }
    if (message.cumulativeExplainedVarianceRatio !== undefined) {
      DoubleValue.encode({ value: message.cumulativeExplainedVarianceRatio! }, writer.uint32(34).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Model_TrainingRun_IterationResult_PrincipalComponentInfo {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseModel_TrainingRun_IterationResult_PrincipalComponentInfo();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.principalComponentId = Int64Value.decode(reader, reader.uint32()).value;
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.explainedVariance = DoubleValue.decode(reader, reader.uint32()).value;
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.explainedVarianceRatio = DoubleValue.decode(reader, reader.uint32()).value;
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.cumulativeExplainedVarianceRatio = DoubleValue.decode(reader, reader.uint32()).value;
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Model_TrainingRun_IterationResult_PrincipalComponentInfo {
    return {
      principalComponentId: isSet(object.principalComponentId)
        ? Long.fromValue(object.principalComponentId)
        : undefined,
      explainedVariance: isSet(object.explainedVariance) ? Number(object.explainedVariance) : undefined,
      explainedVarianceRatio: isSet(object.explainedVarianceRatio) ? Number(object.explainedVarianceRatio) : undefined,
      cumulativeExplainedVarianceRatio: isSet(object.cumulativeExplainedVarianceRatio)
        ? Number(object.cumulativeExplainedVarianceRatio)
        : undefined,
    };
  },

  toJSON(message: Model_TrainingRun_IterationResult_PrincipalComponentInfo): unknown {
    const obj: any = {};
    if (message.principalComponentId !== undefined) {
      obj.principalComponentId = message.principalComponentId;
    }
    if (message.explainedVariance !== undefined) {
      obj.explainedVariance = message.explainedVariance;
    }
    if (message.explainedVarianceRatio !== undefined) {
      obj.explainedVarianceRatio = message.explainedVarianceRatio;
    }
    if (message.cumulativeExplainedVarianceRatio !== undefined) {
      obj.cumulativeExplainedVarianceRatio = message.cumulativeExplainedVarianceRatio;
    }
    return obj;
  },

  create(
    base?: DeepPartial<Model_TrainingRun_IterationResult_PrincipalComponentInfo>,
  ): Model_TrainingRun_IterationResult_PrincipalComponentInfo {
    return Model_TrainingRun_IterationResult_PrincipalComponentInfo.fromPartial(base ?? {});
  },
  fromPartial(
    object: DeepPartial<Model_TrainingRun_IterationResult_PrincipalComponentInfo>,
  ): Model_TrainingRun_IterationResult_PrincipalComponentInfo {
    const message = createBaseModel_TrainingRun_IterationResult_PrincipalComponentInfo();
    message.principalComponentId = (object.principalComponentId !== undefined && object.principalComponentId !== null)
      ? Long.fromValue(object.principalComponentId)
      : undefined;
    message.explainedVariance = object.explainedVariance ?? undefined;
    message.explainedVarianceRatio = object.explainedVarianceRatio ?? undefined;
    message.cumulativeExplainedVarianceRatio = object.cumulativeExplainedVarianceRatio ?? undefined;
    return message;
  },
};

function createBaseModel_DoubleHparamSearchSpace(): Model_DoubleHparamSearchSpace {
  return { range: undefined, candidates: undefined };
}

export const Model_DoubleHparamSearchSpace: MessageFns<Model_DoubleHparamSearchSpace> = {
  encode(message: Model_DoubleHparamSearchSpace, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.range !== undefined) {
      Model_DoubleHparamSearchSpace_DoubleRange.encode(message.range, writer.uint32(10).fork()).join();
    }
    if (message.candidates !== undefined) {
      Model_DoubleHparamSearchSpace_DoubleCandidates.encode(message.candidates, writer.uint32(18).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Model_DoubleHparamSearchSpace {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseModel_DoubleHparamSearchSpace();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.range = Model_DoubleHparamSearchSpace_DoubleRange.decode(reader, reader.uint32());
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.candidates = Model_DoubleHparamSearchSpace_DoubleCandidates.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Model_DoubleHparamSearchSpace {
    return {
      range: isSet(object.range) ? Model_DoubleHparamSearchSpace_DoubleRange.fromJSON(object.range) : undefined,
      candidates: isSet(object.candidates)
        ? Model_DoubleHparamSearchSpace_DoubleCandidates.fromJSON(object.candidates)
        : undefined,
    };
  },

  toJSON(message: Model_DoubleHparamSearchSpace): unknown {
    const obj: any = {};
    if (message.range !== undefined) {
      obj.range = Model_DoubleHparamSearchSpace_DoubleRange.toJSON(message.range);
    }
    if (message.candidates !== undefined) {
      obj.candidates = Model_DoubleHparamSearchSpace_DoubleCandidates.toJSON(message.candidates);
    }
    return obj;
  },

  create(base?: DeepPartial<Model_DoubleHparamSearchSpace>): Model_DoubleHparamSearchSpace {
    return Model_DoubleHparamSearchSpace.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<Model_DoubleHparamSearchSpace>): Model_DoubleHparamSearchSpace {
    const message = createBaseModel_DoubleHparamSearchSpace();
    message.range = (object.range !== undefined && object.range !== null)
      ? Model_DoubleHparamSearchSpace_DoubleRange.fromPartial(object.range)
      : undefined;
    message.candidates = (object.candidates !== undefined && object.candidates !== null)
      ? Model_DoubleHparamSearchSpace_DoubleCandidates.fromPartial(object.candidates)
      : undefined;
    return message;
  },
};

function createBaseModel_DoubleHparamSearchSpace_DoubleRange(): Model_DoubleHparamSearchSpace_DoubleRange {
  return { min: undefined, max: undefined };
}

export const Model_DoubleHparamSearchSpace_DoubleRange: MessageFns<Model_DoubleHparamSearchSpace_DoubleRange> = {
  encode(message: Model_DoubleHparamSearchSpace_DoubleRange, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.min !== undefined) {
      DoubleValue.encode({ value: message.min! }, writer.uint32(10).fork()).join();
    }
    if (message.max !== undefined) {
      DoubleValue.encode({ value: message.max! }, writer.uint32(18).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Model_DoubleHparamSearchSpace_DoubleRange {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseModel_DoubleHparamSearchSpace_DoubleRange();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.min = DoubleValue.decode(reader, reader.uint32()).value;
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.max = DoubleValue.decode(reader, reader.uint32()).value;
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Model_DoubleHparamSearchSpace_DoubleRange {
    return {
      min: isSet(object.min) ? Number(object.min) : undefined,
      max: isSet(object.max) ? Number(object.max) : undefined,
    };
  },

  toJSON(message: Model_DoubleHparamSearchSpace_DoubleRange): unknown {
    const obj: any = {};
    if (message.min !== undefined) {
      obj.min = message.min;
    }
    if (message.max !== undefined) {
      obj.max = message.max;
    }
    return obj;
  },

  create(base?: DeepPartial<Model_DoubleHparamSearchSpace_DoubleRange>): Model_DoubleHparamSearchSpace_DoubleRange {
    return Model_DoubleHparamSearchSpace_DoubleRange.fromPartial(base ?? {});
  },
  fromPartial(
    object: DeepPartial<Model_DoubleHparamSearchSpace_DoubleRange>,
  ): Model_DoubleHparamSearchSpace_DoubleRange {
    const message = createBaseModel_DoubleHparamSearchSpace_DoubleRange();
    message.min = object.min ?? undefined;
    message.max = object.max ?? undefined;
    return message;
  },
};

function createBaseModel_DoubleHparamSearchSpace_DoubleCandidates(): Model_DoubleHparamSearchSpace_DoubleCandidates {
  return { candidates: [] };
}

export const Model_DoubleHparamSearchSpace_DoubleCandidates: MessageFns<
  Model_DoubleHparamSearchSpace_DoubleCandidates
> = {
  encode(
    message: Model_DoubleHparamSearchSpace_DoubleCandidates,
    writer: BinaryWriter = new BinaryWriter(),
  ): BinaryWriter {
    for (const v of message.candidates) {
      DoubleValue.encode({ value: v!! }, writer.uint32(10).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Model_DoubleHparamSearchSpace_DoubleCandidates {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseModel_DoubleHparamSearchSpace_DoubleCandidates();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.candidates.push(DoubleValue.decode(reader, reader.uint32()).value);
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Model_DoubleHparamSearchSpace_DoubleCandidates {
    return {
      candidates: globalThis.Array.isArray(object?.candidates) ? object.candidates.map((e: any) => Number(e)) : [],
    };
  },

  toJSON(message: Model_DoubleHparamSearchSpace_DoubleCandidates): unknown {
    const obj: any = {};
    if (message.candidates?.length) {
      obj.candidates = message.candidates;
    }
    return obj;
  },

  create(
    base?: DeepPartial<Model_DoubleHparamSearchSpace_DoubleCandidates>,
  ): Model_DoubleHparamSearchSpace_DoubleCandidates {
    return Model_DoubleHparamSearchSpace_DoubleCandidates.fromPartial(base ?? {});
  },
  fromPartial(
    object: DeepPartial<Model_DoubleHparamSearchSpace_DoubleCandidates>,
  ): Model_DoubleHparamSearchSpace_DoubleCandidates {
    const message = createBaseModel_DoubleHparamSearchSpace_DoubleCandidates();
    message.candidates = object.candidates?.map((e) => e) || [];
    return message;
  },
};

function createBaseModel_IntHparamSearchSpace(): Model_IntHparamSearchSpace {
  return { range: undefined, candidates: undefined };
}

export const Model_IntHparamSearchSpace: MessageFns<Model_IntHparamSearchSpace> = {
  encode(message: Model_IntHparamSearchSpace, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.range !== undefined) {
      Model_IntHparamSearchSpace_IntRange.encode(message.range, writer.uint32(10).fork()).join();
    }
    if (message.candidates !== undefined) {
      Model_IntHparamSearchSpace_IntCandidates.encode(message.candidates, writer.uint32(18).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Model_IntHparamSearchSpace {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseModel_IntHparamSearchSpace();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.range = Model_IntHparamSearchSpace_IntRange.decode(reader, reader.uint32());
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.candidates = Model_IntHparamSearchSpace_IntCandidates.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Model_IntHparamSearchSpace {
    return {
      range: isSet(object.range) ? Model_IntHparamSearchSpace_IntRange.fromJSON(object.range) : undefined,
      candidates: isSet(object.candidates)
        ? Model_IntHparamSearchSpace_IntCandidates.fromJSON(object.candidates)
        : undefined,
    };
  },

  toJSON(message: Model_IntHparamSearchSpace): unknown {
    const obj: any = {};
    if (message.range !== undefined) {
      obj.range = Model_IntHparamSearchSpace_IntRange.toJSON(message.range);
    }
    if (message.candidates !== undefined) {
      obj.candidates = Model_IntHparamSearchSpace_IntCandidates.toJSON(message.candidates);
    }
    return obj;
  },

  create(base?: DeepPartial<Model_IntHparamSearchSpace>): Model_IntHparamSearchSpace {
    return Model_IntHparamSearchSpace.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<Model_IntHparamSearchSpace>): Model_IntHparamSearchSpace {
    const message = createBaseModel_IntHparamSearchSpace();
    message.range = (object.range !== undefined && object.range !== null)
      ? Model_IntHparamSearchSpace_IntRange.fromPartial(object.range)
      : undefined;
    message.candidates = (object.candidates !== undefined && object.candidates !== null)
      ? Model_IntHparamSearchSpace_IntCandidates.fromPartial(object.candidates)
      : undefined;
    return message;
  },
};

function createBaseModel_IntHparamSearchSpace_IntRange(): Model_IntHparamSearchSpace_IntRange {
  return { min: undefined, max: undefined };
}

export const Model_IntHparamSearchSpace_IntRange: MessageFns<Model_IntHparamSearchSpace_IntRange> = {
  encode(message: Model_IntHparamSearchSpace_IntRange, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.min !== undefined) {
      Int64Value.encode({ value: message.min! }, writer.uint32(10).fork()).join();
    }
    if (message.max !== undefined) {
      Int64Value.encode({ value: message.max! }, writer.uint32(18).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Model_IntHparamSearchSpace_IntRange {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseModel_IntHparamSearchSpace_IntRange();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.min = Int64Value.decode(reader, reader.uint32()).value;
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.max = Int64Value.decode(reader, reader.uint32()).value;
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Model_IntHparamSearchSpace_IntRange {
    return {
      min: isSet(object.min) ? Long.fromValue(object.min) : undefined,
      max: isSet(object.max) ? Long.fromValue(object.max) : undefined,
    };
  },

  toJSON(message: Model_IntHparamSearchSpace_IntRange): unknown {
    const obj: any = {};
    if (message.min !== undefined) {
      obj.min = message.min;
    }
    if (message.max !== undefined) {
      obj.max = message.max;
    }
    return obj;
  },

  create(base?: DeepPartial<Model_IntHparamSearchSpace_IntRange>): Model_IntHparamSearchSpace_IntRange {
    return Model_IntHparamSearchSpace_IntRange.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<Model_IntHparamSearchSpace_IntRange>): Model_IntHparamSearchSpace_IntRange {
    const message = createBaseModel_IntHparamSearchSpace_IntRange();
    message.min = (object.min !== undefined && object.min !== null) ? Long.fromValue(object.min) : undefined;
    message.max = (object.max !== undefined && object.max !== null) ? Long.fromValue(object.max) : undefined;
    return message;
  },
};

function createBaseModel_IntHparamSearchSpace_IntCandidates(): Model_IntHparamSearchSpace_IntCandidates {
  return { candidates: [] };
}

export const Model_IntHparamSearchSpace_IntCandidates: MessageFns<Model_IntHparamSearchSpace_IntCandidates> = {
  encode(message: Model_IntHparamSearchSpace_IntCandidates, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.candidates) {
      Int64Value.encode({ value: v!! }, writer.uint32(10).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Model_IntHparamSearchSpace_IntCandidates {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseModel_IntHparamSearchSpace_IntCandidates();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.candidates.push(Int64Value.decode(reader, reader.uint32()).value);
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Model_IntHparamSearchSpace_IntCandidates {
    return {
      candidates: globalThis.Array.isArray(object?.candidates)
        ? object.candidates.map((e: any) => Long.fromValue(e))
        : [],
    };
  },

  toJSON(message: Model_IntHparamSearchSpace_IntCandidates): unknown {
    const obj: any = {};
    if (message.candidates?.length) {
      obj.candidates = message.candidates;
    }
    return obj;
  },

  create(base?: DeepPartial<Model_IntHparamSearchSpace_IntCandidates>): Model_IntHparamSearchSpace_IntCandidates {
    return Model_IntHparamSearchSpace_IntCandidates.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<Model_IntHparamSearchSpace_IntCandidates>): Model_IntHparamSearchSpace_IntCandidates {
    const message = createBaseModel_IntHparamSearchSpace_IntCandidates();
    message.candidates = object.candidates?.map((e) => Long.fromValue(e)) || [];
    return message;
  },
};

function createBaseModel_StringHparamSearchSpace(): Model_StringHparamSearchSpace {
  return { candidates: [] };
}

export const Model_StringHparamSearchSpace: MessageFns<Model_StringHparamSearchSpace> = {
  encode(message: Model_StringHparamSearchSpace, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.candidates) {
      writer.uint32(10).string(v!);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Model_StringHparamSearchSpace {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseModel_StringHparamSearchSpace();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.candidates.push(reader.string());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Model_StringHparamSearchSpace {
    return {
      candidates: globalThis.Array.isArray(object?.candidates)
        ? object.candidates.map((e: any) => globalThis.String(e))
        : [],
    };
  },

  toJSON(message: Model_StringHparamSearchSpace): unknown {
    const obj: any = {};
    if (message.candidates?.length) {
      obj.candidates = message.candidates;
    }
    return obj;
  },

  create(base?: DeepPartial<Model_StringHparamSearchSpace>): Model_StringHparamSearchSpace {
    return Model_StringHparamSearchSpace.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<Model_StringHparamSearchSpace>): Model_StringHparamSearchSpace {
    const message = createBaseModel_StringHparamSearchSpace();
    message.candidates = object.candidates?.map((e) => e) || [];
    return message;
  },
};

function createBaseModel_IntArrayHparamSearchSpace(): Model_IntArrayHparamSearchSpace {
  return { candidates: [] };
}

export const Model_IntArrayHparamSearchSpace: MessageFns<Model_IntArrayHparamSearchSpace> = {
  encode(message: Model_IntArrayHparamSearchSpace, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.candidates) {
      Model_IntArrayHparamSearchSpace_IntArray.encode(v!, writer.uint32(10).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Model_IntArrayHparamSearchSpace {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseModel_IntArrayHparamSearchSpace();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.candidates.push(Model_IntArrayHparamSearchSpace_IntArray.decode(reader, reader.uint32()));
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Model_IntArrayHparamSearchSpace {
    return {
      candidates: globalThis.Array.isArray(object?.candidates)
        ? object.candidates.map((e: any) => Model_IntArrayHparamSearchSpace_IntArray.fromJSON(e))
        : [],
    };
  },

  toJSON(message: Model_IntArrayHparamSearchSpace): unknown {
    const obj: any = {};
    if (message.candidates?.length) {
      obj.candidates = message.candidates.map((e) => Model_IntArrayHparamSearchSpace_IntArray.toJSON(e));
    }
    return obj;
  },

  create(base?: DeepPartial<Model_IntArrayHparamSearchSpace>): Model_IntArrayHparamSearchSpace {
    return Model_IntArrayHparamSearchSpace.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<Model_IntArrayHparamSearchSpace>): Model_IntArrayHparamSearchSpace {
    const message = createBaseModel_IntArrayHparamSearchSpace();
    message.candidates = object.candidates?.map((e) => Model_IntArrayHparamSearchSpace_IntArray.fromPartial(e)) || [];
    return message;
  },
};

function createBaseModel_IntArrayHparamSearchSpace_IntArray(): Model_IntArrayHparamSearchSpace_IntArray {
  return { elements: [] };
}

export const Model_IntArrayHparamSearchSpace_IntArray: MessageFns<Model_IntArrayHparamSearchSpace_IntArray> = {
  encode(message: Model_IntArrayHparamSearchSpace_IntArray, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    writer.uint32(10).fork();
    for (const v of message.elements) {
      writer.int64(v.toString());
    }
    writer.join();
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Model_IntArrayHparamSearchSpace_IntArray {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseModel_IntArrayHparamSearchSpace_IntArray();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag === 8) {
            message.elements.push(Long.fromString(reader.int64().toString()));

            continue;
          }

          if (tag === 10) {
            const end2 = reader.uint32() + reader.pos;
            while (reader.pos < end2) {
              message.elements.push(Long.fromString(reader.int64().toString()));
            }

            continue;
          }

          break;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Model_IntArrayHparamSearchSpace_IntArray {
    return {
      elements: globalThis.Array.isArray(object?.elements) ? object.elements.map((e: any) => Long.fromValue(e)) : [],
    };
  },

  toJSON(message: Model_IntArrayHparamSearchSpace_IntArray): unknown {
    const obj: any = {};
    if (message.elements?.length) {
      obj.elements = message.elements.map((e) => (e || Long.ZERO).toString());
    }
    return obj;
  },

  create(base?: DeepPartial<Model_IntArrayHparamSearchSpace_IntArray>): Model_IntArrayHparamSearchSpace_IntArray {
    return Model_IntArrayHparamSearchSpace_IntArray.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<Model_IntArrayHparamSearchSpace_IntArray>): Model_IntArrayHparamSearchSpace_IntArray {
    const message = createBaseModel_IntArrayHparamSearchSpace_IntArray();
    message.elements = object.elements?.map((e) => Long.fromValue(e)) || [];
    return message;
  },
};

function createBaseModel_HparamSearchSpaces(): Model_HparamSearchSpaces {
  return {
    learnRate: undefined,
    l1Reg: undefined,
    l2Reg: undefined,
    numClusters: undefined,
    numFactors: undefined,
    hiddenUnits: undefined,
    batchSize: undefined,
    dropout: undefined,
    maxTreeDepth: undefined,
    subsample: undefined,
    minSplitLoss: undefined,
    walsAlpha: undefined,
    boosterType: undefined,
    numParallelTree: undefined,
    dartNormalizeType: undefined,
    treeMethod: undefined,
    minTreeChildWeight: undefined,
    colsampleBytree: undefined,
    colsampleBylevel: undefined,
    colsampleBynode: undefined,
    activationFn: undefined,
    optimizer: undefined,
  };
}

export const Model_HparamSearchSpaces: MessageFns<Model_HparamSearchSpaces> = {
  encode(message: Model_HparamSearchSpaces, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.learnRate !== undefined) {
      Model_DoubleHparamSearchSpace.encode(message.learnRate, writer.uint32(18).fork()).join();
    }
    if (message.l1Reg !== undefined) {
      Model_DoubleHparamSearchSpace.encode(message.l1Reg, writer.uint32(26).fork()).join();
    }
    if (message.l2Reg !== undefined) {
      Model_DoubleHparamSearchSpace.encode(message.l2Reg, writer.uint32(34).fork()).join();
    }
    if (message.numClusters !== undefined) {
      Model_IntHparamSearchSpace.encode(message.numClusters, writer.uint32(210).fork()).join();
    }
    if (message.numFactors !== undefined) {
      Model_IntHparamSearchSpace.encode(message.numFactors, writer.uint32(250).fork()).join();
    }
    if (message.hiddenUnits !== undefined) {
      Model_IntArrayHparamSearchSpace.encode(message.hiddenUnits, writer.uint32(274).fork()).join();
    }
    if (message.batchSize !== undefined) {
      Model_IntHparamSearchSpace.encode(message.batchSize, writer.uint32(298).fork()).join();
    }
    if (message.dropout !== undefined) {
      Model_DoubleHparamSearchSpace.encode(message.dropout, writer.uint32(306).fork()).join();
    }
    if (message.maxTreeDepth !== undefined) {
      Model_IntHparamSearchSpace.encode(message.maxTreeDepth, writer.uint32(330).fork()).join();
    }
    if (message.subsample !== undefined) {
      Model_DoubleHparamSearchSpace.encode(message.subsample, writer.uint32(338).fork()).join();
    }
    if (message.minSplitLoss !== undefined) {
      Model_DoubleHparamSearchSpace.encode(message.minSplitLoss, writer.uint32(346).fork()).join();
    }
    if (message.walsAlpha !== undefined) {
      Model_DoubleHparamSearchSpace.encode(message.walsAlpha, writer.uint32(394).fork()).join();
    }
    if (message.boosterType !== undefined) {
      Model_StringHparamSearchSpace.encode(message.boosterType, writer.uint32(450).fork()).join();
    }
    if (message.numParallelTree !== undefined) {
      Model_IntHparamSearchSpace.encode(message.numParallelTree, writer.uint32(458).fork()).join();
    }
    if (message.dartNormalizeType !== undefined) {
      Model_StringHparamSearchSpace.encode(message.dartNormalizeType, writer.uint32(466).fork()).join();
    }
    if (message.treeMethod !== undefined) {
      Model_StringHparamSearchSpace.encode(message.treeMethod, writer.uint32(474).fork()).join();
    }
    if (message.minTreeChildWeight !== undefined) {
      Model_IntHparamSearchSpace.encode(message.minTreeChildWeight, writer.uint32(482).fork()).join();
    }
    if (message.colsampleBytree !== undefined) {
      Model_DoubleHparamSearchSpace.encode(message.colsampleBytree, writer.uint32(490).fork()).join();
    }
    if (message.colsampleBylevel !== undefined) {
      Model_DoubleHparamSearchSpace.encode(message.colsampleBylevel, writer.uint32(498).fork()).join();
    }
    if (message.colsampleBynode !== undefined) {
      Model_DoubleHparamSearchSpace.encode(message.colsampleBynode, writer.uint32(506).fork()).join();
    }
    if (message.activationFn !== undefined) {
      Model_StringHparamSearchSpace.encode(message.activationFn, writer.uint32(538).fork()).join();
    }
    if (message.optimizer !== undefined) {
      Model_StringHparamSearchSpace.encode(message.optimizer, writer.uint32(546).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Model_HparamSearchSpaces {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseModel_HparamSearchSpaces();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 2:
          if (tag !== 18) {
            break;
          }

          message.learnRate = Model_DoubleHparamSearchSpace.decode(reader, reader.uint32());
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.l1Reg = Model_DoubleHparamSearchSpace.decode(reader, reader.uint32());
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.l2Reg = Model_DoubleHparamSearchSpace.decode(reader, reader.uint32());
          continue;
        case 26:
          if (tag !== 210) {
            break;
          }

          message.numClusters = Model_IntHparamSearchSpace.decode(reader, reader.uint32());
          continue;
        case 31:
          if (tag !== 250) {
            break;
          }

          message.numFactors = Model_IntHparamSearchSpace.decode(reader, reader.uint32());
          continue;
        case 34:
          if (tag !== 274) {
            break;
          }

          message.hiddenUnits = Model_IntArrayHparamSearchSpace.decode(reader, reader.uint32());
          continue;
        case 37:
          if (tag !== 298) {
            break;
          }

          message.batchSize = Model_IntHparamSearchSpace.decode(reader, reader.uint32());
          continue;
        case 38:
          if (tag !== 306) {
            break;
          }

          message.dropout = Model_DoubleHparamSearchSpace.decode(reader, reader.uint32());
          continue;
        case 41:
          if (tag !== 330) {
            break;
          }

          message.maxTreeDepth = Model_IntHparamSearchSpace.decode(reader, reader.uint32());
          continue;
        case 42:
          if (tag !== 338) {
            break;
          }

          message.subsample = Model_DoubleHparamSearchSpace.decode(reader, reader.uint32());
          continue;
        case 43:
          if (tag !== 346) {
            break;
          }

          message.minSplitLoss = Model_DoubleHparamSearchSpace.decode(reader, reader.uint32());
          continue;
        case 49:
          if (tag !== 394) {
            break;
          }

          message.walsAlpha = Model_DoubleHparamSearchSpace.decode(reader, reader.uint32());
          continue;
        case 56:
          if (tag !== 450) {
            break;
          }

          message.boosterType = Model_StringHparamSearchSpace.decode(reader, reader.uint32());
          continue;
        case 57:
          if (tag !== 458) {
            break;
          }

          message.numParallelTree = Model_IntHparamSearchSpace.decode(reader, reader.uint32());
          continue;
        case 58:
          if (tag !== 466) {
            break;
          }

          message.dartNormalizeType = Model_StringHparamSearchSpace.decode(reader, reader.uint32());
          continue;
        case 59:
          if (tag !== 474) {
            break;
          }

          message.treeMethod = Model_StringHparamSearchSpace.decode(reader, reader.uint32());
          continue;
        case 60:
          if (tag !== 482) {
            break;
          }

          message.minTreeChildWeight = Model_IntHparamSearchSpace.decode(reader, reader.uint32());
          continue;
        case 61:
          if (tag !== 490) {
            break;
          }

          message.colsampleBytree = Model_DoubleHparamSearchSpace.decode(reader, reader.uint32());
          continue;
        case 62:
          if (tag !== 498) {
            break;
          }

          message.colsampleBylevel = Model_DoubleHparamSearchSpace.decode(reader, reader.uint32());
          continue;
        case 63:
          if (tag !== 506) {
            break;
          }

          message.colsampleBynode = Model_DoubleHparamSearchSpace.decode(reader, reader.uint32());
          continue;
        case 67:
          if (tag !== 538) {
            break;
          }

          message.activationFn = Model_StringHparamSearchSpace.decode(reader, reader.uint32());
          continue;
        case 68:
          if (tag !== 546) {
            break;
          }

          message.optimizer = Model_StringHparamSearchSpace.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Model_HparamSearchSpaces {
    return {
      learnRate: isSet(object.learnRate) ? Model_DoubleHparamSearchSpace.fromJSON(object.learnRate) : undefined,
      l1Reg: isSet(object.l1Reg) ? Model_DoubleHparamSearchSpace.fromJSON(object.l1Reg) : undefined,
      l2Reg: isSet(object.l2Reg) ? Model_DoubleHparamSearchSpace.fromJSON(object.l2Reg) : undefined,
      numClusters: isSet(object.numClusters) ? Model_IntHparamSearchSpace.fromJSON(object.numClusters) : undefined,
      numFactors: isSet(object.numFactors) ? Model_IntHparamSearchSpace.fromJSON(object.numFactors) : undefined,
      hiddenUnits: isSet(object.hiddenUnits) ? Model_IntArrayHparamSearchSpace.fromJSON(object.hiddenUnits) : undefined,
      batchSize: isSet(object.batchSize) ? Model_IntHparamSearchSpace.fromJSON(object.batchSize) : undefined,
      dropout: isSet(object.dropout) ? Model_DoubleHparamSearchSpace.fromJSON(object.dropout) : undefined,
      maxTreeDepth: isSet(object.maxTreeDepth) ? Model_IntHparamSearchSpace.fromJSON(object.maxTreeDepth) : undefined,
      subsample: isSet(object.subsample) ? Model_DoubleHparamSearchSpace.fromJSON(object.subsample) : undefined,
      minSplitLoss: isSet(object.minSplitLoss)
        ? Model_DoubleHparamSearchSpace.fromJSON(object.minSplitLoss)
        : undefined,
      walsAlpha: isSet(object.walsAlpha) ? Model_DoubleHparamSearchSpace.fromJSON(object.walsAlpha) : undefined,
      boosterType: isSet(object.boosterType) ? Model_StringHparamSearchSpace.fromJSON(object.boosterType) : undefined,
      numParallelTree: isSet(object.numParallelTree)
        ? Model_IntHparamSearchSpace.fromJSON(object.numParallelTree)
        : undefined,
      dartNormalizeType: isSet(object.dartNormalizeType)
        ? Model_StringHparamSearchSpace.fromJSON(object.dartNormalizeType)
        : undefined,
      treeMethod: isSet(object.treeMethod) ? Model_StringHparamSearchSpace.fromJSON(object.treeMethod) : undefined,
      minTreeChildWeight: isSet(object.minTreeChildWeight)
        ? Model_IntHparamSearchSpace.fromJSON(object.minTreeChildWeight)
        : undefined,
      colsampleBytree: isSet(object.colsampleBytree)
        ? Model_DoubleHparamSearchSpace.fromJSON(object.colsampleBytree)
        : undefined,
      colsampleBylevel: isSet(object.colsampleBylevel)
        ? Model_DoubleHparamSearchSpace.fromJSON(object.colsampleBylevel)
        : undefined,
      colsampleBynode: isSet(object.colsampleBynode)
        ? Model_DoubleHparamSearchSpace.fromJSON(object.colsampleBynode)
        : undefined,
      activationFn: isSet(object.activationFn)
        ? Model_StringHparamSearchSpace.fromJSON(object.activationFn)
        : undefined,
      optimizer: isSet(object.optimizer) ? Model_StringHparamSearchSpace.fromJSON(object.optimizer) : undefined,
    };
  },

  toJSON(message: Model_HparamSearchSpaces): unknown {
    const obj: any = {};
    if (message.learnRate !== undefined) {
      obj.learnRate = Model_DoubleHparamSearchSpace.toJSON(message.learnRate);
    }
    if (message.l1Reg !== undefined) {
      obj.l1Reg = Model_DoubleHparamSearchSpace.toJSON(message.l1Reg);
    }
    if (message.l2Reg !== undefined) {
      obj.l2Reg = Model_DoubleHparamSearchSpace.toJSON(message.l2Reg);
    }
    if (message.numClusters !== undefined) {
      obj.numClusters = Model_IntHparamSearchSpace.toJSON(message.numClusters);
    }
    if (message.numFactors !== undefined) {
      obj.numFactors = Model_IntHparamSearchSpace.toJSON(message.numFactors);
    }
    if (message.hiddenUnits !== undefined) {
      obj.hiddenUnits = Model_IntArrayHparamSearchSpace.toJSON(message.hiddenUnits);
    }
    if (message.batchSize !== undefined) {
      obj.batchSize = Model_IntHparamSearchSpace.toJSON(message.batchSize);
    }
    if (message.dropout !== undefined) {
      obj.dropout = Model_DoubleHparamSearchSpace.toJSON(message.dropout);
    }
    if (message.maxTreeDepth !== undefined) {
      obj.maxTreeDepth = Model_IntHparamSearchSpace.toJSON(message.maxTreeDepth);
    }
    if (message.subsample !== undefined) {
      obj.subsample = Model_DoubleHparamSearchSpace.toJSON(message.subsample);
    }
    if (message.minSplitLoss !== undefined) {
      obj.minSplitLoss = Model_DoubleHparamSearchSpace.toJSON(message.minSplitLoss);
    }
    if (message.walsAlpha !== undefined) {
      obj.walsAlpha = Model_DoubleHparamSearchSpace.toJSON(message.walsAlpha);
    }
    if (message.boosterType !== undefined) {
      obj.boosterType = Model_StringHparamSearchSpace.toJSON(message.boosterType);
    }
    if (message.numParallelTree !== undefined) {
      obj.numParallelTree = Model_IntHparamSearchSpace.toJSON(message.numParallelTree);
    }
    if (message.dartNormalizeType !== undefined) {
      obj.dartNormalizeType = Model_StringHparamSearchSpace.toJSON(message.dartNormalizeType);
    }
    if (message.treeMethod !== undefined) {
      obj.treeMethod = Model_StringHparamSearchSpace.toJSON(message.treeMethod);
    }
    if (message.minTreeChildWeight !== undefined) {
      obj.minTreeChildWeight = Model_IntHparamSearchSpace.toJSON(message.minTreeChildWeight);
    }
    if (message.colsampleBytree !== undefined) {
      obj.colsampleBytree = Model_DoubleHparamSearchSpace.toJSON(message.colsampleBytree);
    }
    if (message.colsampleBylevel !== undefined) {
      obj.colsampleBylevel = Model_DoubleHparamSearchSpace.toJSON(message.colsampleBylevel);
    }
    if (message.colsampleBynode !== undefined) {
      obj.colsampleBynode = Model_DoubleHparamSearchSpace.toJSON(message.colsampleBynode);
    }
    if (message.activationFn !== undefined) {
      obj.activationFn = Model_StringHparamSearchSpace.toJSON(message.activationFn);
    }
    if (message.optimizer !== undefined) {
      obj.optimizer = Model_StringHparamSearchSpace.toJSON(message.optimizer);
    }
    return obj;
  },

  create(base?: DeepPartial<Model_HparamSearchSpaces>): Model_HparamSearchSpaces {
    return Model_HparamSearchSpaces.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<Model_HparamSearchSpaces>): Model_HparamSearchSpaces {
    const message = createBaseModel_HparamSearchSpaces();
    message.learnRate = (object.learnRate !== undefined && object.learnRate !== null)
      ? Model_DoubleHparamSearchSpace.fromPartial(object.learnRate)
      : undefined;
    message.l1Reg = (object.l1Reg !== undefined && object.l1Reg !== null)
      ? Model_DoubleHparamSearchSpace.fromPartial(object.l1Reg)
      : undefined;
    message.l2Reg = (object.l2Reg !== undefined && object.l2Reg !== null)
      ? Model_DoubleHparamSearchSpace.fromPartial(object.l2Reg)
      : undefined;
    message.numClusters = (object.numClusters !== undefined && object.numClusters !== null)
      ? Model_IntHparamSearchSpace.fromPartial(object.numClusters)
      : undefined;
    message.numFactors = (object.numFactors !== undefined && object.numFactors !== null)
      ? Model_IntHparamSearchSpace.fromPartial(object.numFactors)
      : undefined;
    message.hiddenUnits = (object.hiddenUnits !== undefined && object.hiddenUnits !== null)
      ? Model_IntArrayHparamSearchSpace.fromPartial(object.hiddenUnits)
      : undefined;
    message.batchSize = (object.batchSize !== undefined && object.batchSize !== null)
      ? Model_IntHparamSearchSpace.fromPartial(object.batchSize)
      : undefined;
    message.dropout = (object.dropout !== undefined && object.dropout !== null)
      ? Model_DoubleHparamSearchSpace.fromPartial(object.dropout)
      : undefined;
    message.maxTreeDepth = (object.maxTreeDepth !== undefined && object.maxTreeDepth !== null)
      ? Model_IntHparamSearchSpace.fromPartial(object.maxTreeDepth)
      : undefined;
    message.subsample = (object.subsample !== undefined && object.subsample !== null)
      ? Model_DoubleHparamSearchSpace.fromPartial(object.subsample)
      : undefined;
    message.minSplitLoss = (object.minSplitLoss !== undefined && object.minSplitLoss !== null)
      ? Model_DoubleHparamSearchSpace.fromPartial(object.minSplitLoss)
      : undefined;
    message.walsAlpha = (object.walsAlpha !== undefined && object.walsAlpha !== null)
      ? Model_DoubleHparamSearchSpace.fromPartial(object.walsAlpha)
      : undefined;
    message.boosterType = (object.boosterType !== undefined && object.boosterType !== null)
      ? Model_StringHparamSearchSpace.fromPartial(object.boosterType)
      : undefined;
    message.numParallelTree = (object.numParallelTree !== undefined && object.numParallelTree !== null)
      ? Model_IntHparamSearchSpace.fromPartial(object.numParallelTree)
      : undefined;
    message.dartNormalizeType = (object.dartNormalizeType !== undefined && object.dartNormalizeType !== null)
      ? Model_StringHparamSearchSpace.fromPartial(object.dartNormalizeType)
      : undefined;
    message.treeMethod = (object.treeMethod !== undefined && object.treeMethod !== null)
      ? Model_StringHparamSearchSpace.fromPartial(object.treeMethod)
      : undefined;
    message.minTreeChildWeight = (object.minTreeChildWeight !== undefined && object.minTreeChildWeight !== null)
      ? Model_IntHparamSearchSpace.fromPartial(object.minTreeChildWeight)
      : undefined;
    message.colsampleBytree = (object.colsampleBytree !== undefined && object.colsampleBytree !== null)
      ? Model_DoubleHparamSearchSpace.fromPartial(object.colsampleBytree)
      : undefined;
    message.colsampleBylevel = (object.colsampleBylevel !== undefined && object.colsampleBylevel !== null)
      ? Model_DoubleHparamSearchSpace.fromPartial(object.colsampleBylevel)
      : undefined;
    message.colsampleBynode = (object.colsampleBynode !== undefined && object.colsampleBynode !== null)
      ? Model_DoubleHparamSearchSpace.fromPartial(object.colsampleBynode)
      : undefined;
    message.activationFn = (object.activationFn !== undefined && object.activationFn !== null)
      ? Model_StringHparamSearchSpace.fromPartial(object.activationFn)
      : undefined;
    message.optimizer = (object.optimizer !== undefined && object.optimizer !== null)
      ? Model_StringHparamSearchSpace.fromPartial(object.optimizer)
      : undefined;
    return message;
  },
};

function createBaseModel_HparamTuningTrial(): Model_HparamTuningTrial {
  return {
    trialId: Long.ZERO,
    startTimeMs: Long.ZERO,
    endTimeMs: Long.ZERO,
    hparams: undefined,
    evaluationMetrics: undefined,
    status: 0,
    errorMessage: "",
    trainingLoss: undefined,
    evalLoss: undefined,
    hparamTuningEvaluationMetrics: undefined,
  };
}

export const Model_HparamTuningTrial: MessageFns<Model_HparamTuningTrial> = {
  encode(message: Model_HparamTuningTrial, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (!message.trialId.equals(Long.ZERO)) {
      writer.uint32(8).int64(message.trialId.toString());
    }
    if (!message.startTimeMs.equals(Long.ZERO)) {
      writer.uint32(16).int64(message.startTimeMs.toString());
    }
    if (!message.endTimeMs.equals(Long.ZERO)) {
      writer.uint32(24).int64(message.endTimeMs.toString());
    }
    if (message.hparams !== undefined) {
      Model_TrainingRun_TrainingOptions.encode(message.hparams, writer.uint32(34).fork()).join();
    }
    if (message.evaluationMetrics !== undefined) {
      Model_EvaluationMetrics.encode(message.evaluationMetrics, writer.uint32(42).fork()).join();
    }
    if (message.status !== 0) {
      writer.uint32(48).int32(message.status);
    }
    if (message.errorMessage !== "") {
      writer.uint32(58).string(message.errorMessage);
    }
    if (message.trainingLoss !== undefined) {
      DoubleValue.encode({ value: message.trainingLoss! }, writer.uint32(66).fork()).join();
    }
    if (message.evalLoss !== undefined) {
      DoubleValue.encode({ value: message.evalLoss! }, writer.uint32(74).fork()).join();
    }
    if (message.hparamTuningEvaluationMetrics !== undefined) {
      Model_EvaluationMetrics.encode(message.hparamTuningEvaluationMetrics, writer.uint32(82).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Model_HparamTuningTrial {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseModel_HparamTuningTrial();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 8) {
            break;
          }

          message.trialId = Long.fromString(reader.int64().toString());
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.startTimeMs = Long.fromString(reader.int64().toString());
          continue;
        case 3:
          if (tag !== 24) {
            break;
          }

          message.endTimeMs = Long.fromString(reader.int64().toString());
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.hparams = Model_TrainingRun_TrainingOptions.decode(reader, reader.uint32());
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.evaluationMetrics = Model_EvaluationMetrics.decode(reader, reader.uint32());
          continue;
        case 6:
          if (tag !== 48) {
            break;
          }

          message.status = reader.int32() as any;
          continue;
        case 7:
          if (tag !== 58) {
            break;
          }

          message.errorMessage = reader.string();
          continue;
        case 8:
          if (tag !== 66) {
            break;
          }

          message.trainingLoss = DoubleValue.decode(reader, reader.uint32()).value;
          continue;
        case 9:
          if (tag !== 74) {
            break;
          }

          message.evalLoss = DoubleValue.decode(reader, reader.uint32()).value;
          continue;
        case 10:
          if (tag !== 82) {
            break;
          }

          message.hparamTuningEvaluationMetrics = Model_EvaluationMetrics.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Model_HparamTuningTrial {
    return {
      trialId: isSet(object.trialId) ? Long.fromValue(object.trialId) : Long.ZERO,
      startTimeMs: isSet(object.startTimeMs) ? Long.fromValue(object.startTimeMs) : Long.ZERO,
      endTimeMs: isSet(object.endTimeMs) ? Long.fromValue(object.endTimeMs) : Long.ZERO,
      hparams: isSet(object.hparams) ? Model_TrainingRun_TrainingOptions.fromJSON(object.hparams) : undefined,
      evaluationMetrics: isSet(object.evaluationMetrics)
        ? Model_EvaluationMetrics.fromJSON(object.evaluationMetrics)
        : undefined,
      status: isSet(object.status) ? model_HparamTuningTrial_TrialStatusFromJSON(object.status) : 0,
      errorMessage: isSet(object.errorMessage) ? globalThis.String(object.errorMessage) : "",
      trainingLoss: isSet(object.trainingLoss) ? Number(object.trainingLoss) : undefined,
      evalLoss: isSet(object.evalLoss) ? Number(object.evalLoss) : undefined,
      hparamTuningEvaluationMetrics: isSet(object.hparamTuningEvaluationMetrics)
        ? Model_EvaluationMetrics.fromJSON(object.hparamTuningEvaluationMetrics)
        : undefined,
    };
  },

  toJSON(message: Model_HparamTuningTrial): unknown {
    const obj: any = {};
    if (!message.trialId.equals(Long.ZERO)) {
      obj.trialId = (message.trialId || Long.ZERO).toString();
    }
    if (!message.startTimeMs.equals(Long.ZERO)) {
      obj.startTimeMs = (message.startTimeMs || Long.ZERO).toString();
    }
    if (!message.endTimeMs.equals(Long.ZERO)) {
      obj.endTimeMs = (message.endTimeMs || Long.ZERO).toString();
    }
    if (message.hparams !== undefined) {
      obj.hparams = Model_TrainingRun_TrainingOptions.toJSON(message.hparams);
    }
    if (message.evaluationMetrics !== undefined) {
      obj.evaluationMetrics = Model_EvaluationMetrics.toJSON(message.evaluationMetrics);
    }
    if (message.status !== 0) {
      obj.status = model_HparamTuningTrial_TrialStatusToJSON(message.status);
    }
    if (message.errorMessage !== "") {
      obj.errorMessage = message.errorMessage;
    }
    if (message.trainingLoss !== undefined) {
      obj.trainingLoss = message.trainingLoss;
    }
    if (message.evalLoss !== undefined) {
      obj.evalLoss = message.evalLoss;
    }
    if (message.hparamTuningEvaluationMetrics !== undefined) {
      obj.hparamTuningEvaluationMetrics = Model_EvaluationMetrics.toJSON(message.hparamTuningEvaluationMetrics);
    }
    return obj;
  },

  create(base?: DeepPartial<Model_HparamTuningTrial>): Model_HparamTuningTrial {
    return Model_HparamTuningTrial.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<Model_HparamTuningTrial>): Model_HparamTuningTrial {
    const message = createBaseModel_HparamTuningTrial();
    message.trialId = (object.trialId !== undefined && object.trialId !== null)
      ? Long.fromValue(object.trialId)
      : Long.ZERO;
    message.startTimeMs = (object.startTimeMs !== undefined && object.startTimeMs !== null)
      ? Long.fromValue(object.startTimeMs)
      : Long.ZERO;
    message.endTimeMs = (object.endTimeMs !== undefined && object.endTimeMs !== null)
      ? Long.fromValue(object.endTimeMs)
      : Long.ZERO;
    message.hparams = (object.hparams !== undefined && object.hparams !== null)
      ? Model_TrainingRun_TrainingOptions.fromPartial(object.hparams)
      : undefined;
    message.evaluationMetrics = (object.evaluationMetrics !== undefined && object.evaluationMetrics !== null)
      ? Model_EvaluationMetrics.fromPartial(object.evaluationMetrics)
      : undefined;
    message.status = object.status ?? 0;
    message.errorMessage = object.errorMessage ?? "";
    message.trainingLoss = object.trainingLoss ?? undefined;
    message.evalLoss = object.evalLoss ?? undefined;
    message.hparamTuningEvaluationMetrics =
      (object.hparamTuningEvaluationMetrics !== undefined && object.hparamTuningEvaluationMetrics !== null)
        ? Model_EvaluationMetrics.fromPartial(object.hparamTuningEvaluationMetrics)
        : undefined;
    return message;
  },
};

function createBaseModel_LabelsEntry(): Model_LabelsEntry {
  return { key: "", value: "" };
}

export const Model_LabelsEntry: MessageFns<Model_LabelsEntry> = {
  encode(message: Model_LabelsEntry, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.key !== "") {
      writer.uint32(10).string(message.key);
    }
    if (message.value !== "") {
      writer.uint32(18).string(message.value);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Model_LabelsEntry {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseModel_LabelsEntry();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.key = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.value = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Model_LabelsEntry {
    return {
      key: isSet(object.key) ? globalThis.String(object.key) : "",
      value: isSet(object.value) ? globalThis.String(object.value) : "",
    };
  },

  toJSON(message: Model_LabelsEntry): unknown {
    const obj: any = {};
    if (message.key !== "") {
      obj.key = message.key;
    }
    if (message.value !== "") {
      obj.value = message.value;
    }
    return obj;
  },

  create(base?: DeepPartial<Model_LabelsEntry>): Model_LabelsEntry {
    return Model_LabelsEntry.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<Model_LabelsEntry>): Model_LabelsEntry {
    const message = createBaseModel_LabelsEntry();
    message.key = object.key ?? "";
    message.value = object.value ?? "";
    return message;
  },
};

function createBaseGetModelRequest(): GetModelRequest {
  return { projectId: "", datasetId: "", modelId: "" };
}

export const GetModelRequest: MessageFns<GetModelRequest> = {
  encode(message: GetModelRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.projectId !== "") {
      writer.uint32(10).string(message.projectId);
    }
    if (message.datasetId !== "") {
      writer.uint32(18).string(message.datasetId);
    }
    if (message.modelId !== "") {
      writer.uint32(26).string(message.modelId);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): GetModelRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseGetModelRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.projectId = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.datasetId = reader.string();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.modelId = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): GetModelRequest {
    return {
      projectId: isSet(object.projectId) ? globalThis.String(object.projectId) : "",
      datasetId: isSet(object.datasetId) ? globalThis.String(object.datasetId) : "",
      modelId: isSet(object.modelId) ? globalThis.String(object.modelId) : "",
    };
  },

  toJSON(message: GetModelRequest): unknown {
    const obj: any = {};
    if (message.projectId !== "") {
      obj.projectId = message.projectId;
    }
    if (message.datasetId !== "") {
      obj.datasetId = message.datasetId;
    }
    if (message.modelId !== "") {
      obj.modelId = message.modelId;
    }
    return obj;
  },

  create(base?: DeepPartial<GetModelRequest>): GetModelRequest {
    return GetModelRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<GetModelRequest>): GetModelRequest {
    const message = createBaseGetModelRequest();
    message.projectId = object.projectId ?? "";
    message.datasetId = object.datasetId ?? "";
    message.modelId = object.modelId ?? "";
    return message;
  },
};

function createBasePatchModelRequest(): PatchModelRequest {
  return { projectId: "", datasetId: "", modelId: "", model: undefined };
}

export const PatchModelRequest: MessageFns<PatchModelRequest> = {
  encode(message: PatchModelRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.projectId !== "") {
      writer.uint32(10).string(message.projectId);
    }
    if (message.datasetId !== "") {
      writer.uint32(18).string(message.datasetId);
    }
    if (message.modelId !== "") {
      writer.uint32(26).string(message.modelId);
    }
    if (message.model !== undefined) {
      Model.encode(message.model, writer.uint32(34).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): PatchModelRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBasePatchModelRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.projectId = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.datasetId = reader.string();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.modelId = reader.string();
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.model = Model.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): PatchModelRequest {
    return {
      projectId: isSet(object.projectId) ? globalThis.String(object.projectId) : "",
      datasetId: isSet(object.datasetId) ? globalThis.String(object.datasetId) : "",
      modelId: isSet(object.modelId) ? globalThis.String(object.modelId) : "",
      model: isSet(object.model) ? Model.fromJSON(object.model) : undefined,
    };
  },

  toJSON(message: PatchModelRequest): unknown {
    const obj: any = {};
    if (message.projectId !== "") {
      obj.projectId = message.projectId;
    }
    if (message.datasetId !== "") {
      obj.datasetId = message.datasetId;
    }
    if (message.modelId !== "") {
      obj.modelId = message.modelId;
    }
    if (message.model !== undefined) {
      obj.model = Model.toJSON(message.model);
    }
    return obj;
  },

  create(base?: DeepPartial<PatchModelRequest>): PatchModelRequest {
    return PatchModelRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<PatchModelRequest>): PatchModelRequest {
    const message = createBasePatchModelRequest();
    message.projectId = object.projectId ?? "";
    message.datasetId = object.datasetId ?? "";
    message.modelId = object.modelId ?? "";
    message.model = (object.model !== undefined && object.model !== null) ? Model.fromPartial(object.model) : undefined;
    return message;
  },
};

function createBaseDeleteModelRequest(): DeleteModelRequest {
  return { projectId: "", datasetId: "", modelId: "" };
}

export const DeleteModelRequest: MessageFns<DeleteModelRequest> = {
  encode(message: DeleteModelRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.projectId !== "") {
      writer.uint32(10).string(message.projectId);
    }
    if (message.datasetId !== "") {
      writer.uint32(18).string(message.datasetId);
    }
    if (message.modelId !== "") {
      writer.uint32(26).string(message.modelId);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): DeleteModelRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDeleteModelRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.projectId = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.datasetId = reader.string();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.modelId = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): DeleteModelRequest {
    return {
      projectId: isSet(object.projectId) ? globalThis.String(object.projectId) : "",
      datasetId: isSet(object.datasetId) ? globalThis.String(object.datasetId) : "",
      modelId: isSet(object.modelId) ? globalThis.String(object.modelId) : "",
    };
  },

  toJSON(message: DeleteModelRequest): unknown {
    const obj: any = {};
    if (message.projectId !== "") {
      obj.projectId = message.projectId;
    }
    if (message.datasetId !== "") {
      obj.datasetId = message.datasetId;
    }
    if (message.modelId !== "") {
      obj.modelId = message.modelId;
    }
    return obj;
  },

  create(base?: DeepPartial<DeleteModelRequest>): DeleteModelRequest {
    return DeleteModelRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<DeleteModelRequest>): DeleteModelRequest {
    const message = createBaseDeleteModelRequest();
    message.projectId = object.projectId ?? "";
    message.datasetId = object.datasetId ?? "";
    message.modelId = object.modelId ?? "";
    return message;
  },
};

function createBaseListModelsRequest(): ListModelsRequest {
  return { projectId: "", datasetId: "", maxResults: undefined, pageToken: "" };
}

export const ListModelsRequest: MessageFns<ListModelsRequest> = {
  encode(message: ListModelsRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.projectId !== "") {
      writer.uint32(10).string(message.projectId);
    }
    if (message.datasetId !== "") {
      writer.uint32(18).string(message.datasetId);
    }
    if (message.maxResults !== undefined) {
      UInt32Value.encode({ value: message.maxResults! }, writer.uint32(26).fork()).join();
    }
    if (message.pageToken !== "") {
      writer.uint32(34).string(message.pageToken);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ListModelsRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseListModelsRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.projectId = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.datasetId = reader.string();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.maxResults = UInt32Value.decode(reader, reader.uint32()).value;
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.pageToken = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ListModelsRequest {
    return {
      projectId: isSet(object.projectId) ? globalThis.String(object.projectId) : "",
      datasetId: isSet(object.datasetId) ? globalThis.String(object.datasetId) : "",
      maxResults: isSet(object.maxResults) ? Number(object.maxResults) : undefined,
      pageToken: isSet(object.pageToken) ? globalThis.String(object.pageToken) : "",
    };
  },

  toJSON(message: ListModelsRequest): unknown {
    const obj: any = {};
    if (message.projectId !== "") {
      obj.projectId = message.projectId;
    }
    if (message.datasetId !== "") {
      obj.datasetId = message.datasetId;
    }
    if (message.maxResults !== undefined) {
      obj.maxResults = message.maxResults;
    }
    if (message.pageToken !== "") {
      obj.pageToken = message.pageToken;
    }
    return obj;
  },

  create(base?: DeepPartial<ListModelsRequest>): ListModelsRequest {
    return ListModelsRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ListModelsRequest>): ListModelsRequest {
    const message = createBaseListModelsRequest();
    message.projectId = object.projectId ?? "";
    message.datasetId = object.datasetId ?? "";
    message.maxResults = object.maxResults ?? undefined;
    message.pageToken = object.pageToken ?? "";
    return message;
  },
};

function createBaseListModelsResponse(): ListModelsResponse {
  return { models: [], nextPageToken: "" };
}

export const ListModelsResponse: MessageFns<ListModelsResponse> = {
  encode(message: ListModelsResponse, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.models) {
      Model.encode(v!, writer.uint32(10).fork()).join();
    }
    if (message.nextPageToken !== "") {
      writer.uint32(18).string(message.nextPageToken);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ListModelsResponse {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseListModelsResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.models.push(Model.decode(reader, reader.uint32()));
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.nextPageToken = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ListModelsResponse {
    return {
      models: globalThis.Array.isArray(object?.models) ? object.models.map((e: any) => Model.fromJSON(e)) : [],
      nextPageToken: isSet(object.nextPageToken) ? globalThis.String(object.nextPageToken) : "",
    };
  },

  toJSON(message: ListModelsResponse): unknown {
    const obj: any = {};
    if (message.models?.length) {
      obj.models = message.models.map((e) => Model.toJSON(e));
    }
    if (message.nextPageToken !== "") {
      obj.nextPageToken = message.nextPageToken;
    }
    return obj;
  },

  create(base?: DeepPartial<ListModelsResponse>): ListModelsResponse {
    return ListModelsResponse.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ListModelsResponse>): ListModelsResponse {
    const message = createBaseListModelsResponse();
    message.models = object.models?.map((e) => Model.fromPartial(e)) || [];
    message.nextPageToken = object.nextPageToken ?? "";
    return message;
  },
};

/**
 * This is an experimental RPC service definition for the BigQuery
 * Model Service.
 *
 * It should not be relied on for production use cases at this time.
 */
export type ModelServiceDefinition = typeof ModelServiceDefinition;
export const ModelServiceDefinition = {
  name: "ModelService",
  fullName: "google.cloud.bigquery.v2.ModelService",
  methods: {
    /** Gets the specified model resource by model ID. */
    getModel: {
      name: "GetModel",
      requestType: GetModelRequest,
      requestStream: false,
      responseType: Model,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [
            Buffer.from([
              30,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              95,
              105,
              100,
              44,
              100,
              97,
              116,
              97,
              115,
              101,
              116,
              95,
              105,
              100,
              44,
              109,
              111,
              100,
              101,
              108,
              95,
              105,
              100,
            ]),
          ],
          578365826: [
            Buffer.from([
              82,
              18,
              80,
              47,
              98,
              105,
              103,
              113,
              117,
              101,
              114,
              121,
              47,
              118,
              50,
              47,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              123,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              95,
              105,
              100,
              61,
              42,
              125,
              47,
              100,
              97,
              116,
              97,
              115,
              101,
              116,
              115,
              47,
              123,
              100,
              97,
              116,
              97,
              115,
              101,
              116,
              95,
              105,
              100,
              61,
              42,
              125,
              47,
              109,
              111,
              100,
              101,
              108,
              115,
              47,
              123,
              109,
              111,
              100,
              101,
              108,
              95,
              105,
              100,
              61,
              42,
              125,
            ]),
          ],
        },
      },
    },
    /**
     * Lists all models in the specified dataset. Requires the READER dataset
     * role. After retrieving the list of models, you can get information about a
     * particular model by calling the models.get method.
     */
    listModels: {
      name: "ListModels",
      requestType: ListModelsRequest,
      requestStream: false,
      responseType: ListModelsResponse,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [
            Buffer.from([
              33,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              95,
              105,
              100,
              44,
              100,
              97,
              116,
              97,
              115,
              101,
              116,
              95,
              105,
              100,
              44,
              109,
              97,
              120,
              95,
              114,
              101,
              115,
              117,
              108,
              116,
              115,
            ]),
          ],
          578365826: [
            Buffer.from([
              69,
              18,
              67,
              47,
              98,
              105,
              103,
              113,
              117,
              101,
              114,
              121,
              47,
              118,
              50,
              47,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              123,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              95,
              105,
              100,
              61,
              42,
              125,
              47,
              100,
              97,
              116,
              97,
              115,
              101,
              116,
              115,
              47,
              123,
              100,
              97,
              116,
              97,
              115,
              101,
              116,
              95,
              105,
              100,
              61,
              42,
              125,
              47,
              109,
              111,
              100,
              101,
              108,
              115,
            ]),
          ],
        },
      },
    },
    /** Patch specific fields in the specified model. */
    patchModel: {
      name: "PatchModel",
      requestType: PatchModelRequest,
      requestStream: false,
      responseType: Model,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [
            Buffer.from([
              36,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              95,
              105,
              100,
              44,
              100,
              97,
              116,
              97,
              115,
              101,
              116,
              95,
              105,
              100,
              44,
              109,
              111,
              100,
              101,
              108,
              95,
              105,
              100,
              44,
              109,
              111,
              100,
              101,
              108,
            ]),
          ],
          578365826: [
            Buffer.from([
              89,
              58,
              5,
              109,
              111,
              100,
              101,
              108,
              50,
              80,
              47,
              98,
              105,
              103,
              113,
              117,
              101,
              114,
              121,
              47,
              118,
              50,
              47,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              123,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              95,
              105,
              100,
              61,
              42,
              125,
              47,
              100,
              97,
              116,
              97,
              115,
              101,
              116,
              115,
              47,
              123,
              100,
              97,
              116,
              97,
              115,
              101,
              116,
              95,
              105,
              100,
              61,
              42,
              125,
              47,
              109,
              111,
              100,
              101,
              108,
              115,
              47,
              123,
              109,
              111,
              100,
              101,
              108,
              95,
              105,
              100,
              61,
              42,
              125,
            ]),
          ],
        },
      },
    },
    /** Deletes the model specified by modelId from the dataset. */
    deleteModel: {
      name: "DeleteModel",
      requestType: DeleteModelRequest,
      requestStream: false,
      responseType: Empty,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [
            Buffer.from([
              30,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              95,
              105,
              100,
              44,
              100,
              97,
              116,
              97,
              115,
              101,
              116,
              95,
              105,
              100,
              44,
              109,
              111,
              100,
              101,
              108,
              95,
              105,
              100,
            ]),
          ],
          578365826: [
            Buffer.from([
              82,
              42,
              80,
              47,
              98,
              105,
              103,
              113,
              117,
              101,
              114,
              121,
              47,
              118,
              50,
              47,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              123,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              95,
              105,
              100,
              61,
              42,
              125,
              47,
              100,
              97,
              116,
              97,
              115,
              101,
              116,
              115,
              47,
              123,
              100,
              97,
              116,
              97,
              115,
              101,
              116,
              95,
              105,
              100,
              61,
              42,
              125,
              47,
              109,
              111,
              100,
              101,
              108,
              115,
              47,
              123,
              109,
              111,
              100,
              101,
              108,
              95,
              105,
              100,
              61,
              42,
              125,
            ]),
          ],
        },
      },
    },
  },
} as const;

export interface ModelServiceImplementation<CallContextExt = {}> {
  /** Gets the specified model resource by model ID. */
  getModel(request: GetModelRequest, context: CallContext & CallContextExt): Promise<DeepPartial<Model>>;
  /**
   * Lists all models in the specified dataset. Requires the READER dataset
   * role. After retrieving the list of models, you can get information about a
   * particular model by calling the models.get method.
   */
  listModels(
    request: ListModelsRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<ListModelsResponse>>;
  /** Patch specific fields in the specified model. */
  patchModel(request: PatchModelRequest, context: CallContext & CallContextExt): Promise<DeepPartial<Model>>;
  /** Deletes the model specified by modelId from the dataset. */
  deleteModel(request: DeleteModelRequest, context: CallContext & CallContextExt): Promise<DeepPartial<Empty>>;
}

export interface ModelServiceClient<CallOptionsExt = {}> {
  /** Gets the specified model resource by model ID. */
  getModel(request: DeepPartial<GetModelRequest>, options?: CallOptions & CallOptionsExt): Promise<Model>;
  /**
   * Lists all models in the specified dataset. Requires the READER dataset
   * role. After retrieving the list of models, you can get information about a
   * particular model by calling the models.get method.
   */
  listModels(
    request: DeepPartial<ListModelsRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<ListModelsResponse>;
  /** Patch specific fields in the specified model. */
  patchModel(request: DeepPartial<PatchModelRequest>, options?: CallOptions & CallOptionsExt): Promise<Model>;
  /** Deletes the model specified by modelId from the dataset. */
  deleteModel(request: DeepPartial<DeleteModelRequest>, options?: CallOptions & CallOptionsExt): Promise<Empty>;
}

type Builtin = Date | Function | Uint8Array | string | number | boolean | undefined;

export type DeepPartial<T> = T extends Builtin ? T
  : T extends Long ? string | number | Long : T extends globalThis.Array<infer U> ? globalThis.Array<DeepPartial<U>>
  : T extends ReadonlyArray<infer U> ? ReadonlyArray<DeepPartial<U>>
  : T extends {} ? { [K in keyof T]?: DeepPartial<T[K]> }
  : Partial<T>;

function toTimestamp(date: Date): Timestamp {
  const seconds = numberToLong(Math.trunc(date.getTime() / 1_000));
  const nanos = (date.getTime() % 1_000) * 1_000_000;
  return { seconds, nanos };
}

function fromTimestamp(t: Timestamp): Date {
  let millis = (t.seconds.toNumber() || 0) * 1_000;
  millis += (t.nanos || 0) / 1_000_000;
  return new globalThis.Date(millis);
}

function fromJsonTimestamp(o: any): Date {
  if (o instanceof globalThis.Date) {
    return o;
  } else if (typeof o === "string") {
    return new globalThis.Date(o);
  } else {
    return fromTimestamp(Timestamp.fromJSON(o));
  }
}

function numberToLong(number: number) {
  return Long.fromNumber(number);
}

function isObject(value: any): boolean {
  return typeof value === "object" && value !== null;
}

function isSet(value: any): boolean {
  return value !== null && value !== undefined;
}

export interface MessageFns<T> {
  encode(message: T, writer?: BinaryWriter): BinaryWriter;
  decode(input: BinaryReader | Uint8Array, length?: number): T;
  fromJSON(object: any): T;
  toJSON(message: T): unknown;
  create(base?: DeepPartial<T>): T;
  fromPartial(object: DeepPartial<T>): T;
}
