// Code generated by protoc-gen-ts_proto. DO NOT EDIT.
// versions:
//   protoc-gen-ts_proto  v2.2.0
//   protoc               unknown
// source: google/cloud/bigquery/v2/job.proto

/* eslint-disable */
import { BinaryReader, BinaryWriter } from "@bufbuild/protobuf/wire";
import Long from "long";
import { type CallContext, type CallOptions } from "nice-grpc-common";
import { Empty } from "../../../protobuf/empty.js";
import { Struct } from "../../../protobuf/struct.js";
import { BoolValue, Int32Value, Int64Value, UInt32Value, UInt64Value } from "../../../protobuf/wrappers.js";
import { DataFormatOptions } from "./data_format_options.js";
import { DatasetReference } from "./dataset_reference.js";
import { ErrorProto } from "./error.js";
import { ConnectionProperty, JobConfiguration } from "./job_config.js";
import { JobCreationReason } from "./job_creation_reason.js";
import { JobReference } from "./job_reference.js";
import { DmlStats, JobStatistics } from "./job_stats.js";
import { JobStatus } from "./job_status.js";
import { QueryParameter } from "./query_parameter.js";
import { SessionInfo } from "./session_info.js";
import { TableSchema } from "./table_schema.js";

export const protobufPackage = "google.cloud.bigquery.v2";

export interface Job {
  /** Output only. The type of the resource. */
  kind: string;
  /** Output only. A hash of this resource. */
  etag: string;
  /** Output only. Opaque ID field of the job. */
  id: string;
  /** Output only. A URL that can be used to access the resource again. */
  selfLink: string;
  /** Output only. Email address of the user who ran the job. */
  userEmail: string;
  /** Required. Describes the job configuration. */
  configuration:
    | JobConfiguration
    | undefined;
  /** Optional. Reference describing the unique-per-user name of the job. */
  jobReference:
    | JobReference
    | undefined;
  /**
   * Output only. Information about the job, including starting time and ending
   * time of the job.
   */
  statistics:
    | JobStatistics
    | undefined;
  /**
   * Output only. The status of this job. Examine this value when polling an
   * asynchronous job to see if the job is complete.
   */
  status:
    | JobStatus
    | undefined;
  /**
   * Output only. [Full-projection-only] String representation of identity of
   * requesting party. Populated for both first- and third-party identities.
   * Only present for APIs that support third-party identities.
   */
  principalSubject: string;
  /**
   * Output only. The reason why a Job was created.
   * [Preview](https://cloud.google.com/products/#product-launch-stages)
   */
  jobCreationReason: JobCreationReason | undefined;
}

/** Describes format of a jobs cancellation request. */
export interface CancelJobRequest {
  /** Required. Project ID of the job to cancel */
  projectId: string;
  /** Required. Job ID of the job to cancel */
  jobId: string;
  /**
   * The geographic location of the job. You must specify the location to run
   * the job for the following scenarios:
   *
   * * If the location to run a job is not in the `us` or
   *   the `eu` multi-regional location
   * * If the job's location is in a single region (for example,
   *   `us-central1`)
   *
   * For more information, see
   * https://cloud.google.com/bigquery/docs/locations#specifying_your_location.
   */
  location: string;
}

/** Describes format of a jobs cancellation response. */
export interface JobCancelResponse {
  /** The resource type of the response. */
  kind: string;
  /** The final state of the job. */
  job: Job | undefined;
}

/** Describes format of a jobs get request. */
export interface GetJobRequest {
  /** Required. Project ID of the requested job. */
  projectId: string;
  /** Required. Job ID of the requested job. */
  jobId: string;
  /**
   * The geographic location of the job. You must specify the location to run
   * the job for the following scenarios:
   *
   * * If the location to run a job is not in the `us` or
   *   the `eu` multi-regional location
   * * If the job's location is in a single region (for example,
   *   `us-central1`)
   *
   * For more information, see
   * https://cloud.google.com/bigquery/docs/locations#specifying_your_location.
   */
  location: string;
}

/** Describes format of a job insertion request. */
export interface InsertJobRequest {
  /** Project ID of project that will be billed for the job. */
  projectId: string;
  /** Jobs resource to insert. */
  job: Job | undefined;
}

/** Describes the format of a jobs deletion request. */
export interface DeleteJobRequest {
  /** Required. Project ID of the job for which metadata is to be deleted. */
  projectId: string;
  /**
   * Required. Job ID of the job for which metadata is to be deleted. If this is
   * a parent job which has child jobs, the metadata from all child jobs will be
   * deleted as well. Direct deletion of the metadata of child jobs is not
   * allowed.
   */
  jobId: string;
  /**
   * The geographic location of the job. Required.
   * See details at:
   * https://cloud.google.com/bigquery/docs/locations#specifying_your_location.
   */
  location: string;
}

/** Describes the format of the list jobs request. */
export interface ListJobsRequest {
  /** Project ID of the jobs to list. */
  projectId: string;
  /** Whether to display jobs owned by all users in the project. Default False. */
  allUsers: boolean;
  /**
   * The maximum number of results to return in a single response page.
   * Leverage the page tokens to iterate through the entire collection.
   */
  maxResults:
    | number
    | undefined;
  /**
   * Min value for job creation time, in milliseconds since the POSIX epoch.
   * If set, only jobs created after or at this timestamp are returned.
   */
  minCreationTime: Long;
  /**
   * Max value for job creation time, in milliseconds since the POSIX epoch.
   * If set, only jobs created before or at this timestamp are returned.
   */
  maxCreationTime:
    | Long
    | undefined;
  /**
   * Page token, returned by a previous call, to request the next page of
   * results.
   */
  pageToken: string;
  /** Restrict information returned to a set of selected fields */
  projection: ListJobsRequest_Projection;
  /** Filter for job state */
  stateFilter: ListJobsRequest_StateFilter[];
  /**
   * If set, show only child jobs of the specified parent.  Otherwise, show all
   * top-level jobs.
   */
  parentJobId: string;
}

/** Projection is used to control what job information is returned. */
export enum ListJobsRequest_Projection {
  /** minimal - Does not include the job configuration */
  minimal = 0,
  /** MINIMAL - Does not include the job configuration */
  MINIMAL = 0,
  /** full - Includes all job data */
  full = 1,
  /** FULL - Includes all job data */
  FULL = 1,
  UNRECOGNIZED = -1,
}

export function listJobsRequest_ProjectionFromJSON(object: any): ListJobsRequest_Projection {
  switch (object) {
    case 0:
    case "minimal":
      return ListJobsRequest_Projection.minimal;
    case 0:
    case "MINIMAL":
      return ListJobsRequest_Projection.MINIMAL;
    case 1:
    case "full":
      return ListJobsRequest_Projection.full;
    case 1:
    case "FULL":
      return ListJobsRequest_Projection.FULL;
    case -1:
    case "UNRECOGNIZED":
    default:
      return ListJobsRequest_Projection.UNRECOGNIZED;
  }
}

export function listJobsRequest_ProjectionToJSON(object: ListJobsRequest_Projection): string {
  switch (object) {
    case ListJobsRequest_Projection.minimal:
      return "minimal";
    case ListJobsRequest_Projection.MINIMAL:
      return "MINIMAL";
    case ListJobsRequest_Projection.full:
      return "full";
    case ListJobsRequest_Projection.FULL:
      return "FULL";
    case ListJobsRequest_Projection.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/** StateFilter allows filtration by job execution state. */
export enum ListJobsRequest_StateFilter {
  /** done - Finished jobs */
  done = 0,
  /** DONE - Finished jobs */
  DONE = 0,
  /** pending - Pending jobs */
  pending = 1,
  /** PENDING - Pending jobs */
  PENDING = 1,
  /** running - Running jobs */
  running = 2,
  /** RUNNING - Running jobs. */
  RUNNING = 2,
  UNRECOGNIZED = -1,
}

export function listJobsRequest_StateFilterFromJSON(object: any): ListJobsRequest_StateFilter {
  switch (object) {
    case 0:
    case "done":
      return ListJobsRequest_StateFilter.done;
    case 0:
    case "DONE":
      return ListJobsRequest_StateFilter.DONE;
    case 1:
    case "pending":
      return ListJobsRequest_StateFilter.pending;
    case 1:
    case "PENDING":
      return ListJobsRequest_StateFilter.PENDING;
    case 2:
    case "running":
      return ListJobsRequest_StateFilter.running;
    case 2:
    case "RUNNING":
      return ListJobsRequest_StateFilter.RUNNING;
    case -1:
    case "UNRECOGNIZED":
    default:
      return ListJobsRequest_StateFilter.UNRECOGNIZED;
  }
}

export function listJobsRequest_StateFilterToJSON(object: ListJobsRequest_StateFilter): string {
  switch (object) {
    case ListJobsRequest_StateFilter.done:
      return "done";
    case ListJobsRequest_StateFilter.DONE:
      return "DONE";
    case ListJobsRequest_StateFilter.pending:
      return "pending";
    case ListJobsRequest_StateFilter.PENDING:
      return "PENDING";
    case ListJobsRequest_StateFilter.running:
      return "running";
    case ListJobsRequest_StateFilter.RUNNING:
      return "RUNNING";
    case ListJobsRequest_StateFilter.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/**
 * ListFormatJob is a partial projection of job information returned as part
 * of a jobs.list response.
 */
export interface ListFormatJob {
  /** Unique opaque ID of the job. */
  id: string;
  /** The resource type. */
  kind: string;
  /** Unique opaque ID of the job. */
  jobReference:
    | JobReference
    | undefined;
  /**
   * Running state of the job. When the state is DONE, errorResult can be
   * checked to determine whether the job succeeded or failed.
   */
  state: string;
  /** A result object that will be present only if the job has failed. */
  errorResult:
    | ErrorProto
    | undefined;
  /**
   * Output only. Information about the job, including starting time and ending
   * time of the job.
   */
  statistics:
    | JobStatistics
    | undefined;
  /** Required. Describes the job configuration. */
  configuration:
    | JobConfiguration
    | undefined;
  /** [Full-projection-only] Describes the status of this job. */
  status:
    | JobStatus
    | undefined;
  /** [Full-projection-only] Email address of the user who ran the job. */
  userEmail: string;
  /**
   * [Full-projection-only] String representation of identity of requesting
   * party. Populated for both first- and third-party identities. Only present
   * for APIs that support third-party identities.
   */
  principalSubject: string;
}

/** JobList is the response format for a jobs.list call. */
export interface JobList {
  /** A hash of this page of results. */
  etag: string;
  /** The resource type of the response. */
  kind: string;
  /** A token to request the next page of results. */
  nextPageToken: string;
  /** List of jobs that were requested. */
  jobs: ListFormatJob[];
  /**
   * A list of skipped locations that were unreachable. For more information
   * about BigQuery locations, see:
   * https://cloud.google.com/bigquery/docs/locations. Example: "europe-west5"
   */
  unreachable: string[];
}

/** Request object of GetQueryResults. */
export interface GetQueryResultsRequest {
  /** Required. Project ID of the query job. */
  projectId: string;
  /** Required. Job ID of the query job. */
  jobId: string;
  /** Zero-based index of the starting row. */
  startIndex:
    | Long
    | undefined;
  /**
   * Page token, returned by a previous call, to request the next page of
   * results.
   */
  pageToken: string;
  /** Maximum number of results to read. */
  maxResults:
    | number
    | undefined;
  /**
   * Optional: Specifies the maximum amount of time, in milliseconds, that the
   * client is willing to wait for the query to complete. By default, this limit
   * is 10 seconds (10,000 milliseconds). If the query is complete, the
   * jobComplete field in the response is true. If the query has not yet
   * completed, jobComplete is false.
   *
   * You can request a longer timeout period in the timeoutMs field.  However,
   * the call is not guaranteed to wait for the specified timeout; it typically
   * returns after around 200 seconds (200,000 milliseconds), even if the query
   * is not complete.
   *
   * If jobComplete is false, you can continue to wait for the query to complete
   * by calling the getQueryResults method until the jobComplete field in the
   * getQueryResults response is true.
   */
  timeoutMs:
    | number
    | undefined;
  /**
   * The geographic location of the job. You must specify the location to run
   * the job for the following scenarios:
   *
   * * If the location to run a job is not in the `us` or
   *   the `eu` multi-regional location
   * * If the job's location is in a single region (for example,
   * `us-central1`)
   *
   * For more information, see
   * https://cloud.google.com/bigquery/docs/locations#specifying_your_location.
   */
  location: string;
  /** Optional. Output format adjustments. */
  formatOptions: DataFormatOptions | undefined;
}

/** Response object of GetQueryResults. */
export interface GetQueryResultsResponse {
  /** The resource type of the response. */
  kind: string;
  /** A hash of this response. */
  etag: string;
  /**
   * The schema of the results. Present only when the query completes
   * successfully.
   */
  schema:
    | TableSchema
    | undefined;
  /**
   * Reference to the BigQuery Job that was created to run the query. This field
   * will be present even if the original request timed out, in which case
   * GetQueryResults can be used to read the results once the query has
   * completed. Since this API only returns the first page of results,
   * subsequent pages can be fetched via the same mechanism (GetQueryResults).
   */
  jobReference:
    | JobReference
    | undefined;
  /**
   * The total number of rows in the complete query result set, which can be
   * more than the number of rows in this single page of results. Present only
   * when the query completes successfully.
   */
  totalRows:
    | Long
    | undefined;
  /**
   * A token used for paging results.  When this token is non-empty, it
   * indicates additional results are available.
   */
  pageToken: string;
  /**
   * An object with as many results as can be contained within the maximum
   * permitted reply size. To get any additional rows, you can call
   * GetQueryResults and specify the jobReference returned above. Present only
   * when the query completes successfully.
   *
   * The REST-based representation of this data leverages a series of
   * JSON f,v objects for indicating fields and values.
   */
  rows: { [key: string]: any }[];
  /** The total number of bytes processed for this query. */
  totalBytesProcessed:
    | Long
    | undefined;
  /**
   * Whether the query has completed or not. If rows or totalRows are present,
   * this will always be true. If this is false, totalRows will not be
   * available.
   */
  jobComplete:
    | boolean
    | undefined;
  /**
   * Output only. The first errors or warnings encountered during the running
   * of the job. The final message includes the number of errors that caused the
   * process to stop. Errors here do not necessarily mean that the job has
   * completed or was unsuccessful. For more information about error messages,
   * see [Error
   * messages](https://cloud.google.com/bigquery/docs/error-messages).
   */
  errors: ErrorProto[];
  /** Whether the query result was fetched from the query cache. */
  cacheHit:
    | boolean
    | undefined;
  /**
   * Output only. The number of rows affected by a DML statement. Present only
   * for DML statements INSERT, UPDATE or DELETE.
   */
  numDmlAffectedRows: Long | undefined;
}

/** Request format for the query request. */
export interface PostQueryRequest {
  /** Required. Project ID of the query request. */
  projectId: string;
  /** The query request body. */
  queryRequest: QueryRequest | undefined;
}

/** Describes the format of the jobs.query request. */
export interface QueryRequest {
  /** The resource type of the request. */
  kind: string;
  /**
   * Required. A query string to execute, using Google Standard SQL or legacy
   * SQL syntax. Example: "SELECT COUNT(f1) FROM
   * myProjectId.myDatasetId.myTableId".
   */
  query: string;
  /**
   * Optional. The maximum number of rows of data to return per page of
   * results. Setting this flag to a small value such as 1000 and then paging
   * through results might improve reliability when the query result set is
   * large. In addition to this limit, responses are also limited to 10 MB. By
   * default, there is no maximum row count, and only the byte limit applies.
   */
  maxResults:
    | number
    | undefined;
  /**
   * Optional. Specifies the default datasetId and projectId to assume for any
   * unqualified table names in the query. If not set, all table names in the
   * query string must be qualified in the format 'datasetId.tableId'.
   */
  defaultDataset:
    | DatasetReference
    | undefined;
  /**
   * Optional. Optional: Specifies the maximum amount of time, in milliseconds,
   * that the client is willing to wait for the query to complete. By default,
   * this limit is 10 seconds (10,000 milliseconds). If the query is complete,
   * the jobComplete field in the response is true. If the query has not yet
   * completed, jobComplete is false.
   *
   * You can request a longer timeout period in the timeoutMs field.  However,
   * the call is not guaranteed to wait for the specified timeout; it typically
   * returns after around 200 seconds (200,000 milliseconds), even if the query
   * is not complete.
   *
   * If jobComplete is false, you can continue to wait for the query to complete
   * by calling the getQueryResults method until the jobComplete field in the
   * getQueryResults response is true.
   */
  timeoutMs:
    | number
    | undefined;
  /**
   * Optional. If set to true, BigQuery doesn't run the job. Instead, if the
   * query is valid, BigQuery returns statistics about the job such as how many
   * bytes would be processed. If the query is invalid, an error returns. The
   * default value is false.
   */
  dryRun: boolean;
  /**
   * Optional. Whether to look for the result in the query cache. The query
   * cache is a best-effort cache that will be flushed whenever tables in the
   * query are modified. The default value is true.
   */
  useQueryCache:
    | boolean
    | undefined;
  /**
   * Specifies whether to use BigQuery's legacy SQL dialect for this query. The
   * default value is true. If set to false, the query will use BigQuery's
   * GoogleSQL: https://cloud.google.com/bigquery/sql-reference/ When
   * useLegacySql is set to false, the value of flattenResults is ignored; query
   * will be run as if flattenResults is false.
   */
  useLegacySql:
    | boolean
    | undefined;
  /**
   * GoogleSQL only. Set to POSITIONAL to use positional (?) query parameters
   * or to NAMED to use named (@myparam) query parameters in this query.
   */
  parameterMode: string;
  /** Query parameters for GoogleSQL queries. */
  queryParameters: QueryParameter[];
  /**
   * The geographic location where the job should run. See details at
   * https://cloud.google.com/bigquery/docs/locations#specifying_your_location.
   */
  location: string;
  /** Optional. Output format adjustments. */
  formatOptions:
    | DataFormatOptions
    | undefined;
  /** Optional. Connection properties which can modify the query behavior. */
  connectionProperties: ConnectionProperty[];
  /**
   * Optional. The labels associated with this query.
   * Labels can be used to organize and group query jobs.
   * Label keys and values can be no longer than 63 characters, can only contain
   * lowercase letters, numeric characters, underscores and dashes.
   * International characters are allowed. Label keys must start with a letter
   * and each label in the list must have a different key.
   */
  labels: { [key: string]: string };
  /**
   * Optional. Limits the bytes billed for this query. Queries with
   * bytes billed above this limit will fail (without incurring a charge).
   * If unspecified, the project default is used.
   */
  maximumBytesBilled:
    | Long
    | undefined;
  /**
   * Optional. A unique user provided identifier to ensure idempotent behavior
   * for queries. Note that this is different from the job_id. It has the
   * following properties:
   *
   * 1. It is case-sensitive, limited to up to 36 ASCII characters. A UUID is
   *    recommended.
   *
   * 2. Read only queries can ignore this token since they are nullipotent by
   *    definition.
   *
   * 3. For the purposes of idempotency ensured by the request_id, a request
   *    is considered duplicate of another only if they have the same request_id
   *    and are actually duplicates. When determining whether a request is a
   *    duplicate of another request, all parameters in the request that
   *    may affect the result are considered. For example, query,
   *    connection_properties, query_parameters, use_legacy_sql are parameters
   *    that affect the result and are considered when determining whether a
   *    request is a duplicate, but properties like timeout_ms don't
   *    affect the result and are thus not considered. Dry run query
   *    requests are never considered duplicate of another request.
   *
   * 4. When a duplicate mutating query request is detected, it returns:
   *    a. the results of the mutation if it completes successfully within
   *       the timeout.
   *    b. the running operation if it is still in progress at the end of the
   *        timeout.
   *
   * 5. Its lifetime is limited to 15 minutes. In other words, if two
   *    requests are sent with the same request_id, but more than 15 minutes
   *    apart, idempotency is not guaranteed.
   */
  requestId: string;
  /**
   * Optional. If true, creates a new session using a randomly generated
   * session_id. If false, runs query with an existing session_id passed in
   * ConnectionProperty, otherwise runs query in non-session mode.
   *
   * The session location will be set to QueryRequest.location if it is present,
   * otherwise it's set to the default location based on existing routing logic.
   */
  createSession:
    | boolean
    | undefined;
  /**
   * Optional. If not set, jobs are always required.
   *
   * If set, the query request will follow the behavior described
   * JobCreationMode.
   * [Preview](https://cloud.google.com/products/#product-launch-stages)
   */
  jobCreationMode: QueryRequest_JobCreationMode;
}

/** Job Creation Mode provides different options on job creation. */
export enum QueryRequest_JobCreationMode {
  /** JOB_CREATION_MODE_UNSPECIFIED - If unspecified JOB_CREATION_REQUIRED is the default. */
  JOB_CREATION_MODE_UNSPECIFIED = 0,
  /** JOB_CREATION_REQUIRED - Default. Job creation is always required. */
  JOB_CREATION_REQUIRED = 1,
  /**
   * JOB_CREATION_OPTIONAL - Job creation is optional. Returning immediate results is prioritized.
   * BigQuery will automatically determine if a Job needs to be created.
   * The conditions under which BigQuery can decide to not create a Job are
   * subject to change. If Job creation is required, JOB_CREATION_REQUIRED
   * mode should be used, which is the default.
   */
  JOB_CREATION_OPTIONAL = 2,
  UNRECOGNIZED = -1,
}

export function queryRequest_JobCreationModeFromJSON(object: any): QueryRequest_JobCreationMode {
  switch (object) {
    case 0:
    case "JOB_CREATION_MODE_UNSPECIFIED":
      return QueryRequest_JobCreationMode.JOB_CREATION_MODE_UNSPECIFIED;
    case 1:
    case "JOB_CREATION_REQUIRED":
      return QueryRequest_JobCreationMode.JOB_CREATION_REQUIRED;
    case 2:
    case "JOB_CREATION_OPTIONAL":
      return QueryRequest_JobCreationMode.JOB_CREATION_OPTIONAL;
    case -1:
    case "UNRECOGNIZED":
    default:
      return QueryRequest_JobCreationMode.UNRECOGNIZED;
  }
}

export function queryRequest_JobCreationModeToJSON(object: QueryRequest_JobCreationMode): string {
  switch (object) {
    case QueryRequest_JobCreationMode.JOB_CREATION_MODE_UNSPECIFIED:
      return "JOB_CREATION_MODE_UNSPECIFIED";
    case QueryRequest_JobCreationMode.JOB_CREATION_REQUIRED:
      return "JOB_CREATION_REQUIRED";
    case QueryRequest_JobCreationMode.JOB_CREATION_OPTIONAL:
      return "JOB_CREATION_OPTIONAL";
    case QueryRequest_JobCreationMode.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

export interface QueryRequest_LabelsEntry {
  key: string;
  value: string;
}

export interface QueryResponse {
  /** The resource type. */
  kind: string;
  /**
   * The schema of the results. Present only when the query completes
   * successfully.
   */
  schema:
    | TableSchema
    | undefined;
  /**
   * Reference to the Job that was created to run the query. This field will be
   * present even if the original request timed out, in which case
   * GetQueryResults can be used to read the results once the query has
   * completed. Since this API only returns the first page of results,
   * subsequent pages can be fetched via the same mechanism (GetQueryResults).
   *
   * If job_creation_mode was set to `JOB_CREATION_OPTIONAL` and the query
   * completes without creating a job, this field will be empty.
   */
  jobReference:
    | JobReference
    | undefined;
  /**
   * Optional. The reason why a Job was created.
   *
   * Only relevant when a job_reference is present in the response.
   * If job_reference is not present it will always be unset.
   * [Preview](https://cloud.google.com/products/#product-launch-stages)
   */
  jobCreationReason:
    | JobCreationReason
    | undefined;
  /**
   * Auto-generated ID for the query.
   * [Preview](https://cloud.google.com/products/#product-launch-stages)
   */
  queryId: string;
  /**
   * The total number of rows in the complete query result set, which can be
   * more than the number of rows in this single page of results.
   */
  totalRows:
    | Long
    | undefined;
  /**
   * A token used for paging results. A non-empty token indicates that
   * additional results are available. To see additional results,
   * query the
   * [`jobs.getQueryResults`](https://cloud.google.com/bigquery/docs/reference/rest/v2/jobs/getQueryResults)
   * method. For more information, see [Paging through table
   * data](https://cloud.google.com/bigquery/docs/paging-results).
   */
  pageToken: string;
  /**
   * An object with as many results as can be contained within the maximum
   * permitted reply size. To get any additional rows, you can call
   * GetQueryResults and specify the jobReference returned above.
   */
  rows: { [key: string]: any }[];
  /**
   * The total number of bytes processed for this query. If this query was a dry
   * run, this is the number of bytes that would be processed if the query were
   * run.
   */
  totalBytesProcessed:
    | Long
    | undefined;
  /**
   * Whether the query has completed or not. If rows or totalRows are present,
   * this will always be true. If this is false, totalRows will not be
   * available.
   */
  jobComplete:
    | boolean
    | undefined;
  /**
   * Output only. The first errors or warnings encountered during the running of
   * the job. The final message includes the number of errors that caused the
   * process to stop. Errors here do not necessarily mean that the job has
   * completed or was unsuccessful. For more information about error messages,
   * see [Error
   * messages](https://cloud.google.com/bigquery/docs/error-messages).
   */
  errors: ErrorProto[];
  /** Whether the query result was fetched from the query cache. */
  cacheHit:
    | boolean
    | undefined;
  /**
   * Output only. The number of rows affected by a DML statement. Present only
   * for DML statements INSERT, UPDATE or DELETE.
   */
  numDmlAffectedRows:
    | Long
    | undefined;
  /** Output only. Information of the session if this job is part of one. */
  sessionInfo:
    | SessionInfo
    | undefined;
  /**
   * Output only. Detailed statistics for DML statements INSERT, UPDATE, DELETE,
   * MERGE or TRUNCATE.
   */
  dmlStats: DmlStats | undefined;
}

function createBaseJob(): Job {
  return {
    kind: "",
    etag: "",
    id: "",
    selfLink: "",
    userEmail: "",
    configuration: undefined,
    jobReference: undefined,
    statistics: undefined,
    status: undefined,
    principalSubject: "",
    jobCreationReason: undefined,
  };
}

export const Job: MessageFns<Job> = {
  encode(message: Job, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.kind !== "") {
      writer.uint32(10).string(message.kind);
    }
    if (message.etag !== "") {
      writer.uint32(18).string(message.etag);
    }
    if (message.id !== "") {
      writer.uint32(26).string(message.id);
    }
    if (message.selfLink !== "") {
      writer.uint32(34).string(message.selfLink);
    }
    if (message.userEmail !== "") {
      writer.uint32(42).string(message.userEmail);
    }
    if (message.configuration !== undefined) {
      JobConfiguration.encode(message.configuration, writer.uint32(50).fork()).join();
    }
    if (message.jobReference !== undefined) {
      JobReference.encode(message.jobReference, writer.uint32(58).fork()).join();
    }
    if (message.statistics !== undefined) {
      JobStatistics.encode(message.statistics, writer.uint32(66).fork()).join();
    }
    if (message.status !== undefined) {
      JobStatus.encode(message.status, writer.uint32(74).fork()).join();
    }
    if (message.principalSubject !== "") {
      writer.uint32(106).string(message.principalSubject);
    }
    if (message.jobCreationReason !== undefined) {
      JobCreationReason.encode(message.jobCreationReason, writer.uint32(114).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Job {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseJob();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.kind = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.etag = reader.string();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.id = reader.string();
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.selfLink = reader.string();
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.userEmail = reader.string();
          continue;
        case 6:
          if (tag !== 50) {
            break;
          }

          message.configuration = JobConfiguration.decode(reader, reader.uint32());
          continue;
        case 7:
          if (tag !== 58) {
            break;
          }

          message.jobReference = JobReference.decode(reader, reader.uint32());
          continue;
        case 8:
          if (tag !== 66) {
            break;
          }

          message.statistics = JobStatistics.decode(reader, reader.uint32());
          continue;
        case 9:
          if (tag !== 74) {
            break;
          }

          message.status = JobStatus.decode(reader, reader.uint32());
          continue;
        case 13:
          if (tag !== 106) {
            break;
          }

          message.principalSubject = reader.string();
          continue;
        case 14:
          if (tag !== 114) {
            break;
          }

          message.jobCreationReason = JobCreationReason.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Job {
    return {
      kind: isSet(object.kind) ? globalThis.String(object.kind) : "",
      etag: isSet(object.etag) ? globalThis.String(object.etag) : "",
      id: isSet(object.id) ? globalThis.String(object.id) : "",
      selfLink: isSet(object.selfLink) ? globalThis.String(object.selfLink) : "",
      userEmail: isSet(object.userEmail) ? globalThis.String(object.userEmail) : "",
      configuration: isSet(object.configuration) ? JobConfiguration.fromJSON(object.configuration) : undefined,
      jobReference: isSet(object.jobReference) ? JobReference.fromJSON(object.jobReference) : undefined,
      statistics: isSet(object.statistics) ? JobStatistics.fromJSON(object.statistics) : undefined,
      status: isSet(object.status) ? JobStatus.fromJSON(object.status) : undefined,
      principalSubject: isSet(object.principalSubject) ? globalThis.String(object.principalSubject) : "",
      jobCreationReason: isSet(object.jobCreationReason)
        ? JobCreationReason.fromJSON(object.jobCreationReason)
        : undefined,
    };
  },

  toJSON(message: Job): unknown {
    const obj: any = {};
    if (message.kind !== "") {
      obj.kind = message.kind;
    }
    if (message.etag !== "") {
      obj.etag = message.etag;
    }
    if (message.id !== "") {
      obj.id = message.id;
    }
    if (message.selfLink !== "") {
      obj.selfLink = message.selfLink;
    }
    if (message.userEmail !== "") {
      obj.userEmail = message.userEmail;
    }
    if (message.configuration !== undefined) {
      obj.configuration = JobConfiguration.toJSON(message.configuration);
    }
    if (message.jobReference !== undefined) {
      obj.jobReference = JobReference.toJSON(message.jobReference);
    }
    if (message.statistics !== undefined) {
      obj.statistics = JobStatistics.toJSON(message.statistics);
    }
    if (message.status !== undefined) {
      obj.status = JobStatus.toJSON(message.status);
    }
    if (message.principalSubject !== "") {
      obj.principalSubject = message.principalSubject;
    }
    if (message.jobCreationReason !== undefined) {
      obj.jobCreationReason = JobCreationReason.toJSON(message.jobCreationReason);
    }
    return obj;
  },

  create(base?: DeepPartial<Job>): Job {
    return Job.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<Job>): Job {
    const message = createBaseJob();
    message.kind = object.kind ?? "";
    message.etag = object.etag ?? "";
    message.id = object.id ?? "";
    message.selfLink = object.selfLink ?? "";
    message.userEmail = object.userEmail ?? "";
    message.configuration = (object.configuration !== undefined && object.configuration !== null)
      ? JobConfiguration.fromPartial(object.configuration)
      : undefined;
    message.jobReference = (object.jobReference !== undefined && object.jobReference !== null)
      ? JobReference.fromPartial(object.jobReference)
      : undefined;
    message.statistics = (object.statistics !== undefined && object.statistics !== null)
      ? JobStatistics.fromPartial(object.statistics)
      : undefined;
    message.status = (object.status !== undefined && object.status !== null)
      ? JobStatus.fromPartial(object.status)
      : undefined;
    message.principalSubject = object.principalSubject ?? "";
    message.jobCreationReason = (object.jobCreationReason !== undefined && object.jobCreationReason !== null)
      ? JobCreationReason.fromPartial(object.jobCreationReason)
      : undefined;
    return message;
  },
};

function createBaseCancelJobRequest(): CancelJobRequest {
  return { projectId: "", jobId: "", location: "" };
}

export const CancelJobRequest: MessageFns<CancelJobRequest> = {
  encode(message: CancelJobRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.projectId !== "") {
      writer.uint32(10).string(message.projectId);
    }
    if (message.jobId !== "") {
      writer.uint32(18).string(message.jobId);
    }
    if (message.location !== "") {
      writer.uint32(26).string(message.location);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): CancelJobRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseCancelJobRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.projectId = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.jobId = reader.string();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.location = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): CancelJobRequest {
    return {
      projectId: isSet(object.projectId) ? globalThis.String(object.projectId) : "",
      jobId: isSet(object.jobId) ? globalThis.String(object.jobId) : "",
      location: isSet(object.location) ? globalThis.String(object.location) : "",
    };
  },

  toJSON(message: CancelJobRequest): unknown {
    const obj: any = {};
    if (message.projectId !== "") {
      obj.projectId = message.projectId;
    }
    if (message.jobId !== "") {
      obj.jobId = message.jobId;
    }
    if (message.location !== "") {
      obj.location = message.location;
    }
    return obj;
  },

  create(base?: DeepPartial<CancelJobRequest>): CancelJobRequest {
    return CancelJobRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<CancelJobRequest>): CancelJobRequest {
    const message = createBaseCancelJobRequest();
    message.projectId = object.projectId ?? "";
    message.jobId = object.jobId ?? "";
    message.location = object.location ?? "";
    return message;
  },
};

function createBaseJobCancelResponse(): JobCancelResponse {
  return { kind: "", job: undefined };
}

export const JobCancelResponse: MessageFns<JobCancelResponse> = {
  encode(message: JobCancelResponse, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.kind !== "") {
      writer.uint32(10).string(message.kind);
    }
    if (message.job !== undefined) {
      Job.encode(message.job, writer.uint32(18).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): JobCancelResponse {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseJobCancelResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.kind = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.job = Job.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): JobCancelResponse {
    return {
      kind: isSet(object.kind) ? globalThis.String(object.kind) : "",
      job: isSet(object.job) ? Job.fromJSON(object.job) : undefined,
    };
  },

  toJSON(message: JobCancelResponse): unknown {
    const obj: any = {};
    if (message.kind !== "") {
      obj.kind = message.kind;
    }
    if (message.job !== undefined) {
      obj.job = Job.toJSON(message.job);
    }
    return obj;
  },

  create(base?: DeepPartial<JobCancelResponse>): JobCancelResponse {
    return JobCancelResponse.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<JobCancelResponse>): JobCancelResponse {
    const message = createBaseJobCancelResponse();
    message.kind = object.kind ?? "";
    message.job = (object.job !== undefined && object.job !== null) ? Job.fromPartial(object.job) : undefined;
    return message;
  },
};

function createBaseGetJobRequest(): GetJobRequest {
  return { projectId: "", jobId: "", location: "" };
}

export const GetJobRequest: MessageFns<GetJobRequest> = {
  encode(message: GetJobRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.projectId !== "") {
      writer.uint32(10).string(message.projectId);
    }
    if (message.jobId !== "") {
      writer.uint32(18).string(message.jobId);
    }
    if (message.location !== "") {
      writer.uint32(26).string(message.location);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): GetJobRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseGetJobRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.projectId = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.jobId = reader.string();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.location = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): GetJobRequest {
    return {
      projectId: isSet(object.projectId) ? globalThis.String(object.projectId) : "",
      jobId: isSet(object.jobId) ? globalThis.String(object.jobId) : "",
      location: isSet(object.location) ? globalThis.String(object.location) : "",
    };
  },

  toJSON(message: GetJobRequest): unknown {
    const obj: any = {};
    if (message.projectId !== "") {
      obj.projectId = message.projectId;
    }
    if (message.jobId !== "") {
      obj.jobId = message.jobId;
    }
    if (message.location !== "") {
      obj.location = message.location;
    }
    return obj;
  },

  create(base?: DeepPartial<GetJobRequest>): GetJobRequest {
    return GetJobRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<GetJobRequest>): GetJobRequest {
    const message = createBaseGetJobRequest();
    message.projectId = object.projectId ?? "";
    message.jobId = object.jobId ?? "";
    message.location = object.location ?? "";
    return message;
  },
};

function createBaseInsertJobRequest(): InsertJobRequest {
  return { projectId: "", job: undefined };
}

export const InsertJobRequest: MessageFns<InsertJobRequest> = {
  encode(message: InsertJobRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.projectId !== "") {
      writer.uint32(10).string(message.projectId);
    }
    if (message.job !== undefined) {
      Job.encode(message.job, writer.uint32(26).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): InsertJobRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseInsertJobRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.projectId = reader.string();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.job = Job.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): InsertJobRequest {
    return {
      projectId: isSet(object.projectId) ? globalThis.String(object.projectId) : "",
      job: isSet(object.job) ? Job.fromJSON(object.job) : undefined,
    };
  },

  toJSON(message: InsertJobRequest): unknown {
    const obj: any = {};
    if (message.projectId !== "") {
      obj.projectId = message.projectId;
    }
    if (message.job !== undefined) {
      obj.job = Job.toJSON(message.job);
    }
    return obj;
  },

  create(base?: DeepPartial<InsertJobRequest>): InsertJobRequest {
    return InsertJobRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<InsertJobRequest>): InsertJobRequest {
    const message = createBaseInsertJobRequest();
    message.projectId = object.projectId ?? "";
    message.job = (object.job !== undefined && object.job !== null) ? Job.fromPartial(object.job) : undefined;
    return message;
  },
};

function createBaseDeleteJobRequest(): DeleteJobRequest {
  return { projectId: "", jobId: "", location: "" };
}

export const DeleteJobRequest: MessageFns<DeleteJobRequest> = {
  encode(message: DeleteJobRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.projectId !== "") {
      writer.uint32(10).string(message.projectId);
    }
    if (message.jobId !== "") {
      writer.uint32(18).string(message.jobId);
    }
    if (message.location !== "") {
      writer.uint32(26).string(message.location);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): DeleteJobRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDeleteJobRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.projectId = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.jobId = reader.string();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.location = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): DeleteJobRequest {
    return {
      projectId: isSet(object.projectId) ? globalThis.String(object.projectId) : "",
      jobId: isSet(object.jobId) ? globalThis.String(object.jobId) : "",
      location: isSet(object.location) ? globalThis.String(object.location) : "",
    };
  },

  toJSON(message: DeleteJobRequest): unknown {
    const obj: any = {};
    if (message.projectId !== "") {
      obj.projectId = message.projectId;
    }
    if (message.jobId !== "") {
      obj.jobId = message.jobId;
    }
    if (message.location !== "") {
      obj.location = message.location;
    }
    return obj;
  },

  create(base?: DeepPartial<DeleteJobRequest>): DeleteJobRequest {
    return DeleteJobRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<DeleteJobRequest>): DeleteJobRequest {
    const message = createBaseDeleteJobRequest();
    message.projectId = object.projectId ?? "";
    message.jobId = object.jobId ?? "";
    message.location = object.location ?? "";
    return message;
  },
};

function createBaseListJobsRequest(): ListJobsRequest {
  return {
    projectId: "",
    allUsers: false,
    maxResults: undefined,
    minCreationTime: Long.UZERO,
    maxCreationTime: undefined,
    pageToken: "",
    projection: 0,
    stateFilter: [],
    parentJobId: "",
  };
}

export const ListJobsRequest: MessageFns<ListJobsRequest> = {
  encode(message: ListJobsRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.projectId !== "") {
      writer.uint32(10).string(message.projectId);
    }
    if (message.allUsers !== false) {
      writer.uint32(16).bool(message.allUsers);
    }
    if (message.maxResults !== undefined) {
      Int32Value.encode({ value: message.maxResults! }, writer.uint32(26).fork()).join();
    }
    if (!message.minCreationTime.equals(Long.UZERO)) {
      writer.uint32(32).uint64(message.minCreationTime.toString());
    }
    if (message.maxCreationTime !== undefined) {
      UInt64Value.encode({ value: message.maxCreationTime! }, writer.uint32(42).fork()).join();
    }
    if (message.pageToken !== "") {
      writer.uint32(50).string(message.pageToken);
    }
    if (message.projection !== 0) {
      writer.uint32(56).int32(message.projection);
    }
    writer.uint32(66).fork();
    for (const v of message.stateFilter) {
      writer.int32(v);
    }
    writer.join();
    if (message.parentJobId !== "") {
      writer.uint32(74).string(message.parentJobId);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ListJobsRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseListJobsRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.projectId = reader.string();
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.allUsers = reader.bool();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.maxResults = Int32Value.decode(reader, reader.uint32()).value;
          continue;
        case 4:
          if (tag !== 32) {
            break;
          }

          message.minCreationTime = Long.fromString(reader.uint64().toString(), true);
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.maxCreationTime = UInt64Value.decode(reader, reader.uint32()).value;
          continue;
        case 6:
          if (tag !== 50) {
            break;
          }

          message.pageToken = reader.string();
          continue;
        case 7:
          if (tag !== 56) {
            break;
          }

          message.projection = reader.int32() as any;
          continue;
        case 8:
          if (tag === 64) {
            message.stateFilter.push(reader.int32() as any);

            continue;
          }

          if (tag === 66) {
            const end2 = reader.uint32() + reader.pos;
            while (reader.pos < end2) {
              message.stateFilter.push(reader.int32() as any);
            }

            continue;
          }

          break;
        case 9:
          if (tag !== 74) {
            break;
          }

          message.parentJobId = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ListJobsRequest {
    return {
      projectId: isSet(object.projectId) ? globalThis.String(object.projectId) : "",
      allUsers: isSet(object.allUsers) ? globalThis.Boolean(object.allUsers) : false,
      maxResults: isSet(object.maxResults) ? Number(object.maxResults) : undefined,
      minCreationTime: isSet(object.minCreationTime) ? Long.fromValue(object.minCreationTime) : Long.UZERO,
      maxCreationTime: isSet(object.maxCreationTime) ? Long.fromValue(object.maxCreationTime) : undefined,
      pageToken: isSet(object.pageToken) ? globalThis.String(object.pageToken) : "",
      projection: isSet(object.projection) ? listJobsRequest_ProjectionFromJSON(object.projection) : 0,
      stateFilter: globalThis.Array.isArray(object?.stateFilter)
        ? object.stateFilter.map((e: any) => listJobsRequest_StateFilterFromJSON(e))
        : [],
      parentJobId: isSet(object.parentJobId) ? globalThis.String(object.parentJobId) : "",
    };
  },

  toJSON(message: ListJobsRequest): unknown {
    const obj: any = {};
    if (message.projectId !== "") {
      obj.projectId = message.projectId;
    }
    if (message.allUsers !== false) {
      obj.allUsers = message.allUsers;
    }
    if (message.maxResults !== undefined) {
      obj.maxResults = message.maxResults;
    }
    if (!message.minCreationTime.equals(Long.UZERO)) {
      obj.minCreationTime = (message.minCreationTime || Long.UZERO).toString();
    }
    if (message.maxCreationTime !== undefined) {
      obj.maxCreationTime = message.maxCreationTime;
    }
    if (message.pageToken !== "") {
      obj.pageToken = message.pageToken;
    }
    if (message.projection !== 0) {
      obj.projection = listJobsRequest_ProjectionToJSON(message.projection);
    }
    if (message.stateFilter?.length) {
      obj.stateFilter = message.stateFilter.map((e) => listJobsRequest_StateFilterToJSON(e));
    }
    if (message.parentJobId !== "") {
      obj.parentJobId = message.parentJobId;
    }
    return obj;
  },

  create(base?: DeepPartial<ListJobsRequest>): ListJobsRequest {
    return ListJobsRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ListJobsRequest>): ListJobsRequest {
    const message = createBaseListJobsRequest();
    message.projectId = object.projectId ?? "";
    message.allUsers = object.allUsers ?? false;
    message.maxResults = object.maxResults ?? undefined;
    message.minCreationTime = (object.minCreationTime !== undefined && object.minCreationTime !== null)
      ? Long.fromValue(object.minCreationTime)
      : Long.UZERO;
    message.maxCreationTime = (object.maxCreationTime !== undefined && object.maxCreationTime !== null)
      ? Long.fromValue(object.maxCreationTime)
      : undefined;
    message.pageToken = object.pageToken ?? "";
    message.projection = object.projection ?? 0;
    message.stateFilter = object.stateFilter?.map((e) => e) || [];
    message.parentJobId = object.parentJobId ?? "";
    return message;
  },
};

function createBaseListFormatJob(): ListFormatJob {
  return {
    id: "",
    kind: "",
    jobReference: undefined,
    state: "",
    errorResult: undefined,
    statistics: undefined,
    configuration: undefined,
    status: undefined,
    userEmail: "",
    principalSubject: "",
  };
}

export const ListFormatJob: MessageFns<ListFormatJob> = {
  encode(message: ListFormatJob, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.id !== "") {
      writer.uint32(10).string(message.id);
    }
    if (message.kind !== "") {
      writer.uint32(18).string(message.kind);
    }
    if (message.jobReference !== undefined) {
      JobReference.encode(message.jobReference, writer.uint32(26).fork()).join();
    }
    if (message.state !== "") {
      writer.uint32(34).string(message.state);
    }
    if (message.errorResult !== undefined) {
      ErrorProto.encode(message.errorResult, writer.uint32(42).fork()).join();
    }
    if (message.statistics !== undefined) {
      JobStatistics.encode(message.statistics, writer.uint32(50).fork()).join();
    }
    if (message.configuration !== undefined) {
      JobConfiguration.encode(message.configuration, writer.uint32(58).fork()).join();
    }
    if (message.status !== undefined) {
      JobStatus.encode(message.status, writer.uint32(66).fork()).join();
    }
    if (message.userEmail !== "") {
      writer.uint32(74).string(message.userEmail);
    }
    if (message.principalSubject !== "") {
      writer.uint32(82).string(message.principalSubject);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ListFormatJob {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseListFormatJob();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.id = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.kind = reader.string();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.jobReference = JobReference.decode(reader, reader.uint32());
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.state = reader.string();
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.errorResult = ErrorProto.decode(reader, reader.uint32());
          continue;
        case 6:
          if (tag !== 50) {
            break;
          }

          message.statistics = JobStatistics.decode(reader, reader.uint32());
          continue;
        case 7:
          if (tag !== 58) {
            break;
          }

          message.configuration = JobConfiguration.decode(reader, reader.uint32());
          continue;
        case 8:
          if (tag !== 66) {
            break;
          }

          message.status = JobStatus.decode(reader, reader.uint32());
          continue;
        case 9:
          if (tag !== 74) {
            break;
          }

          message.userEmail = reader.string();
          continue;
        case 10:
          if (tag !== 82) {
            break;
          }

          message.principalSubject = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ListFormatJob {
    return {
      id: isSet(object.id) ? globalThis.String(object.id) : "",
      kind: isSet(object.kind) ? globalThis.String(object.kind) : "",
      jobReference: isSet(object.jobReference) ? JobReference.fromJSON(object.jobReference) : undefined,
      state: isSet(object.state) ? globalThis.String(object.state) : "",
      errorResult: isSet(object.errorResult) ? ErrorProto.fromJSON(object.errorResult) : undefined,
      statistics: isSet(object.statistics) ? JobStatistics.fromJSON(object.statistics) : undefined,
      configuration: isSet(object.configuration) ? JobConfiguration.fromJSON(object.configuration) : undefined,
      status: isSet(object.status) ? JobStatus.fromJSON(object.status) : undefined,
      userEmail: isSet(object.userEmail) ? globalThis.String(object.userEmail) : "",
      principalSubject: isSet(object.principalSubject) ? globalThis.String(object.principalSubject) : "",
    };
  },

  toJSON(message: ListFormatJob): unknown {
    const obj: any = {};
    if (message.id !== "") {
      obj.id = message.id;
    }
    if (message.kind !== "") {
      obj.kind = message.kind;
    }
    if (message.jobReference !== undefined) {
      obj.jobReference = JobReference.toJSON(message.jobReference);
    }
    if (message.state !== "") {
      obj.state = message.state;
    }
    if (message.errorResult !== undefined) {
      obj.errorResult = ErrorProto.toJSON(message.errorResult);
    }
    if (message.statistics !== undefined) {
      obj.statistics = JobStatistics.toJSON(message.statistics);
    }
    if (message.configuration !== undefined) {
      obj.configuration = JobConfiguration.toJSON(message.configuration);
    }
    if (message.status !== undefined) {
      obj.status = JobStatus.toJSON(message.status);
    }
    if (message.userEmail !== "") {
      obj.userEmail = message.userEmail;
    }
    if (message.principalSubject !== "") {
      obj.principalSubject = message.principalSubject;
    }
    return obj;
  },

  create(base?: DeepPartial<ListFormatJob>): ListFormatJob {
    return ListFormatJob.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ListFormatJob>): ListFormatJob {
    const message = createBaseListFormatJob();
    message.id = object.id ?? "";
    message.kind = object.kind ?? "";
    message.jobReference = (object.jobReference !== undefined && object.jobReference !== null)
      ? JobReference.fromPartial(object.jobReference)
      : undefined;
    message.state = object.state ?? "";
    message.errorResult = (object.errorResult !== undefined && object.errorResult !== null)
      ? ErrorProto.fromPartial(object.errorResult)
      : undefined;
    message.statistics = (object.statistics !== undefined && object.statistics !== null)
      ? JobStatistics.fromPartial(object.statistics)
      : undefined;
    message.configuration = (object.configuration !== undefined && object.configuration !== null)
      ? JobConfiguration.fromPartial(object.configuration)
      : undefined;
    message.status = (object.status !== undefined && object.status !== null)
      ? JobStatus.fromPartial(object.status)
      : undefined;
    message.userEmail = object.userEmail ?? "";
    message.principalSubject = object.principalSubject ?? "";
    return message;
  },
};

function createBaseJobList(): JobList {
  return { etag: "", kind: "", nextPageToken: "", jobs: [], unreachable: [] };
}

export const JobList: MessageFns<JobList> = {
  encode(message: JobList, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.etag !== "") {
      writer.uint32(10).string(message.etag);
    }
    if (message.kind !== "") {
      writer.uint32(18).string(message.kind);
    }
    if (message.nextPageToken !== "") {
      writer.uint32(26).string(message.nextPageToken);
    }
    for (const v of message.jobs) {
      ListFormatJob.encode(v!, writer.uint32(34).fork()).join();
    }
    for (const v of message.unreachable) {
      writer.uint32(42).string(v!);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): JobList {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseJobList();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.etag = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.kind = reader.string();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.nextPageToken = reader.string();
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.jobs.push(ListFormatJob.decode(reader, reader.uint32()));
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.unreachable.push(reader.string());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): JobList {
    return {
      etag: isSet(object.etag) ? globalThis.String(object.etag) : "",
      kind: isSet(object.kind) ? globalThis.String(object.kind) : "",
      nextPageToken: isSet(object.nextPageToken) ? globalThis.String(object.nextPageToken) : "",
      jobs: globalThis.Array.isArray(object?.jobs) ? object.jobs.map((e: any) => ListFormatJob.fromJSON(e)) : [],
      unreachable: globalThis.Array.isArray(object?.unreachable)
        ? object.unreachable.map((e: any) => globalThis.String(e))
        : [],
    };
  },

  toJSON(message: JobList): unknown {
    const obj: any = {};
    if (message.etag !== "") {
      obj.etag = message.etag;
    }
    if (message.kind !== "") {
      obj.kind = message.kind;
    }
    if (message.nextPageToken !== "") {
      obj.nextPageToken = message.nextPageToken;
    }
    if (message.jobs?.length) {
      obj.jobs = message.jobs.map((e) => ListFormatJob.toJSON(e));
    }
    if (message.unreachable?.length) {
      obj.unreachable = message.unreachable;
    }
    return obj;
  },

  create(base?: DeepPartial<JobList>): JobList {
    return JobList.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<JobList>): JobList {
    const message = createBaseJobList();
    message.etag = object.etag ?? "";
    message.kind = object.kind ?? "";
    message.nextPageToken = object.nextPageToken ?? "";
    message.jobs = object.jobs?.map((e) => ListFormatJob.fromPartial(e)) || [];
    message.unreachable = object.unreachable?.map((e) => e) || [];
    return message;
  },
};

function createBaseGetQueryResultsRequest(): GetQueryResultsRequest {
  return {
    projectId: "",
    jobId: "",
    startIndex: undefined,
    pageToken: "",
    maxResults: undefined,
    timeoutMs: undefined,
    location: "",
    formatOptions: undefined,
  };
}

export const GetQueryResultsRequest: MessageFns<GetQueryResultsRequest> = {
  encode(message: GetQueryResultsRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.projectId !== "") {
      writer.uint32(10).string(message.projectId);
    }
    if (message.jobId !== "") {
      writer.uint32(18).string(message.jobId);
    }
    if (message.startIndex !== undefined) {
      UInt64Value.encode({ value: message.startIndex! }, writer.uint32(26).fork()).join();
    }
    if (message.pageToken !== "") {
      writer.uint32(34).string(message.pageToken);
    }
    if (message.maxResults !== undefined) {
      UInt32Value.encode({ value: message.maxResults! }, writer.uint32(42).fork()).join();
    }
    if (message.timeoutMs !== undefined) {
      UInt32Value.encode({ value: message.timeoutMs! }, writer.uint32(50).fork()).join();
    }
    if (message.location !== "") {
      writer.uint32(58).string(message.location);
    }
    if (message.formatOptions !== undefined) {
      DataFormatOptions.encode(message.formatOptions, writer.uint32(66).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): GetQueryResultsRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseGetQueryResultsRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.projectId = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.jobId = reader.string();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.startIndex = UInt64Value.decode(reader, reader.uint32()).value;
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.pageToken = reader.string();
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.maxResults = UInt32Value.decode(reader, reader.uint32()).value;
          continue;
        case 6:
          if (tag !== 50) {
            break;
          }

          message.timeoutMs = UInt32Value.decode(reader, reader.uint32()).value;
          continue;
        case 7:
          if (tag !== 58) {
            break;
          }

          message.location = reader.string();
          continue;
        case 8:
          if (tag !== 66) {
            break;
          }

          message.formatOptions = DataFormatOptions.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): GetQueryResultsRequest {
    return {
      projectId: isSet(object.projectId) ? globalThis.String(object.projectId) : "",
      jobId: isSet(object.jobId) ? globalThis.String(object.jobId) : "",
      startIndex: isSet(object.startIndex) ? Long.fromValue(object.startIndex) : undefined,
      pageToken: isSet(object.pageToken) ? globalThis.String(object.pageToken) : "",
      maxResults: isSet(object.maxResults) ? Number(object.maxResults) : undefined,
      timeoutMs: isSet(object.timeoutMs) ? Number(object.timeoutMs) : undefined,
      location: isSet(object.location) ? globalThis.String(object.location) : "",
      formatOptions: isSet(object.formatOptions) ? DataFormatOptions.fromJSON(object.formatOptions) : undefined,
    };
  },

  toJSON(message: GetQueryResultsRequest): unknown {
    const obj: any = {};
    if (message.projectId !== "") {
      obj.projectId = message.projectId;
    }
    if (message.jobId !== "") {
      obj.jobId = message.jobId;
    }
    if (message.startIndex !== undefined) {
      obj.startIndex = message.startIndex;
    }
    if (message.pageToken !== "") {
      obj.pageToken = message.pageToken;
    }
    if (message.maxResults !== undefined) {
      obj.maxResults = message.maxResults;
    }
    if (message.timeoutMs !== undefined) {
      obj.timeoutMs = message.timeoutMs;
    }
    if (message.location !== "") {
      obj.location = message.location;
    }
    if (message.formatOptions !== undefined) {
      obj.formatOptions = DataFormatOptions.toJSON(message.formatOptions);
    }
    return obj;
  },

  create(base?: DeepPartial<GetQueryResultsRequest>): GetQueryResultsRequest {
    return GetQueryResultsRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<GetQueryResultsRequest>): GetQueryResultsRequest {
    const message = createBaseGetQueryResultsRequest();
    message.projectId = object.projectId ?? "";
    message.jobId = object.jobId ?? "";
    message.startIndex = (object.startIndex !== undefined && object.startIndex !== null)
      ? Long.fromValue(object.startIndex)
      : undefined;
    message.pageToken = object.pageToken ?? "";
    message.maxResults = object.maxResults ?? undefined;
    message.timeoutMs = object.timeoutMs ?? undefined;
    message.location = object.location ?? "";
    message.formatOptions = (object.formatOptions !== undefined && object.formatOptions !== null)
      ? DataFormatOptions.fromPartial(object.formatOptions)
      : undefined;
    return message;
  },
};

function createBaseGetQueryResultsResponse(): GetQueryResultsResponse {
  return {
    kind: "",
    etag: "",
    schema: undefined,
    jobReference: undefined,
    totalRows: undefined,
    pageToken: "",
    rows: [],
    totalBytesProcessed: undefined,
    jobComplete: undefined,
    errors: [],
    cacheHit: undefined,
    numDmlAffectedRows: undefined,
  };
}

export const GetQueryResultsResponse: MessageFns<GetQueryResultsResponse> = {
  encode(message: GetQueryResultsResponse, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.kind !== "") {
      writer.uint32(10).string(message.kind);
    }
    if (message.etag !== "") {
      writer.uint32(18).string(message.etag);
    }
    if (message.schema !== undefined) {
      TableSchema.encode(message.schema, writer.uint32(26).fork()).join();
    }
    if (message.jobReference !== undefined) {
      JobReference.encode(message.jobReference, writer.uint32(34).fork()).join();
    }
    if (message.totalRows !== undefined) {
      UInt64Value.encode({ value: message.totalRows! }, writer.uint32(42).fork()).join();
    }
    if (message.pageToken !== "") {
      writer.uint32(50).string(message.pageToken);
    }
    for (const v of message.rows) {
      Struct.encode(Struct.wrap(v!), writer.uint32(58).fork()).join();
    }
    if (message.totalBytesProcessed !== undefined) {
      Int64Value.encode({ value: message.totalBytesProcessed! }, writer.uint32(66).fork()).join();
    }
    if (message.jobComplete !== undefined) {
      BoolValue.encode({ value: message.jobComplete! }, writer.uint32(74).fork()).join();
    }
    for (const v of message.errors) {
      ErrorProto.encode(v!, writer.uint32(82).fork()).join();
    }
    if (message.cacheHit !== undefined) {
      BoolValue.encode({ value: message.cacheHit! }, writer.uint32(90).fork()).join();
    }
    if (message.numDmlAffectedRows !== undefined) {
      Int64Value.encode({ value: message.numDmlAffectedRows! }, writer.uint32(98).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): GetQueryResultsResponse {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseGetQueryResultsResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.kind = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.etag = reader.string();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.schema = TableSchema.decode(reader, reader.uint32());
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.jobReference = JobReference.decode(reader, reader.uint32());
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.totalRows = UInt64Value.decode(reader, reader.uint32()).value;
          continue;
        case 6:
          if (tag !== 50) {
            break;
          }

          message.pageToken = reader.string();
          continue;
        case 7:
          if (tag !== 58) {
            break;
          }

          message.rows.push(Struct.unwrap(Struct.decode(reader, reader.uint32())));
          continue;
        case 8:
          if (tag !== 66) {
            break;
          }

          message.totalBytesProcessed = Int64Value.decode(reader, reader.uint32()).value;
          continue;
        case 9:
          if (tag !== 74) {
            break;
          }

          message.jobComplete = BoolValue.decode(reader, reader.uint32()).value;
          continue;
        case 10:
          if (tag !== 82) {
            break;
          }

          message.errors.push(ErrorProto.decode(reader, reader.uint32()));
          continue;
        case 11:
          if (tag !== 90) {
            break;
          }

          message.cacheHit = BoolValue.decode(reader, reader.uint32()).value;
          continue;
        case 12:
          if (tag !== 98) {
            break;
          }

          message.numDmlAffectedRows = Int64Value.decode(reader, reader.uint32()).value;
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): GetQueryResultsResponse {
    return {
      kind: isSet(object.kind) ? globalThis.String(object.kind) : "",
      etag: isSet(object.etag) ? globalThis.String(object.etag) : "",
      schema: isSet(object.schema) ? TableSchema.fromJSON(object.schema) : undefined,
      jobReference: isSet(object.jobReference) ? JobReference.fromJSON(object.jobReference) : undefined,
      totalRows: isSet(object.totalRows) ? Long.fromValue(object.totalRows) : undefined,
      pageToken: isSet(object.pageToken) ? globalThis.String(object.pageToken) : "",
      rows: globalThis.Array.isArray(object?.rows) ? [...object.rows] : [],
      totalBytesProcessed: isSet(object.totalBytesProcessed) ? Long.fromValue(object.totalBytesProcessed) : undefined,
      jobComplete: isSet(object.jobComplete) ? Boolean(object.jobComplete) : undefined,
      errors: globalThis.Array.isArray(object?.errors) ? object.errors.map((e: any) => ErrorProto.fromJSON(e)) : [],
      cacheHit: isSet(object.cacheHit) ? Boolean(object.cacheHit) : undefined,
      numDmlAffectedRows: isSet(object.numDmlAffectedRows) ? Long.fromValue(object.numDmlAffectedRows) : undefined,
    };
  },

  toJSON(message: GetQueryResultsResponse): unknown {
    const obj: any = {};
    if (message.kind !== "") {
      obj.kind = message.kind;
    }
    if (message.etag !== "") {
      obj.etag = message.etag;
    }
    if (message.schema !== undefined) {
      obj.schema = TableSchema.toJSON(message.schema);
    }
    if (message.jobReference !== undefined) {
      obj.jobReference = JobReference.toJSON(message.jobReference);
    }
    if (message.totalRows !== undefined) {
      obj.totalRows = message.totalRows;
    }
    if (message.pageToken !== "") {
      obj.pageToken = message.pageToken;
    }
    if (message.rows?.length) {
      obj.rows = message.rows;
    }
    if (message.totalBytesProcessed !== undefined) {
      obj.totalBytesProcessed = message.totalBytesProcessed;
    }
    if (message.jobComplete !== undefined) {
      obj.jobComplete = message.jobComplete;
    }
    if (message.errors?.length) {
      obj.errors = message.errors.map((e) => ErrorProto.toJSON(e));
    }
    if (message.cacheHit !== undefined) {
      obj.cacheHit = message.cacheHit;
    }
    if (message.numDmlAffectedRows !== undefined) {
      obj.numDmlAffectedRows = message.numDmlAffectedRows;
    }
    return obj;
  },

  create(base?: DeepPartial<GetQueryResultsResponse>): GetQueryResultsResponse {
    return GetQueryResultsResponse.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<GetQueryResultsResponse>): GetQueryResultsResponse {
    const message = createBaseGetQueryResultsResponse();
    message.kind = object.kind ?? "";
    message.etag = object.etag ?? "";
    message.schema = (object.schema !== undefined && object.schema !== null)
      ? TableSchema.fromPartial(object.schema)
      : undefined;
    message.jobReference = (object.jobReference !== undefined && object.jobReference !== null)
      ? JobReference.fromPartial(object.jobReference)
      : undefined;
    message.totalRows = (object.totalRows !== undefined && object.totalRows !== null)
      ? Long.fromValue(object.totalRows)
      : undefined;
    message.pageToken = object.pageToken ?? "";
    message.rows = object.rows?.map((e) => e) || [];
    message.totalBytesProcessed = (object.totalBytesProcessed !== undefined && object.totalBytesProcessed !== null)
      ? Long.fromValue(object.totalBytesProcessed)
      : undefined;
    message.jobComplete = object.jobComplete ?? undefined;
    message.errors = object.errors?.map((e) => ErrorProto.fromPartial(e)) || [];
    message.cacheHit = object.cacheHit ?? undefined;
    message.numDmlAffectedRows = (object.numDmlAffectedRows !== undefined && object.numDmlAffectedRows !== null)
      ? Long.fromValue(object.numDmlAffectedRows)
      : undefined;
    return message;
  },
};

function createBasePostQueryRequest(): PostQueryRequest {
  return { projectId: "", queryRequest: undefined };
}

export const PostQueryRequest: MessageFns<PostQueryRequest> = {
  encode(message: PostQueryRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.projectId !== "") {
      writer.uint32(10).string(message.projectId);
    }
    if (message.queryRequest !== undefined) {
      QueryRequest.encode(message.queryRequest, writer.uint32(18).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): PostQueryRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBasePostQueryRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.projectId = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.queryRequest = QueryRequest.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): PostQueryRequest {
    return {
      projectId: isSet(object.projectId) ? globalThis.String(object.projectId) : "",
      queryRequest: isSet(object.queryRequest) ? QueryRequest.fromJSON(object.queryRequest) : undefined,
    };
  },

  toJSON(message: PostQueryRequest): unknown {
    const obj: any = {};
    if (message.projectId !== "") {
      obj.projectId = message.projectId;
    }
    if (message.queryRequest !== undefined) {
      obj.queryRequest = QueryRequest.toJSON(message.queryRequest);
    }
    return obj;
  },

  create(base?: DeepPartial<PostQueryRequest>): PostQueryRequest {
    return PostQueryRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<PostQueryRequest>): PostQueryRequest {
    const message = createBasePostQueryRequest();
    message.projectId = object.projectId ?? "";
    message.queryRequest = (object.queryRequest !== undefined && object.queryRequest !== null)
      ? QueryRequest.fromPartial(object.queryRequest)
      : undefined;
    return message;
  },
};

function createBaseQueryRequest(): QueryRequest {
  return {
    kind: "",
    query: "",
    maxResults: undefined,
    defaultDataset: undefined,
    timeoutMs: undefined,
    dryRun: false,
    useQueryCache: undefined,
    useLegacySql: undefined,
    parameterMode: "",
    queryParameters: [],
    location: "",
    formatOptions: undefined,
    connectionProperties: [],
    labels: {},
    maximumBytesBilled: undefined,
    requestId: "",
    createSession: undefined,
    jobCreationMode: 0,
  };
}

export const QueryRequest: MessageFns<QueryRequest> = {
  encode(message: QueryRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.kind !== "") {
      writer.uint32(18).string(message.kind);
    }
    if (message.query !== "") {
      writer.uint32(26).string(message.query);
    }
    if (message.maxResults !== undefined) {
      UInt32Value.encode({ value: message.maxResults! }, writer.uint32(34).fork()).join();
    }
    if (message.defaultDataset !== undefined) {
      DatasetReference.encode(message.defaultDataset, writer.uint32(42).fork()).join();
    }
    if (message.timeoutMs !== undefined) {
      UInt32Value.encode({ value: message.timeoutMs! }, writer.uint32(50).fork()).join();
    }
    if (message.dryRun !== false) {
      writer.uint32(56).bool(message.dryRun);
    }
    if (message.useQueryCache !== undefined) {
      BoolValue.encode({ value: message.useQueryCache! }, writer.uint32(74).fork()).join();
    }
    if (message.useLegacySql !== undefined) {
      BoolValue.encode({ value: message.useLegacySql! }, writer.uint32(82).fork()).join();
    }
    if (message.parameterMode !== "") {
      writer.uint32(90).string(message.parameterMode);
    }
    for (const v of message.queryParameters) {
      QueryParameter.encode(v!, writer.uint32(98).fork()).join();
    }
    if (message.location !== "") {
      writer.uint32(106).string(message.location);
    }
    if (message.formatOptions !== undefined) {
      DataFormatOptions.encode(message.formatOptions, writer.uint32(122).fork()).join();
    }
    for (const v of message.connectionProperties) {
      ConnectionProperty.encode(v!, writer.uint32(130).fork()).join();
    }
    Object.entries(message.labels).forEach(([key, value]) => {
      QueryRequest_LabelsEntry.encode({ key: key as any, value }, writer.uint32(138).fork()).join();
    });
    if (message.maximumBytesBilled !== undefined) {
      Int64Value.encode({ value: message.maximumBytesBilled! }, writer.uint32(146).fork()).join();
    }
    if (message.requestId !== "") {
      writer.uint32(154).string(message.requestId);
    }
    if (message.createSession !== undefined) {
      BoolValue.encode({ value: message.createSession! }, writer.uint32(162).fork()).join();
    }
    if (message.jobCreationMode !== 0) {
      writer.uint32(176).int32(message.jobCreationMode);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): QueryRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseQueryRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 2:
          if (tag !== 18) {
            break;
          }

          message.kind = reader.string();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.query = reader.string();
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.maxResults = UInt32Value.decode(reader, reader.uint32()).value;
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.defaultDataset = DatasetReference.decode(reader, reader.uint32());
          continue;
        case 6:
          if (tag !== 50) {
            break;
          }

          message.timeoutMs = UInt32Value.decode(reader, reader.uint32()).value;
          continue;
        case 7:
          if (tag !== 56) {
            break;
          }

          message.dryRun = reader.bool();
          continue;
        case 9:
          if (tag !== 74) {
            break;
          }

          message.useQueryCache = BoolValue.decode(reader, reader.uint32()).value;
          continue;
        case 10:
          if (tag !== 82) {
            break;
          }

          message.useLegacySql = BoolValue.decode(reader, reader.uint32()).value;
          continue;
        case 11:
          if (tag !== 90) {
            break;
          }

          message.parameterMode = reader.string();
          continue;
        case 12:
          if (tag !== 98) {
            break;
          }

          message.queryParameters.push(QueryParameter.decode(reader, reader.uint32()));
          continue;
        case 13:
          if (tag !== 106) {
            break;
          }

          message.location = reader.string();
          continue;
        case 15:
          if (tag !== 122) {
            break;
          }

          message.formatOptions = DataFormatOptions.decode(reader, reader.uint32());
          continue;
        case 16:
          if (tag !== 130) {
            break;
          }

          message.connectionProperties.push(ConnectionProperty.decode(reader, reader.uint32()));
          continue;
        case 17:
          if (tag !== 138) {
            break;
          }

          const entry17 = QueryRequest_LabelsEntry.decode(reader, reader.uint32());
          if (entry17.value !== undefined) {
            message.labels[entry17.key] = entry17.value;
          }
          continue;
        case 18:
          if (tag !== 146) {
            break;
          }

          message.maximumBytesBilled = Int64Value.decode(reader, reader.uint32()).value;
          continue;
        case 19:
          if (tag !== 154) {
            break;
          }

          message.requestId = reader.string();
          continue;
        case 20:
          if (tag !== 162) {
            break;
          }

          message.createSession = BoolValue.decode(reader, reader.uint32()).value;
          continue;
        case 22:
          if (tag !== 176) {
            break;
          }

          message.jobCreationMode = reader.int32() as any;
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): QueryRequest {
    return {
      kind: isSet(object.kind) ? globalThis.String(object.kind) : "",
      query: isSet(object.query) ? globalThis.String(object.query) : "",
      maxResults: isSet(object.maxResults) ? Number(object.maxResults) : undefined,
      defaultDataset: isSet(object.defaultDataset) ? DatasetReference.fromJSON(object.defaultDataset) : undefined,
      timeoutMs: isSet(object.timeoutMs) ? Number(object.timeoutMs) : undefined,
      dryRun: isSet(object.dryRun) ? globalThis.Boolean(object.dryRun) : false,
      useQueryCache: isSet(object.useQueryCache) ? Boolean(object.useQueryCache) : undefined,
      useLegacySql: isSet(object.useLegacySql) ? Boolean(object.useLegacySql) : undefined,
      parameterMode: isSet(object.parameterMode) ? globalThis.String(object.parameterMode) : "",
      queryParameters: globalThis.Array.isArray(object?.queryParameters)
        ? object.queryParameters.map((e: any) => QueryParameter.fromJSON(e))
        : [],
      location: isSet(object.location) ? globalThis.String(object.location) : "",
      formatOptions: isSet(object.formatOptions) ? DataFormatOptions.fromJSON(object.formatOptions) : undefined,
      connectionProperties: globalThis.Array.isArray(object?.connectionProperties)
        ? object.connectionProperties.map((e: any) => ConnectionProperty.fromJSON(e))
        : [],
      labels: isObject(object.labels)
        ? Object.entries(object.labels).reduce<{ [key: string]: string }>((acc, [key, value]) => {
          acc[key] = String(value);
          return acc;
        }, {})
        : {},
      maximumBytesBilled: isSet(object.maximumBytesBilled) ? Long.fromValue(object.maximumBytesBilled) : undefined,
      requestId: isSet(object.requestId) ? globalThis.String(object.requestId) : "",
      createSession: isSet(object.createSession) ? Boolean(object.createSession) : undefined,
      jobCreationMode: isSet(object.jobCreationMode) ? queryRequest_JobCreationModeFromJSON(object.jobCreationMode) : 0,
    };
  },

  toJSON(message: QueryRequest): unknown {
    const obj: any = {};
    if (message.kind !== "") {
      obj.kind = message.kind;
    }
    if (message.query !== "") {
      obj.query = message.query;
    }
    if (message.maxResults !== undefined) {
      obj.maxResults = message.maxResults;
    }
    if (message.defaultDataset !== undefined) {
      obj.defaultDataset = DatasetReference.toJSON(message.defaultDataset);
    }
    if (message.timeoutMs !== undefined) {
      obj.timeoutMs = message.timeoutMs;
    }
    if (message.dryRun !== false) {
      obj.dryRun = message.dryRun;
    }
    if (message.useQueryCache !== undefined) {
      obj.useQueryCache = message.useQueryCache;
    }
    if (message.useLegacySql !== undefined) {
      obj.useLegacySql = message.useLegacySql;
    }
    if (message.parameterMode !== "") {
      obj.parameterMode = message.parameterMode;
    }
    if (message.queryParameters?.length) {
      obj.queryParameters = message.queryParameters.map((e) => QueryParameter.toJSON(e));
    }
    if (message.location !== "") {
      obj.location = message.location;
    }
    if (message.formatOptions !== undefined) {
      obj.formatOptions = DataFormatOptions.toJSON(message.formatOptions);
    }
    if (message.connectionProperties?.length) {
      obj.connectionProperties = message.connectionProperties.map((e) => ConnectionProperty.toJSON(e));
    }
    if (message.labels) {
      const entries = Object.entries(message.labels);
      if (entries.length > 0) {
        obj.labels = {};
        entries.forEach(([k, v]) => {
          obj.labels[k] = v;
        });
      }
    }
    if (message.maximumBytesBilled !== undefined) {
      obj.maximumBytesBilled = message.maximumBytesBilled;
    }
    if (message.requestId !== "") {
      obj.requestId = message.requestId;
    }
    if (message.createSession !== undefined) {
      obj.createSession = message.createSession;
    }
    if (message.jobCreationMode !== 0) {
      obj.jobCreationMode = queryRequest_JobCreationModeToJSON(message.jobCreationMode);
    }
    return obj;
  },

  create(base?: DeepPartial<QueryRequest>): QueryRequest {
    return QueryRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<QueryRequest>): QueryRequest {
    const message = createBaseQueryRequest();
    message.kind = object.kind ?? "";
    message.query = object.query ?? "";
    message.maxResults = object.maxResults ?? undefined;
    message.defaultDataset = (object.defaultDataset !== undefined && object.defaultDataset !== null)
      ? DatasetReference.fromPartial(object.defaultDataset)
      : undefined;
    message.timeoutMs = object.timeoutMs ?? undefined;
    message.dryRun = object.dryRun ?? false;
    message.useQueryCache = object.useQueryCache ?? undefined;
    message.useLegacySql = object.useLegacySql ?? undefined;
    message.parameterMode = object.parameterMode ?? "";
    message.queryParameters = object.queryParameters?.map((e) => QueryParameter.fromPartial(e)) || [];
    message.location = object.location ?? "";
    message.formatOptions = (object.formatOptions !== undefined && object.formatOptions !== null)
      ? DataFormatOptions.fromPartial(object.formatOptions)
      : undefined;
    message.connectionProperties = object.connectionProperties?.map((e) => ConnectionProperty.fromPartial(e)) || [];
    message.labels = Object.entries(object.labels ?? {}).reduce<{ [key: string]: string }>((acc, [key, value]) => {
      if (value !== undefined) {
        acc[key] = globalThis.String(value);
      }
      return acc;
    }, {});
    message.maximumBytesBilled = (object.maximumBytesBilled !== undefined && object.maximumBytesBilled !== null)
      ? Long.fromValue(object.maximumBytesBilled)
      : undefined;
    message.requestId = object.requestId ?? "";
    message.createSession = object.createSession ?? undefined;
    message.jobCreationMode = object.jobCreationMode ?? 0;
    return message;
  },
};

function createBaseQueryRequest_LabelsEntry(): QueryRequest_LabelsEntry {
  return { key: "", value: "" };
}

export const QueryRequest_LabelsEntry: MessageFns<QueryRequest_LabelsEntry> = {
  encode(message: QueryRequest_LabelsEntry, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.key !== "") {
      writer.uint32(10).string(message.key);
    }
    if (message.value !== "") {
      writer.uint32(18).string(message.value);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): QueryRequest_LabelsEntry {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseQueryRequest_LabelsEntry();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.key = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.value = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): QueryRequest_LabelsEntry {
    return {
      key: isSet(object.key) ? globalThis.String(object.key) : "",
      value: isSet(object.value) ? globalThis.String(object.value) : "",
    };
  },

  toJSON(message: QueryRequest_LabelsEntry): unknown {
    const obj: any = {};
    if (message.key !== "") {
      obj.key = message.key;
    }
    if (message.value !== "") {
      obj.value = message.value;
    }
    return obj;
  },

  create(base?: DeepPartial<QueryRequest_LabelsEntry>): QueryRequest_LabelsEntry {
    return QueryRequest_LabelsEntry.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<QueryRequest_LabelsEntry>): QueryRequest_LabelsEntry {
    const message = createBaseQueryRequest_LabelsEntry();
    message.key = object.key ?? "";
    message.value = object.value ?? "";
    return message;
  },
};

function createBaseQueryResponse(): QueryResponse {
  return {
    kind: "",
    schema: undefined,
    jobReference: undefined,
    jobCreationReason: undefined,
    queryId: "",
    totalRows: undefined,
    pageToken: "",
    rows: [],
    totalBytesProcessed: undefined,
    jobComplete: undefined,
    errors: [],
    cacheHit: undefined,
    numDmlAffectedRows: undefined,
    sessionInfo: undefined,
    dmlStats: undefined,
  };
}

export const QueryResponse: MessageFns<QueryResponse> = {
  encode(message: QueryResponse, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.kind !== "") {
      writer.uint32(10).string(message.kind);
    }
    if (message.schema !== undefined) {
      TableSchema.encode(message.schema, writer.uint32(18).fork()).join();
    }
    if (message.jobReference !== undefined) {
      JobReference.encode(message.jobReference, writer.uint32(26).fork()).join();
    }
    if (message.jobCreationReason !== undefined) {
      JobCreationReason.encode(message.jobCreationReason, writer.uint32(122).fork()).join();
    }
    if (message.queryId !== "") {
      writer.uint32(114).string(message.queryId);
    }
    if (message.totalRows !== undefined) {
      UInt64Value.encode({ value: message.totalRows! }, writer.uint32(34).fork()).join();
    }
    if (message.pageToken !== "") {
      writer.uint32(42).string(message.pageToken);
    }
    for (const v of message.rows) {
      Struct.encode(Struct.wrap(v!), writer.uint32(50).fork()).join();
    }
    if (message.totalBytesProcessed !== undefined) {
      Int64Value.encode({ value: message.totalBytesProcessed! }, writer.uint32(58).fork()).join();
    }
    if (message.jobComplete !== undefined) {
      BoolValue.encode({ value: message.jobComplete! }, writer.uint32(66).fork()).join();
    }
    for (const v of message.errors) {
      ErrorProto.encode(v!, writer.uint32(74).fork()).join();
    }
    if (message.cacheHit !== undefined) {
      BoolValue.encode({ value: message.cacheHit! }, writer.uint32(82).fork()).join();
    }
    if (message.numDmlAffectedRows !== undefined) {
      Int64Value.encode({ value: message.numDmlAffectedRows! }, writer.uint32(90).fork()).join();
    }
    if (message.sessionInfo !== undefined) {
      SessionInfo.encode(message.sessionInfo, writer.uint32(98).fork()).join();
    }
    if (message.dmlStats !== undefined) {
      DmlStats.encode(message.dmlStats, writer.uint32(106).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): QueryResponse {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseQueryResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.kind = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.schema = TableSchema.decode(reader, reader.uint32());
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.jobReference = JobReference.decode(reader, reader.uint32());
          continue;
        case 15:
          if (tag !== 122) {
            break;
          }

          message.jobCreationReason = JobCreationReason.decode(reader, reader.uint32());
          continue;
        case 14:
          if (tag !== 114) {
            break;
          }

          message.queryId = reader.string();
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.totalRows = UInt64Value.decode(reader, reader.uint32()).value;
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.pageToken = reader.string();
          continue;
        case 6:
          if (tag !== 50) {
            break;
          }

          message.rows.push(Struct.unwrap(Struct.decode(reader, reader.uint32())));
          continue;
        case 7:
          if (tag !== 58) {
            break;
          }

          message.totalBytesProcessed = Int64Value.decode(reader, reader.uint32()).value;
          continue;
        case 8:
          if (tag !== 66) {
            break;
          }

          message.jobComplete = BoolValue.decode(reader, reader.uint32()).value;
          continue;
        case 9:
          if (tag !== 74) {
            break;
          }

          message.errors.push(ErrorProto.decode(reader, reader.uint32()));
          continue;
        case 10:
          if (tag !== 82) {
            break;
          }

          message.cacheHit = BoolValue.decode(reader, reader.uint32()).value;
          continue;
        case 11:
          if (tag !== 90) {
            break;
          }

          message.numDmlAffectedRows = Int64Value.decode(reader, reader.uint32()).value;
          continue;
        case 12:
          if (tag !== 98) {
            break;
          }

          message.sessionInfo = SessionInfo.decode(reader, reader.uint32());
          continue;
        case 13:
          if (tag !== 106) {
            break;
          }

          message.dmlStats = DmlStats.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): QueryResponse {
    return {
      kind: isSet(object.kind) ? globalThis.String(object.kind) : "",
      schema: isSet(object.schema) ? TableSchema.fromJSON(object.schema) : undefined,
      jobReference: isSet(object.jobReference) ? JobReference.fromJSON(object.jobReference) : undefined,
      jobCreationReason: isSet(object.jobCreationReason)
        ? JobCreationReason.fromJSON(object.jobCreationReason)
        : undefined,
      queryId: isSet(object.queryId) ? globalThis.String(object.queryId) : "",
      totalRows: isSet(object.totalRows) ? Long.fromValue(object.totalRows) : undefined,
      pageToken: isSet(object.pageToken) ? globalThis.String(object.pageToken) : "",
      rows: globalThis.Array.isArray(object?.rows) ? [...object.rows] : [],
      totalBytesProcessed: isSet(object.totalBytesProcessed) ? Long.fromValue(object.totalBytesProcessed) : undefined,
      jobComplete: isSet(object.jobComplete) ? Boolean(object.jobComplete) : undefined,
      errors: globalThis.Array.isArray(object?.errors) ? object.errors.map((e: any) => ErrorProto.fromJSON(e)) : [],
      cacheHit: isSet(object.cacheHit) ? Boolean(object.cacheHit) : undefined,
      numDmlAffectedRows: isSet(object.numDmlAffectedRows) ? Long.fromValue(object.numDmlAffectedRows) : undefined,
      sessionInfo: isSet(object.sessionInfo) ? SessionInfo.fromJSON(object.sessionInfo) : undefined,
      dmlStats: isSet(object.dmlStats) ? DmlStats.fromJSON(object.dmlStats) : undefined,
    };
  },

  toJSON(message: QueryResponse): unknown {
    const obj: any = {};
    if (message.kind !== "") {
      obj.kind = message.kind;
    }
    if (message.schema !== undefined) {
      obj.schema = TableSchema.toJSON(message.schema);
    }
    if (message.jobReference !== undefined) {
      obj.jobReference = JobReference.toJSON(message.jobReference);
    }
    if (message.jobCreationReason !== undefined) {
      obj.jobCreationReason = JobCreationReason.toJSON(message.jobCreationReason);
    }
    if (message.queryId !== "") {
      obj.queryId = message.queryId;
    }
    if (message.totalRows !== undefined) {
      obj.totalRows = message.totalRows;
    }
    if (message.pageToken !== "") {
      obj.pageToken = message.pageToken;
    }
    if (message.rows?.length) {
      obj.rows = message.rows;
    }
    if (message.totalBytesProcessed !== undefined) {
      obj.totalBytesProcessed = message.totalBytesProcessed;
    }
    if (message.jobComplete !== undefined) {
      obj.jobComplete = message.jobComplete;
    }
    if (message.errors?.length) {
      obj.errors = message.errors.map((e) => ErrorProto.toJSON(e));
    }
    if (message.cacheHit !== undefined) {
      obj.cacheHit = message.cacheHit;
    }
    if (message.numDmlAffectedRows !== undefined) {
      obj.numDmlAffectedRows = message.numDmlAffectedRows;
    }
    if (message.sessionInfo !== undefined) {
      obj.sessionInfo = SessionInfo.toJSON(message.sessionInfo);
    }
    if (message.dmlStats !== undefined) {
      obj.dmlStats = DmlStats.toJSON(message.dmlStats);
    }
    return obj;
  },

  create(base?: DeepPartial<QueryResponse>): QueryResponse {
    return QueryResponse.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<QueryResponse>): QueryResponse {
    const message = createBaseQueryResponse();
    message.kind = object.kind ?? "";
    message.schema = (object.schema !== undefined && object.schema !== null)
      ? TableSchema.fromPartial(object.schema)
      : undefined;
    message.jobReference = (object.jobReference !== undefined && object.jobReference !== null)
      ? JobReference.fromPartial(object.jobReference)
      : undefined;
    message.jobCreationReason = (object.jobCreationReason !== undefined && object.jobCreationReason !== null)
      ? JobCreationReason.fromPartial(object.jobCreationReason)
      : undefined;
    message.queryId = object.queryId ?? "";
    message.totalRows = (object.totalRows !== undefined && object.totalRows !== null)
      ? Long.fromValue(object.totalRows)
      : undefined;
    message.pageToken = object.pageToken ?? "";
    message.rows = object.rows?.map((e) => e) || [];
    message.totalBytesProcessed = (object.totalBytesProcessed !== undefined && object.totalBytesProcessed !== null)
      ? Long.fromValue(object.totalBytesProcessed)
      : undefined;
    message.jobComplete = object.jobComplete ?? undefined;
    message.errors = object.errors?.map((e) => ErrorProto.fromPartial(e)) || [];
    message.cacheHit = object.cacheHit ?? undefined;
    message.numDmlAffectedRows = (object.numDmlAffectedRows !== undefined && object.numDmlAffectedRows !== null)
      ? Long.fromValue(object.numDmlAffectedRows)
      : undefined;
    message.sessionInfo = (object.sessionInfo !== undefined && object.sessionInfo !== null)
      ? SessionInfo.fromPartial(object.sessionInfo)
      : undefined;
    message.dmlStats = (object.dmlStats !== undefined && object.dmlStats !== null)
      ? DmlStats.fromPartial(object.dmlStats)
      : undefined;
    return message;
  },
};

/**
 * This is an experimental RPC service definition for the BigQuery
 * Job Service.
 *
 * It should not be relied on for production use cases at this time.
 */
export type JobServiceDefinition = typeof JobServiceDefinition;
export const JobServiceDefinition = {
  name: "JobService",
  fullName: "google.cloud.bigquery.v2.JobService",
  methods: {
    /**
     * Requests that a job be cancelled. This call will return immediately, and
     * the client will need to poll for the job status to see if the cancel
     * completed successfully. Cancelled jobs may still incur costs.
     */
    cancelJob: {
      name: "CancelJob",
      requestType: CancelJobRequest,
      requestStream: false,
      responseType: JobCancelResponse,
      responseStream: false,
      options: {
        _unknownFields: {
          578365826: [
            Buffer.from([
              61,
              34,
              59,
              47,
              98,
              105,
              103,
              113,
              117,
              101,
              114,
              121,
              47,
              118,
              50,
              47,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              123,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              95,
              105,
              100,
              61,
              42,
              125,
              47,
              106,
              111,
              98,
              115,
              47,
              123,
              106,
              111,
              98,
              95,
              105,
              100,
              61,
              42,
              125,
              47,
              99,
              97,
              110,
              99,
              101,
              108,
            ]),
          ],
        },
      },
    },
    /**
     * Returns information about a specific job. Job information is available for
     * a six month period after creation. Requires that you're the person who ran
     * the job, or have the Is Owner project role.
     */
    getJob: {
      name: "GetJob",
      requestType: GetJobRequest,
      requestStream: false,
      responseType: Job,
      responseStream: false,
      options: {
        _unknownFields: {
          578365826: [
            Buffer.from([
              54,
              18,
              52,
              47,
              98,
              105,
              103,
              113,
              117,
              101,
              114,
              121,
              47,
              118,
              50,
              47,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              123,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              95,
              105,
              100,
              61,
              42,
              125,
              47,
              106,
              111,
              98,
              115,
              47,
              123,
              106,
              111,
              98,
              95,
              105,
              100,
              61,
              42,
              125,
            ]),
          ],
        },
      },
    },
    /**
     * Starts a new asynchronous job.
     *
     * This API has two different kinds of endpoint URIs, as this method supports
     * a variety of use cases.
     *
     * * The *Metadata* URI is used for most interactions, as it accepts the job
     *   configuration directly.
     * * The *Upload* URI is ONLY for the case when you're sending both a load job
     *   configuration and a data stream together.  In this case, the Upload URI
     *   accepts the job configuration and the data as two distinct multipart MIME
     *   parts.
     */
    insertJob: {
      name: "InsertJob",
      requestType: InsertJobRequest,
      requestStream: false,
      responseType: Job,
      responseStream: false,
      options: {
        _unknownFields: {
          578365826: [
            Buffer.from([
              48,
              58,
              3,
              106,
              111,
              98,
              34,
              41,
              47,
              98,
              105,
              103,
              113,
              117,
              101,
              114,
              121,
              47,
              118,
              50,
              47,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              123,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              95,
              105,
              100,
              61,
              42,
              125,
              47,
              106,
              111,
              98,
              115,
            ]),
          ],
        },
      },
    },
    /**
     * Requests the deletion of the metadata of a job. This call returns when the
     * job's metadata is deleted.
     */
    deleteJob: {
      name: "DeleteJob",
      requestType: DeleteJobRequest,
      requestStream: false,
      responseType: Empty,
      responseStream: false,
      options: {
        _unknownFields: {
          578365826: [
            Buffer.from([
              61,
              42,
              59,
              47,
              98,
              105,
              103,
              113,
              117,
              101,
              114,
              121,
              47,
              118,
              50,
              47,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              123,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              95,
              105,
              100,
              61,
              42,
              125,
              47,
              106,
              111,
              98,
              115,
              47,
              123,
              106,
              111,
              98,
              95,
              105,
              100,
              61,
              42,
              125,
              47,
              100,
              101,
              108,
              101,
              116,
              101,
            ]),
          ],
        },
      },
    },
    /**
     * Lists all jobs that you started in the specified project. Job information
     * is available for a six month period after creation. The job list is sorted
     * in reverse chronological order, by job creation time. Requires the Can View
     * project role, or the Is Owner project role if you set the allUsers
     * property.
     */
    listJobs: {
      name: "ListJobs",
      requestType: ListJobsRequest,
      requestStream: false,
      responseType: JobList,
      responseStream: false,
      options: {
        _unknownFields: {
          578365826: [
            Buffer.from([
              43,
              18,
              41,
              47,
              98,
              105,
              103,
              113,
              117,
              101,
              114,
              121,
              47,
              118,
              50,
              47,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              123,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              95,
              105,
              100,
              61,
              42,
              125,
              47,
              106,
              111,
              98,
              115,
            ]),
          ],
        },
      },
    },
    /** RPC to get the results of a query job. */
    getQueryResults: {
      name: "GetQueryResults",
      requestType: GetQueryResultsRequest,
      requestStream: false,
      responseType: GetQueryResultsResponse,
      responseStream: false,
      options: {
        _unknownFields: {
          578365826: [
            Buffer.from([
              57,
              18,
              55,
              47,
              98,
              105,
              103,
              113,
              117,
              101,
              114,
              121,
              47,
              118,
              50,
              47,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              123,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              95,
              105,
              100,
              61,
              42,
              125,
              47,
              113,
              117,
              101,
              114,
              105,
              101,
              115,
              47,
              123,
              106,
              111,
              98,
              95,
              105,
              100,
              61,
              42,
              125,
            ]),
          ],
        },
      },
    },
    /**
     * Runs a BigQuery SQL query synchronously and returns query results if the
     * query completes within a specified timeout.
     */
    query: {
      name: "Query",
      requestType: PostQueryRequest,
      requestStream: false,
      responseType: QueryResponse,
      responseStream: false,
      options: {
        _unknownFields: {
          578365826: [
            Buffer.from([
              61,
              58,
              13,
              113,
              117,
              101,
              114,
              121,
              95,
              114,
              101,
              113,
              117,
              101,
              115,
              116,
              34,
              44,
              47,
              98,
              105,
              103,
              113,
              117,
              101,
              114,
              121,
              47,
              118,
              50,
              47,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              123,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              95,
              105,
              100,
              61,
              42,
              125,
              47,
              113,
              117,
              101,
              114,
              105,
              101,
              115,
            ]),
          ],
        },
      },
    },
  },
} as const;

export interface JobServiceImplementation<CallContextExt = {}> {
  /**
   * Requests that a job be cancelled. This call will return immediately, and
   * the client will need to poll for the job status to see if the cancel
   * completed successfully. Cancelled jobs may still incur costs.
   */
  cancelJob(request: CancelJobRequest, context: CallContext & CallContextExt): Promise<DeepPartial<JobCancelResponse>>;
  /**
   * Returns information about a specific job. Job information is available for
   * a six month period after creation. Requires that you're the person who ran
   * the job, or have the Is Owner project role.
   */
  getJob(request: GetJobRequest, context: CallContext & CallContextExt): Promise<DeepPartial<Job>>;
  /**
   * Starts a new asynchronous job.
   *
   * This API has two different kinds of endpoint URIs, as this method supports
   * a variety of use cases.
   *
   * * The *Metadata* URI is used for most interactions, as it accepts the job
   *   configuration directly.
   * * The *Upload* URI is ONLY for the case when you're sending both a load job
   *   configuration and a data stream together.  In this case, the Upload URI
   *   accepts the job configuration and the data as two distinct multipart MIME
   *   parts.
   */
  insertJob(request: InsertJobRequest, context: CallContext & CallContextExt): Promise<DeepPartial<Job>>;
  /**
   * Requests the deletion of the metadata of a job. This call returns when the
   * job's metadata is deleted.
   */
  deleteJob(request: DeleteJobRequest, context: CallContext & CallContextExt): Promise<DeepPartial<Empty>>;
  /**
   * Lists all jobs that you started in the specified project. Job information
   * is available for a six month period after creation. The job list is sorted
   * in reverse chronological order, by job creation time. Requires the Can View
   * project role, or the Is Owner project role if you set the allUsers
   * property.
   */
  listJobs(request: ListJobsRequest, context: CallContext & CallContextExt): Promise<DeepPartial<JobList>>;
  /** RPC to get the results of a query job. */
  getQueryResults(
    request: GetQueryResultsRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<GetQueryResultsResponse>>;
  /**
   * Runs a BigQuery SQL query synchronously and returns query results if the
   * query completes within a specified timeout.
   */
  query(request: PostQueryRequest, context: CallContext & CallContextExt): Promise<DeepPartial<QueryResponse>>;
}

export interface JobServiceClient<CallOptionsExt = {}> {
  /**
   * Requests that a job be cancelled. This call will return immediately, and
   * the client will need to poll for the job status to see if the cancel
   * completed successfully. Cancelled jobs may still incur costs.
   */
  cancelJob(request: DeepPartial<CancelJobRequest>, options?: CallOptions & CallOptionsExt): Promise<JobCancelResponse>;
  /**
   * Returns information about a specific job. Job information is available for
   * a six month period after creation. Requires that you're the person who ran
   * the job, or have the Is Owner project role.
   */
  getJob(request: DeepPartial<GetJobRequest>, options?: CallOptions & CallOptionsExt): Promise<Job>;
  /**
   * Starts a new asynchronous job.
   *
   * This API has two different kinds of endpoint URIs, as this method supports
   * a variety of use cases.
   *
   * * The *Metadata* URI is used for most interactions, as it accepts the job
   *   configuration directly.
   * * The *Upload* URI is ONLY for the case when you're sending both a load job
   *   configuration and a data stream together.  In this case, the Upload URI
   *   accepts the job configuration and the data as two distinct multipart MIME
   *   parts.
   */
  insertJob(request: DeepPartial<InsertJobRequest>, options?: CallOptions & CallOptionsExt): Promise<Job>;
  /**
   * Requests the deletion of the metadata of a job. This call returns when the
   * job's metadata is deleted.
   */
  deleteJob(request: DeepPartial<DeleteJobRequest>, options?: CallOptions & CallOptionsExt): Promise<Empty>;
  /**
   * Lists all jobs that you started in the specified project. Job information
   * is available for a six month period after creation. The job list is sorted
   * in reverse chronological order, by job creation time. Requires the Can View
   * project role, or the Is Owner project role if you set the allUsers
   * property.
   */
  listJobs(request: DeepPartial<ListJobsRequest>, options?: CallOptions & CallOptionsExt): Promise<JobList>;
  /** RPC to get the results of a query job. */
  getQueryResults(
    request: DeepPartial<GetQueryResultsRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<GetQueryResultsResponse>;
  /**
   * Runs a BigQuery SQL query synchronously and returns query results if the
   * query completes within a specified timeout.
   */
  query(request: DeepPartial<PostQueryRequest>, options?: CallOptions & CallOptionsExt): Promise<QueryResponse>;
}

type Builtin = Date | Function | Uint8Array | string | number | boolean | undefined;

export type DeepPartial<T> = T extends Builtin ? T
  : T extends Long ? string | number | Long : T extends globalThis.Array<infer U> ? globalThis.Array<DeepPartial<U>>
  : T extends ReadonlyArray<infer U> ? ReadonlyArray<DeepPartial<U>>
  : T extends {} ? { [K in keyof T]?: DeepPartial<T[K]> }
  : Partial<T>;

function isObject(value: any): boolean {
  return typeof value === "object" && value !== null;
}

function isSet(value: any): boolean {
  return value !== null && value !== undefined;
}

export interface MessageFns<T> {
  encode(message: T, writer?: BinaryWriter): BinaryWriter;
  decode(input: BinaryReader | Uint8Array, length?: number): T;
  fromJSON(object: any): T;
  toJSON(message: T): unknown;
  create(base?: DeepPartial<T>): T;
  fromPartial(object: DeepPartial<T>): T;
}
