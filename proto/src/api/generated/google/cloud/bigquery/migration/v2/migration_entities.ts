// Code generated by protoc-gen-ts_proto. DO NOT EDIT.
// versions:
//   protoc-gen-ts_proto  v2.2.0
//   protoc               unknown
// source: google/cloud/bigquery/migration/v2/migration_entities.proto

/* eslint-disable */
import { BinaryReader, BinaryWriter } from "@bufbuild/protobuf/wire";
import Long from "long";
import { Timestamp } from "../../../../protobuf/timestamp.js";
import { ErrorInfo } from "../../../../rpc/error_details.js";
import { ResourceErrorDetail } from "./migration_error_details.js";
import { TimeSeries } from "./migration_metrics.js";
import { TranslationConfigDetails } from "./translation_config.js";
import { Literal, TranslationDetails } from "./translation_details.js";
import { GcsReportLogMessage } from "./translation_usability.js";

export const protobufPackage = "google.cloud.bigquery.migration.v2";

/**
 * A migration workflow which specifies what needs to be done for an EDW
 * migration.
 */
export interface MigrationWorkflow {
  /**
   * Output only. Immutable. Identifier. The unique identifier for the migration
   * workflow. The ID is server-generated.
   *
   * Example: `projects/123/locations/us/workflows/345`
   */
  name: string;
  /**
   * The display name of the workflow. This can be set to give a workflow
   * a descriptive name. There is no guarantee or enforcement of uniqueness.
   */
  displayName: string;
  /**
   * The tasks in a workflow in a named map. The name (i.e. key) has no
   * meaning and is merely a convenient way to address a specific task
   * in a workflow.
   */
  tasks: { [key: string]: MigrationTask };
  /** Output only. That status of the workflow. */
  state: MigrationWorkflow_State;
  /** Time when the workflow was created. */
  createTime:
    | Date
    | undefined;
  /** Time when the workflow was last updated. */
  lastUpdateTime: Date | undefined;
}

/** Possible migration workflow states. */
export enum MigrationWorkflow_State {
  /** STATE_UNSPECIFIED - Workflow state is unspecified. */
  STATE_UNSPECIFIED = 0,
  /**
   * DRAFT - Workflow is in draft status, i.e. tasks are not yet eligible for
   * execution.
   */
  DRAFT = 1,
  /** RUNNING - Workflow is running (i.e. tasks are eligible for execution). */
  RUNNING = 2,
  /**
   * PAUSED - Workflow is paused. Tasks currently in progress may continue, but no
   * further tasks will be scheduled.
   */
  PAUSED = 3,
  /**
   * COMPLETED - Workflow is complete. There should not be any task in a non-terminal
   * state, but if they are (e.g. forced termination), they will not be
   * scheduled.
   */
  COMPLETED = 4,
  UNRECOGNIZED = -1,
}

export function migrationWorkflow_StateFromJSON(object: any): MigrationWorkflow_State {
  switch (object) {
    case 0:
    case "STATE_UNSPECIFIED":
      return MigrationWorkflow_State.STATE_UNSPECIFIED;
    case 1:
    case "DRAFT":
      return MigrationWorkflow_State.DRAFT;
    case 2:
    case "RUNNING":
      return MigrationWorkflow_State.RUNNING;
    case 3:
    case "PAUSED":
      return MigrationWorkflow_State.PAUSED;
    case 4:
    case "COMPLETED":
      return MigrationWorkflow_State.COMPLETED;
    case -1:
    case "UNRECOGNIZED":
    default:
      return MigrationWorkflow_State.UNRECOGNIZED;
  }
}

export function migrationWorkflow_StateToJSON(object: MigrationWorkflow_State): string {
  switch (object) {
    case MigrationWorkflow_State.STATE_UNSPECIFIED:
      return "STATE_UNSPECIFIED";
    case MigrationWorkflow_State.DRAFT:
      return "DRAFT";
    case MigrationWorkflow_State.RUNNING:
      return "RUNNING";
    case MigrationWorkflow_State.PAUSED:
      return "PAUSED";
    case MigrationWorkflow_State.COMPLETED:
      return "COMPLETED";
    case MigrationWorkflow_State.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

export interface MigrationWorkflow_TasksEntry {
  key: string;
  value: MigrationTask | undefined;
}

/**
 * A single task for a migration which has details about the configuration of
 * the task.
 */
export interface MigrationTask {
  /** Task configuration for CW Batch/Offline SQL Translation. */
  translationConfigDetails?:
    | TranslationConfigDetails
    | undefined;
  /** Task details for unified SQL Translation. */
  translationDetails?:
    | TranslationDetails
    | undefined;
  /**
   * Output only. Immutable. The unique identifier for the migration task. The
   * ID is server-generated.
   */
  id: string;
  /**
   * The type of the task. This must be one of the supported task types:
   * Translation_Teradata2BQ, Translation_Redshift2BQ, Translation_Bteq2BQ,
   * Translation_Oracle2BQ, Translation_HiveQL2BQ, Translation_SparkSQL2BQ,
   * Translation_Snowflake2BQ, Translation_Netezza2BQ,
   * Translation_AzureSynapse2BQ, Translation_Vertica2BQ,
   * Translation_SQLServer2BQ, Translation_Presto2BQ, Translation_MySQL2BQ,
   * Translation_Postgresql2BQ, Translation_SQLite2BQ, Translation_Greenplum2BQ.
   */
  type: string;
  /** Output only. The current state of the task. */
  state: MigrationTask_State;
  /**
   * Output only. An explanation that may be populated when the task is in
   * FAILED state.
   */
  processingError:
    | ErrorInfo
    | undefined;
  /** Time when the task was created. */
  createTime:
    | Date
    | undefined;
  /** Time when the task was last updated. */
  lastUpdateTime:
    | Date
    | undefined;
  /**
   * Output only. Provides details to errors and issues encountered while
   * processing the task. Presence of error details does not mean that the task
   * failed.
   */
  resourceErrorDetails: ResourceErrorDetail[];
  /**
   * The number or resources with errors. Note: This is not the total
   * number of errors as each resource can have more than one error.
   * This is used to indicate truncation by having a `resource_error_count`
   * that is higher than the size of `resource_error_details`.
   */
  resourceErrorCount: number;
  /** The metrics for the task. */
  metrics: TimeSeries[];
  /** Output only. The result of the task. */
  taskResult:
    | MigrationTaskResult
    | undefined;
  /** Count of all the processing errors in this task and its subtasks. */
  totalProcessingErrorCount: number;
  /** Count of all the resource errors in this task and its subtasks. */
  totalResourceErrorCount: number;
}

/** Possible states of a migration task. */
export enum MigrationTask_State {
  /** STATE_UNSPECIFIED - The state is unspecified. */
  STATE_UNSPECIFIED = 0,
  /** PENDING - The task is waiting for orchestration. */
  PENDING = 1,
  /** ORCHESTRATING - The task is assigned to an orchestrator. */
  ORCHESTRATING = 2,
  /** RUNNING - The task is running, i.e. its subtasks are ready for execution. */
  RUNNING = 3,
  /**
   * PAUSED - Tha task is paused. Assigned subtasks can continue, but no new subtasks
   * will be scheduled.
   */
  PAUSED = 4,
  /** SUCCEEDED - The task finished successfully. */
  SUCCEEDED = 5,
  /** FAILED - The task finished unsuccessfully. */
  FAILED = 6,
  UNRECOGNIZED = -1,
}

export function migrationTask_StateFromJSON(object: any): MigrationTask_State {
  switch (object) {
    case 0:
    case "STATE_UNSPECIFIED":
      return MigrationTask_State.STATE_UNSPECIFIED;
    case 1:
    case "PENDING":
      return MigrationTask_State.PENDING;
    case 2:
    case "ORCHESTRATING":
      return MigrationTask_State.ORCHESTRATING;
    case 3:
    case "RUNNING":
      return MigrationTask_State.RUNNING;
    case 4:
    case "PAUSED":
      return MigrationTask_State.PAUSED;
    case 5:
    case "SUCCEEDED":
      return MigrationTask_State.SUCCEEDED;
    case 6:
    case "FAILED":
      return MigrationTask_State.FAILED;
    case -1:
    case "UNRECOGNIZED":
    default:
      return MigrationTask_State.UNRECOGNIZED;
  }
}

export function migrationTask_StateToJSON(object: MigrationTask_State): string {
  switch (object) {
    case MigrationTask_State.STATE_UNSPECIFIED:
      return "STATE_UNSPECIFIED";
    case MigrationTask_State.PENDING:
      return "PENDING";
    case MigrationTask_State.ORCHESTRATING:
      return "ORCHESTRATING";
    case MigrationTask_State.RUNNING:
      return "RUNNING";
    case MigrationTask_State.PAUSED:
      return "PAUSED";
    case MigrationTask_State.SUCCEEDED:
      return "SUCCEEDED";
    case MigrationTask_State.FAILED:
      return "FAILED";
    case MigrationTask_State.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/**
 * A subtask for a migration which carries details about the configuration of
 * the subtask. The content of the details should not matter to the end user,
 * but is a contract between the subtask creator and subtask worker.
 */
export interface MigrationSubtask {
  /**
   * Output only. Immutable. The resource name for the migration subtask. The ID
   * is server-generated.
   *
   * Example: `projects/123/locations/us/workflows/345/subtasks/678`
   */
  name: string;
  /** The unique ID of the task to which this subtask belongs. */
  taskId: string;
  /**
   * The type of the Subtask. The migration service does not check whether this
   * is a known type. It is up to the task creator (i.e. orchestrator or worker)
   * to ensure it only creates subtasks for which there are compatible workers
   * polling for Subtasks.
   */
  type: string;
  /** Output only. The current state of the subtask. */
  state: MigrationSubtask_State;
  /**
   * Output only. An explanation that may be populated when the task is in
   * FAILED state.
   */
  processingError:
    | ErrorInfo
    | undefined;
  /**
   * Output only. Provides details to errors and issues encountered while
   * processing the subtask. Presence of error details does not mean that the
   * subtask failed.
   */
  resourceErrorDetails: ResourceErrorDetail[];
  /**
   * The number or resources with errors. Note: This is not the total
   * number of errors as each resource can have more than one error.
   * This is used to indicate truncation by having a `resource_error_count`
   * that is higher than the size of `resource_error_details`.
   */
  resourceErrorCount: number;
  /** Time when the subtask was created. */
  createTime:
    | Date
    | undefined;
  /** Time when the subtask was last updated. */
  lastUpdateTime:
    | Date
    | undefined;
  /** The metrics for the subtask. */
  metrics: TimeSeries[];
}

/** Possible states of a migration subtask. */
export enum MigrationSubtask_State {
  /** STATE_UNSPECIFIED - The state is unspecified. */
  STATE_UNSPECIFIED = 0,
  /** ACTIVE - The subtask is ready, i.e. it is ready for execution. */
  ACTIVE = 1,
  /** RUNNING - The subtask is running, i.e. it is assigned to a worker for execution. */
  RUNNING = 2,
  /** SUCCEEDED - The subtask finished successfully. */
  SUCCEEDED = 3,
  /** FAILED - The subtask finished unsuccessfully. */
  FAILED = 4,
  /**
   * PAUSED - The subtask is paused, i.e., it will not be scheduled. If it was already
   * assigned,it might still finish but no new lease renewals will be granted.
   */
  PAUSED = 5,
  /**
   * PENDING_DEPENDENCY - The subtask is pending a dependency. It will be scheduled once its
   * dependencies are done.
   */
  PENDING_DEPENDENCY = 6,
  UNRECOGNIZED = -1,
}

export function migrationSubtask_StateFromJSON(object: any): MigrationSubtask_State {
  switch (object) {
    case 0:
    case "STATE_UNSPECIFIED":
      return MigrationSubtask_State.STATE_UNSPECIFIED;
    case 1:
    case "ACTIVE":
      return MigrationSubtask_State.ACTIVE;
    case 2:
    case "RUNNING":
      return MigrationSubtask_State.RUNNING;
    case 3:
    case "SUCCEEDED":
      return MigrationSubtask_State.SUCCEEDED;
    case 4:
    case "FAILED":
      return MigrationSubtask_State.FAILED;
    case 5:
    case "PAUSED":
      return MigrationSubtask_State.PAUSED;
    case 6:
    case "PENDING_DEPENDENCY":
      return MigrationSubtask_State.PENDING_DEPENDENCY;
    case -1:
    case "UNRECOGNIZED":
    default:
      return MigrationSubtask_State.UNRECOGNIZED;
  }
}

export function migrationSubtask_StateToJSON(object: MigrationSubtask_State): string {
  switch (object) {
    case MigrationSubtask_State.STATE_UNSPECIFIED:
      return "STATE_UNSPECIFIED";
    case MigrationSubtask_State.ACTIVE:
      return "ACTIVE";
    case MigrationSubtask_State.RUNNING:
      return "RUNNING";
    case MigrationSubtask_State.SUCCEEDED:
      return "SUCCEEDED";
    case MigrationSubtask_State.FAILED:
      return "FAILED";
    case MigrationSubtask_State.PAUSED:
      return "PAUSED";
    case MigrationSubtask_State.PENDING_DEPENDENCY:
      return "PENDING_DEPENDENCY";
    case MigrationSubtask_State.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/** The migration task result. */
export interface MigrationTaskResult {
  /** Details specific to translation task types. */
  translationTaskResult?: TranslationTaskResult | undefined;
}

/** Translation specific result details from the migration task. */
export interface TranslationTaskResult {
  /** The list of the translated literals. */
  translatedLiterals: Literal[];
  /** The records from the aggregate CSV report for a migration workflow. */
  reportLogMessages: GcsReportLogMessage[];
}

function createBaseMigrationWorkflow(): MigrationWorkflow {
  return { name: "", displayName: "", tasks: {}, state: 0, createTime: undefined, lastUpdateTime: undefined };
}

export const MigrationWorkflow: MessageFns<MigrationWorkflow> = {
  encode(message: MigrationWorkflow, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    if (message.displayName !== "") {
      writer.uint32(50).string(message.displayName);
    }
    Object.entries(message.tasks).forEach(([key, value]) => {
      MigrationWorkflow_TasksEntry.encode({ key: key as any, value }, writer.uint32(18).fork()).join();
    });
    if (message.state !== 0) {
      writer.uint32(24).int32(message.state);
    }
    if (message.createTime !== undefined) {
      Timestamp.encode(toTimestamp(message.createTime), writer.uint32(34).fork()).join();
    }
    if (message.lastUpdateTime !== undefined) {
      Timestamp.encode(toTimestamp(message.lastUpdateTime), writer.uint32(42).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): MigrationWorkflow {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseMigrationWorkflow();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
        case 6:
          if (tag !== 50) {
            break;
          }

          message.displayName = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          const entry2 = MigrationWorkflow_TasksEntry.decode(reader, reader.uint32());
          if (entry2.value !== undefined) {
            message.tasks[entry2.key] = entry2.value;
          }
          continue;
        case 3:
          if (tag !== 24) {
            break;
          }

          message.state = reader.int32() as any;
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.createTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.lastUpdateTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): MigrationWorkflow {
    return {
      name: isSet(object.name) ? globalThis.String(object.name) : "",
      displayName: isSet(object.displayName) ? globalThis.String(object.displayName) : "",
      tasks: isObject(object.tasks)
        ? Object.entries(object.tasks).reduce<{ [key: string]: MigrationTask }>((acc, [key, value]) => {
          acc[key] = MigrationTask.fromJSON(value);
          return acc;
        }, {})
        : {},
      state: isSet(object.state) ? migrationWorkflow_StateFromJSON(object.state) : 0,
      createTime: isSet(object.createTime) ? fromJsonTimestamp(object.createTime) : undefined,
      lastUpdateTime: isSet(object.lastUpdateTime) ? fromJsonTimestamp(object.lastUpdateTime) : undefined,
    };
  },

  toJSON(message: MigrationWorkflow): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    if (message.displayName !== "") {
      obj.displayName = message.displayName;
    }
    if (message.tasks) {
      const entries = Object.entries(message.tasks);
      if (entries.length > 0) {
        obj.tasks = {};
        entries.forEach(([k, v]) => {
          obj.tasks[k] = MigrationTask.toJSON(v);
        });
      }
    }
    if (message.state !== 0) {
      obj.state = migrationWorkflow_StateToJSON(message.state);
    }
    if (message.createTime !== undefined) {
      obj.createTime = message.createTime.toISOString();
    }
    if (message.lastUpdateTime !== undefined) {
      obj.lastUpdateTime = message.lastUpdateTime.toISOString();
    }
    return obj;
  },

  create(base?: DeepPartial<MigrationWorkflow>): MigrationWorkflow {
    return MigrationWorkflow.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<MigrationWorkflow>): MigrationWorkflow {
    const message = createBaseMigrationWorkflow();
    message.name = object.name ?? "";
    message.displayName = object.displayName ?? "";
    message.tasks = Object.entries(object.tasks ?? {}).reduce<{ [key: string]: MigrationTask }>((acc, [key, value]) => {
      if (value !== undefined) {
        acc[key] = MigrationTask.fromPartial(value);
      }
      return acc;
    }, {});
    message.state = object.state ?? 0;
    message.createTime = object.createTime ?? undefined;
    message.lastUpdateTime = object.lastUpdateTime ?? undefined;
    return message;
  },
};

function createBaseMigrationWorkflow_TasksEntry(): MigrationWorkflow_TasksEntry {
  return { key: "", value: undefined };
}

export const MigrationWorkflow_TasksEntry: MessageFns<MigrationWorkflow_TasksEntry> = {
  encode(message: MigrationWorkflow_TasksEntry, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.key !== "") {
      writer.uint32(10).string(message.key);
    }
    if (message.value !== undefined) {
      MigrationTask.encode(message.value, writer.uint32(18).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): MigrationWorkflow_TasksEntry {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseMigrationWorkflow_TasksEntry();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.key = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.value = MigrationTask.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): MigrationWorkflow_TasksEntry {
    return {
      key: isSet(object.key) ? globalThis.String(object.key) : "",
      value: isSet(object.value) ? MigrationTask.fromJSON(object.value) : undefined,
    };
  },

  toJSON(message: MigrationWorkflow_TasksEntry): unknown {
    const obj: any = {};
    if (message.key !== "") {
      obj.key = message.key;
    }
    if (message.value !== undefined) {
      obj.value = MigrationTask.toJSON(message.value);
    }
    return obj;
  },

  create(base?: DeepPartial<MigrationWorkflow_TasksEntry>): MigrationWorkflow_TasksEntry {
    return MigrationWorkflow_TasksEntry.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<MigrationWorkflow_TasksEntry>): MigrationWorkflow_TasksEntry {
    const message = createBaseMigrationWorkflow_TasksEntry();
    message.key = object.key ?? "";
    message.value = (object.value !== undefined && object.value !== null)
      ? MigrationTask.fromPartial(object.value)
      : undefined;
    return message;
  },
};

function createBaseMigrationTask(): MigrationTask {
  return {
    translationConfigDetails: undefined,
    translationDetails: undefined,
    id: "",
    type: "",
    state: 0,
    processingError: undefined,
    createTime: undefined,
    lastUpdateTime: undefined,
    resourceErrorDetails: [],
    resourceErrorCount: 0,
    metrics: [],
    taskResult: undefined,
    totalProcessingErrorCount: 0,
    totalResourceErrorCount: 0,
  };
}

export const MigrationTask: MessageFns<MigrationTask> = {
  encode(message: MigrationTask, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.translationConfigDetails !== undefined) {
      TranslationConfigDetails.encode(message.translationConfigDetails, writer.uint32(114).fork()).join();
    }
    if (message.translationDetails !== undefined) {
      TranslationDetails.encode(message.translationDetails, writer.uint32(130).fork()).join();
    }
    if (message.id !== "") {
      writer.uint32(10).string(message.id);
    }
    if (message.type !== "") {
      writer.uint32(18).string(message.type);
    }
    if (message.state !== 0) {
      writer.uint32(32).int32(message.state);
    }
    if (message.processingError !== undefined) {
      ErrorInfo.encode(message.processingError, writer.uint32(42).fork()).join();
    }
    if (message.createTime !== undefined) {
      Timestamp.encode(toTimestamp(message.createTime), writer.uint32(50).fork()).join();
    }
    if (message.lastUpdateTime !== undefined) {
      Timestamp.encode(toTimestamp(message.lastUpdateTime), writer.uint32(58).fork()).join();
    }
    for (const v of message.resourceErrorDetails) {
      ResourceErrorDetail.encode(v!, writer.uint32(138).fork()).join();
    }
    if (message.resourceErrorCount !== 0) {
      writer.uint32(144).int32(message.resourceErrorCount);
    }
    for (const v of message.metrics) {
      TimeSeries.encode(v!, writer.uint32(154).fork()).join();
    }
    if (message.taskResult !== undefined) {
      MigrationTaskResult.encode(message.taskResult, writer.uint32(162).fork()).join();
    }
    if (message.totalProcessingErrorCount !== 0) {
      writer.uint32(168).int32(message.totalProcessingErrorCount);
    }
    if (message.totalResourceErrorCount !== 0) {
      writer.uint32(176).int32(message.totalResourceErrorCount);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): MigrationTask {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseMigrationTask();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 14:
          if (tag !== 114) {
            break;
          }

          message.translationConfigDetails = TranslationConfigDetails.decode(reader, reader.uint32());
          continue;
        case 16:
          if (tag !== 130) {
            break;
          }

          message.translationDetails = TranslationDetails.decode(reader, reader.uint32());
          continue;
        case 1:
          if (tag !== 10) {
            break;
          }

          message.id = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.type = reader.string();
          continue;
        case 4:
          if (tag !== 32) {
            break;
          }

          message.state = reader.int32() as any;
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.processingError = ErrorInfo.decode(reader, reader.uint32());
          continue;
        case 6:
          if (tag !== 50) {
            break;
          }

          message.createTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        case 7:
          if (tag !== 58) {
            break;
          }

          message.lastUpdateTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        case 17:
          if (tag !== 138) {
            break;
          }

          message.resourceErrorDetails.push(ResourceErrorDetail.decode(reader, reader.uint32()));
          continue;
        case 18:
          if (tag !== 144) {
            break;
          }

          message.resourceErrorCount = reader.int32();
          continue;
        case 19:
          if (tag !== 154) {
            break;
          }

          message.metrics.push(TimeSeries.decode(reader, reader.uint32()));
          continue;
        case 20:
          if (tag !== 162) {
            break;
          }

          message.taskResult = MigrationTaskResult.decode(reader, reader.uint32());
          continue;
        case 21:
          if (tag !== 168) {
            break;
          }

          message.totalProcessingErrorCount = reader.int32();
          continue;
        case 22:
          if (tag !== 176) {
            break;
          }

          message.totalResourceErrorCount = reader.int32();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): MigrationTask {
    return {
      translationConfigDetails: isSet(object.translationConfigDetails)
        ? TranslationConfigDetails.fromJSON(object.translationConfigDetails)
        : undefined,
      translationDetails: isSet(object.translationDetails)
        ? TranslationDetails.fromJSON(object.translationDetails)
        : undefined,
      id: isSet(object.id) ? globalThis.String(object.id) : "",
      type: isSet(object.type) ? globalThis.String(object.type) : "",
      state: isSet(object.state) ? migrationTask_StateFromJSON(object.state) : 0,
      processingError: isSet(object.processingError) ? ErrorInfo.fromJSON(object.processingError) : undefined,
      createTime: isSet(object.createTime) ? fromJsonTimestamp(object.createTime) : undefined,
      lastUpdateTime: isSet(object.lastUpdateTime) ? fromJsonTimestamp(object.lastUpdateTime) : undefined,
      resourceErrorDetails: globalThis.Array.isArray(object?.resourceErrorDetails)
        ? object.resourceErrorDetails.map((e: any) => ResourceErrorDetail.fromJSON(e))
        : [],
      resourceErrorCount: isSet(object.resourceErrorCount) ? globalThis.Number(object.resourceErrorCount) : 0,
      metrics: globalThis.Array.isArray(object?.metrics) ? object.metrics.map((e: any) => TimeSeries.fromJSON(e)) : [],
      taskResult: isSet(object.taskResult) ? MigrationTaskResult.fromJSON(object.taskResult) : undefined,
      totalProcessingErrorCount: isSet(object.totalProcessingErrorCount)
        ? globalThis.Number(object.totalProcessingErrorCount)
        : 0,
      totalResourceErrorCount: isSet(object.totalResourceErrorCount)
        ? globalThis.Number(object.totalResourceErrorCount)
        : 0,
    };
  },

  toJSON(message: MigrationTask): unknown {
    const obj: any = {};
    if (message.translationConfigDetails !== undefined) {
      obj.translationConfigDetails = TranslationConfigDetails.toJSON(message.translationConfigDetails);
    }
    if (message.translationDetails !== undefined) {
      obj.translationDetails = TranslationDetails.toJSON(message.translationDetails);
    }
    if (message.id !== "") {
      obj.id = message.id;
    }
    if (message.type !== "") {
      obj.type = message.type;
    }
    if (message.state !== 0) {
      obj.state = migrationTask_StateToJSON(message.state);
    }
    if (message.processingError !== undefined) {
      obj.processingError = ErrorInfo.toJSON(message.processingError);
    }
    if (message.createTime !== undefined) {
      obj.createTime = message.createTime.toISOString();
    }
    if (message.lastUpdateTime !== undefined) {
      obj.lastUpdateTime = message.lastUpdateTime.toISOString();
    }
    if (message.resourceErrorDetails?.length) {
      obj.resourceErrorDetails = message.resourceErrorDetails.map((e) => ResourceErrorDetail.toJSON(e));
    }
    if (message.resourceErrorCount !== 0) {
      obj.resourceErrorCount = Math.round(message.resourceErrorCount);
    }
    if (message.metrics?.length) {
      obj.metrics = message.metrics.map((e) => TimeSeries.toJSON(e));
    }
    if (message.taskResult !== undefined) {
      obj.taskResult = MigrationTaskResult.toJSON(message.taskResult);
    }
    if (message.totalProcessingErrorCount !== 0) {
      obj.totalProcessingErrorCount = Math.round(message.totalProcessingErrorCount);
    }
    if (message.totalResourceErrorCount !== 0) {
      obj.totalResourceErrorCount = Math.round(message.totalResourceErrorCount);
    }
    return obj;
  },

  create(base?: DeepPartial<MigrationTask>): MigrationTask {
    return MigrationTask.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<MigrationTask>): MigrationTask {
    const message = createBaseMigrationTask();
    message.translationConfigDetails =
      (object.translationConfigDetails !== undefined && object.translationConfigDetails !== null)
        ? TranslationConfigDetails.fromPartial(object.translationConfigDetails)
        : undefined;
    message.translationDetails = (object.translationDetails !== undefined && object.translationDetails !== null)
      ? TranslationDetails.fromPartial(object.translationDetails)
      : undefined;
    message.id = object.id ?? "";
    message.type = object.type ?? "";
    message.state = object.state ?? 0;
    message.processingError = (object.processingError !== undefined && object.processingError !== null)
      ? ErrorInfo.fromPartial(object.processingError)
      : undefined;
    message.createTime = object.createTime ?? undefined;
    message.lastUpdateTime = object.lastUpdateTime ?? undefined;
    message.resourceErrorDetails = object.resourceErrorDetails?.map((e) => ResourceErrorDetail.fromPartial(e)) || [];
    message.resourceErrorCount = object.resourceErrorCount ?? 0;
    message.metrics = object.metrics?.map((e) => TimeSeries.fromPartial(e)) || [];
    message.taskResult = (object.taskResult !== undefined && object.taskResult !== null)
      ? MigrationTaskResult.fromPartial(object.taskResult)
      : undefined;
    message.totalProcessingErrorCount = object.totalProcessingErrorCount ?? 0;
    message.totalResourceErrorCount = object.totalResourceErrorCount ?? 0;
    return message;
  },
};

function createBaseMigrationSubtask(): MigrationSubtask {
  return {
    name: "",
    taskId: "",
    type: "",
    state: 0,
    processingError: undefined,
    resourceErrorDetails: [],
    resourceErrorCount: 0,
    createTime: undefined,
    lastUpdateTime: undefined,
    metrics: [],
  };
}

export const MigrationSubtask: MessageFns<MigrationSubtask> = {
  encode(message: MigrationSubtask, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    if (message.taskId !== "") {
      writer.uint32(18).string(message.taskId);
    }
    if (message.type !== "") {
      writer.uint32(26).string(message.type);
    }
    if (message.state !== 0) {
      writer.uint32(40).int32(message.state);
    }
    if (message.processingError !== undefined) {
      ErrorInfo.encode(message.processingError, writer.uint32(50).fork()).join();
    }
    for (const v of message.resourceErrorDetails) {
      ResourceErrorDetail.encode(v!, writer.uint32(98).fork()).join();
    }
    if (message.resourceErrorCount !== 0) {
      writer.uint32(104).int32(message.resourceErrorCount);
    }
    if (message.createTime !== undefined) {
      Timestamp.encode(toTimestamp(message.createTime), writer.uint32(58).fork()).join();
    }
    if (message.lastUpdateTime !== undefined) {
      Timestamp.encode(toTimestamp(message.lastUpdateTime), writer.uint32(66).fork()).join();
    }
    for (const v of message.metrics) {
      TimeSeries.encode(v!, writer.uint32(90).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): MigrationSubtask {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseMigrationSubtask();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.taskId = reader.string();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.type = reader.string();
          continue;
        case 5:
          if (tag !== 40) {
            break;
          }

          message.state = reader.int32() as any;
          continue;
        case 6:
          if (tag !== 50) {
            break;
          }

          message.processingError = ErrorInfo.decode(reader, reader.uint32());
          continue;
        case 12:
          if (tag !== 98) {
            break;
          }

          message.resourceErrorDetails.push(ResourceErrorDetail.decode(reader, reader.uint32()));
          continue;
        case 13:
          if (tag !== 104) {
            break;
          }

          message.resourceErrorCount = reader.int32();
          continue;
        case 7:
          if (tag !== 58) {
            break;
          }

          message.createTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        case 8:
          if (tag !== 66) {
            break;
          }

          message.lastUpdateTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        case 11:
          if (tag !== 90) {
            break;
          }

          message.metrics.push(TimeSeries.decode(reader, reader.uint32()));
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): MigrationSubtask {
    return {
      name: isSet(object.name) ? globalThis.String(object.name) : "",
      taskId: isSet(object.taskId) ? globalThis.String(object.taskId) : "",
      type: isSet(object.type) ? globalThis.String(object.type) : "",
      state: isSet(object.state) ? migrationSubtask_StateFromJSON(object.state) : 0,
      processingError: isSet(object.processingError) ? ErrorInfo.fromJSON(object.processingError) : undefined,
      resourceErrorDetails: globalThis.Array.isArray(object?.resourceErrorDetails)
        ? object.resourceErrorDetails.map((e: any) => ResourceErrorDetail.fromJSON(e))
        : [],
      resourceErrorCount: isSet(object.resourceErrorCount) ? globalThis.Number(object.resourceErrorCount) : 0,
      createTime: isSet(object.createTime) ? fromJsonTimestamp(object.createTime) : undefined,
      lastUpdateTime: isSet(object.lastUpdateTime) ? fromJsonTimestamp(object.lastUpdateTime) : undefined,
      metrics: globalThis.Array.isArray(object?.metrics) ? object.metrics.map((e: any) => TimeSeries.fromJSON(e)) : [],
    };
  },

  toJSON(message: MigrationSubtask): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    if (message.taskId !== "") {
      obj.taskId = message.taskId;
    }
    if (message.type !== "") {
      obj.type = message.type;
    }
    if (message.state !== 0) {
      obj.state = migrationSubtask_StateToJSON(message.state);
    }
    if (message.processingError !== undefined) {
      obj.processingError = ErrorInfo.toJSON(message.processingError);
    }
    if (message.resourceErrorDetails?.length) {
      obj.resourceErrorDetails = message.resourceErrorDetails.map((e) => ResourceErrorDetail.toJSON(e));
    }
    if (message.resourceErrorCount !== 0) {
      obj.resourceErrorCount = Math.round(message.resourceErrorCount);
    }
    if (message.createTime !== undefined) {
      obj.createTime = message.createTime.toISOString();
    }
    if (message.lastUpdateTime !== undefined) {
      obj.lastUpdateTime = message.lastUpdateTime.toISOString();
    }
    if (message.metrics?.length) {
      obj.metrics = message.metrics.map((e) => TimeSeries.toJSON(e));
    }
    return obj;
  },

  create(base?: DeepPartial<MigrationSubtask>): MigrationSubtask {
    return MigrationSubtask.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<MigrationSubtask>): MigrationSubtask {
    const message = createBaseMigrationSubtask();
    message.name = object.name ?? "";
    message.taskId = object.taskId ?? "";
    message.type = object.type ?? "";
    message.state = object.state ?? 0;
    message.processingError = (object.processingError !== undefined && object.processingError !== null)
      ? ErrorInfo.fromPartial(object.processingError)
      : undefined;
    message.resourceErrorDetails = object.resourceErrorDetails?.map((e) => ResourceErrorDetail.fromPartial(e)) || [];
    message.resourceErrorCount = object.resourceErrorCount ?? 0;
    message.createTime = object.createTime ?? undefined;
    message.lastUpdateTime = object.lastUpdateTime ?? undefined;
    message.metrics = object.metrics?.map((e) => TimeSeries.fromPartial(e)) || [];
    return message;
  },
};

function createBaseMigrationTaskResult(): MigrationTaskResult {
  return { translationTaskResult: undefined };
}

export const MigrationTaskResult: MessageFns<MigrationTaskResult> = {
  encode(message: MigrationTaskResult, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.translationTaskResult !== undefined) {
      TranslationTaskResult.encode(message.translationTaskResult, writer.uint32(18).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): MigrationTaskResult {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseMigrationTaskResult();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 2:
          if (tag !== 18) {
            break;
          }

          message.translationTaskResult = TranslationTaskResult.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): MigrationTaskResult {
    return {
      translationTaskResult: isSet(object.translationTaskResult)
        ? TranslationTaskResult.fromJSON(object.translationTaskResult)
        : undefined,
    };
  },

  toJSON(message: MigrationTaskResult): unknown {
    const obj: any = {};
    if (message.translationTaskResult !== undefined) {
      obj.translationTaskResult = TranslationTaskResult.toJSON(message.translationTaskResult);
    }
    return obj;
  },

  create(base?: DeepPartial<MigrationTaskResult>): MigrationTaskResult {
    return MigrationTaskResult.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<MigrationTaskResult>): MigrationTaskResult {
    const message = createBaseMigrationTaskResult();
    message.translationTaskResult =
      (object.translationTaskResult !== undefined && object.translationTaskResult !== null)
        ? TranslationTaskResult.fromPartial(object.translationTaskResult)
        : undefined;
    return message;
  },
};

function createBaseTranslationTaskResult(): TranslationTaskResult {
  return { translatedLiterals: [], reportLogMessages: [] };
}

export const TranslationTaskResult: MessageFns<TranslationTaskResult> = {
  encode(message: TranslationTaskResult, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.translatedLiterals) {
      Literal.encode(v!, writer.uint32(10).fork()).join();
    }
    for (const v of message.reportLogMessages) {
      GcsReportLogMessage.encode(v!, writer.uint32(18).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): TranslationTaskResult {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseTranslationTaskResult();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.translatedLiterals.push(Literal.decode(reader, reader.uint32()));
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.reportLogMessages.push(GcsReportLogMessage.decode(reader, reader.uint32()));
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): TranslationTaskResult {
    return {
      translatedLiterals: globalThis.Array.isArray(object?.translatedLiterals)
        ? object.translatedLiterals.map((e: any) => Literal.fromJSON(e))
        : [],
      reportLogMessages: globalThis.Array.isArray(object?.reportLogMessages)
        ? object.reportLogMessages.map((e: any) => GcsReportLogMessage.fromJSON(e))
        : [],
    };
  },

  toJSON(message: TranslationTaskResult): unknown {
    const obj: any = {};
    if (message.translatedLiterals?.length) {
      obj.translatedLiterals = message.translatedLiterals.map((e) => Literal.toJSON(e));
    }
    if (message.reportLogMessages?.length) {
      obj.reportLogMessages = message.reportLogMessages.map((e) => GcsReportLogMessage.toJSON(e));
    }
    return obj;
  },

  create(base?: DeepPartial<TranslationTaskResult>): TranslationTaskResult {
    return TranslationTaskResult.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<TranslationTaskResult>): TranslationTaskResult {
    const message = createBaseTranslationTaskResult();
    message.translatedLiterals = object.translatedLiterals?.map((e) => Literal.fromPartial(e)) || [];
    message.reportLogMessages = object.reportLogMessages?.map((e) => GcsReportLogMessage.fromPartial(e)) || [];
    return message;
  },
};

type Builtin = Date | Function | Uint8Array | string | number | boolean | undefined;

export type DeepPartial<T> = T extends Builtin ? T
  : T extends Long ? string | number | Long : T extends globalThis.Array<infer U> ? globalThis.Array<DeepPartial<U>>
  : T extends ReadonlyArray<infer U> ? ReadonlyArray<DeepPartial<U>>
  : T extends {} ? { [K in keyof T]?: DeepPartial<T[K]> }
  : Partial<T>;

function toTimestamp(date: Date): Timestamp {
  const seconds = numberToLong(Math.trunc(date.getTime() / 1_000));
  const nanos = (date.getTime() % 1_000) * 1_000_000;
  return { seconds, nanos };
}

function fromTimestamp(t: Timestamp): Date {
  let millis = (t.seconds.toNumber() || 0) * 1_000;
  millis += (t.nanos || 0) / 1_000_000;
  return new globalThis.Date(millis);
}

function fromJsonTimestamp(o: any): Date {
  if (o instanceof globalThis.Date) {
    return o;
  } else if (typeof o === "string") {
    return new globalThis.Date(o);
  } else {
    return fromTimestamp(Timestamp.fromJSON(o));
  }
}

function numberToLong(number: number) {
  return Long.fromNumber(number);
}

function isObject(value: any): boolean {
  return typeof value === "object" && value !== null;
}

function isSet(value: any): boolean {
  return value !== null && value !== undefined;
}

export interface MessageFns<T> {
  encode(message: T, writer?: BinaryWriter): BinaryWriter;
  decode(input: BinaryReader | Uint8Array, length?: number): T;
  fromJSON(object: any): T;
  toJSON(message: T): unknown;
  create(base?: DeepPartial<T>): T;
  fromPartial(object: DeepPartial<T>): T;
}
