// Code generated by protoc-gen-ts_proto. DO NOT EDIT.
// versions:
//   protoc-gen-ts_proto  v2.2.0
//   protoc               unknown
// source: google/cloud/bigquery/storage/v1/protobuf.proto

/* eslint-disable */
import { BinaryReader, BinaryWriter } from "@bufbuild/protobuf/wire";
import Long from "long";
import { DescriptorProto } from "../../../../protobuf/descriptor.js";

export const protobufPackage = "google.cloud.bigquery.storage.v1";

/** ProtoSchema describes the schema of the serialized protocol buffer data rows. */
export interface ProtoSchema {
  /**
   * Descriptor for input message.  The provided descriptor must be self
   * contained, such that data rows sent can be fully decoded using only the
   * single descriptor.  For data rows that are compositions of multiple
   * independent messages, this means the descriptor may need to be transformed
   * to only use nested types:
   * https://developers.google.com/protocol-buffers/docs/proto#nested
   *
   * For additional information for how proto types and values map onto BigQuery
   * see: https://cloud.google.com/bigquery/docs/write-api#data_type_conversions
   */
  protoDescriptor: DescriptorProto | undefined;
}

export interface ProtoRows {
  /**
   * A sequence of rows serialized as a Protocol Buffer.
   *
   * See https://developers.google.com/protocol-buffers/docs/overview for more
   * information on deserializing this field.
   */
  serializedRows: Buffer[];
}

function createBaseProtoSchema(): ProtoSchema {
  return { protoDescriptor: undefined };
}

export const ProtoSchema: MessageFns<ProtoSchema> = {
  encode(message: ProtoSchema, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.protoDescriptor !== undefined) {
      DescriptorProto.encode(message.protoDescriptor, writer.uint32(10).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ProtoSchema {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseProtoSchema();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.protoDescriptor = DescriptorProto.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ProtoSchema {
    return {
      protoDescriptor: isSet(object.protoDescriptor) ? DescriptorProto.fromJSON(object.protoDescriptor) : undefined,
    };
  },

  toJSON(message: ProtoSchema): unknown {
    const obj: any = {};
    if (message.protoDescriptor !== undefined) {
      obj.protoDescriptor = DescriptorProto.toJSON(message.protoDescriptor);
    }
    return obj;
  },

  create(base?: DeepPartial<ProtoSchema>): ProtoSchema {
    return ProtoSchema.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ProtoSchema>): ProtoSchema {
    const message = createBaseProtoSchema();
    message.protoDescriptor = (object.protoDescriptor !== undefined && object.protoDescriptor !== null)
      ? DescriptorProto.fromPartial(object.protoDescriptor)
      : undefined;
    return message;
  },
};

function createBaseProtoRows(): ProtoRows {
  return { serializedRows: [] };
}

export const ProtoRows: MessageFns<ProtoRows> = {
  encode(message: ProtoRows, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.serializedRows) {
      writer.uint32(10).bytes(v!);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ProtoRows {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseProtoRows();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.serializedRows.push(Buffer.from(reader.bytes()));
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ProtoRows {
    return {
      serializedRows: globalThis.Array.isArray(object?.serializedRows)
        ? object.serializedRows.map((e: any) => Buffer.from(bytesFromBase64(e)))
        : [],
    };
  },

  toJSON(message: ProtoRows): unknown {
    const obj: any = {};
    if (message.serializedRows?.length) {
      obj.serializedRows = message.serializedRows.map((e) => base64FromBytes(e));
    }
    return obj;
  },

  create(base?: DeepPartial<ProtoRows>): ProtoRows {
    return ProtoRows.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ProtoRows>): ProtoRows {
    const message = createBaseProtoRows();
    message.serializedRows = object.serializedRows?.map((e) => e) || [];
    return message;
  },
};

function bytesFromBase64(b64: string): Uint8Array {
  return Uint8Array.from(globalThis.Buffer.from(b64, "base64"));
}

function base64FromBytes(arr: Uint8Array): string {
  return globalThis.Buffer.from(arr).toString("base64");
}

type Builtin = Date | Function | Uint8Array | string | number | boolean | undefined;

export type DeepPartial<T> = T extends Builtin ? T
  : T extends Long ? string | number | Long : T extends globalThis.Array<infer U> ? globalThis.Array<DeepPartial<U>>
  : T extends ReadonlyArray<infer U> ? ReadonlyArray<DeepPartial<U>>
  : T extends {} ? { [K in keyof T]?: DeepPartial<T[K]> }
  : Partial<T>;

function isSet(value: any): boolean {
  return value !== null && value !== undefined;
}

export interface MessageFns<T> {
  encode(message: T, writer?: BinaryWriter): BinaryWriter;
  decode(input: BinaryReader | Uint8Array, length?: number): T;
  fromJSON(object: any): T;
  toJSON(message: T): unknown;
  create(base?: DeepPartial<T>): T;
  fromPartial(object: DeepPartial<T>): T;
}
