// Code generated by protoc-gen-ts_proto. DO NOT EDIT.
// versions:
//   protoc-gen-ts_proto  v2.2.0
//   protoc               unknown
// source: google/cloud/bigquery/storage/v1beta2/stream.proto

/* eslint-disable */
import { BinaryReader, BinaryWriter } from "@bufbuild/protobuf/wire";
import Long from "long";
import { Timestamp } from "../../../../protobuf/timestamp.js";
import { ArrowSchema, ArrowSerializationOptions } from "./arrow.js";
import { AvroSchema } from "./avro.js";
import { TableSchema } from "./table.js";

export const protobufPackage = "google.cloud.bigquery.storage.v1beta2";

/** Data format for input or output data. */
export enum DataFormat {
  DATA_FORMAT_UNSPECIFIED = 0,
  /**
   * AVRO - Avro is a standard open source row based file format.
   * See https://avro.apache.org/ for more details.
   */
  AVRO = 1,
  /**
   * ARROW - Arrow is a standard open source column-based message format.
   * See https://arrow.apache.org/ for more details.
   */
  ARROW = 2,
  UNRECOGNIZED = -1,
}

export function dataFormatFromJSON(object: any): DataFormat {
  switch (object) {
    case 0:
    case "DATA_FORMAT_UNSPECIFIED":
      return DataFormat.DATA_FORMAT_UNSPECIFIED;
    case 1:
    case "AVRO":
      return DataFormat.AVRO;
    case 2:
    case "ARROW":
      return DataFormat.ARROW;
    case -1:
    case "UNRECOGNIZED":
    default:
      return DataFormat.UNRECOGNIZED;
  }
}

export function dataFormatToJSON(object: DataFormat): string {
  switch (object) {
    case DataFormat.DATA_FORMAT_UNSPECIFIED:
      return "DATA_FORMAT_UNSPECIFIED";
    case DataFormat.AVRO:
      return "AVRO";
    case DataFormat.ARROW:
      return "ARROW";
    case DataFormat.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/** Information about the ReadSession. */
export interface ReadSession {
  /**
   * Output only. Unique identifier for the session, in the form
   * `projects/{project_id}/locations/{location}/sessions/{session_id}`.
   */
  name: string;
  /**
   * Output only. Time at which the session becomes invalid. After this time, subsequent
   * requests to read this Session will return errors. The expire_time is
   * automatically assigned and currently cannot be specified or updated.
   */
  expireTime:
    | Date
    | undefined;
  /** Immutable. Data format of the output data. */
  dataFormat: DataFormat;
  /** Output only. Avro schema. */
  avroSchema?:
    | AvroSchema
    | undefined;
  /** Output only. Arrow schema. */
  arrowSchema?:
    | ArrowSchema
    | undefined;
  /**
   * Immutable. Table that this ReadSession is reading from, in the form
   * `projects/{project_id}/datasets/{dataset_id}/tables/{table_id}
   */
  table: string;
  /** Optional. Any modifiers which are applied when reading from the specified table. */
  tableModifiers:
    | ReadSession_TableModifiers
    | undefined;
  /** Optional. Read options for this session (e.g. column selection, filters). */
  readOptions:
    | ReadSession_TableReadOptions
    | undefined;
  /**
   * Output only. A list of streams created with the session.
   *
   * At least one stream is created with the session. In the future, larger
   * request_stream_count values *may* result in this list being unpopulated,
   * in that case, the user will need to use a List method to get the streams
   * instead, which is not yet available.
   */
  streams: ReadStream[];
}

/** Additional attributes when reading a table. */
export interface ReadSession_TableModifiers {
  /** The snapshot time of the table. If not set, interpreted as now. */
  snapshotTime: Date | undefined;
}

/** Options dictating how we read a table. */
export interface ReadSession_TableReadOptions {
  /**
   * Names of the fields in the table that should be read. If empty, all
   * fields will be read. If the specified field is a nested field, all
   * the sub-fields in the field will be selected. The output field order is
   * unrelated to the order of fields in selected_fields.
   */
  selectedFields: string[];
  /**
   * SQL text filtering statement, similar to a WHERE clause in a query.
   * Aggregates are not supported.
   *
   * Examples: "int_field > 5"
   *           "date_field = CAST('2014-9-27' as DATE)"
   *           "nullable_field is not NULL"
   *           "st_equals(geo_field, st_geofromtext("POINT(2, 2)"))"
   *           "numeric_field BETWEEN 1.0 AND 5.0"
   *
   * Restricted to a maximum length for 1 MB.
   */
  rowRestriction: string;
  /** Optional. Options specific to the Apache Arrow output format. */
  arrowSerializationOptions: ArrowSerializationOptions | undefined;
}

/**
 * Information about a single stream that gets data out of the storage system.
 * Most of the information about `ReadStream` instances is aggregated, making
 * `ReadStream` lightweight.
 */
export interface ReadStream {
  /**
   * Output only. Name of the stream, in the form
   * `projects/{project_id}/locations/{location}/sessions/{session_id}/streams/{stream_id}`.
   */
  name: string;
}

/** Information about a single stream that gets data inside the storage system. */
export interface WriteStream {
  /**
   * Output only. Name of the stream, in the form
   * `projects/{project}/datasets/{dataset}/tables/{table}/streams/{stream}`.
   */
  name: string;
  /** Immutable. Type of the stream. */
  type: WriteStream_Type;
  /**
   * Output only. Create time of the stream. For the _default stream, this is the
   * creation_time of the table.
   */
  createTime:
    | Date
    | undefined;
  /**
   * Output only. Commit time of the stream.
   * If a stream is of `COMMITTED` type, then it will have a commit_time same as
   * `create_time`. If the stream is of `PENDING` type, commit_time being empty
   * means it is not committed.
   */
  commitTime:
    | Date
    | undefined;
  /**
   * Output only. The schema of the destination table. It is only returned in
   * `CreateWriteStream` response. Caller should generate data that's
   * compatible with this schema to send in initial `AppendRowsRequest`.
   * The table schema could go out of date during the life time of the stream.
   */
  tableSchema: TableSchema | undefined;
}

/** Type enum of the stream. */
export enum WriteStream_Type {
  /** TYPE_UNSPECIFIED - Unknown type. */
  TYPE_UNSPECIFIED = 0,
  /**
   * COMMITTED - Data will commit automatically and appear as soon as the write is
   * acknowledged.
   */
  COMMITTED = 1,
  /** PENDING - Data is invisible until the stream is committed. */
  PENDING = 2,
  /** BUFFERED - Data is only visible up to the offset to which it was flushed. */
  BUFFERED = 3,
  UNRECOGNIZED = -1,
}

export function writeStream_TypeFromJSON(object: any): WriteStream_Type {
  switch (object) {
    case 0:
    case "TYPE_UNSPECIFIED":
      return WriteStream_Type.TYPE_UNSPECIFIED;
    case 1:
    case "COMMITTED":
      return WriteStream_Type.COMMITTED;
    case 2:
    case "PENDING":
      return WriteStream_Type.PENDING;
    case 3:
    case "BUFFERED":
      return WriteStream_Type.BUFFERED;
    case -1:
    case "UNRECOGNIZED":
    default:
      return WriteStream_Type.UNRECOGNIZED;
  }
}

export function writeStream_TypeToJSON(object: WriteStream_Type): string {
  switch (object) {
    case WriteStream_Type.TYPE_UNSPECIFIED:
      return "TYPE_UNSPECIFIED";
    case WriteStream_Type.COMMITTED:
      return "COMMITTED";
    case WriteStream_Type.PENDING:
      return "PENDING";
    case WriteStream_Type.BUFFERED:
      return "BUFFERED";
    case WriteStream_Type.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

function createBaseReadSession(): ReadSession {
  return {
    name: "",
    expireTime: undefined,
    dataFormat: 0,
    avroSchema: undefined,
    arrowSchema: undefined,
    table: "",
    tableModifiers: undefined,
    readOptions: undefined,
    streams: [],
  };
}

export const ReadSession: MessageFns<ReadSession> = {
  encode(message: ReadSession, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    if (message.expireTime !== undefined) {
      Timestamp.encode(toTimestamp(message.expireTime), writer.uint32(18).fork()).join();
    }
    if (message.dataFormat !== 0) {
      writer.uint32(24).int32(message.dataFormat);
    }
    if (message.avroSchema !== undefined) {
      AvroSchema.encode(message.avroSchema, writer.uint32(34).fork()).join();
    }
    if (message.arrowSchema !== undefined) {
      ArrowSchema.encode(message.arrowSchema, writer.uint32(42).fork()).join();
    }
    if (message.table !== "") {
      writer.uint32(50).string(message.table);
    }
    if (message.tableModifiers !== undefined) {
      ReadSession_TableModifiers.encode(message.tableModifiers, writer.uint32(58).fork()).join();
    }
    if (message.readOptions !== undefined) {
      ReadSession_TableReadOptions.encode(message.readOptions, writer.uint32(66).fork()).join();
    }
    for (const v of message.streams) {
      ReadStream.encode(v!, writer.uint32(82).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ReadSession {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseReadSession();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.expireTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        case 3:
          if (tag !== 24) {
            break;
          }

          message.dataFormat = reader.int32() as any;
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.avroSchema = AvroSchema.decode(reader, reader.uint32());
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.arrowSchema = ArrowSchema.decode(reader, reader.uint32());
          continue;
        case 6:
          if (tag !== 50) {
            break;
          }

          message.table = reader.string();
          continue;
        case 7:
          if (tag !== 58) {
            break;
          }

          message.tableModifiers = ReadSession_TableModifiers.decode(reader, reader.uint32());
          continue;
        case 8:
          if (tag !== 66) {
            break;
          }

          message.readOptions = ReadSession_TableReadOptions.decode(reader, reader.uint32());
          continue;
        case 10:
          if (tag !== 82) {
            break;
          }

          message.streams.push(ReadStream.decode(reader, reader.uint32()));
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ReadSession {
    return {
      name: isSet(object.name) ? globalThis.String(object.name) : "",
      expireTime: isSet(object.expireTime) ? fromJsonTimestamp(object.expireTime) : undefined,
      dataFormat: isSet(object.dataFormat) ? dataFormatFromJSON(object.dataFormat) : 0,
      avroSchema: isSet(object.avroSchema) ? AvroSchema.fromJSON(object.avroSchema) : undefined,
      arrowSchema: isSet(object.arrowSchema) ? ArrowSchema.fromJSON(object.arrowSchema) : undefined,
      table: isSet(object.table) ? globalThis.String(object.table) : "",
      tableModifiers: isSet(object.tableModifiers)
        ? ReadSession_TableModifiers.fromJSON(object.tableModifiers)
        : undefined,
      readOptions: isSet(object.readOptions) ? ReadSession_TableReadOptions.fromJSON(object.readOptions) : undefined,
      streams: globalThis.Array.isArray(object?.streams) ? object.streams.map((e: any) => ReadStream.fromJSON(e)) : [],
    };
  },

  toJSON(message: ReadSession): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    if (message.expireTime !== undefined) {
      obj.expireTime = message.expireTime.toISOString();
    }
    if (message.dataFormat !== 0) {
      obj.dataFormat = dataFormatToJSON(message.dataFormat);
    }
    if (message.avroSchema !== undefined) {
      obj.avroSchema = AvroSchema.toJSON(message.avroSchema);
    }
    if (message.arrowSchema !== undefined) {
      obj.arrowSchema = ArrowSchema.toJSON(message.arrowSchema);
    }
    if (message.table !== "") {
      obj.table = message.table;
    }
    if (message.tableModifiers !== undefined) {
      obj.tableModifiers = ReadSession_TableModifiers.toJSON(message.tableModifiers);
    }
    if (message.readOptions !== undefined) {
      obj.readOptions = ReadSession_TableReadOptions.toJSON(message.readOptions);
    }
    if (message.streams?.length) {
      obj.streams = message.streams.map((e) => ReadStream.toJSON(e));
    }
    return obj;
  },

  create(base?: DeepPartial<ReadSession>): ReadSession {
    return ReadSession.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ReadSession>): ReadSession {
    const message = createBaseReadSession();
    message.name = object.name ?? "";
    message.expireTime = object.expireTime ?? undefined;
    message.dataFormat = object.dataFormat ?? 0;
    message.avroSchema = (object.avroSchema !== undefined && object.avroSchema !== null)
      ? AvroSchema.fromPartial(object.avroSchema)
      : undefined;
    message.arrowSchema = (object.arrowSchema !== undefined && object.arrowSchema !== null)
      ? ArrowSchema.fromPartial(object.arrowSchema)
      : undefined;
    message.table = object.table ?? "";
    message.tableModifiers = (object.tableModifiers !== undefined && object.tableModifiers !== null)
      ? ReadSession_TableModifiers.fromPartial(object.tableModifiers)
      : undefined;
    message.readOptions = (object.readOptions !== undefined && object.readOptions !== null)
      ? ReadSession_TableReadOptions.fromPartial(object.readOptions)
      : undefined;
    message.streams = object.streams?.map((e) => ReadStream.fromPartial(e)) || [];
    return message;
  },
};

function createBaseReadSession_TableModifiers(): ReadSession_TableModifiers {
  return { snapshotTime: undefined };
}

export const ReadSession_TableModifiers: MessageFns<ReadSession_TableModifiers> = {
  encode(message: ReadSession_TableModifiers, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.snapshotTime !== undefined) {
      Timestamp.encode(toTimestamp(message.snapshotTime), writer.uint32(10).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ReadSession_TableModifiers {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseReadSession_TableModifiers();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.snapshotTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ReadSession_TableModifiers {
    return { snapshotTime: isSet(object.snapshotTime) ? fromJsonTimestamp(object.snapshotTime) : undefined };
  },

  toJSON(message: ReadSession_TableModifiers): unknown {
    const obj: any = {};
    if (message.snapshotTime !== undefined) {
      obj.snapshotTime = message.snapshotTime.toISOString();
    }
    return obj;
  },

  create(base?: DeepPartial<ReadSession_TableModifiers>): ReadSession_TableModifiers {
    return ReadSession_TableModifiers.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ReadSession_TableModifiers>): ReadSession_TableModifiers {
    const message = createBaseReadSession_TableModifiers();
    message.snapshotTime = object.snapshotTime ?? undefined;
    return message;
  },
};

function createBaseReadSession_TableReadOptions(): ReadSession_TableReadOptions {
  return { selectedFields: [], rowRestriction: "", arrowSerializationOptions: undefined };
}

export const ReadSession_TableReadOptions: MessageFns<ReadSession_TableReadOptions> = {
  encode(message: ReadSession_TableReadOptions, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.selectedFields) {
      writer.uint32(10).string(v!);
    }
    if (message.rowRestriction !== "") {
      writer.uint32(18).string(message.rowRestriction);
    }
    if (message.arrowSerializationOptions !== undefined) {
      ArrowSerializationOptions.encode(message.arrowSerializationOptions, writer.uint32(26).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ReadSession_TableReadOptions {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseReadSession_TableReadOptions();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.selectedFields.push(reader.string());
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.rowRestriction = reader.string();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.arrowSerializationOptions = ArrowSerializationOptions.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ReadSession_TableReadOptions {
    return {
      selectedFields: globalThis.Array.isArray(object?.selectedFields)
        ? object.selectedFields.map((e: any) => globalThis.String(e))
        : [],
      rowRestriction: isSet(object.rowRestriction) ? globalThis.String(object.rowRestriction) : "",
      arrowSerializationOptions: isSet(object.arrowSerializationOptions)
        ? ArrowSerializationOptions.fromJSON(object.arrowSerializationOptions)
        : undefined,
    };
  },

  toJSON(message: ReadSession_TableReadOptions): unknown {
    const obj: any = {};
    if (message.selectedFields?.length) {
      obj.selectedFields = message.selectedFields;
    }
    if (message.rowRestriction !== "") {
      obj.rowRestriction = message.rowRestriction;
    }
    if (message.arrowSerializationOptions !== undefined) {
      obj.arrowSerializationOptions = ArrowSerializationOptions.toJSON(message.arrowSerializationOptions);
    }
    return obj;
  },

  create(base?: DeepPartial<ReadSession_TableReadOptions>): ReadSession_TableReadOptions {
    return ReadSession_TableReadOptions.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ReadSession_TableReadOptions>): ReadSession_TableReadOptions {
    const message = createBaseReadSession_TableReadOptions();
    message.selectedFields = object.selectedFields?.map((e) => e) || [];
    message.rowRestriction = object.rowRestriction ?? "";
    message.arrowSerializationOptions =
      (object.arrowSerializationOptions !== undefined && object.arrowSerializationOptions !== null)
        ? ArrowSerializationOptions.fromPartial(object.arrowSerializationOptions)
        : undefined;
    return message;
  },
};

function createBaseReadStream(): ReadStream {
  return { name: "" };
}

export const ReadStream: MessageFns<ReadStream> = {
  encode(message: ReadStream, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ReadStream {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseReadStream();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ReadStream {
    return { name: isSet(object.name) ? globalThis.String(object.name) : "" };
  },

  toJSON(message: ReadStream): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    return obj;
  },

  create(base?: DeepPartial<ReadStream>): ReadStream {
    return ReadStream.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ReadStream>): ReadStream {
    const message = createBaseReadStream();
    message.name = object.name ?? "";
    return message;
  },
};

function createBaseWriteStream(): WriteStream {
  return { name: "", type: 0, createTime: undefined, commitTime: undefined, tableSchema: undefined };
}

export const WriteStream: MessageFns<WriteStream> = {
  encode(message: WriteStream, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    if (message.type !== 0) {
      writer.uint32(16).int32(message.type);
    }
    if (message.createTime !== undefined) {
      Timestamp.encode(toTimestamp(message.createTime), writer.uint32(26).fork()).join();
    }
    if (message.commitTime !== undefined) {
      Timestamp.encode(toTimestamp(message.commitTime), writer.uint32(34).fork()).join();
    }
    if (message.tableSchema !== undefined) {
      TableSchema.encode(message.tableSchema, writer.uint32(42).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): WriteStream {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseWriteStream();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.type = reader.int32() as any;
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.createTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.commitTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.tableSchema = TableSchema.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): WriteStream {
    return {
      name: isSet(object.name) ? globalThis.String(object.name) : "",
      type: isSet(object.type) ? writeStream_TypeFromJSON(object.type) : 0,
      createTime: isSet(object.createTime) ? fromJsonTimestamp(object.createTime) : undefined,
      commitTime: isSet(object.commitTime) ? fromJsonTimestamp(object.commitTime) : undefined,
      tableSchema: isSet(object.tableSchema) ? TableSchema.fromJSON(object.tableSchema) : undefined,
    };
  },

  toJSON(message: WriteStream): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    if (message.type !== 0) {
      obj.type = writeStream_TypeToJSON(message.type);
    }
    if (message.createTime !== undefined) {
      obj.createTime = message.createTime.toISOString();
    }
    if (message.commitTime !== undefined) {
      obj.commitTime = message.commitTime.toISOString();
    }
    if (message.tableSchema !== undefined) {
      obj.tableSchema = TableSchema.toJSON(message.tableSchema);
    }
    return obj;
  },

  create(base?: DeepPartial<WriteStream>): WriteStream {
    return WriteStream.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<WriteStream>): WriteStream {
    const message = createBaseWriteStream();
    message.name = object.name ?? "";
    message.type = object.type ?? 0;
    message.createTime = object.createTime ?? undefined;
    message.commitTime = object.commitTime ?? undefined;
    message.tableSchema = (object.tableSchema !== undefined && object.tableSchema !== null)
      ? TableSchema.fromPartial(object.tableSchema)
      : undefined;
    return message;
  },
};

type Builtin = Date | Function | Uint8Array | string | number | boolean | undefined;

export type DeepPartial<T> = T extends Builtin ? T
  : T extends Long ? string | number | Long : T extends globalThis.Array<infer U> ? globalThis.Array<DeepPartial<U>>
  : T extends ReadonlyArray<infer U> ? ReadonlyArray<DeepPartial<U>>
  : T extends {} ? { [K in keyof T]?: DeepPartial<T[K]> }
  : Partial<T>;

function toTimestamp(date: Date): Timestamp {
  const seconds = numberToLong(Math.trunc(date.getTime() / 1_000));
  const nanos = (date.getTime() % 1_000) * 1_000_000;
  return { seconds, nanos };
}

function fromTimestamp(t: Timestamp): Date {
  let millis = (t.seconds.toNumber() || 0) * 1_000;
  millis += (t.nanos || 0) / 1_000_000;
  return new globalThis.Date(millis);
}

function fromJsonTimestamp(o: any): Date {
  if (o instanceof globalThis.Date) {
    return o;
  } else if (typeof o === "string") {
    return new globalThis.Date(o);
  } else {
    return fromTimestamp(Timestamp.fromJSON(o));
  }
}

function numberToLong(number: number) {
  return Long.fromNumber(number);
}

function isSet(value: any): boolean {
  return value !== null && value !== undefined;
}

export interface MessageFns<T> {
  encode(message: T, writer?: BinaryWriter): BinaryWriter;
  decode(input: BinaryReader | Uint8Array, length?: number): T;
  fromJSON(object: any): T;
  toJSON(message: T): unknown;
  create(base?: DeepPartial<T>): T;
  fromPartial(object: DeepPartial<T>): T;
}
