// Code generated by protoc-gen-ts_proto. DO NOT EDIT.
// versions:
//   protoc-gen-ts_proto  v2.2.0
//   protoc               unknown
// source: google/cloud/lifesciences/v2beta/workflows.proto

/* eslint-disable */
import { BinaryReader, BinaryWriter } from "@bufbuild/protobuf/wire";
import Long from "long";
import { type CallContext, type CallOptions } from "nice-grpc-common";
import { Operation } from "../../../longrunning/operations.js";
import { Duration } from "../../../protobuf/duration.js";
import { Timestamp } from "../../../protobuf/timestamp.js";
import { Code, codeFromJSON, codeToJSON } from "../../../rpc/code.js";

export const protobufPackage = "google.cloud.lifesciences.v2beta";

/**
 * The arguments to the `RunPipeline` method. The requesting user must have
 * the `iam.serviceAccounts.actAs` permission for the Cloud Life Sciences
 * service account or the request will fail.
 */
export interface RunPipelineRequest {
  /** The project and location that this request should be executed against. */
  parent: string;
  /** Required. The description of the pipeline to run. */
  pipeline:
    | Pipeline
    | undefined;
  /**
   * User-defined labels to associate with the returned operation. These
   * labels are not propagated to any Google Cloud Platform resources used by
   * the operation, and can be modified at any time.
   *
   * To associate labels with resources created while executing the operation,
   * see the appropriate resource message (for example, `VirtualMachine`).
   */
  labels: { [key: string]: string };
  /**
   * The name of an existing Pub/Sub topic.  The server will publish
   * messages to this topic whenever the status of the operation changes.
   * The Life Sciences Service Agent account must have publisher permissions to
   * the specified topic or notifications will not be sent.
   */
  pubSubTopic: string;
}

export interface RunPipelineRequest_LabelsEntry {
  key: string;
  value: string;
}

/**
 * The response to the RunPipeline method, returned in the operation's result
 * field on success.
 */
export interface RunPipelineResponse {
}

/** Specifies a series of actions to execute, expressed as Docker containers. */
export interface Pipeline {
  /** The list of actions to execute, in the order they are specified. */
  actions: Action[];
  /** The resources required for execution. */
  resources:
    | Resources
    | undefined;
  /**
   * The environment to pass into every action. Each action can also specify
   * additional environment variables but cannot delete an entry from this map
   * (though they can overwrite it with a different value).
   */
  environment: { [key: string]: string };
  /**
   * The encrypted environment to pass into every action. Each action can also
   * specify its own encrypted environment.
   *
   * The secret must decrypt to a JSON-encoded dictionary where key-value pairs
   * serve as environment variable names and their values. The decoded
   * environment variables can overwrite the values specified by the
   * `environment` field.
   */
  encryptedEnvironment:
    | Secret
    | undefined;
  /**
   * The maximum amount of time to give the pipeline to complete.  This includes
   * the time spent waiting for a worker to be allocated.  If the pipeline fails
   * to complete before the timeout, it will be cancelled and the error code
   * will be set to DEADLINE_EXCEEDED.
   *
   * If unspecified, it will default to 7 days.
   */
  timeout: Duration | undefined;
}

export interface Pipeline_EnvironmentEntry {
  key: string;
  value: string;
}

/** Specifies a single action that runs a Docker container. */
export interface Action {
  /**
   * An optional name for the container. The container hostname will be set to
   * this name, making it useful for inter-container communication. The name
   * must contain only upper and lowercase alphanumeric characters and hyphens
   * and cannot start with a hyphen.
   */
  containerName: string;
  /**
   * Required. The URI to pull the container image from. Note that all images
   * referenced by actions in the pipeline are pulled before the first action
   * runs. If multiple actions reference the same image, it is only pulled once,
   * ensuring that the same image is used for all actions in a single pipeline.
   *
   * The image URI can be either a complete host and image specification (e.g.,
   * quay.io/biocontainers/samtools), a library and image name (e.g.,
   * google/cloud-sdk) or a bare image name ('bash') to pull from the default
   * library.  No schema is required in any of these cases.
   *
   * If the specified image is not public, the service account specified for
   * the Virtual Machine must have access to pull the images from GCR, or
   * appropriate credentials must be specified in the
   * [google.cloud.lifesciences.v2beta.Action.credentials][google.cloud.lifesciences.v2beta.Action.credentials]
   * field.
   */
  imageUri: string;
  /**
   * If specified, overrides the `CMD` specified in the container. If the
   * container also has an `ENTRYPOINT` the values are used as entrypoint
   * arguments. Otherwise, they are used as a command and arguments to run
   * inside the container.
   */
  commands: string[];
  /** If specified, overrides the `ENTRYPOINT` specified in the container. */
  entrypoint: string;
  /**
   * The environment to pass into the container. This environment is merged
   * with values specified in the
   * [google.cloud.lifesciences.v2beta.Pipeline][google.cloud.lifesciences.v2beta.Pipeline]
   * message, overwriting any duplicate values.
   *
   * In addition to the values passed here, a few other values are
   * automatically injected into the environment. These cannot be hidden or
   * overwritten.
   *
   * `GOOGLE_PIPELINE_FAILED` will be set to "1" if the pipeline failed
   * because an action has exited with a non-zero status (and did not have the
   * `IGNORE_EXIT_STATUS` flag set). This can be used to determine if additional
   * debug or logging actions should execute.
   *
   * `GOOGLE_LAST_EXIT_STATUS` will be set to the exit status of the last
   * non-background action that executed. This can be used by workflow engine
   * authors to determine whether an individual action has succeeded or failed.
   */
  environment: { [key: string]: string };
  /**
   * The encrypted environment to pass into the container. This environment is
   * merged with values specified in the
   * [google.cloud.lifesciences.v2beta.Pipeline][google.cloud.lifesciences.v2beta.Pipeline]
   * message, overwriting any duplicate values.
   *
   * The secret must decrypt to a JSON-encoded dictionary where key-value pairs
   * serve as environment variable names and their values. The decoded
   * environment variables can overwrite the values specified by the
   * `environment` field.
   */
  encryptedEnvironment:
    | Secret
    | undefined;
  /**
   * An optional identifier for a PID namespace to run the action inside.
   * Multiple actions should use the same string to share a namespace.  If
   * unspecified, a separate isolated namespace is used.
   */
  pidNamespace: string;
  /**
   * A map of containers to host port mappings for this container. If the
   * container already specifies exposed ports, use the
   * `PUBLISH_EXPOSED_PORTS` flag instead.
   *
   * The host port number must be less than 65536. If it is zero, an unused
   * random port is assigned. To determine the resulting port number, consult
   * the `ContainerStartedEvent` in the operation metadata.
   */
  portMappings: { [key: number]: number };
  /**
   * A list of mounts to make available to the action.
   *
   * In addition to the values specified here, every action has a special
   * virtual disk mounted under `/google` that contains log files and other
   * operational components.
   *
   * <ul>
   *   <li><code>/google/logs</code> All logs written during the pipeline
   *   execution.</li>
   *   <li><code>/google/logs/output</code> The combined standard output and
   *   standard error of all actions run as part of the pipeline
   *   execution.</li>
   *   <li><code>/google/logs/action/* /stdout</code> The complete contents of
   *   each individual action's standard output.</li>
   *   <li><code>/google/logs/action/* /stderr</code> The complete contents of
   *   each individual action's standard error output.</li>
   * </ul>
   */
  mounts: Mount[];
  /**
   * Labels to associate with the action. This field is provided to assist
   * workflow engine authors in identifying actions (for example, to indicate
   * what sort of action they perform, such as localization or debugging).
   * They are returned in the operation metadata, but are otherwise ignored.
   */
  labels: { [key: string]: string };
  /**
   * If the specified image is hosted on a private registry other than Google
   * Container Registry, the credentials required to pull the image must be
   * specified here as an encrypted secret.
   *
   * The secret must decrypt to a JSON-encoded dictionary containing both
   * `username` and `password` keys.
   */
  credentials:
    | Secret
    | undefined;
  /**
   * The maximum amount of time to give the action to complete. If the action
   * fails to complete before the timeout, it will be terminated and the exit
   * status will be non-zero. The pipeline will continue or terminate based
   * on the rules defined by the `ALWAYS_RUN` and `IGNORE_EXIT_STATUS` flags.
   */
  timeout:
    | Duration
    | undefined;
  /**
   * Normally, a non-zero exit status causes the pipeline to fail. This flag
   * allows execution of other actions to continue instead.
   */
  ignoreExitStatus: boolean;
  /**
   * This flag allows an action to continue running in the background while
   * executing subsequent actions. This is useful to provide services to
   * other actions (or to provide debugging support tools like SSH servers).
   */
  runInBackground: boolean;
  /**
   * By default, after an action fails, no further actions are run. This flag
   * indicates that this action must be run even if the pipeline has already
   * failed. This is useful for actions that copy output files off of the VM
   * or for debugging. Note that no actions will be run if image prefetching
   * fails.
   */
  alwaysRun: boolean;
  /**
   * Enable access to the FUSE device for this action. Filesystems can then
   * be mounted into disks shared with other actions. The other actions do
   * not need the `enable_fuse` flag to access the mounted filesystem.
   *
   * This has the effect of causing the container to be executed with
   * `CAP_SYS_ADMIN` and exposes `/dev/fuse` to the container, so use it only
   * for containers you trust.
   */
  enableFuse: boolean;
  /**
   * Exposes all ports specified by `EXPOSE` statements in the container. To
   * discover the host side port numbers, consult the `ACTION_STARTED` event
   * in the operation metadata.
   */
  publishExposedPorts: boolean;
  /**
   * All container images are typically downloaded before any actions are
   * executed. This helps prevent typos in URIs or issues like lack of disk
   * space from wasting large amounts of compute resources.
   *
   * If set, this flag prevents the worker from downloading the image until
   * just before the action is executed.
   */
  disableImagePrefetch: boolean;
  /**
   * A small portion of the container's standard error stream is typically
   * captured and returned inside the `ContainerStoppedEvent`. Setting this
   * flag disables this functionality.
   */
  disableStandardErrorCapture: boolean;
  /** Prevents the container from accessing the external network. */
  blockExternalNetwork: boolean;
}

export interface Action_EnvironmentEntry {
  key: string;
  value: string;
}

export interface Action_PortMappingsEntry {
  key: number;
  value: number;
}

export interface Action_LabelsEntry {
  key: string;
  value: string;
}

/**
 * Holds encrypted information that is only decrypted and stored in RAM
 * by the worker VM when running the pipeline.
 */
export interface Secret {
  /**
   * The name of the Cloud KMS key that will be used to decrypt the secret
   * value. The VM service account must have the required permissions and
   * authentication scopes to invoke the `decrypt` method on the specified key.
   */
  keyName: string;
  /**
   * The value of the cipherText response from the `encrypt` method. This field
   * is intentionally unaudited.
   */
  cipherText: string;
}

/** Carries information about a particular disk mount inside a container. */
export interface Mount {
  /** The name of the disk to mount, as specified in the resources section. */
  disk: string;
  /** The path to mount the disk inside the container. */
  path: string;
  /** If true, the disk is mounted read-only inside the container. */
  readOnly: boolean;
}

/**
 * The system resources for the pipeline run.
 *
 * At least one zone or region must be specified or the pipeline run will fail.
 */
export interface Resources {
  /**
   * The list of regions allowed for VM allocation. If set, the `zones` field
   * must not be set.
   */
  regions: string[];
  /**
   * The list of zones allowed for VM allocation. If set, the `regions` field
   * must not be set.
   */
  zones: string[];
  /** The virtual machine specification. */
  virtualMachine: VirtualMachine | undefined;
}

/** Carries information about a Compute Engine VM resource. */
export interface VirtualMachine {
  /**
   * Required. The machine type of the virtual machine to create. Must be the
   * short name of a standard machine type (such as "n1-standard-1") or a custom
   * machine type (such as "custom-1-4096", where "1" indicates the number of
   * vCPUs and "4096" indicates the memory in MB). See [Creating an instance
   * with a custom machine
   * type](https://cloud.google.com/compute/docs/instances/creating-instance-with-custom-machine-type#create)
   * for more specifications on creating a custom machine type.
   */
  machineType: string;
  /** If true, allocate a preemptible VM. */
  preemptible: boolean;
  /**
   * Optional set of labels to apply to the VM and any attached disk resources.
   * These labels must adhere to the [name and value
   * restrictions](https://cloud.google.com/compute/docs/labeling-resources) on
   * VM labels imposed by Compute Engine.
   *
   * Labels keys with the prefix 'google-' are reserved for use by Google.
   *
   * Labels applied at creation time to the VM. Applied on a best-effort basis
   * to attached disk resources shortly after VM creation.
   */
  labels: { [key: string]: string };
  /**
   * The list of disks to create and attach to the VM.
   *
   * Specify either the `volumes[]` field or the `disks[]` field, but not both.
   */
  disks: Disk[];
  /** The VM network configuration. */
  network:
    | Network
    | undefined;
  /** The list of accelerators to attach to the VM. */
  accelerators: Accelerator[];
  /**
   * The service account to install on the VM. This account does not need
   * any permissions other than those required by the pipeline.
   */
  serviceAccount:
    | ServiceAccount
    | undefined;
  /**
   * The size of the boot disk, in GB. The boot disk must be large
   * enough to accommodate all of the Docker images from each action in the
   * pipeline at the same time. If not specified, a small but reasonable
   * default value is used.
   */
  bootDiskSizeGb: number;
  /**
   * The CPU platform to request. An instance based on a newer platform can be
   * allocated, but never one with fewer capabilities. The value of this
   * parameter must be a valid Compute Engine CPU platform name (such as "Intel
   * Skylake"). This parameter is only useful for carefully optimized work
   * loads where the CPU platform has a significant impact.
   *
   * For more information about the effect of this parameter, see
   * https://cloud.google.com/compute/docs/instances/specify-min-cpu-platform.
   */
  cpuPlatform: string;
  /**
   * The host operating system image to use.
   *
   * Currently, only Container-Optimized OS images can be used.
   *
   * The default value is `projects/cos-cloud/global/images/family/cos-stable`,
   * which selects the latest stable release of Container-Optimized OS.
   *
   * This option is provided to allow testing against the beta release of the
   * operating system to ensure that the new version does not interact
   * negatively with production pipelines.
   *
   * To test a pipeline against the beta release of Container-Optimized OS,
   * use the value `projects/cos-cloud/global/images/family/cos-beta`.
   */
  bootImage: string;
  /**
   * The NVIDIA driver version to use when attaching an NVIDIA GPU accelerator.
   * The version specified here must be compatible with the GPU libraries
   * contained in the container being executed, and must be one of the drivers
   * hosted in the `nvidia-drivers-us-public` bucket on Google Cloud Storage.
   *
   * @deprecated
   */
  nvidiaDriverVersion: string;
  /** Whether Stackdriver monitoring should be enabled on the VM. */
  enableStackdriverMonitoring: boolean;
  /**
   * The Compute Engine Disk Images to use as a Docker cache. The disks will be
   * mounted into the Docker folder in a way that the images present in the
   * cache will not need to be pulled. The digests of the cached images must
   * match those of the tags used or the latest version will still be pulled.
   * The root directory of the ext4 image must contain `image` and `overlay2`
   * directories copied from the Docker directory of a VM where the desired
   * Docker images have already been pulled. Any images pulled that are not
   * cached will be stored on the first cache disk instead of the boot disk.
   * Only a single image is supported.
   */
  dockerCacheImages: string[];
  /**
   * The list of disks and other storage to create or attach to the VM.
   *
   * Specify either the `volumes[]` field or the `disks[]` field, but not both.
   */
  volumes: Volume[];
  /**
   * If specified, the VM will only be allocated inside the matching
   * reservation. It will fail if the VM parameters don't match the reservation.
   */
  reservation: string;
}

export interface VirtualMachine_LabelsEntry {
  key: string;
  value: string;
}

/** Carries information about a Google Cloud service account. */
export interface ServiceAccount {
  /**
   * Email address of the service account. If not specified, the default
   * Compute Engine service account for the project will be used.
   */
  email: string;
  /**
   * List of scopes to be enabled for this service account on the VM, in
   * addition to the cloud-platform API scope that will be added by default.
   */
  scopes: string[];
}

/** Carries information about an accelerator that can be attached to a VM. */
export interface Accelerator {
  /**
   * The accelerator type string (for example, "nvidia-tesla-t4").
   *
   * Only NVIDIA GPU accelerators are currently supported. If an NVIDIA GPU is
   * attached, the required runtime libraries will be made available to all
   * containers under `/usr/local/nvidia`. The driver version to install must
   * be specified using the NVIDIA driver version parameter on the virtual
   * machine specification. Note that attaching a GPU increases the worker VM
   * startup time by a few minutes.
   */
  type: string;
  /** How many accelerators of this type to attach. */
  count: Long;
}

/** VM networking options. */
export interface Network {
  /**
   * The network name to attach the VM's network interface to. The value will
   * be prefixed with `global/networks/` unless it contains a `/`, in which
   * case it is assumed to be a fully specified network resource URL.
   *
   * If unspecified, the global default network is used.
   */
  network: string;
  /**
   * If set to true, do not attach a public IP address to the VM. Note that
   * without a public IP address, additional configuration is required to
   * allow the VM to access Google services.
   *
   * See https://cloud.google.com/vpc/docs/configure-private-google-access
   * for more information.
   */
  usePrivateAddress: boolean;
  /**
   * If the specified network is configured for custom subnet creation, the
   * name of the subnetwork to attach the instance to must be specified here.
   *
   * The value is prefixed with `regions/* /subnetworks/` unless it contains a
   * `/`, in which case it is assumed to be a fully specified subnetwork
   * resource URL.
   *
   * If the `*` character appears in the value, it is replaced with the region
   * that the virtual machine has been allocated in.
   */
  subnetwork: string;
}

/**
 * Carries information about a disk that can be attached to a VM.
 *
 * See https://cloud.google.com/compute/docs/disks/performance for more
 * information about disk type, size, and performance considerations.
 *
 * Specify either [`Volume`][google.cloud.lifesciences.v2beta.Volume] or
 * [`Disk`][google.cloud.lifesciences.v2beta.Disk], but not both.
 */
export interface Disk {
  /**
   * A user-supplied name for the disk. Used when mounting the disk into
   * actions. The name must contain only upper and lowercase alphanumeric
   * characters and hyphens and cannot start with a hyphen.
   */
  name: string;
  /**
   * The size, in GB, of the disk to attach. If the size is not
   * specified, a default is chosen to ensure reasonable I/O performance.
   *
   * If the disk type is specified as `local-ssd`, multiple local drives are
   * automatically combined to provide the requested size. Note, however, that
   * each physical SSD is 375GB in size, and no more than 8 drives can be
   * attached to a single instance.
   */
  sizeGb: number;
  /** The Compute Engine disk type. If unspecified, `pd-standard` is used. */
  type: string;
  /** An optional image to put on the disk before attaching it to the VM. */
  sourceImage: string;
}

/**
 * Carries information about storage that can be attached to a VM.
 *
 * Specify either [`Volume`][google.cloud.lifesciences.v2beta.Volume] or
 * [`Disk`][google.cloud.lifesciences.v2beta.Disk], but not both.
 */
export interface Volume {
  /**
   * A user-supplied name for the volume. Used when mounting the volume into
   * [`Actions`][google.cloud.lifesciences.v2beta.Action]. The name must contain
   * only upper and lowercase alphanumeric characters and hyphens and cannot
   * start with a hyphen.
   */
  volume: string;
  /** Configuration for a persistent disk. */
  persistentDisk?:
    | PersistentDisk
    | undefined;
  /** Configuration for a existing disk. */
  existingDisk?:
    | ExistingDisk
    | undefined;
  /** Configuration for an NFS mount. */
  nfsMount?: NFSMount | undefined;
}

/**
 * Configuration for a persistent disk to be attached to the VM.
 *
 * See https://cloud.google.com/compute/docs/disks/performance for more
 * information about disk type, size, and performance considerations.
 */
export interface PersistentDisk {
  /**
   * The size, in GB, of the disk to attach. If the size is not
   * specified, a default is chosen to ensure reasonable I/O performance.
   *
   * If the disk type is specified as `local-ssd`, multiple local drives are
   * automatically combined to provide the requested size. Note, however, that
   * each physical SSD is 375GB in size, and no more than 8 drives can be
   * attached to a single instance.
   */
  sizeGb: number;
  /** The Compute Engine disk type. If unspecified, `pd-standard` is used. */
  type: string;
  /** An image to put on the disk before attaching it to the VM. */
  sourceImage: string;
}

/** Configuration for an existing disk to be attached to the VM. */
export interface ExistingDisk {
  /**
   * If `disk` contains slashes, the Cloud Life Sciences API assumes that it is
   * a complete URL for the disk.  If `disk` does not contain slashes, the Cloud
   * Life Sciences API assumes that the disk is a zonal disk and a URL will be
   * generated of the form `zones/<zone>/disks/<disk>`, where `<zone>` is the
   * zone in which the instance is allocated. The disk must be ext4 formatted.
   *
   * If all `Mount` references to this disk have the `read_only` flag set to
   * true, the disk will be attached in `read-only` mode and can be shared with
   * other instances. Otherwise, the disk will be available for writing but
   * cannot be shared.
   */
  disk: string;
}

/** Configuration for an `NFSMount` to be attached to the VM. */
export interface NFSMount {
  /** A target NFS mount. The target must be specified as `address:/mount". */
  target: string;
}

/**
 * Carries information about the pipeline execution that is returned
 * in the long running operation's metadata field.
 */
export interface Metadata {
  /** The pipeline this operation represents. */
  pipeline:
    | Pipeline
    | undefined;
  /** The user-defined labels associated with this operation. */
  labels: { [key: string]: string };
  /**
   * The list of events that have happened so far during the execution of this
   * operation.
   */
  events: Event[];
  /** The time at which the operation was created by the API. */
  createTime:
    | Date
    | undefined;
  /** The first time at which resources were allocated to execute the pipeline. */
  startTime:
    | Date
    | undefined;
  /** The time at which execution was completed and resources were cleaned up. */
  endTime:
    | Date
    | undefined;
  /**
   * The name of the Cloud Pub/Sub topic where notifications of operation status
   * changes are sent.
   */
  pubSubTopic: string;
}

export interface Metadata_LabelsEntry {
  key: string;
  value: string;
}

/** Carries information about events that occur during pipeline execution. */
export interface Event {
  /** The time at which the event occurred. */
  timestamp:
    | Date
    | undefined;
  /**
   * A human-readable description of the event. Note that these strings can
   * change at any time without notice. Any application logic must use the
   * information in the `details` field.
   */
  description: string;
  /**
   * See
   * [google.cloud.lifesciences.v2beta.DelayedEvent][google.cloud.lifesciences.v2beta.DelayedEvent].
   */
  delayed?:
    | DelayedEvent
    | undefined;
  /**
   * See
   * [google.cloud.lifesciences.v2beta.WorkerAssignedEvent][google.cloud.lifesciences.v2beta.WorkerAssignedEvent].
   */
  workerAssigned?:
    | WorkerAssignedEvent
    | undefined;
  /**
   * See
   * [google.cloud.lifesciences.v2beta.WorkerReleasedEvent][google.cloud.lifesciences.v2beta.WorkerReleasedEvent].
   */
  workerReleased?:
    | WorkerReleasedEvent
    | undefined;
  /**
   * See
   * [google.cloud.lifesciences.v2beta.PullStartedEvent][google.cloud.lifesciences.v2beta.PullStartedEvent].
   */
  pullStarted?:
    | PullStartedEvent
    | undefined;
  /**
   * See
   * [google.cloud.lifesciences.v2beta.PullStoppedEvent][google.cloud.lifesciences.v2beta.PullStoppedEvent].
   */
  pullStopped?:
    | PullStoppedEvent
    | undefined;
  /**
   * See
   * [google.cloud.lifesciences.v2beta.ContainerStartedEvent][google.cloud.lifesciences.v2beta.ContainerStartedEvent].
   */
  containerStarted?:
    | ContainerStartedEvent
    | undefined;
  /**
   * See
   * [google.cloud.lifesciences.v2beta.ContainerStoppedEvent][google.cloud.lifesciences.v2beta.ContainerStoppedEvent].
   */
  containerStopped?:
    | ContainerStoppedEvent
    | undefined;
  /**
   * See
   * [google.cloud.lifesciences.v2beta.ContainerKilledEvent][google.cloud.lifesciences.v2beta.ContainerKilledEvent].
   */
  containerKilled?:
    | ContainerKilledEvent
    | undefined;
  /**
   * See
   * [google.cloud.lifesciences.v2beta.UnexpectedExitStatusEvent][google.cloud.lifesciences.v2beta.UnexpectedExitStatusEvent].
   */
  unexpectedExitStatus?:
    | UnexpectedExitStatusEvent
    | undefined;
  /**
   * See
   * [google.cloud.lifesciences.v2beta.FailedEvent][google.cloud.lifesciences.v2beta.FailedEvent].
   */
  failed?: FailedEvent | undefined;
}

/**
 * An event generated whenever a resource limitation or transient error
 * delays execution of a pipeline that was otherwise ready to run.
 */
export interface DelayedEvent {
  /**
   * A textual description of the cause of the delay. The string can change
   * without notice because it is often generated by another service (such as
   * Compute Engine).
   */
  cause: string;
  /**
   * If the delay was caused by a resource shortage, this field lists the
   * Compute Engine metrics that are preventing this operation from running
   * (for example, `CPUS` or `INSTANCES`). If the particular metric is not
   * known, a single `UNKNOWN` metric will be present.
   */
  metrics: string[];
}

/**
 * An event generated after a worker VM has been assigned to run the
 * pipeline.
 */
export interface WorkerAssignedEvent {
  /** The zone the worker is running in. */
  zone: string;
  /** The worker's instance name. */
  instance: string;
  /** The machine type that was assigned for the worker. */
  machineType: string;
}

/**
 * An event generated when the worker VM that was assigned to the pipeline
 * has been released (deleted).
 */
export interface WorkerReleasedEvent {
  /** The zone the worker was running in. */
  zone: string;
  /** The worker's instance name. */
  instance: string;
}

/** An event generated when the worker starts pulling an image. */
export interface PullStartedEvent {
  /** The URI of the image that was pulled. */
  imageUri: string;
}

/** An event generated when the worker stops pulling an image. */
export interface PullStoppedEvent {
  /** The URI of the image that was pulled. */
  imageUri: string;
}

/** An event generated when a container starts. */
export interface ContainerStartedEvent {
  /** The numeric ID of the action that started this container. */
  actionId: number;
  /**
   * The container-to-host port mappings installed for this container. This
   * set will contain any ports exposed using the `PUBLISH_EXPOSED_PORTS` flag
   * as well as any specified in the `Action` definition.
   */
  portMappings: { [key: number]: number };
  /**
   * The public IP address that can be used to connect to the container. This
   * field is only populated when at least one port mapping is present. If the
   * instance was created with a private address, this field will be empty even
   * if port mappings exist.
   */
  ipAddress: string;
}

export interface ContainerStartedEvent_PortMappingsEntry {
  key: number;
  value: number;
}

/** An event generated when a container exits. */
export interface ContainerStoppedEvent {
  /** The numeric ID of the action that started this container. */
  actionId: number;
  /** The exit status of the container. */
  exitStatus: number;
  /**
   * The tail end of any content written to standard error by the container.
   * If the content emits large amounts of debugging noise or contains
   * sensitive information, you can prevent the content from being printed by
   * setting the `DISABLE_STANDARD_ERROR_CAPTURE` flag.
   *
   * Note that only a small amount of the end of the stream is captured here.
   * The entire stream is stored in the `/google/logs` directory mounted into
   * each action, and can be copied off the machine as described elsewhere.
   */
  stderr: string;
}

/**
 * An event generated when the execution of a container results in a
 * non-zero exit status that was not otherwise ignored. Execution will
 * continue, but only actions that are flagged as `ALWAYS_RUN` will be
 * executed. Other actions will be skipped.
 */
export interface UnexpectedExitStatusEvent {
  /** The numeric ID of the action that started the container. */
  actionId: number;
  /** The exit status of the container. */
  exitStatus: number;
}

/**
 * An event generated when a container is forcibly terminated by the
 * worker. Currently, this only occurs when the container outlives the
 * timeout specified by the user.
 */
export interface ContainerKilledEvent {
  /** The numeric ID of the action that started the container. */
  actionId: number;
}

/**
 * An event generated when the execution of a pipeline has failed. Note
 * that other events can continue to occur after this event.
 */
export interface FailedEvent {
  /** The Google standard error code that best describes this failure. */
  code: Code;
  /** The human-readable description of the cause of the failure. */
  cause: string;
}

function createBaseRunPipelineRequest(): RunPipelineRequest {
  return { parent: "", pipeline: undefined, labels: {}, pubSubTopic: "" };
}

export const RunPipelineRequest: MessageFns<RunPipelineRequest> = {
  encode(message: RunPipelineRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.parent !== "") {
      writer.uint32(34).string(message.parent);
    }
    if (message.pipeline !== undefined) {
      Pipeline.encode(message.pipeline, writer.uint32(10).fork()).join();
    }
    Object.entries(message.labels).forEach(([key, value]) => {
      RunPipelineRequest_LabelsEntry.encode({ key: key as any, value }, writer.uint32(18).fork()).join();
    });
    if (message.pubSubTopic !== "") {
      writer.uint32(26).string(message.pubSubTopic);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): RunPipelineRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseRunPipelineRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 4:
          if (tag !== 34) {
            break;
          }

          message.parent = reader.string();
          continue;
        case 1:
          if (tag !== 10) {
            break;
          }

          message.pipeline = Pipeline.decode(reader, reader.uint32());
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          const entry2 = RunPipelineRequest_LabelsEntry.decode(reader, reader.uint32());
          if (entry2.value !== undefined) {
            message.labels[entry2.key] = entry2.value;
          }
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.pubSubTopic = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): RunPipelineRequest {
    return {
      parent: isSet(object.parent) ? globalThis.String(object.parent) : "",
      pipeline: isSet(object.pipeline) ? Pipeline.fromJSON(object.pipeline) : undefined,
      labels: isObject(object.labels)
        ? Object.entries(object.labels).reduce<{ [key: string]: string }>((acc, [key, value]) => {
          acc[key] = String(value);
          return acc;
        }, {})
        : {},
      pubSubTopic: isSet(object.pubSubTopic) ? globalThis.String(object.pubSubTopic) : "",
    };
  },

  toJSON(message: RunPipelineRequest): unknown {
    const obj: any = {};
    if (message.parent !== "") {
      obj.parent = message.parent;
    }
    if (message.pipeline !== undefined) {
      obj.pipeline = Pipeline.toJSON(message.pipeline);
    }
    if (message.labels) {
      const entries = Object.entries(message.labels);
      if (entries.length > 0) {
        obj.labels = {};
        entries.forEach(([k, v]) => {
          obj.labels[k] = v;
        });
      }
    }
    if (message.pubSubTopic !== "") {
      obj.pubSubTopic = message.pubSubTopic;
    }
    return obj;
  },

  create(base?: DeepPartial<RunPipelineRequest>): RunPipelineRequest {
    return RunPipelineRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<RunPipelineRequest>): RunPipelineRequest {
    const message = createBaseRunPipelineRequest();
    message.parent = object.parent ?? "";
    message.pipeline = (object.pipeline !== undefined && object.pipeline !== null)
      ? Pipeline.fromPartial(object.pipeline)
      : undefined;
    message.labels = Object.entries(object.labels ?? {}).reduce<{ [key: string]: string }>((acc, [key, value]) => {
      if (value !== undefined) {
        acc[key] = globalThis.String(value);
      }
      return acc;
    }, {});
    message.pubSubTopic = object.pubSubTopic ?? "";
    return message;
  },
};

function createBaseRunPipelineRequest_LabelsEntry(): RunPipelineRequest_LabelsEntry {
  return { key: "", value: "" };
}

export const RunPipelineRequest_LabelsEntry: MessageFns<RunPipelineRequest_LabelsEntry> = {
  encode(message: RunPipelineRequest_LabelsEntry, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.key !== "") {
      writer.uint32(10).string(message.key);
    }
    if (message.value !== "") {
      writer.uint32(18).string(message.value);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): RunPipelineRequest_LabelsEntry {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseRunPipelineRequest_LabelsEntry();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.key = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.value = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): RunPipelineRequest_LabelsEntry {
    return {
      key: isSet(object.key) ? globalThis.String(object.key) : "",
      value: isSet(object.value) ? globalThis.String(object.value) : "",
    };
  },

  toJSON(message: RunPipelineRequest_LabelsEntry): unknown {
    const obj: any = {};
    if (message.key !== "") {
      obj.key = message.key;
    }
    if (message.value !== "") {
      obj.value = message.value;
    }
    return obj;
  },

  create(base?: DeepPartial<RunPipelineRequest_LabelsEntry>): RunPipelineRequest_LabelsEntry {
    return RunPipelineRequest_LabelsEntry.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<RunPipelineRequest_LabelsEntry>): RunPipelineRequest_LabelsEntry {
    const message = createBaseRunPipelineRequest_LabelsEntry();
    message.key = object.key ?? "";
    message.value = object.value ?? "";
    return message;
  },
};

function createBaseRunPipelineResponse(): RunPipelineResponse {
  return {};
}

export const RunPipelineResponse: MessageFns<RunPipelineResponse> = {
  encode(_: RunPipelineResponse, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): RunPipelineResponse {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseRunPipelineResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(_: any): RunPipelineResponse {
    return {};
  },

  toJSON(_: RunPipelineResponse): unknown {
    const obj: any = {};
    return obj;
  },

  create(base?: DeepPartial<RunPipelineResponse>): RunPipelineResponse {
    return RunPipelineResponse.fromPartial(base ?? {});
  },
  fromPartial(_: DeepPartial<RunPipelineResponse>): RunPipelineResponse {
    const message = createBaseRunPipelineResponse();
    return message;
  },
};

function createBasePipeline(): Pipeline {
  return { actions: [], resources: undefined, environment: {}, encryptedEnvironment: undefined, timeout: undefined };
}

export const Pipeline: MessageFns<Pipeline> = {
  encode(message: Pipeline, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.actions) {
      Action.encode(v!, writer.uint32(10).fork()).join();
    }
    if (message.resources !== undefined) {
      Resources.encode(message.resources, writer.uint32(18).fork()).join();
    }
    Object.entries(message.environment).forEach(([key, value]) => {
      Pipeline_EnvironmentEntry.encode({ key: key as any, value }, writer.uint32(26).fork()).join();
    });
    if (message.encryptedEnvironment !== undefined) {
      Secret.encode(message.encryptedEnvironment, writer.uint32(42).fork()).join();
    }
    if (message.timeout !== undefined) {
      Duration.encode(message.timeout, writer.uint32(34).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Pipeline {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBasePipeline();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.actions.push(Action.decode(reader, reader.uint32()));
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.resources = Resources.decode(reader, reader.uint32());
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          const entry3 = Pipeline_EnvironmentEntry.decode(reader, reader.uint32());
          if (entry3.value !== undefined) {
            message.environment[entry3.key] = entry3.value;
          }
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.encryptedEnvironment = Secret.decode(reader, reader.uint32());
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.timeout = Duration.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Pipeline {
    return {
      actions: globalThis.Array.isArray(object?.actions) ? object.actions.map((e: any) => Action.fromJSON(e)) : [],
      resources: isSet(object.resources) ? Resources.fromJSON(object.resources) : undefined,
      environment: isObject(object.environment)
        ? Object.entries(object.environment).reduce<{ [key: string]: string }>((acc, [key, value]) => {
          acc[key] = String(value);
          return acc;
        }, {})
        : {},
      encryptedEnvironment: isSet(object.encryptedEnvironment)
        ? Secret.fromJSON(object.encryptedEnvironment)
        : undefined,
      timeout: isSet(object.timeout) ? Duration.fromJSON(object.timeout) : undefined,
    };
  },

  toJSON(message: Pipeline): unknown {
    const obj: any = {};
    if (message.actions?.length) {
      obj.actions = message.actions.map((e) => Action.toJSON(e));
    }
    if (message.resources !== undefined) {
      obj.resources = Resources.toJSON(message.resources);
    }
    if (message.environment) {
      const entries = Object.entries(message.environment);
      if (entries.length > 0) {
        obj.environment = {};
        entries.forEach(([k, v]) => {
          obj.environment[k] = v;
        });
      }
    }
    if (message.encryptedEnvironment !== undefined) {
      obj.encryptedEnvironment = Secret.toJSON(message.encryptedEnvironment);
    }
    if (message.timeout !== undefined) {
      obj.timeout = Duration.toJSON(message.timeout);
    }
    return obj;
  },

  create(base?: DeepPartial<Pipeline>): Pipeline {
    return Pipeline.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<Pipeline>): Pipeline {
    const message = createBasePipeline();
    message.actions = object.actions?.map((e) => Action.fromPartial(e)) || [];
    message.resources = (object.resources !== undefined && object.resources !== null)
      ? Resources.fromPartial(object.resources)
      : undefined;
    message.environment = Object.entries(object.environment ?? {}).reduce<{ [key: string]: string }>(
      (acc, [key, value]) => {
        if (value !== undefined) {
          acc[key] = globalThis.String(value);
        }
        return acc;
      },
      {},
    );
    message.encryptedEnvironment = (object.encryptedEnvironment !== undefined && object.encryptedEnvironment !== null)
      ? Secret.fromPartial(object.encryptedEnvironment)
      : undefined;
    message.timeout = (object.timeout !== undefined && object.timeout !== null)
      ? Duration.fromPartial(object.timeout)
      : undefined;
    return message;
  },
};

function createBasePipeline_EnvironmentEntry(): Pipeline_EnvironmentEntry {
  return { key: "", value: "" };
}

export const Pipeline_EnvironmentEntry: MessageFns<Pipeline_EnvironmentEntry> = {
  encode(message: Pipeline_EnvironmentEntry, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.key !== "") {
      writer.uint32(10).string(message.key);
    }
    if (message.value !== "") {
      writer.uint32(18).string(message.value);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Pipeline_EnvironmentEntry {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBasePipeline_EnvironmentEntry();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.key = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.value = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Pipeline_EnvironmentEntry {
    return {
      key: isSet(object.key) ? globalThis.String(object.key) : "",
      value: isSet(object.value) ? globalThis.String(object.value) : "",
    };
  },

  toJSON(message: Pipeline_EnvironmentEntry): unknown {
    const obj: any = {};
    if (message.key !== "") {
      obj.key = message.key;
    }
    if (message.value !== "") {
      obj.value = message.value;
    }
    return obj;
  },

  create(base?: DeepPartial<Pipeline_EnvironmentEntry>): Pipeline_EnvironmentEntry {
    return Pipeline_EnvironmentEntry.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<Pipeline_EnvironmentEntry>): Pipeline_EnvironmentEntry {
    const message = createBasePipeline_EnvironmentEntry();
    message.key = object.key ?? "";
    message.value = object.value ?? "";
    return message;
  },
};

function createBaseAction(): Action {
  return {
    containerName: "",
    imageUri: "",
    commands: [],
    entrypoint: "",
    environment: {},
    encryptedEnvironment: undefined,
    pidNamespace: "",
    portMappings: {},
    mounts: [],
    labels: {},
    credentials: undefined,
    timeout: undefined,
    ignoreExitStatus: false,
    runInBackground: false,
    alwaysRun: false,
    enableFuse: false,
    publishExposedPorts: false,
    disableImagePrefetch: false,
    disableStandardErrorCapture: false,
    blockExternalNetwork: false,
  };
}

export const Action: MessageFns<Action> = {
  encode(message: Action, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.containerName !== "") {
      writer.uint32(10).string(message.containerName);
    }
    if (message.imageUri !== "") {
      writer.uint32(18).string(message.imageUri);
    }
    for (const v of message.commands) {
      writer.uint32(26).string(v!);
    }
    if (message.entrypoint !== "") {
      writer.uint32(34).string(message.entrypoint);
    }
    Object.entries(message.environment).forEach(([key, value]) => {
      Action_EnvironmentEntry.encode({ key: key as any, value }, writer.uint32(42).fork()).join();
    });
    if (message.encryptedEnvironment !== undefined) {
      Secret.encode(message.encryptedEnvironment, writer.uint32(170).fork()).join();
    }
    if (message.pidNamespace !== "") {
      writer.uint32(50).string(message.pidNamespace);
    }
    Object.entries(message.portMappings).forEach(([key, value]) => {
      Action_PortMappingsEntry.encode({ key: key as any, value }, writer.uint32(66).fork()).join();
    });
    for (const v of message.mounts) {
      Mount.encode(v!, writer.uint32(74).fork()).join();
    }
    Object.entries(message.labels).forEach(([key, value]) => {
      Action_LabelsEntry.encode({ key: key as any, value }, writer.uint32(82).fork()).join();
    });
    if (message.credentials !== undefined) {
      Secret.encode(message.credentials, writer.uint32(90).fork()).join();
    }
    if (message.timeout !== undefined) {
      Duration.encode(message.timeout, writer.uint32(98).fork()).join();
    }
    if (message.ignoreExitStatus !== false) {
      writer.uint32(104).bool(message.ignoreExitStatus);
    }
    if (message.runInBackground !== false) {
      writer.uint32(112).bool(message.runInBackground);
    }
    if (message.alwaysRun !== false) {
      writer.uint32(120).bool(message.alwaysRun);
    }
    if (message.enableFuse !== false) {
      writer.uint32(128).bool(message.enableFuse);
    }
    if (message.publishExposedPorts !== false) {
      writer.uint32(136).bool(message.publishExposedPorts);
    }
    if (message.disableImagePrefetch !== false) {
      writer.uint32(144).bool(message.disableImagePrefetch);
    }
    if (message.disableStandardErrorCapture !== false) {
      writer.uint32(152).bool(message.disableStandardErrorCapture);
    }
    if (message.blockExternalNetwork !== false) {
      writer.uint32(160).bool(message.blockExternalNetwork);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Action {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseAction();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.containerName = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.imageUri = reader.string();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.commands.push(reader.string());
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.entrypoint = reader.string();
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          const entry5 = Action_EnvironmentEntry.decode(reader, reader.uint32());
          if (entry5.value !== undefined) {
            message.environment[entry5.key] = entry5.value;
          }
          continue;
        case 21:
          if (tag !== 170) {
            break;
          }

          message.encryptedEnvironment = Secret.decode(reader, reader.uint32());
          continue;
        case 6:
          if (tag !== 50) {
            break;
          }

          message.pidNamespace = reader.string();
          continue;
        case 8:
          if (tag !== 66) {
            break;
          }

          const entry8 = Action_PortMappingsEntry.decode(reader, reader.uint32());
          if (entry8.value !== undefined) {
            message.portMappings[entry8.key] = entry8.value;
          }
          continue;
        case 9:
          if (tag !== 74) {
            break;
          }

          message.mounts.push(Mount.decode(reader, reader.uint32()));
          continue;
        case 10:
          if (tag !== 82) {
            break;
          }

          const entry10 = Action_LabelsEntry.decode(reader, reader.uint32());
          if (entry10.value !== undefined) {
            message.labels[entry10.key] = entry10.value;
          }
          continue;
        case 11:
          if (tag !== 90) {
            break;
          }

          message.credentials = Secret.decode(reader, reader.uint32());
          continue;
        case 12:
          if (tag !== 98) {
            break;
          }

          message.timeout = Duration.decode(reader, reader.uint32());
          continue;
        case 13:
          if (tag !== 104) {
            break;
          }

          message.ignoreExitStatus = reader.bool();
          continue;
        case 14:
          if (tag !== 112) {
            break;
          }

          message.runInBackground = reader.bool();
          continue;
        case 15:
          if (tag !== 120) {
            break;
          }

          message.alwaysRun = reader.bool();
          continue;
        case 16:
          if (tag !== 128) {
            break;
          }

          message.enableFuse = reader.bool();
          continue;
        case 17:
          if (tag !== 136) {
            break;
          }

          message.publishExposedPorts = reader.bool();
          continue;
        case 18:
          if (tag !== 144) {
            break;
          }

          message.disableImagePrefetch = reader.bool();
          continue;
        case 19:
          if (tag !== 152) {
            break;
          }

          message.disableStandardErrorCapture = reader.bool();
          continue;
        case 20:
          if (tag !== 160) {
            break;
          }

          message.blockExternalNetwork = reader.bool();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Action {
    return {
      containerName: isSet(object.containerName) ? globalThis.String(object.containerName) : "",
      imageUri: isSet(object.imageUri) ? globalThis.String(object.imageUri) : "",
      commands: globalThis.Array.isArray(object?.commands) ? object.commands.map((e: any) => globalThis.String(e)) : [],
      entrypoint: isSet(object.entrypoint) ? globalThis.String(object.entrypoint) : "",
      environment: isObject(object.environment)
        ? Object.entries(object.environment).reduce<{ [key: string]: string }>((acc, [key, value]) => {
          acc[key] = String(value);
          return acc;
        }, {})
        : {},
      encryptedEnvironment: isSet(object.encryptedEnvironment)
        ? Secret.fromJSON(object.encryptedEnvironment)
        : undefined,
      pidNamespace: isSet(object.pidNamespace) ? globalThis.String(object.pidNamespace) : "",
      portMappings: isObject(object.portMappings)
        ? Object.entries(object.portMappings).reduce<{ [key: number]: number }>((acc, [key, value]) => {
          acc[globalThis.Number(key)] = Number(value);
          return acc;
        }, {})
        : {},
      mounts: globalThis.Array.isArray(object?.mounts) ? object.mounts.map((e: any) => Mount.fromJSON(e)) : [],
      labels: isObject(object.labels)
        ? Object.entries(object.labels).reduce<{ [key: string]: string }>((acc, [key, value]) => {
          acc[key] = String(value);
          return acc;
        }, {})
        : {},
      credentials: isSet(object.credentials) ? Secret.fromJSON(object.credentials) : undefined,
      timeout: isSet(object.timeout) ? Duration.fromJSON(object.timeout) : undefined,
      ignoreExitStatus: isSet(object.ignoreExitStatus) ? globalThis.Boolean(object.ignoreExitStatus) : false,
      runInBackground: isSet(object.runInBackground) ? globalThis.Boolean(object.runInBackground) : false,
      alwaysRun: isSet(object.alwaysRun) ? globalThis.Boolean(object.alwaysRun) : false,
      enableFuse: isSet(object.enableFuse) ? globalThis.Boolean(object.enableFuse) : false,
      publishExposedPorts: isSet(object.publishExposedPorts) ? globalThis.Boolean(object.publishExposedPorts) : false,
      disableImagePrefetch: isSet(object.disableImagePrefetch)
        ? globalThis.Boolean(object.disableImagePrefetch)
        : false,
      disableStandardErrorCapture: isSet(object.disableStandardErrorCapture)
        ? globalThis.Boolean(object.disableStandardErrorCapture)
        : false,
      blockExternalNetwork: isSet(object.blockExternalNetwork)
        ? globalThis.Boolean(object.blockExternalNetwork)
        : false,
    };
  },

  toJSON(message: Action): unknown {
    const obj: any = {};
    if (message.containerName !== "") {
      obj.containerName = message.containerName;
    }
    if (message.imageUri !== "") {
      obj.imageUri = message.imageUri;
    }
    if (message.commands?.length) {
      obj.commands = message.commands;
    }
    if (message.entrypoint !== "") {
      obj.entrypoint = message.entrypoint;
    }
    if (message.environment) {
      const entries = Object.entries(message.environment);
      if (entries.length > 0) {
        obj.environment = {};
        entries.forEach(([k, v]) => {
          obj.environment[k] = v;
        });
      }
    }
    if (message.encryptedEnvironment !== undefined) {
      obj.encryptedEnvironment = Secret.toJSON(message.encryptedEnvironment);
    }
    if (message.pidNamespace !== "") {
      obj.pidNamespace = message.pidNamespace;
    }
    if (message.portMappings) {
      const entries = Object.entries(message.portMappings);
      if (entries.length > 0) {
        obj.portMappings = {};
        entries.forEach(([k, v]) => {
          obj.portMappings[k] = Math.round(v);
        });
      }
    }
    if (message.mounts?.length) {
      obj.mounts = message.mounts.map((e) => Mount.toJSON(e));
    }
    if (message.labels) {
      const entries = Object.entries(message.labels);
      if (entries.length > 0) {
        obj.labels = {};
        entries.forEach(([k, v]) => {
          obj.labels[k] = v;
        });
      }
    }
    if (message.credentials !== undefined) {
      obj.credentials = Secret.toJSON(message.credentials);
    }
    if (message.timeout !== undefined) {
      obj.timeout = Duration.toJSON(message.timeout);
    }
    if (message.ignoreExitStatus !== false) {
      obj.ignoreExitStatus = message.ignoreExitStatus;
    }
    if (message.runInBackground !== false) {
      obj.runInBackground = message.runInBackground;
    }
    if (message.alwaysRun !== false) {
      obj.alwaysRun = message.alwaysRun;
    }
    if (message.enableFuse !== false) {
      obj.enableFuse = message.enableFuse;
    }
    if (message.publishExposedPorts !== false) {
      obj.publishExposedPorts = message.publishExposedPorts;
    }
    if (message.disableImagePrefetch !== false) {
      obj.disableImagePrefetch = message.disableImagePrefetch;
    }
    if (message.disableStandardErrorCapture !== false) {
      obj.disableStandardErrorCapture = message.disableStandardErrorCapture;
    }
    if (message.blockExternalNetwork !== false) {
      obj.blockExternalNetwork = message.blockExternalNetwork;
    }
    return obj;
  },

  create(base?: DeepPartial<Action>): Action {
    return Action.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<Action>): Action {
    const message = createBaseAction();
    message.containerName = object.containerName ?? "";
    message.imageUri = object.imageUri ?? "";
    message.commands = object.commands?.map((e) => e) || [];
    message.entrypoint = object.entrypoint ?? "";
    message.environment = Object.entries(object.environment ?? {}).reduce<{ [key: string]: string }>(
      (acc, [key, value]) => {
        if (value !== undefined) {
          acc[key] = globalThis.String(value);
        }
        return acc;
      },
      {},
    );
    message.encryptedEnvironment = (object.encryptedEnvironment !== undefined && object.encryptedEnvironment !== null)
      ? Secret.fromPartial(object.encryptedEnvironment)
      : undefined;
    message.pidNamespace = object.pidNamespace ?? "";
    message.portMappings = Object.entries(object.portMappings ?? {}).reduce<{ [key: number]: number }>(
      (acc, [key, value]) => {
        if (value !== undefined) {
          acc[globalThis.Number(key)] = globalThis.Number(value);
        }
        return acc;
      },
      {},
    );
    message.mounts = object.mounts?.map((e) => Mount.fromPartial(e)) || [];
    message.labels = Object.entries(object.labels ?? {}).reduce<{ [key: string]: string }>((acc, [key, value]) => {
      if (value !== undefined) {
        acc[key] = globalThis.String(value);
      }
      return acc;
    }, {});
    message.credentials = (object.credentials !== undefined && object.credentials !== null)
      ? Secret.fromPartial(object.credentials)
      : undefined;
    message.timeout = (object.timeout !== undefined && object.timeout !== null)
      ? Duration.fromPartial(object.timeout)
      : undefined;
    message.ignoreExitStatus = object.ignoreExitStatus ?? false;
    message.runInBackground = object.runInBackground ?? false;
    message.alwaysRun = object.alwaysRun ?? false;
    message.enableFuse = object.enableFuse ?? false;
    message.publishExposedPorts = object.publishExposedPorts ?? false;
    message.disableImagePrefetch = object.disableImagePrefetch ?? false;
    message.disableStandardErrorCapture = object.disableStandardErrorCapture ?? false;
    message.blockExternalNetwork = object.blockExternalNetwork ?? false;
    return message;
  },
};

function createBaseAction_EnvironmentEntry(): Action_EnvironmentEntry {
  return { key: "", value: "" };
}

export const Action_EnvironmentEntry: MessageFns<Action_EnvironmentEntry> = {
  encode(message: Action_EnvironmentEntry, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.key !== "") {
      writer.uint32(10).string(message.key);
    }
    if (message.value !== "") {
      writer.uint32(18).string(message.value);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Action_EnvironmentEntry {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseAction_EnvironmentEntry();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.key = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.value = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Action_EnvironmentEntry {
    return {
      key: isSet(object.key) ? globalThis.String(object.key) : "",
      value: isSet(object.value) ? globalThis.String(object.value) : "",
    };
  },

  toJSON(message: Action_EnvironmentEntry): unknown {
    const obj: any = {};
    if (message.key !== "") {
      obj.key = message.key;
    }
    if (message.value !== "") {
      obj.value = message.value;
    }
    return obj;
  },

  create(base?: DeepPartial<Action_EnvironmentEntry>): Action_EnvironmentEntry {
    return Action_EnvironmentEntry.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<Action_EnvironmentEntry>): Action_EnvironmentEntry {
    const message = createBaseAction_EnvironmentEntry();
    message.key = object.key ?? "";
    message.value = object.value ?? "";
    return message;
  },
};

function createBaseAction_PortMappingsEntry(): Action_PortMappingsEntry {
  return { key: 0, value: 0 };
}

export const Action_PortMappingsEntry: MessageFns<Action_PortMappingsEntry> = {
  encode(message: Action_PortMappingsEntry, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.key !== 0) {
      writer.uint32(8).int32(message.key);
    }
    if (message.value !== 0) {
      writer.uint32(16).int32(message.value);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Action_PortMappingsEntry {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseAction_PortMappingsEntry();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 8) {
            break;
          }

          message.key = reader.int32();
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.value = reader.int32();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Action_PortMappingsEntry {
    return {
      key: isSet(object.key) ? globalThis.Number(object.key) : 0,
      value: isSet(object.value) ? globalThis.Number(object.value) : 0,
    };
  },

  toJSON(message: Action_PortMappingsEntry): unknown {
    const obj: any = {};
    if (message.key !== 0) {
      obj.key = Math.round(message.key);
    }
    if (message.value !== 0) {
      obj.value = Math.round(message.value);
    }
    return obj;
  },

  create(base?: DeepPartial<Action_PortMappingsEntry>): Action_PortMappingsEntry {
    return Action_PortMappingsEntry.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<Action_PortMappingsEntry>): Action_PortMappingsEntry {
    const message = createBaseAction_PortMappingsEntry();
    message.key = object.key ?? 0;
    message.value = object.value ?? 0;
    return message;
  },
};

function createBaseAction_LabelsEntry(): Action_LabelsEntry {
  return { key: "", value: "" };
}

export const Action_LabelsEntry: MessageFns<Action_LabelsEntry> = {
  encode(message: Action_LabelsEntry, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.key !== "") {
      writer.uint32(10).string(message.key);
    }
    if (message.value !== "") {
      writer.uint32(18).string(message.value);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Action_LabelsEntry {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseAction_LabelsEntry();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.key = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.value = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Action_LabelsEntry {
    return {
      key: isSet(object.key) ? globalThis.String(object.key) : "",
      value: isSet(object.value) ? globalThis.String(object.value) : "",
    };
  },

  toJSON(message: Action_LabelsEntry): unknown {
    const obj: any = {};
    if (message.key !== "") {
      obj.key = message.key;
    }
    if (message.value !== "") {
      obj.value = message.value;
    }
    return obj;
  },

  create(base?: DeepPartial<Action_LabelsEntry>): Action_LabelsEntry {
    return Action_LabelsEntry.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<Action_LabelsEntry>): Action_LabelsEntry {
    const message = createBaseAction_LabelsEntry();
    message.key = object.key ?? "";
    message.value = object.value ?? "";
    return message;
  },
};

function createBaseSecret(): Secret {
  return { keyName: "", cipherText: "" };
}

export const Secret: MessageFns<Secret> = {
  encode(message: Secret, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.keyName !== "") {
      writer.uint32(10).string(message.keyName);
    }
    if (message.cipherText !== "") {
      writer.uint32(18).string(message.cipherText);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Secret {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseSecret();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.keyName = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.cipherText = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Secret {
    return {
      keyName: isSet(object.keyName) ? globalThis.String(object.keyName) : "",
      cipherText: isSet(object.cipherText) ? globalThis.String(object.cipherText) : "",
    };
  },

  toJSON(message: Secret): unknown {
    const obj: any = {};
    if (message.keyName !== "") {
      obj.keyName = message.keyName;
    }
    if (message.cipherText !== "") {
      obj.cipherText = message.cipherText;
    }
    return obj;
  },

  create(base?: DeepPartial<Secret>): Secret {
    return Secret.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<Secret>): Secret {
    const message = createBaseSecret();
    message.keyName = object.keyName ?? "";
    message.cipherText = object.cipherText ?? "";
    return message;
  },
};

function createBaseMount(): Mount {
  return { disk: "", path: "", readOnly: false };
}

export const Mount: MessageFns<Mount> = {
  encode(message: Mount, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.disk !== "") {
      writer.uint32(10).string(message.disk);
    }
    if (message.path !== "") {
      writer.uint32(18).string(message.path);
    }
    if (message.readOnly !== false) {
      writer.uint32(24).bool(message.readOnly);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Mount {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseMount();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.disk = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.path = reader.string();
          continue;
        case 3:
          if (tag !== 24) {
            break;
          }

          message.readOnly = reader.bool();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Mount {
    return {
      disk: isSet(object.disk) ? globalThis.String(object.disk) : "",
      path: isSet(object.path) ? globalThis.String(object.path) : "",
      readOnly: isSet(object.readOnly) ? globalThis.Boolean(object.readOnly) : false,
    };
  },

  toJSON(message: Mount): unknown {
    const obj: any = {};
    if (message.disk !== "") {
      obj.disk = message.disk;
    }
    if (message.path !== "") {
      obj.path = message.path;
    }
    if (message.readOnly !== false) {
      obj.readOnly = message.readOnly;
    }
    return obj;
  },

  create(base?: DeepPartial<Mount>): Mount {
    return Mount.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<Mount>): Mount {
    const message = createBaseMount();
    message.disk = object.disk ?? "";
    message.path = object.path ?? "";
    message.readOnly = object.readOnly ?? false;
    return message;
  },
};

function createBaseResources(): Resources {
  return { regions: [], zones: [], virtualMachine: undefined };
}

export const Resources: MessageFns<Resources> = {
  encode(message: Resources, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.regions) {
      writer.uint32(18).string(v!);
    }
    for (const v of message.zones) {
      writer.uint32(26).string(v!);
    }
    if (message.virtualMachine !== undefined) {
      VirtualMachine.encode(message.virtualMachine, writer.uint32(34).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Resources {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseResources();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 2:
          if (tag !== 18) {
            break;
          }

          message.regions.push(reader.string());
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.zones.push(reader.string());
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.virtualMachine = VirtualMachine.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Resources {
    return {
      regions: globalThis.Array.isArray(object?.regions) ? object.regions.map((e: any) => globalThis.String(e)) : [],
      zones: globalThis.Array.isArray(object?.zones) ? object.zones.map((e: any) => globalThis.String(e)) : [],
      virtualMachine: isSet(object.virtualMachine) ? VirtualMachine.fromJSON(object.virtualMachine) : undefined,
    };
  },

  toJSON(message: Resources): unknown {
    const obj: any = {};
    if (message.regions?.length) {
      obj.regions = message.regions;
    }
    if (message.zones?.length) {
      obj.zones = message.zones;
    }
    if (message.virtualMachine !== undefined) {
      obj.virtualMachine = VirtualMachine.toJSON(message.virtualMachine);
    }
    return obj;
  },

  create(base?: DeepPartial<Resources>): Resources {
    return Resources.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<Resources>): Resources {
    const message = createBaseResources();
    message.regions = object.regions?.map((e) => e) || [];
    message.zones = object.zones?.map((e) => e) || [];
    message.virtualMachine = (object.virtualMachine !== undefined && object.virtualMachine !== null)
      ? VirtualMachine.fromPartial(object.virtualMachine)
      : undefined;
    return message;
  },
};

function createBaseVirtualMachine(): VirtualMachine {
  return {
    machineType: "",
    preemptible: false,
    labels: {},
    disks: [],
    network: undefined,
    accelerators: [],
    serviceAccount: undefined,
    bootDiskSizeGb: 0,
    cpuPlatform: "",
    bootImage: "",
    nvidiaDriverVersion: "",
    enableStackdriverMonitoring: false,
    dockerCacheImages: [],
    volumes: [],
    reservation: "",
  };
}

export const VirtualMachine: MessageFns<VirtualMachine> = {
  encode(message: VirtualMachine, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.machineType !== "") {
      writer.uint32(10).string(message.machineType);
    }
    if (message.preemptible !== false) {
      writer.uint32(16).bool(message.preemptible);
    }
    Object.entries(message.labels).forEach(([key, value]) => {
      VirtualMachine_LabelsEntry.encode({ key: key as any, value }, writer.uint32(26).fork()).join();
    });
    for (const v of message.disks) {
      Disk.encode(v!, writer.uint32(34).fork()).join();
    }
    if (message.network !== undefined) {
      Network.encode(message.network, writer.uint32(42).fork()).join();
    }
    for (const v of message.accelerators) {
      Accelerator.encode(v!, writer.uint32(50).fork()).join();
    }
    if (message.serviceAccount !== undefined) {
      ServiceAccount.encode(message.serviceAccount, writer.uint32(58).fork()).join();
    }
    if (message.bootDiskSizeGb !== 0) {
      writer.uint32(64).int32(message.bootDiskSizeGb);
    }
    if (message.cpuPlatform !== "") {
      writer.uint32(74).string(message.cpuPlatform);
    }
    if (message.bootImage !== "") {
      writer.uint32(82).string(message.bootImage);
    }
    if (message.nvidiaDriverVersion !== "") {
      writer.uint32(90).string(message.nvidiaDriverVersion);
    }
    if (message.enableStackdriverMonitoring !== false) {
      writer.uint32(96).bool(message.enableStackdriverMonitoring);
    }
    for (const v of message.dockerCacheImages) {
      writer.uint32(106).string(v!);
    }
    for (const v of message.volumes) {
      Volume.encode(v!, writer.uint32(114).fork()).join();
    }
    if (message.reservation !== "") {
      writer.uint32(122).string(message.reservation);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): VirtualMachine {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseVirtualMachine();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.machineType = reader.string();
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.preemptible = reader.bool();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          const entry3 = VirtualMachine_LabelsEntry.decode(reader, reader.uint32());
          if (entry3.value !== undefined) {
            message.labels[entry3.key] = entry3.value;
          }
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.disks.push(Disk.decode(reader, reader.uint32()));
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.network = Network.decode(reader, reader.uint32());
          continue;
        case 6:
          if (tag !== 50) {
            break;
          }

          message.accelerators.push(Accelerator.decode(reader, reader.uint32()));
          continue;
        case 7:
          if (tag !== 58) {
            break;
          }

          message.serviceAccount = ServiceAccount.decode(reader, reader.uint32());
          continue;
        case 8:
          if (tag !== 64) {
            break;
          }

          message.bootDiskSizeGb = reader.int32();
          continue;
        case 9:
          if (tag !== 74) {
            break;
          }

          message.cpuPlatform = reader.string();
          continue;
        case 10:
          if (tag !== 82) {
            break;
          }

          message.bootImage = reader.string();
          continue;
        case 11:
          if (tag !== 90) {
            break;
          }

          message.nvidiaDriverVersion = reader.string();
          continue;
        case 12:
          if (tag !== 96) {
            break;
          }

          message.enableStackdriverMonitoring = reader.bool();
          continue;
        case 13:
          if (tag !== 106) {
            break;
          }

          message.dockerCacheImages.push(reader.string());
          continue;
        case 14:
          if (tag !== 114) {
            break;
          }

          message.volumes.push(Volume.decode(reader, reader.uint32()));
          continue;
        case 15:
          if (tag !== 122) {
            break;
          }

          message.reservation = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): VirtualMachine {
    return {
      machineType: isSet(object.machineType) ? globalThis.String(object.machineType) : "",
      preemptible: isSet(object.preemptible) ? globalThis.Boolean(object.preemptible) : false,
      labels: isObject(object.labels)
        ? Object.entries(object.labels).reduce<{ [key: string]: string }>((acc, [key, value]) => {
          acc[key] = String(value);
          return acc;
        }, {})
        : {},
      disks: globalThis.Array.isArray(object?.disks) ? object.disks.map((e: any) => Disk.fromJSON(e)) : [],
      network: isSet(object.network) ? Network.fromJSON(object.network) : undefined,
      accelerators: globalThis.Array.isArray(object?.accelerators)
        ? object.accelerators.map((e: any) => Accelerator.fromJSON(e))
        : [],
      serviceAccount: isSet(object.serviceAccount) ? ServiceAccount.fromJSON(object.serviceAccount) : undefined,
      bootDiskSizeGb: isSet(object.bootDiskSizeGb) ? globalThis.Number(object.bootDiskSizeGb) : 0,
      cpuPlatform: isSet(object.cpuPlatform) ? globalThis.String(object.cpuPlatform) : "",
      bootImage: isSet(object.bootImage) ? globalThis.String(object.bootImage) : "",
      nvidiaDriverVersion: isSet(object.nvidiaDriverVersion) ? globalThis.String(object.nvidiaDriverVersion) : "",
      enableStackdriverMonitoring: isSet(object.enableStackdriverMonitoring)
        ? globalThis.Boolean(object.enableStackdriverMonitoring)
        : false,
      dockerCacheImages: globalThis.Array.isArray(object?.dockerCacheImages)
        ? object.dockerCacheImages.map((e: any) => globalThis.String(e))
        : [],
      volumes: globalThis.Array.isArray(object?.volumes)
        ? object.volumes.map((e: any) => Volume.fromJSON(e))
        : [],
      reservation: isSet(object.reservation) ? globalThis.String(object.reservation) : "",
    };
  },

  toJSON(message: VirtualMachine): unknown {
    const obj: any = {};
    if (message.machineType !== "") {
      obj.machineType = message.machineType;
    }
    if (message.preemptible !== false) {
      obj.preemptible = message.preemptible;
    }
    if (message.labels) {
      const entries = Object.entries(message.labels);
      if (entries.length > 0) {
        obj.labels = {};
        entries.forEach(([k, v]) => {
          obj.labels[k] = v;
        });
      }
    }
    if (message.disks?.length) {
      obj.disks = message.disks.map((e) => Disk.toJSON(e));
    }
    if (message.network !== undefined) {
      obj.network = Network.toJSON(message.network);
    }
    if (message.accelerators?.length) {
      obj.accelerators = message.accelerators.map((e) => Accelerator.toJSON(e));
    }
    if (message.serviceAccount !== undefined) {
      obj.serviceAccount = ServiceAccount.toJSON(message.serviceAccount);
    }
    if (message.bootDiskSizeGb !== 0) {
      obj.bootDiskSizeGb = Math.round(message.bootDiskSizeGb);
    }
    if (message.cpuPlatform !== "") {
      obj.cpuPlatform = message.cpuPlatform;
    }
    if (message.bootImage !== "") {
      obj.bootImage = message.bootImage;
    }
    if (message.nvidiaDriverVersion !== "") {
      obj.nvidiaDriverVersion = message.nvidiaDriverVersion;
    }
    if (message.enableStackdriverMonitoring !== false) {
      obj.enableStackdriverMonitoring = message.enableStackdriverMonitoring;
    }
    if (message.dockerCacheImages?.length) {
      obj.dockerCacheImages = message.dockerCacheImages;
    }
    if (message.volumes?.length) {
      obj.volumes = message.volumes.map((e) => Volume.toJSON(e));
    }
    if (message.reservation !== "") {
      obj.reservation = message.reservation;
    }
    return obj;
  },

  create(base?: DeepPartial<VirtualMachine>): VirtualMachine {
    return VirtualMachine.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<VirtualMachine>): VirtualMachine {
    const message = createBaseVirtualMachine();
    message.machineType = object.machineType ?? "";
    message.preemptible = object.preemptible ?? false;
    message.labels = Object.entries(object.labels ?? {}).reduce<{ [key: string]: string }>((acc, [key, value]) => {
      if (value !== undefined) {
        acc[key] = globalThis.String(value);
      }
      return acc;
    }, {});
    message.disks = object.disks?.map((e) => Disk.fromPartial(e)) || [];
    message.network = (object.network !== undefined && object.network !== null)
      ? Network.fromPartial(object.network)
      : undefined;
    message.accelerators = object.accelerators?.map((e) => Accelerator.fromPartial(e)) || [];
    message.serviceAccount = (object.serviceAccount !== undefined && object.serviceAccount !== null)
      ? ServiceAccount.fromPartial(object.serviceAccount)
      : undefined;
    message.bootDiskSizeGb = object.bootDiskSizeGb ?? 0;
    message.cpuPlatform = object.cpuPlatform ?? "";
    message.bootImage = object.bootImage ?? "";
    message.nvidiaDriverVersion = object.nvidiaDriverVersion ?? "";
    message.enableStackdriverMonitoring = object.enableStackdriverMonitoring ?? false;
    message.dockerCacheImages = object.dockerCacheImages?.map((e) => e) || [];
    message.volumes = object.volumes?.map((e) => Volume.fromPartial(e)) || [];
    message.reservation = object.reservation ?? "";
    return message;
  },
};

function createBaseVirtualMachine_LabelsEntry(): VirtualMachine_LabelsEntry {
  return { key: "", value: "" };
}

export const VirtualMachine_LabelsEntry: MessageFns<VirtualMachine_LabelsEntry> = {
  encode(message: VirtualMachine_LabelsEntry, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.key !== "") {
      writer.uint32(10).string(message.key);
    }
    if (message.value !== "") {
      writer.uint32(18).string(message.value);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): VirtualMachine_LabelsEntry {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseVirtualMachine_LabelsEntry();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.key = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.value = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): VirtualMachine_LabelsEntry {
    return {
      key: isSet(object.key) ? globalThis.String(object.key) : "",
      value: isSet(object.value) ? globalThis.String(object.value) : "",
    };
  },

  toJSON(message: VirtualMachine_LabelsEntry): unknown {
    const obj: any = {};
    if (message.key !== "") {
      obj.key = message.key;
    }
    if (message.value !== "") {
      obj.value = message.value;
    }
    return obj;
  },

  create(base?: DeepPartial<VirtualMachine_LabelsEntry>): VirtualMachine_LabelsEntry {
    return VirtualMachine_LabelsEntry.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<VirtualMachine_LabelsEntry>): VirtualMachine_LabelsEntry {
    const message = createBaseVirtualMachine_LabelsEntry();
    message.key = object.key ?? "";
    message.value = object.value ?? "";
    return message;
  },
};

function createBaseServiceAccount(): ServiceAccount {
  return { email: "", scopes: [] };
}

export const ServiceAccount: MessageFns<ServiceAccount> = {
  encode(message: ServiceAccount, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.email !== "") {
      writer.uint32(10).string(message.email);
    }
    for (const v of message.scopes) {
      writer.uint32(18).string(v!);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ServiceAccount {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseServiceAccount();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.email = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.scopes.push(reader.string());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ServiceAccount {
    return {
      email: isSet(object.email) ? globalThis.String(object.email) : "",
      scopes: globalThis.Array.isArray(object?.scopes) ? object.scopes.map((e: any) => globalThis.String(e)) : [],
    };
  },

  toJSON(message: ServiceAccount): unknown {
    const obj: any = {};
    if (message.email !== "") {
      obj.email = message.email;
    }
    if (message.scopes?.length) {
      obj.scopes = message.scopes;
    }
    return obj;
  },

  create(base?: DeepPartial<ServiceAccount>): ServiceAccount {
    return ServiceAccount.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ServiceAccount>): ServiceAccount {
    const message = createBaseServiceAccount();
    message.email = object.email ?? "";
    message.scopes = object.scopes?.map((e) => e) || [];
    return message;
  },
};

function createBaseAccelerator(): Accelerator {
  return { type: "", count: Long.ZERO };
}

export const Accelerator: MessageFns<Accelerator> = {
  encode(message: Accelerator, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.type !== "") {
      writer.uint32(10).string(message.type);
    }
    if (!message.count.equals(Long.ZERO)) {
      writer.uint32(16).int64(message.count.toString());
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Accelerator {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseAccelerator();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.type = reader.string();
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.count = Long.fromString(reader.int64().toString());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Accelerator {
    return {
      type: isSet(object.type) ? globalThis.String(object.type) : "",
      count: isSet(object.count) ? Long.fromValue(object.count) : Long.ZERO,
    };
  },

  toJSON(message: Accelerator): unknown {
    const obj: any = {};
    if (message.type !== "") {
      obj.type = message.type;
    }
    if (!message.count.equals(Long.ZERO)) {
      obj.count = (message.count || Long.ZERO).toString();
    }
    return obj;
  },

  create(base?: DeepPartial<Accelerator>): Accelerator {
    return Accelerator.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<Accelerator>): Accelerator {
    const message = createBaseAccelerator();
    message.type = object.type ?? "";
    message.count = (object.count !== undefined && object.count !== null) ? Long.fromValue(object.count) : Long.ZERO;
    return message;
  },
};

function createBaseNetwork(): Network {
  return { network: "", usePrivateAddress: false, subnetwork: "" };
}

export const Network: MessageFns<Network> = {
  encode(message: Network, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.network !== "") {
      writer.uint32(10).string(message.network);
    }
    if (message.usePrivateAddress !== false) {
      writer.uint32(16).bool(message.usePrivateAddress);
    }
    if (message.subnetwork !== "") {
      writer.uint32(26).string(message.subnetwork);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Network {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseNetwork();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.network = reader.string();
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.usePrivateAddress = reader.bool();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.subnetwork = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Network {
    return {
      network: isSet(object.network) ? globalThis.String(object.network) : "",
      usePrivateAddress: isSet(object.usePrivateAddress) ? globalThis.Boolean(object.usePrivateAddress) : false,
      subnetwork: isSet(object.subnetwork) ? globalThis.String(object.subnetwork) : "",
    };
  },

  toJSON(message: Network): unknown {
    const obj: any = {};
    if (message.network !== "") {
      obj.network = message.network;
    }
    if (message.usePrivateAddress !== false) {
      obj.usePrivateAddress = message.usePrivateAddress;
    }
    if (message.subnetwork !== "") {
      obj.subnetwork = message.subnetwork;
    }
    return obj;
  },

  create(base?: DeepPartial<Network>): Network {
    return Network.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<Network>): Network {
    const message = createBaseNetwork();
    message.network = object.network ?? "";
    message.usePrivateAddress = object.usePrivateAddress ?? false;
    message.subnetwork = object.subnetwork ?? "";
    return message;
  },
};

function createBaseDisk(): Disk {
  return { name: "", sizeGb: 0, type: "", sourceImage: "" };
}

export const Disk: MessageFns<Disk> = {
  encode(message: Disk, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    if (message.sizeGb !== 0) {
      writer.uint32(16).int32(message.sizeGb);
    }
    if (message.type !== "") {
      writer.uint32(26).string(message.type);
    }
    if (message.sourceImage !== "") {
      writer.uint32(34).string(message.sourceImage);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Disk {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDisk();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.sizeGb = reader.int32();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.type = reader.string();
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.sourceImage = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Disk {
    return {
      name: isSet(object.name) ? globalThis.String(object.name) : "",
      sizeGb: isSet(object.sizeGb) ? globalThis.Number(object.sizeGb) : 0,
      type: isSet(object.type) ? globalThis.String(object.type) : "",
      sourceImage: isSet(object.sourceImage) ? globalThis.String(object.sourceImage) : "",
    };
  },

  toJSON(message: Disk): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    if (message.sizeGb !== 0) {
      obj.sizeGb = Math.round(message.sizeGb);
    }
    if (message.type !== "") {
      obj.type = message.type;
    }
    if (message.sourceImage !== "") {
      obj.sourceImage = message.sourceImage;
    }
    return obj;
  },

  create(base?: DeepPartial<Disk>): Disk {
    return Disk.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<Disk>): Disk {
    const message = createBaseDisk();
    message.name = object.name ?? "";
    message.sizeGb = object.sizeGb ?? 0;
    message.type = object.type ?? "";
    message.sourceImage = object.sourceImage ?? "";
    return message;
  },
};

function createBaseVolume(): Volume {
  return { volume: "", persistentDisk: undefined, existingDisk: undefined, nfsMount: undefined };
}

export const Volume: MessageFns<Volume> = {
  encode(message: Volume, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.volume !== "") {
      writer.uint32(10).string(message.volume);
    }
    if (message.persistentDisk !== undefined) {
      PersistentDisk.encode(message.persistentDisk, writer.uint32(18).fork()).join();
    }
    if (message.existingDisk !== undefined) {
      ExistingDisk.encode(message.existingDisk, writer.uint32(26).fork()).join();
    }
    if (message.nfsMount !== undefined) {
      NFSMount.encode(message.nfsMount, writer.uint32(34).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Volume {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseVolume();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.volume = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.persistentDisk = PersistentDisk.decode(reader, reader.uint32());
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.existingDisk = ExistingDisk.decode(reader, reader.uint32());
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.nfsMount = NFSMount.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Volume {
    return {
      volume: isSet(object.volume) ? globalThis.String(object.volume) : "",
      persistentDisk: isSet(object.persistentDisk) ? PersistentDisk.fromJSON(object.persistentDisk) : undefined,
      existingDisk: isSet(object.existingDisk) ? ExistingDisk.fromJSON(object.existingDisk) : undefined,
      nfsMount: isSet(object.nfsMount) ? NFSMount.fromJSON(object.nfsMount) : undefined,
    };
  },

  toJSON(message: Volume): unknown {
    const obj: any = {};
    if (message.volume !== "") {
      obj.volume = message.volume;
    }
    if (message.persistentDisk !== undefined) {
      obj.persistentDisk = PersistentDisk.toJSON(message.persistentDisk);
    }
    if (message.existingDisk !== undefined) {
      obj.existingDisk = ExistingDisk.toJSON(message.existingDisk);
    }
    if (message.nfsMount !== undefined) {
      obj.nfsMount = NFSMount.toJSON(message.nfsMount);
    }
    return obj;
  },

  create(base?: DeepPartial<Volume>): Volume {
    return Volume.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<Volume>): Volume {
    const message = createBaseVolume();
    message.volume = object.volume ?? "";
    message.persistentDisk = (object.persistentDisk !== undefined && object.persistentDisk !== null)
      ? PersistentDisk.fromPartial(object.persistentDisk)
      : undefined;
    message.existingDisk = (object.existingDisk !== undefined && object.existingDisk !== null)
      ? ExistingDisk.fromPartial(object.existingDisk)
      : undefined;
    message.nfsMount = (object.nfsMount !== undefined && object.nfsMount !== null)
      ? NFSMount.fromPartial(object.nfsMount)
      : undefined;
    return message;
  },
};

function createBasePersistentDisk(): PersistentDisk {
  return { sizeGb: 0, type: "", sourceImage: "" };
}

export const PersistentDisk: MessageFns<PersistentDisk> = {
  encode(message: PersistentDisk, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.sizeGb !== 0) {
      writer.uint32(8).int32(message.sizeGb);
    }
    if (message.type !== "") {
      writer.uint32(18).string(message.type);
    }
    if (message.sourceImage !== "") {
      writer.uint32(26).string(message.sourceImage);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): PersistentDisk {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBasePersistentDisk();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 8) {
            break;
          }

          message.sizeGb = reader.int32();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.type = reader.string();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.sourceImage = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): PersistentDisk {
    return {
      sizeGb: isSet(object.sizeGb) ? globalThis.Number(object.sizeGb) : 0,
      type: isSet(object.type) ? globalThis.String(object.type) : "",
      sourceImage: isSet(object.sourceImage) ? globalThis.String(object.sourceImage) : "",
    };
  },

  toJSON(message: PersistentDisk): unknown {
    const obj: any = {};
    if (message.sizeGb !== 0) {
      obj.sizeGb = Math.round(message.sizeGb);
    }
    if (message.type !== "") {
      obj.type = message.type;
    }
    if (message.sourceImage !== "") {
      obj.sourceImage = message.sourceImage;
    }
    return obj;
  },

  create(base?: DeepPartial<PersistentDisk>): PersistentDisk {
    return PersistentDisk.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<PersistentDisk>): PersistentDisk {
    const message = createBasePersistentDisk();
    message.sizeGb = object.sizeGb ?? 0;
    message.type = object.type ?? "";
    message.sourceImage = object.sourceImage ?? "";
    return message;
  },
};

function createBaseExistingDisk(): ExistingDisk {
  return { disk: "" };
}

export const ExistingDisk: MessageFns<ExistingDisk> = {
  encode(message: ExistingDisk, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.disk !== "") {
      writer.uint32(10).string(message.disk);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ExistingDisk {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseExistingDisk();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.disk = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ExistingDisk {
    return { disk: isSet(object.disk) ? globalThis.String(object.disk) : "" };
  },

  toJSON(message: ExistingDisk): unknown {
    const obj: any = {};
    if (message.disk !== "") {
      obj.disk = message.disk;
    }
    return obj;
  },

  create(base?: DeepPartial<ExistingDisk>): ExistingDisk {
    return ExistingDisk.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ExistingDisk>): ExistingDisk {
    const message = createBaseExistingDisk();
    message.disk = object.disk ?? "";
    return message;
  },
};

function createBaseNFSMount(): NFSMount {
  return { target: "" };
}

export const NFSMount: MessageFns<NFSMount> = {
  encode(message: NFSMount, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.target !== "") {
      writer.uint32(10).string(message.target);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): NFSMount {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseNFSMount();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.target = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): NFSMount {
    return { target: isSet(object.target) ? globalThis.String(object.target) : "" };
  },

  toJSON(message: NFSMount): unknown {
    const obj: any = {};
    if (message.target !== "") {
      obj.target = message.target;
    }
    return obj;
  },

  create(base?: DeepPartial<NFSMount>): NFSMount {
    return NFSMount.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<NFSMount>): NFSMount {
    const message = createBaseNFSMount();
    message.target = object.target ?? "";
    return message;
  },
};

function createBaseMetadata(): Metadata {
  return {
    pipeline: undefined,
    labels: {},
    events: [],
    createTime: undefined,
    startTime: undefined,
    endTime: undefined,
    pubSubTopic: "",
  };
}

export const Metadata: MessageFns<Metadata> = {
  encode(message: Metadata, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.pipeline !== undefined) {
      Pipeline.encode(message.pipeline, writer.uint32(10).fork()).join();
    }
    Object.entries(message.labels).forEach(([key, value]) => {
      Metadata_LabelsEntry.encode({ key: key as any, value }, writer.uint32(18).fork()).join();
    });
    for (const v of message.events) {
      Event.encode(v!, writer.uint32(26).fork()).join();
    }
    if (message.createTime !== undefined) {
      Timestamp.encode(toTimestamp(message.createTime), writer.uint32(34).fork()).join();
    }
    if (message.startTime !== undefined) {
      Timestamp.encode(toTimestamp(message.startTime), writer.uint32(42).fork()).join();
    }
    if (message.endTime !== undefined) {
      Timestamp.encode(toTimestamp(message.endTime), writer.uint32(50).fork()).join();
    }
    if (message.pubSubTopic !== "") {
      writer.uint32(58).string(message.pubSubTopic);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Metadata {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseMetadata();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.pipeline = Pipeline.decode(reader, reader.uint32());
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          const entry2 = Metadata_LabelsEntry.decode(reader, reader.uint32());
          if (entry2.value !== undefined) {
            message.labels[entry2.key] = entry2.value;
          }
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.events.push(Event.decode(reader, reader.uint32()));
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.createTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.startTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        case 6:
          if (tag !== 50) {
            break;
          }

          message.endTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        case 7:
          if (tag !== 58) {
            break;
          }

          message.pubSubTopic = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Metadata {
    return {
      pipeline: isSet(object.pipeline) ? Pipeline.fromJSON(object.pipeline) : undefined,
      labels: isObject(object.labels)
        ? Object.entries(object.labels).reduce<{ [key: string]: string }>((acc, [key, value]) => {
          acc[key] = String(value);
          return acc;
        }, {})
        : {},
      events: globalThis.Array.isArray(object?.events) ? object.events.map((e: any) => Event.fromJSON(e)) : [],
      createTime: isSet(object.createTime) ? fromJsonTimestamp(object.createTime) : undefined,
      startTime: isSet(object.startTime) ? fromJsonTimestamp(object.startTime) : undefined,
      endTime: isSet(object.endTime) ? fromJsonTimestamp(object.endTime) : undefined,
      pubSubTopic: isSet(object.pubSubTopic) ? globalThis.String(object.pubSubTopic) : "",
    };
  },

  toJSON(message: Metadata): unknown {
    const obj: any = {};
    if (message.pipeline !== undefined) {
      obj.pipeline = Pipeline.toJSON(message.pipeline);
    }
    if (message.labels) {
      const entries = Object.entries(message.labels);
      if (entries.length > 0) {
        obj.labels = {};
        entries.forEach(([k, v]) => {
          obj.labels[k] = v;
        });
      }
    }
    if (message.events?.length) {
      obj.events = message.events.map((e) => Event.toJSON(e));
    }
    if (message.createTime !== undefined) {
      obj.createTime = message.createTime.toISOString();
    }
    if (message.startTime !== undefined) {
      obj.startTime = message.startTime.toISOString();
    }
    if (message.endTime !== undefined) {
      obj.endTime = message.endTime.toISOString();
    }
    if (message.pubSubTopic !== "") {
      obj.pubSubTopic = message.pubSubTopic;
    }
    return obj;
  },

  create(base?: DeepPartial<Metadata>): Metadata {
    return Metadata.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<Metadata>): Metadata {
    const message = createBaseMetadata();
    message.pipeline = (object.pipeline !== undefined && object.pipeline !== null)
      ? Pipeline.fromPartial(object.pipeline)
      : undefined;
    message.labels = Object.entries(object.labels ?? {}).reduce<{ [key: string]: string }>((acc, [key, value]) => {
      if (value !== undefined) {
        acc[key] = globalThis.String(value);
      }
      return acc;
    }, {});
    message.events = object.events?.map((e) => Event.fromPartial(e)) || [];
    message.createTime = object.createTime ?? undefined;
    message.startTime = object.startTime ?? undefined;
    message.endTime = object.endTime ?? undefined;
    message.pubSubTopic = object.pubSubTopic ?? "";
    return message;
  },
};

function createBaseMetadata_LabelsEntry(): Metadata_LabelsEntry {
  return { key: "", value: "" };
}

export const Metadata_LabelsEntry: MessageFns<Metadata_LabelsEntry> = {
  encode(message: Metadata_LabelsEntry, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.key !== "") {
      writer.uint32(10).string(message.key);
    }
    if (message.value !== "") {
      writer.uint32(18).string(message.value);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Metadata_LabelsEntry {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseMetadata_LabelsEntry();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.key = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.value = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Metadata_LabelsEntry {
    return {
      key: isSet(object.key) ? globalThis.String(object.key) : "",
      value: isSet(object.value) ? globalThis.String(object.value) : "",
    };
  },

  toJSON(message: Metadata_LabelsEntry): unknown {
    const obj: any = {};
    if (message.key !== "") {
      obj.key = message.key;
    }
    if (message.value !== "") {
      obj.value = message.value;
    }
    return obj;
  },

  create(base?: DeepPartial<Metadata_LabelsEntry>): Metadata_LabelsEntry {
    return Metadata_LabelsEntry.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<Metadata_LabelsEntry>): Metadata_LabelsEntry {
    const message = createBaseMetadata_LabelsEntry();
    message.key = object.key ?? "";
    message.value = object.value ?? "";
    return message;
  },
};

function createBaseEvent(): Event {
  return {
    timestamp: undefined,
    description: "",
    delayed: undefined,
    workerAssigned: undefined,
    workerReleased: undefined,
    pullStarted: undefined,
    pullStopped: undefined,
    containerStarted: undefined,
    containerStopped: undefined,
    containerKilled: undefined,
    unexpectedExitStatus: undefined,
    failed: undefined,
  };
}

export const Event: MessageFns<Event> = {
  encode(message: Event, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.timestamp !== undefined) {
      Timestamp.encode(toTimestamp(message.timestamp), writer.uint32(10).fork()).join();
    }
    if (message.description !== "") {
      writer.uint32(18).string(message.description);
    }
    if (message.delayed !== undefined) {
      DelayedEvent.encode(message.delayed, writer.uint32(138).fork()).join();
    }
    if (message.workerAssigned !== undefined) {
      WorkerAssignedEvent.encode(message.workerAssigned, writer.uint32(146).fork()).join();
    }
    if (message.workerReleased !== undefined) {
      WorkerReleasedEvent.encode(message.workerReleased, writer.uint32(154).fork()).join();
    }
    if (message.pullStarted !== undefined) {
      PullStartedEvent.encode(message.pullStarted, writer.uint32(162).fork()).join();
    }
    if (message.pullStopped !== undefined) {
      PullStoppedEvent.encode(message.pullStopped, writer.uint32(170).fork()).join();
    }
    if (message.containerStarted !== undefined) {
      ContainerStartedEvent.encode(message.containerStarted, writer.uint32(178).fork()).join();
    }
    if (message.containerStopped !== undefined) {
      ContainerStoppedEvent.encode(message.containerStopped, writer.uint32(186).fork()).join();
    }
    if (message.containerKilled !== undefined) {
      ContainerKilledEvent.encode(message.containerKilled, writer.uint32(194).fork()).join();
    }
    if (message.unexpectedExitStatus !== undefined) {
      UnexpectedExitStatusEvent.encode(message.unexpectedExitStatus, writer.uint32(202).fork()).join();
    }
    if (message.failed !== undefined) {
      FailedEvent.encode(message.failed, writer.uint32(210).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Event {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseEvent();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.timestamp = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.description = reader.string();
          continue;
        case 17:
          if (tag !== 138) {
            break;
          }

          message.delayed = DelayedEvent.decode(reader, reader.uint32());
          continue;
        case 18:
          if (tag !== 146) {
            break;
          }

          message.workerAssigned = WorkerAssignedEvent.decode(reader, reader.uint32());
          continue;
        case 19:
          if (tag !== 154) {
            break;
          }

          message.workerReleased = WorkerReleasedEvent.decode(reader, reader.uint32());
          continue;
        case 20:
          if (tag !== 162) {
            break;
          }

          message.pullStarted = PullStartedEvent.decode(reader, reader.uint32());
          continue;
        case 21:
          if (tag !== 170) {
            break;
          }

          message.pullStopped = PullStoppedEvent.decode(reader, reader.uint32());
          continue;
        case 22:
          if (tag !== 178) {
            break;
          }

          message.containerStarted = ContainerStartedEvent.decode(reader, reader.uint32());
          continue;
        case 23:
          if (tag !== 186) {
            break;
          }

          message.containerStopped = ContainerStoppedEvent.decode(reader, reader.uint32());
          continue;
        case 24:
          if (tag !== 194) {
            break;
          }

          message.containerKilled = ContainerKilledEvent.decode(reader, reader.uint32());
          continue;
        case 25:
          if (tag !== 202) {
            break;
          }

          message.unexpectedExitStatus = UnexpectedExitStatusEvent.decode(reader, reader.uint32());
          continue;
        case 26:
          if (tag !== 210) {
            break;
          }

          message.failed = FailedEvent.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Event {
    return {
      timestamp: isSet(object.timestamp) ? fromJsonTimestamp(object.timestamp) : undefined,
      description: isSet(object.description) ? globalThis.String(object.description) : "",
      delayed: isSet(object.delayed) ? DelayedEvent.fromJSON(object.delayed) : undefined,
      workerAssigned: isSet(object.workerAssigned) ? WorkerAssignedEvent.fromJSON(object.workerAssigned) : undefined,
      workerReleased: isSet(object.workerReleased) ? WorkerReleasedEvent.fromJSON(object.workerReleased) : undefined,
      pullStarted: isSet(object.pullStarted) ? PullStartedEvent.fromJSON(object.pullStarted) : undefined,
      pullStopped: isSet(object.pullStopped) ? PullStoppedEvent.fromJSON(object.pullStopped) : undefined,
      containerStarted: isSet(object.containerStarted)
        ? ContainerStartedEvent.fromJSON(object.containerStarted)
        : undefined,
      containerStopped: isSet(object.containerStopped)
        ? ContainerStoppedEvent.fromJSON(object.containerStopped)
        : undefined,
      containerKilled: isSet(object.containerKilled)
        ? ContainerKilledEvent.fromJSON(object.containerKilled)
        : undefined,
      unexpectedExitStatus: isSet(object.unexpectedExitStatus)
        ? UnexpectedExitStatusEvent.fromJSON(object.unexpectedExitStatus)
        : undefined,
      failed: isSet(object.failed) ? FailedEvent.fromJSON(object.failed) : undefined,
    };
  },

  toJSON(message: Event): unknown {
    const obj: any = {};
    if (message.timestamp !== undefined) {
      obj.timestamp = message.timestamp.toISOString();
    }
    if (message.description !== "") {
      obj.description = message.description;
    }
    if (message.delayed !== undefined) {
      obj.delayed = DelayedEvent.toJSON(message.delayed);
    }
    if (message.workerAssigned !== undefined) {
      obj.workerAssigned = WorkerAssignedEvent.toJSON(message.workerAssigned);
    }
    if (message.workerReleased !== undefined) {
      obj.workerReleased = WorkerReleasedEvent.toJSON(message.workerReleased);
    }
    if (message.pullStarted !== undefined) {
      obj.pullStarted = PullStartedEvent.toJSON(message.pullStarted);
    }
    if (message.pullStopped !== undefined) {
      obj.pullStopped = PullStoppedEvent.toJSON(message.pullStopped);
    }
    if (message.containerStarted !== undefined) {
      obj.containerStarted = ContainerStartedEvent.toJSON(message.containerStarted);
    }
    if (message.containerStopped !== undefined) {
      obj.containerStopped = ContainerStoppedEvent.toJSON(message.containerStopped);
    }
    if (message.containerKilled !== undefined) {
      obj.containerKilled = ContainerKilledEvent.toJSON(message.containerKilled);
    }
    if (message.unexpectedExitStatus !== undefined) {
      obj.unexpectedExitStatus = UnexpectedExitStatusEvent.toJSON(message.unexpectedExitStatus);
    }
    if (message.failed !== undefined) {
      obj.failed = FailedEvent.toJSON(message.failed);
    }
    return obj;
  },

  create(base?: DeepPartial<Event>): Event {
    return Event.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<Event>): Event {
    const message = createBaseEvent();
    message.timestamp = object.timestamp ?? undefined;
    message.description = object.description ?? "";
    message.delayed = (object.delayed !== undefined && object.delayed !== null)
      ? DelayedEvent.fromPartial(object.delayed)
      : undefined;
    message.workerAssigned = (object.workerAssigned !== undefined && object.workerAssigned !== null)
      ? WorkerAssignedEvent.fromPartial(object.workerAssigned)
      : undefined;
    message.workerReleased = (object.workerReleased !== undefined && object.workerReleased !== null)
      ? WorkerReleasedEvent.fromPartial(object.workerReleased)
      : undefined;
    message.pullStarted = (object.pullStarted !== undefined && object.pullStarted !== null)
      ? PullStartedEvent.fromPartial(object.pullStarted)
      : undefined;
    message.pullStopped = (object.pullStopped !== undefined && object.pullStopped !== null)
      ? PullStoppedEvent.fromPartial(object.pullStopped)
      : undefined;
    message.containerStarted = (object.containerStarted !== undefined && object.containerStarted !== null)
      ? ContainerStartedEvent.fromPartial(object.containerStarted)
      : undefined;
    message.containerStopped = (object.containerStopped !== undefined && object.containerStopped !== null)
      ? ContainerStoppedEvent.fromPartial(object.containerStopped)
      : undefined;
    message.containerKilled = (object.containerKilled !== undefined && object.containerKilled !== null)
      ? ContainerKilledEvent.fromPartial(object.containerKilled)
      : undefined;
    message.unexpectedExitStatus = (object.unexpectedExitStatus !== undefined && object.unexpectedExitStatus !== null)
      ? UnexpectedExitStatusEvent.fromPartial(object.unexpectedExitStatus)
      : undefined;
    message.failed = (object.failed !== undefined && object.failed !== null)
      ? FailedEvent.fromPartial(object.failed)
      : undefined;
    return message;
  },
};

function createBaseDelayedEvent(): DelayedEvent {
  return { cause: "", metrics: [] };
}

export const DelayedEvent: MessageFns<DelayedEvent> = {
  encode(message: DelayedEvent, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.cause !== "") {
      writer.uint32(10).string(message.cause);
    }
    for (const v of message.metrics) {
      writer.uint32(18).string(v!);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): DelayedEvent {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDelayedEvent();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.cause = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.metrics.push(reader.string());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): DelayedEvent {
    return {
      cause: isSet(object.cause) ? globalThis.String(object.cause) : "",
      metrics: globalThis.Array.isArray(object?.metrics) ? object.metrics.map((e: any) => globalThis.String(e)) : [],
    };
  },

  toJSON(message: DelayedEvent): unknown {
    const obj: any = {};
    if (message.cause !== "") {
      obj.cause = message.cause;
    }
    if (message.metrics?.length) {
      obj.metrics = message.metrics;
    }
    return obj;
  },

  create(base?: DeepPartial<DelayedEvent>): DelayedEvent {
    return DelayedEvent.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<DelayedEvent>): DelayedEvent {
    const message = createBaseDelayedEvent();
    message.cause = object.cause ?? "";
    message.metrics = object.metrics?.map((e) => e) || [];
    return message;
  },
};

function createBaseWorkerAssignedEvent(): WorkerAssignedEvent {
  return { zone: "", instance: "", machineType: "" };
}

export const WorkerAssignedEvent: MessageFns<WorkerAssignedEvent> = {
  encode(message: WorkerAssignedEvent, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.zone !== "") {
      writer.uint32(10).string(message.zone);
    }
    if (message.instance !== "") {
      writer.uint32(18).string(message.instance);
    }
    if (message.machineType !== "") {
      writer.uint32(26).string(message.machineType);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): WorkerAssignedEvent {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseWorkerAssignedEvent();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.zone = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.instance = reader.string();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.machineType = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): WorkerAssignedEvent {
    return {
      zone: isSet(object.zone) ? globalThis.String(object.zone) : "",
      instance: isSet(object.instance) ? globalThis.String(object.instance) : "",
      machineType: isSet(object.machineType) ? globalThis.String(object.machineType) : "",
    };
  },

  toJSON(message: WorkerAssignedEvent): unknown {
    const obj: any = {};
    if (message.zone !== "") {
      obj.zone = message.zone;
    }
    if (message.instance !== "") {
      obj.instance = message.instance;
    }
    if (message.machineType !== "") {
      obj.machineType = message.machineType;
    }
    return obj;
  },

  create(base?: DeepPartial<WorkerAssignedEvent>): WorkerAssignedEvent {
    return WorkerAssignedEvent.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<WorkerAssignedEvent>): WorkerAssignedEvent {
    const message = createBaseWorkerAssignedEvent();
    message.zone = object.zone ?? "";
    message.instance = object.instance ?? "";
    message.machineType = object.machineType ?? "";
    return message;
  },
};

function createBaseWorkerReleasedEvent(): WorkerReleasedEvent {
  return { zone: "", instance: "" };
}

export const WorkerReleasedEvent: MessageFns<WorkerReleasedEvent> = {
  encode(message: WorkerReleasedEvent, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.zone !== "") {
      writer.uint32(10).string(message.zone);
    }
    if (message.instance !== "") {
      writer.uint32(18).string(message.instance);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): WorkerReleasedEvent {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseWorkerReleasedEvent();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.zone = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.instance = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): WorkerReleasedEvent {
    return {
      zone: isSet(object.zone) ? globalThis.String(object.zone) : "",
      instance: isSet(object.instance) ? globalThis.String(object.instance) : "",
    };
  },

  toJSON(message: WorkerReleasedEvent): unknown {
    const obj: any = {};
    if (message.zone !== "") {
      obj.zone = message.zone;
    }
    if (message.instance !== "") {
      obj.instance = message.instance;
    }
    return obj;
  },

  create(base?: DeepPartial<WorkerReleasedEvent>): WorkerReleasedEvent {
    return WorkerReleasedEvent.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<WorkerReleasedEvent>): WorkerReleasedEvent {
    const message = createBaseWorkerReleasedEvent();
    message.zone = object.zone ?? "";
    message.instance = object.instance ?? "";
    return message;
  },
};

function createBasePullStartedEvent(): PullStartedEvent {
  return { imageUri: "" };
}

export const PullStartedEvent: MessageFns<PullStartedEvent> = {
  encode(message: PullStartedEvent, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.imageUri !== "") {
      writer.uint32(10).string(message.imageUri);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): PullStartedEvent {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBasePullStartedEvent();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.imageUri = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): PullStartedEvent {
    return { imageUri: isSet(object.imageUri) ? globalThis.String(object.imageUri) : "" };
  },

  toJSON(message: PullStartedEvent): unknown {
    const obj: any = {};
    if (message.imageUri !== "") {
      obj.imageUri = message.imageUri;
    }
    return obj;
  },

  create(base?: DeepPartial<PullStartedEvent>): PullStartedEvent {
    return PullStartedEvent.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<PullStartedEvent>): PullStartedEvent {
    const message = createBasePullStartedEvent();
    message.imageUri = object.imageUri ?? "";
    return message;
  },
};

function createBasePullStoppedEvent(): PullStoppedEvent {
  return { imageUri: "" };
}

export const PullStoppedEvent: MessageFns<PullStoppedEvent> = {
  encode(message: PullStoppedEvent, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.imageUri !== "") {
      writer.uint32(10).string(message.imageUri);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): PullStoppedEvent {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBasePullStoppedEvent();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.imageUri = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): PullStoppedEvent {
    return { imageUri: isSet(object.imageUri) ? globalThis.String(object.imageUri) : "" };
  },

  toJSON(message: PullStoppedEvent): unknown {
    const obj: any = {};
    if (message.imageUri !== "") {
      obj.imageUri = message.imageUri;
    }
    return obj;
  },

  create(base?: DeepPartial<PullStoppedEvent>): PullStoppedEvent {
    return PullStoppedEvent.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<PullStoppedEvent>): PullStoppedEvent {
    const message = createBasePullStoppedEvent();
    message.imageUri = object.imageUri ?? "";
    return message;
  },
};

function createBaseContainerStartedEvent(): ContainerStartedEvent {
  return { actionId: 0, portMappings: {}, ipAddress: "" };
}

export const ContainerStartedEvent: MessageFns<ContainerStartedEvent> = {
  encode(message: ContainerStartedEvent, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.actionId !== 0) {
      writer.uint32(8).int32(message.actionId);
    }
    Object.entries(message.portMappings).forEach(([key, value]) => {
      ContainerStartedEvent_PortMappingsEntry.encode({ key: key as any, value }, writer.uint32(18).fork()).join();
    });
    if (message.ipAddress !== "") {
      writer.uint32(26).string(message.ipAddress);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ContainerStartedEvent {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseContainerStartedEvent();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 8) {
            break;
          }

          message.actionId = reader.int32();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          const entry2 = ContainerStartedEvent_PortMappingsEntry.decode(reader, reader.uint32());
          if (entry2.value !== undefined) {
            message.portMappings[entry2.key] = entry2.value;
          }
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.ipAddress = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ContainerStartedEvent {
    return {
      actionId: isSet(object.actionId) ? globalThis.Number(object.actionId) : 0,
      portMappings: isObject(object.portMappings)
        ? Object.entries(object.portMappings).reduce<{ [key: number]: number }>((acc, [key, value]) => {
          acc[globalThis.Number(key)] = Number(value);
          return acc;
        }, {})
        : {},
      ipAddress: isSet(object.ipAddress) ? globalThis.String(object.ipAddress) : "",
    };
  },

  toJSON(message: ContainerStartedEvent): unknown {
    const obj: any = {};
    if (message.actionId !== 0) {
      obj.actionId = Math.round(message.actionId);
    }
    if (message.portMappings) {
      const entries = Object.entries(message.portMappings);
      if (entries.length > 0) {
        obj.portMappings = {};
        entries.forEach(([k, v]) => {
          obj.portMappings[k] = Math.round(v);
        });
      }
    }
    if (message.ipAddress !== "") {
      obj.ipAddress = message.ipAddress;
    }
    return obj;
  },

  create(base?: DeepPartial<ContainerStartedEvent>): ContainerStartedEvent {
    return ContainerStartedEvent.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ContainerStartedEvent>): ContainerStartedEvent {
    const message = createBaseContainerStartedEvent();
    message.actionId = object.actionId ?? 0;
    message.portMappings = Object.entries(object.portMappings ?? {}).reduce<{ [key: number]: number }>(
      (acc, [key, value]) => {
        if (value !== undefined) {
          acc[globalThis.Number(key)] = globalThis.Number(value);
        }
        return acc;
      },
      {},
    );
    message.ipAddress = object.ipAddress ?? "";
    return message;
  },
};

function createBaseContainerStartedEvent_PortMappingsEntry(): ContainerStartedEvent_PortMappingsEntry {
  return { key: 0, value: 0 };
}

export const ContainerStartedEvent_PortMappingsEntry: MessageFns<ContainerStartedEvent_PortMappingsEntry> = {
  encode(message: ContainerStartedEvent_PortMappingsEntry, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.key !== 0) {
      writer.uint32(8).int32(message.key);
    }
    if (message.value !== 0) {
      writer.uint32(16).int32(message.value);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ContainerStartedEvent_PortMappingsEntry {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseContainerStartedEvent_PortMappingsEntry();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 8) {
            break;
          }

          message.key = reader.int32();
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.value = reader.int32();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ContainerStartedEvent_PortMappingsEntry {
    return {
      key: isSet(object.key) ? globalThis.Number(object.key) : 0,
      value: isSet(object.value) ? globalThis.Number(object.value) : 0,
    };
  },

  toJSON(message: ContainerStartedEvent_PortMappingsEntry): unknown {
    const obj: any = {};
    if (message.key !== 0) {
      obj.key = Math.round(message.key);
    }
    if (message.value !== 0) {
      obj.value = Math.round(message.value);
    }
    return obj;
  },

  create(base?: DeepPartial<ContainerStartedEvent_PortMappingsEntry>): ContainerStartedEvent_PortMappingsEntry {
    return ContainerStartedEvent_PortMappingsEntry.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ContainerStartedEvent_PortMappingsEntry>): ContainerStartedEvent_PortMappingsEntry {
    const message = createBaseContainerStartedEvent_PortMappingsEntry();
    message.key = object.key ?? 0;
    message.value = object.value ?? 0;
    return message;
  },
};

function createBaseContainerStoppedEvent(): ContainerStoppedEvent {
  return { actionId: 0, exitStatus: 0, stderr: "" };
}

export const ContainerStoppedEvent: MessageFns<ContainerStoppedEvent> = {
  encode(message: ContainerStoppedEvent, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.actionId !== 0) {
      writer.uint32(8).int32(message.actionId);
    }
    if (message.exitStatus !== 0) {
      writer.uint32(16).int32(message.exitStatus);
    }
    if (message.stderr !== "") {
      writer.uint32(26).string(message.stderr);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ContainerStoppedEvent {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseContainerStoppedEvent();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 8) {
            break;
          }

          message.actionId = reader.int32();
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.exitStatus = reader.int32();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.stderr = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ContainerStoppedEvent {
    return {
      actionId: isSet(object.actionId) ? globalThis.Number(object.actionId) : 0,
      exitStatus: isSet(object.exitStatus) ? globalThis.Number(object.exitStatus) : 0,
      stderr: isSet(object.stderr) ? globalThis.String(object.stderr) : "",
    };
  },

  toJSON(message: ContainerStoppedEvent): unknown {
    const obj: any = {};
    if (message.actionId !== 0) {
      obj.actionId = Math.round(message.actionId);
    }
    if (message.exitStatus !== 0) {
      obj.exitStatus = Math.round(message.exitStatus);
    }
    if (message.stderr !== "") {
      obj.stderr = message.stderr;
    }
    return obj;
  },

  create(base?: DeepPartial<ContainerStoppedEvent>): ContainerStoppedEvent {
    return ContainerStoppedEvent.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ContainerStoppedEvent>): ContainerStoppedEvent {
    const message = createBaseContainerStoppedEvent();
    message.actionId = object.actionId ?? 0;
    message.exitStatus = object.exitStatus ?? 0;
    message.stderr = object.stderr ?? "";
    return message;
  },
};

function createBaseUnexpectedExitStatusEvent(): UnexpectedExitStatusEvent {
  return { actionId: 0, exitStatus: 0 };
}

export const UnexpectedExitStatusEvent: MessageFns<UnexpectedExitStatusEvent> = {
  encode(message: UnexpectedExitStatusEvent, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.actionId !== 0) {
      writer.uint32(8).int32(message.actionId);
    }
    if (message.exitStatus !== 0) {
      writer.uint32(16).int32(message.exitStatus);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): UnexpectedExitStatusEvent {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseUnexpectedExitStatusEvent();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 8) {
            break;
          }

          message.actionId = reader.int32();
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.exitStatus = reader.int32();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): UnexpectedExitStatusEvent {
    return {
      actionId: isSet(object.actionId) ? globalThis.Number(object.actionId) : 0,
      exitStatus: isSet(object.exitStatus) ? globalThis.Number(object.exitStatus) : 0,
    };
  },

  toJSON(message: UnexpectedExitStatusEvent): unknown {
    const obj: any = {};
    if (message.actionId !== 0) {
      obj.actionId = Math.round(message.actionId);
    }
    if (message.exitStatus !== 0) {
      obj.exitStatus = Math.round(message.exitStatus);
    }
    return obj;
  },

  create(base?: DeepPartial<UnexpectedExitStatusEvent>): UnexpectedExitStatusEvent {
    return UnexpectedExitStatusEvent.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<UnexpectedExitStatusEvent>): UnexpectedExitStatusEvent {
    const message = createBaseUnexpectedExitStatusEvent();
    message.actionId = object.actionId ?? 0;
    message.exitStatus = object.exitStatus ?? 0;
    return message;
  },
};

function createBaseContainerKilledEvent(): ContainerKilledEvent {
  return { actionId: 0 };
}

export const ContainerKilledEvent: MessageFns<ContainerKilledEvent> = {
  encode(message: ContainerKilledEvent, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.actionId !== 0) {
      writer.uint32(8).int32(message.actionId);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ContainerKilledEvent {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseContainerKilledEvent();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 8) {
            break;
          }

          message.actionId = reader.int32();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ContainerKilledEvent {
    return { actionId: isSet(object.actionId) ? globalThis.Number(object.actionId) : 0 };
  },

  toJSON(message: ContainerKilledEvent): unknown {
    const obj: any = {};
    if (message.actionId !== 0) {
      obj.actionId = Math.round(message.actionId);
    }
    return obj;
  },

  create(base?: DeepPartial<ContainerKilledEvent>): ContainerKilledEvent {
    return ContainerKilledEvent.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ContainerKilledEvent>): ContainerKilledEvent {
    const message = createBaseContainerKilledEvent();
    message.actionId = object.actionId ?? 0;
    return message;
  },
};

function createBaseFailedEvent(): FailedEvent {
  return { code: 0, cause: "" };
}

export const FailedEvent: MessageFns<FailedEvent> = {
  encode(message: FailedEvent, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.code !== 0) {
      writer.uint32(8).int32(message.code);
    }
    if (message.cause !== "") {
      writer.uint32(18).string(message.cause);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): FailedEvent {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseFailedEvent();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 8) {
            break;
          }

          message.code = reader.int32() as any;
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.cause = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): FailedEvent {
    return {
      code: isSet(object.code) ? codeFromJSON(object.code) : 0,
      cause: isSet(object.cause) ? globalThis.String(object.cause) : "",
    };
  },

  toJSON(message: FailedEvent): unknown {
    const obj: any = {};
    if (message.code !== 0) {
      obj.code = codeToJSON(message.code);
    }
    if (message.cause !== "") {
      obj.cause = message.cause;
    }
    return obj;
  },

  create(base?: DeepPartial<FailedEvent>): FailedEvent {
    return FailedEvent.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<FailedEvent>): FailedEvent {
    const message = createBaseFailedEvent();
    message.code = object.code ?? 0;
    message.cause = object.cause ?? "";
    return message;
  },
};

/**
 * A service for running workflows, such as pipelines consisting of Docker
 * containers.
 */
export type WorkflowsServiceV2BetaDefinition = typeof WorkflowsServiceV2BetaDefinition;
export const WorkflowsServiceV2BetaDefinition = {
  name: "WorkflowsServiceV2Beta",
  fullName: "google.cloud.lifesciences.v2beta.WorkflowsServiceV2Beta",
  methods: {
    /**
     * Runs a pipeline.  The returned Operation's [metadata]
     * [google.longrunning.Operation.metadata] field will contain a
     * [google.cloud.lifesciences.v2beta.Metadata][google.cloud.lifesciences.v2beta.Metadata]
     * object describing the status of the pipeline execution. The
     * [response][google.longrunning.Operation.response] field will contain a
     * [google.cloud.lifesciences.v2beta.RunPipelineResponse][google.cloud.lifesciences.v2beta.RunPipelineResponse]
     * object if the pipeline completes successfully.
     *
     * **Note:** Before you can use this method, the *Life Sciences Service Agent*
     * must have access to your project. This is done automatically when the
     * Cloud Life Sciences API is first enabled, but if you delete this permission
     * you must disable and re-enable the API to grant the Life Sciences
     * Service Agent the required permissions.
     * Authorization requires the following [Google
     * IAM](https://cloud.google.com/iam/) permission:
     *
     * * `lifesciences.workflows.run`
     */
    runPipeline: {
      name: "RunPipeline",
      requestType: RunPipelineRequest,
      requestStream: false,
      responseType: Operation,
      responseStream: false,
      options: {
        _unknownFields: {
          8394: [
            Buffer.from([
              31,
              10,
              19,
              82,
              117,
              110,
              80,
              105,
              112,
              101,
              108,
              105,
              110,
              101,
              82,
              101,
              115,
              112,
              111,
              110,
              115,
              101,
              18,
              8,
              77,
              101,
              116,
              97,
              100,
              97,
              116,
              97,
            ]),
          ],
          578365826: [
            Buffer.from([
              58,
              58,
              1,
              42,
              34,
              53,
              47,
              118,
              50,
              98,
              101,
              116,
              97,
              47,
              123,
              112,
              97,
              114,
              101,
              110,
              116,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              125,
              47,
              112,
              105,
              112,
              101,
              108,
              105,
              110,
              101,
              115,
              58,
              114,
              117,
              110,
            ]),
          ],
        },
      },
    },
  },
} as const;

export interface WorkflowsServiceV2BetaServiceImplementation<CallContextExt = {}> {
  /**
   * Runs a pipeline.  The returned Operation's [metadata]
   * [google.longrunning.Operation.metadata] field will contain a
   * [google.cloud.lifesciences.v2beta.Metadata][google.cloud.lifesciences.v2beta.Metadata]
   * object describing the status of the pipeline execution. The
   * [response][google.longrunning.Operation.response] field will contain a
   * [google.cloud.lifesciences.v2beta.RunPipelineResponse][google.cloud.lifesciences.v2beta.RunPipelineResponse]
   * object if the pipeline completes successfully.
   *
   * **Note:** Before you can use this method, the *Life Sciences Service Agent*
   * must have access to your project. This is done automatically when the
   * Cloud Life Sciences API is first enabled, but if you delete this permission
   * you must disable and re-enable the API to grant the Life Sciences
   * Service Agent the required permissions.
   * Authorization requires the following [Google
   * IAM](https://cloud.google.com/iam/) permission:
   *
   * * `lifesciences.workflows.run`
   */
  runPipeline(request: RunPipelineRequest, context: CallContext & CallContextExt): Promise<DeepPartial<Operation>>;
}

export interface WorkflowsServiceV2BetaClient<CallOptionsExt = {}> {
  /**
   * Runs a pipeline.  The returned Operation's [metadata]
   * [google.longrunning.Operation.metadata] field will contain a
   * [google.cloud.lifesciences.v2beta.Metadata][google.cloud.lifesciences.v2beta.Metadata]
   * object describing the status of the pipeline execution. The
   * [response][google.longrunning.Operation.response] field will contain a
   * [google.cloud.lifesciences.v2beta.RunPipelineResponse][google.cloud.lifesciences.v2beta.RunPipelineResponse]
   * object if the pipeline completes successfully.
   *
   * **Note:** Before you can use this method, the *Life Sciences Service Agent*
   * must have access to your project. This is done automatically when the
   * Cloud Life Sciences API is first enabled, but if you delete this permission
   * you must disable and re-enable the API to grant the Life Sciences
   * Service Agent the required permissions.
   * Authorization requires the following [Google
   * IAM](https://cloud.google.com/iam/) permission:
   *
   * * `lifesciences.workflows.run`
   */
  runPipeline(request: DeepPartial<RunPipelineRequest>, options?: CallOptions & CallOptionsExt): Promise<Operation>;
}

type Builtin = Date | Function | Uint8Array | string | number | boolean | undefined;

export type DeepPartial<T> = T extends Builtin ? T
  : T extends Long ? string | number | Long : T extends globalThis.Array<infer U> ? globalThis.Array<DeepPartial<U>>
  : T extends ReadonlyArray<infer U> ? ReadonlyArray<DeepPartial<U>>
  : T extends {} ? { [K in keyof T]?: DeepPartial<T[K]> }
  : Partial<T>;

function toTimestamp(date: Date): Timestamp {
  const seconds = numberToLong(Math.trunc(date.getTime() / 1_000));
  const nanos = (date.getTime() % 1_000) * 1_000_000;
  return { seconds, nanos };
}

function fromTimestamp(t: Timestamp): Date {
  let millis = (t.seconds.toNumber() || 0) * 1_000;
  millis += (t.nanos || 0) / 1_000_000;
  return new globalThis.Date(millis);
}

function fromJsonTimestamp(o: any): Date {
  if (o instanceof globalThis.Date) {
    return o;
  } else if (typeof o === "string") {
    return new globalThis.Date(o);
  } else {
    return fromTimestamp(Timestamp.fromJSON(o));
  }
}

function numberToLong(number: number) {
  return Long.fromNumber(number);
}

function isObject(value: any): boolean {
  return typeof value === "object" && value !== null;
}

function isSet(value: any): boolean {
  return value !== null && value !== undefined;
}

export interface MessageFns<T> {
  encode(message: T, writer?: BinaryWriter): BinaryWriter;
  decode(input: BinaryReader | Uint8Array, length?: number): T;
  fromJSON(object: any): T;
  toJSON(message: T): unknown;
  create(base?: DeepPartial<T>): T;
  fromPartial(object: DeepPartial<T>): T;
}
