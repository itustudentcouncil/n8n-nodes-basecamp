// Code generated by protoc-gen-ts_proto. DO NOT EDIT.
// versions:
//   protoc-gen-ts_proto  v2.2.0
//   protoc               unknown
// source: google/cloud/dataplex/v1/processing.proto

/* eslint-disable */
import { BinaryReader, BinaryWriter } from "@bufbuild/protobuf/wire";
import Long from "long";

export const protobufPackage = "google.cloud.dataplex.v1";

/** DataScan scheduling and trigger settings. */
export interface Trigger {
  /** The scan runs once via `RunDataScan` API. */
  onDemand?:
    | Trigger_OnDemand
    | undefined;
  /** The scan is scheduled to run periodically. */
  schedule?: Trigger_Schedule | undefined;
}

/** The scan runs once via `RunDataScan` API. */
export interface Trigger_OnDemand {
}

/** The scan is scheduled to run periodically. */
export interface Trigger_Schedule {
  /**
   * Required. [Cron](https://en.wikipedia.org/wiki/Cron) schedule for running
   * scans periodically.
   *
   * To explicitly set a timezone in the cron tab, apply a prefix in the
   * cron tab: **"CRON_TZ=${IANA_TIME_ZONE}"** or **"TZ=${IANA_TIME_ZONE}"**.
   * The **${IANA_TIME_ZONE}** may only be a valid string from IANA time zone
   * database
   * ([wikipedia](https://en.wikipedia.org/wiki/List_of_tz_database_time_zones#List)).
   * For example, `CRON_TZ=America/New_York 1 * * * *`, or
   * `TZ=America/New_York 1 * * * *`.
   *
   * This field is required for Schedule scans.
   */
  cron: string;
}

/** The data source for DataScan. */
export interface DataSource {
  /**
   * Immutable. The Dataplex entity that represents the data source (e.g.
   * BigQuery table) for DataScan, of the form:
   * `projects/{project_number}/locations/{location_id}/lakes/{lake_id}/zones/{zone_id}/entities/{entity_id}`.
   */
  entity?:
    | string
    | undefined;
  /**
   * Immutable. The service-qualified full resource name of the cloud resource
   * for a DataScan job to scan against. The field could be: BigQuery table of
   * type "TABLE" for DataProfileScan/DataQualityScan Format:
   * //bigquery.googleapis.com/projects/PROJECT_ID/datasets/DATASET_ID/tables/TABLE_ID
   */
  resource?: string | undefined;
}

/** The data scanned during processing (e.g. in incremental DataScan) */
export interface ScannedData {
  /** The range denoted by values of an incremental field */
  incrementalField?: ScannedData_IncrementalField | undefined;
}

/** A data range denoted by a pair of start/end values of a field. */
export interface ScannedData_IncrementalField {
  /**
   * The field that contains values which monotonically increases over time
   * (e.g. a timestamp column).
   */
  field: string;
  /** Value that marks the start of the range. */
  start: string;
  /** Value that marks the end of the range. */
  end: string;
}

function createBaseTrigger(): Trigger {
  return { onDemand: undefined, schedule: undefined };
}

export const Trigger: MessageFns<Trigger> = {
  encode(message: Trigger, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.onDemand !== undefined) {
      Trigger_OnDemand.encode(message.onDemand, writer.uint32(802).fork()).join();
    }
    if (message.schedule !== undefined) {
      Trigger_Schedule.encode(message.schedule, writer.uint32(810).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Trigger {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseTrigger();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 100:
          if (tag !== 802) {
            break;
          }

          message.onDemand = Trigger_OnDemand.decode(reader, reader.uint32());
          continue;
        case 101:
          if (tag !== 810) {
            break;
          }

          message.schedule = Trigger_Schedule.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Trigger {
    return {
      onDemand: isSet(object.onDemand) ? Trigger_OnDemand.fromJSON(object.onDemand) : undefined,
      schedule: isSet(object.schedule) ? Trigger_Schedule.fromJSON(object.schedule) : undefined,
    };
  },

  toJSON(message: Trigger): unknown {
    const obj: any = {};
    if (message.onDemand !== undefined) {
      obj.onDemand = Trigger_OnDemand.toJSON(message.onDemand);
    }
    if (message.schedule !== undefined) {
      obj.schedule = Trigger_Schedule.toJSON(message.schedule);
    }
    return obj;
  },

  create(base?: DeepPartial<Trigger>): Trigger {
    return Trigger.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<Trigger>): Trigger {
    const message = createBaseTrigger();
    message.onDemand = (object.onDemand !== undefined && object.onDemand !== null)
      ? Trigger_OnDemand.fromPartial(object.onDemand)
      : undefined;
    message.schedule = (object.schedule !== undefined && object.schedule !== null)
      ? Trigger_Schedule.fromPartial(object.schedule)
      : undefined;
    return message;
  },
};

function createBaseTrigger_OnDemand(): Trigger_OnDemand {
  return {};
}

export const Trigger_OnDemand: MessageFns<Trigger_OnDemand> = {
  encode(_: Trigger_OnDemand, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Trigger_OnDemand {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseTrigger_OnDemand();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(_: any): Trigger_OnDemand {
    return {};
  },

  toJSON(_: Trigger_OnDemand): unknown {
    const obj: any = {};
    return obj;
  },

  create(base?: DeepPartial<Trigger_OnDemand>): Trigger_OnDemand {
    return Trigger_OnDemand.fromPartial(base ?? {});
  },
  fromPartial(_: DeepPartial<Trigger_OnDemand>): Trigger_OnDemand {
    const message = createBaseTrigger_OnDemand();
    return message;
  },
};

function createBaseTrigger_Schedule(): Trigger_Schedule {
  return { cron: "" };
}

export const Trigger_Schedule: MessageFns<Trigger_Schedule> = {
  encode(message: Trigger_Schedule, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.cron !== "") {
      writer.uint32(10).string(message.cron);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Trigger_Schedule {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseTrigger_Schedule();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.cron = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Trigger_Schedule {
    return { cron: isSet(object.cron) ? globalThis.String(object.cron) : "" };
  },

  toJSON(message: Trigger_Schedule): unknown {
    const obj: any = {};
    if (message.cron !== "") {
      obj.cron = message.cron;
    }
    return obj;
  },

  create(base?: DeepPartial<Trigger_Schedule>): Trigger_Schedule {
    return Trigger_Schedule.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<Trigger_Schedule>): Trigger_Schedule {
    const message = createBaseTrigger_Schedule();
    message.cron = object.cron ?? "";
    return message;
  },
};

function createBaseDataSource(): DataSource {
  return { entity: undefined, resource: undefined };
}

export const DataSource: MessageFns<DataSource> = {
  encode(message: DataSource, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.entity !== undefined) {
      writer.uint32(802).string(message.entity);
    }
    if (message.resource !== undefined) {
      writer.uint32(810).string(message.resource);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): DataSource {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDataSource();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 100:
          if (tag !== 802) {
            break;
          }

          message.entity = reader.string();
          continue;
        case 101:
          if (tag !== 810) {
            break;
          }

          message.resource = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): DataSource {
    return {
      entity: isSet(object.entity) ? globalThis.String(object.entity) : undefined,
      resource: isSet(object.resource) ? globalThis.String(object.resource) : undefined,
    };
  },

  toJSON(message: DataSource): unknown {
    const obj: any = {};
    if (message.entity !== undefined) {
      obj.entity = message.entity;
    }
    if (message.resource !== undefined) {
      obj.resource = message.resource;
    }
    return obj;
  },

  create(base?: DeepPartial<DataSource>): DataSource {
    return DataSource.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<DataSource>): DataSource {
    const message = createBaseDataSource();
    message.entity = object.entity ?? undefined;
    message.resource = object.resource ?? undefined;
    return message;
  },
};

function createBaseScannedData(): ScannedData {
  return { incrementalField: undefined };
}

export const ScannedData: MessageFns<ScannedData> = {
  encode(message: ScannedData, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.incrementalField !== undefined) {
      ScannedData_IncrementalField.encode(message.incrementalField, writer.uint32(10).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ScannedData {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseScannedData();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.incrementalField = ScannedData_IncrementalField.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ScannedData {
    return {
      incrementalField: isSet(object.incrementalField)
        ? ScannedData_IncrementalField.fromJSON(object.incrementalField)
        : undefined,
    };
  },

  toJSON(message: ScannedData): unknown {
    const obj: any = {};
    if (message.incrementalField !== undefined) {
      obj.incrementalField = ScannedData_IncrementalField.toJSON(message.incrementalField);
    }
    return obj;
  },

  create(base?: DeepPartial<ScannedData>): ScannedData {
    return ScannedData.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ScannedData>): ScannedData {
    const message = createBaseScannedData();
    message.incrementalField = (object.incrementalField !== undefined && object.incrementalField !== null)
      ? ScannedData_IncrementalField.fromPartial(object.incrementalField)
      : undefined;
    return message;
  },
};

function createBaseScannedData_IncrementalField(): ScannedData_IncrementalField {
  return { field: "", start: "", end: "" };
}

export const ScannedData_IncrementalField: MessageFns<ScannedData_IncrementalField> = {
  encode(message: ScannedData_IncrementalField, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.field !== "") {
      writer.uint32(10).string(message.field);
    }
    if (message.start !== "") {
      writer.uint32(18).string(message.start);
    }
    if (message.end !== "") {
      writer.uint32(26).string(message.end);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ScannedData_IncrementalField {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseScannedData_IncrementalField();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.field = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.start = reader.string();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.end = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ScannedData_IncrementalField {
    return {
      field: isSet(object.field) ? globalThis.String(object.field) : "",
      start: isSet(object.start) ? globalThis.String(object.start) : "",
      end: isSet(object.end) ? globalThis.String(object.end) : "",
    };
  },

  toJSON(message: ScannedData_IncrementalField): unknown {
    const obj: any = {};
    if (message.field !== "") {
      obj.field = message.field;
    }
    if (message.start !== "") {
      obj.start = message.start;
    }
    if (message.end !== "") {
      obj.end = message.end;
    }
    return obj;
  },

  create(base?: DeepPartial<ScannedData_IncrementalField>): ScannedData_IncrementalField {
    return ScannedData_IncrementalField.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ScannedData_IncrementalField>): ScannedData_IncrementalField {
    const message = createBaseScannedData_IncrementalField();
    message.field = object.field ?? "";
    message.start = object.start ?? "";
    message.end = object.end ?? "";
    return message;
  },
};

type Builtin = Date | Function | Uint8Array | string | number | boolean | undefined;

export type DeepPartial<T> = T extends Builtin ? T
  : T extends Long ? string | number | Long : T extends globalThis.Array<infer U> ? globalThis.Array<DeepPartial<U>>
  : T extends ReadonlyArray<infer U> ? ReadonlyArray<DeepPartial<U>>
  : T extends {} ? { [K in keyof T]?: DeepPartial<T[K]> }
  : Partial<T>;

function isSet(value: any): boolean {
  return value !== null && value !== undefined;
}

export interface MessageFns<T> {
  encode(message: T, writer?: BinaryWriter): BinaryWriter;
  decode(input: BinaryReader | Uint8Array, length?: number): T;
  fromJSON(object: any): T;
  toJSON(message: T): unknown;
  create(base?: DeepPartial<T>): T;
  fromPartial(object: DeepPartial<T>): T;
}
