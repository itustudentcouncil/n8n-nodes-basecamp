// Code generated by protoc-gen-ts_proto. DO NOT EDIT.
// versions:
//   protoc-gen-ts_proto  v2.2.0
//   protoc               unknown
// source: google/cloud/dataplex/v1/logs.proto

/* eslint-disable */
import { BinaryReader, BinaryWriter } from "@bufbuild/protobuf/wire";
import Long from "long";
import { Duration } from "../../../protobuf/duration.js";
import { Timestamp } from "../../../protobuf/timestamp.js";

export const protobufPackage = "google.cloud.dataplex.v1";

/** The payload associated with Discovery data processing. */
export interface DiscoveryEvent {
  /** The log message. */
  message: string;
  /** The id of the associated lake. */
  lakeId: string;
  /** The id of the associated zone. */
  zoneId: string;
  /** The id of the associated asset. */
  assetId: string;
  /** The data location associated with the event. */
  dataLocation: string;
  /** The type of the event being logged. */
  type: DiscoveryEvent_EventType;
  /** Details about discovery configuration in effect. */
  config?:
    | DiscoveryEvent_ConfigDetails
    | undefined;
  /** Details about the entity associated with the event. */
  entity?:
    | DiscoveryEvent_EntityDetails
    | undefined;
  /** Details about the partition associated with the event. */
  partition?:
    | DiscoveryEvent_PartitionDetails
    | undefined;
  /** Details about the action associated with the event. */
  action?: DiscoveryEvent_ActionDetails | undefined;
}

/** The type of the event. */
export enum DiscoveryEvent_EventType {
  /** EVENT_TYPE_UNSPECIFIED - An unspecified event type. */
  EVENT_TYPE_UNSPECIFIED = 0,
  /** CONFIG - An event representing discovery configuration in effect. */
  CONFIG = 1,
  /** ENTITY_CREATED - An event representing a metadata entity being created. */
  ENTITY_CREATED = 2,
  /** ENTITY_UPDATED - An event representing a metadata entity being updated. */
  ENTITY_UPDATED = 3,
  /** ENTITY_DELETED - An event representing a metadata entity being deleted. */
  ENTITY_DELETED = 4,
  /** PARTITION_CREATED - An event representing a partition being created. */
  PARTITION_CREATED = 5,
  /** PARTITION_UPDATED - An event representing a partition being updated. */
  PARTITION_UPDATED = 6,
  /** PARTITION_DELETED - An event representing a partition being deleted. */
  PARTITION_DELETED = 7,
  UNRECOGNIZED = -1,
}

export function discoveryEvent_EventTypeFromJSON(object: any): DiscoveryEvent_EventType {
  switch (object) {
    case 0:
    case "EVENT_TYPE_UNSPECIFIED":
      return DiscoveryEvent_EventType.EVENT_TYPE_UNSPECIFIED;
    case 1:
    case "CONFIG":
      return DiscoveryEvent_EventType.CONFIG;
    case 2:
    case "ENTITY_CREATED":
      return DiscoveryEvent_EventType.ENTITY_CREATED;
    case 3:
    case "ENTITY_UPDATED":
      return DiscoveryEvent_EventType.ENTITY_UPDATED;
    case 4:
    case "ENTITY_DELETED":
      return DiscoveryEvent_EventType.ENTITY_DELETED;
    case 5:
    case "PARTITION_CREATED":
      return DiscoveryEvent_EventType.PARTITION_CREATED;
    case 6:
    case "PARTITION_UPDATED":
      return DiscoveryEvent_EventType.PARTITION_UPDATED;
    case 7:
    case "PARTITION_DELETED":
      return DiscoveryEvent_EventType.PARTITION_DELETED;
    case -1:
    case "UNRECOGNIZED":
    default:
      return DiscoveryEvent_EventType.UNRECOGNIZED;
  }
}

export function discoveryEvent_EventTypeToJSON(object: DiscoveryEvent_EventType): string {
  switch (object) {
    case DiscoveryEvent_EventType.EVENT_TYPE_UNSPECIFIED:
      return "EVENT_TYPE_UNSPECIFIED";
    case DiscoveryEvent_EventType.CONFIG:
      return "CONFIG";
    case DiscoveryEvent_EventType.ENTITY_CREATED:
      return "ENTITY_CREATED";
    case DiscoveryEvent_EventType.ENTITY_UPDATED:
      return "ENTITY_UPDATED";
    case DiscoveryEvent_EventType.ENTITY_DELETED:
      return "ENTITY_DELETED";
    case DiscoveryEvent_EventType.PARTITION_CREATED:
      return "PARTITION_CREATED";
    case DiscoveryEvent_EventType.PARTITION_UPDATED:
      return "PARTITION_UPDATED";
    case DiscoveryEvent_EventType.PARTITION_DELETED:
      return "PARTITION_DELETED";
    case DiscoveryEvent_EventType.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/** The type of the entity. */
export enum DiscoveryEvent_EntityType {
  /** ENTITY_TYPE_UNSPECIFIED - An unspecified event type. */
  ENTITY_TYPE_UNSPECIFIED = 0,
  /** TABLE - Entities representing structured data. */
  TABLE = 1,
  /** FILESET - Entities representing unstructured data. */
  FILESET = 2,
  UNRECOGNIZED = -1,
}

export function discoveryEvent_EntityTypeFromJSON(object: any): DiscoveryEvent_EntityType {
  switch (object) {
    case 0:
    case "ENTITY_TYPE_UNSPECIFIED":
      return DiscoveryEvent_EntityType.ENTITY_TYPE_UNSPECIFIED;
    case 1:
    case "TABLE":
      return DiscoveryEvent_EntityType.TABLE;
    case 2:
    case "FILESET":
      return DiscoveryEvent_EntityType.FILESET;
    case -1:
    case "UNRECOGNIZED":
    default:
      return DiscoveryEvent_EntityType.UNRECOGNIZED;
  }
}

export function discoveryEvent_EntityTypeToJSON(object: DiscoveryEvent_EntityType): string {
  switch (object) {
    case DiscoveryEvent_EntityType.ENTITY_TYPE_UNSPECIFIED:
      return "ENTITY_TYPE_UNSPECIFIED";
    case DiscoveryEvent_EntityType.TABLE:
      return "TABLE";
    case DiscoveryEvent_EntityType.FILESET:
      return "FILESET";
    case DiscoveryEvent_EntityType.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/** Details about configuration events. */
export interface DiscoveryEvent_ConfigDetails {
  /**
   * A list of discovery configuration parameters in effect.
   * The keys are the field paths within DiscoverySpec.
   * Eg. includePatterns, excludePatterns, csvOptions.disableTypeInference,
   * etc.
   */
  parameters: { [key: string]: string };
}

export interface DiscoveryEvent_ConfigDetails_ParametersEntry {
  key: string;
  value: string;
}

/** Details about the entity. */
export interface DiscoveryEvent_EntityDetails {
  /**
   * The name of the entity resource.
   * The name is the fully-qualified resource name.
   */
  entity: string;
  /** The type of the entity resource. */
  type: DiscoveryEvent_EntityType;
}

/** Details about the partition. */
export interface DiscoveryEvent_PartitionDetails {
  /**
   * The name to the partition resource.
   * The name is the fully-qualified resource name.
   */
  partition: string;
  /**
   * The name to the containing entity resource.
   * The name is the fully-qualified resource name.
   */
  entity: string;
  /** The type of the containing entity resource. */
  type: DiscoveryEvent_EntityType;
  /**
   * The locations of the data items (e.g., a Cloud Storage objects) sampled
   * for metadata inference.
   */
  sampledDataLocations: string[];
}

/** Details about the action. */
export interface DiscoveryEvent_ActionDetails {
  /**
   * The type of action.
   * Eg. IncompatibleDataSchema, InvalidDataFormat
   */
  type: string;
}

/**
 * The payload associated with Job logs that contains events describing jobs
 * that have run within a Lake.
 */
export interface JobEvent {
  /** The log message. */
  message: string;
  /** The unique id identifying the job. */
  jobId: string;
  /** The time when the job started running. */
  startTime:
    | Date
    | undefined;
  /** The time when the job ended running. */
  endTime:
    | Date
    | undefined;
  /** The job state on completion. */
  state: JobEvent_State;
  /** The number of retries. */
  retries: number;
  /** The type of the job. */
  type: JobEvent_Type;
  /** The service used to execute the job. */
  service: JobEvent_Service;
  /** The reference to the job within the service. */
  serviceJob: string;
  /** Job execution trigger. */
  executionTrigger: JobEvent_ExecutionTrigger;
}

/** The type of the job. */
export enum JobEvent_Type {
  /** TYPE_UNSPECIFIED - Unspecified job type. */
  TYPE_UNSPECIFIED = 0,
  /** SPARK - Spark jobs. */
  SPARK = 1,
  /** NOTEBOOK - Notebook jobs. */
  NOTEBOOK = 2,
  UNRECOGNIZED = -1,
}

export function jobEvent_TypeFromJSON(object: any): JobEvent_Type {
  switch (object) {
    case 0:
    case "TYPE_UNSPECIFIED":
      return JobEvent_Type.TYPE_UNSPECIFIED;
    case 1:
    case "SPARK":
      return JobEvent_Type.SPARK;
    case 2:
    case "NOTEBOOK":
      return JobEvent_Type.NOTEBOOK;
    case -1:
    case "UNRECOGNIZED":
    default:
      return JobEvent_Type.UNRECOGNIZED;
  }
}

export function jobEvent_TypeToJSON(object: JobEvent_Type): string {
  switch (object) {
    case JobEvent_Type.TYPE_UNSPECIFIED:
      return "TYPE_UNSPECIFIED";
    case JobEvent_Type.SPARK:
      return "SPARK";
    case JobEvent_Type.NOTEBOOK:
      return "NOTEBOOK";
    case JobEvent_Type.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/** The completion status of the job. */
export enum JobEvent_State {
  /** STATE_UNSPECIFIED - Unspecified job state. */
  STATE_UNSPECIFIED = 0,
  /** SUCCEEDED - Job successfully completed. */
  SUCCEEDED = 1,
  /** FAILED - Job was unsuccessful. */
  FAILED = 2,
  /** CANCELLED - Job was cancelled by the user. */
  CANCELLED = 3,
  /** ABORTED - Job was cancelled or aborted via the service executing the job. */
  ABORTED = 4,
  UNRECOGNIZED = -1,
}

export function jobEvent_StateFromJSON(object: any): JobEvent_State {
  switch (object) {
    case 0:
    case "STATE_UNSPECIFIED":
      return JobEvent_State.STATE_UNSPECIFIED;
    case 1:
    case "SUCCEEDED":
      return JobEvent_State.SUCCEEDED;
    case 2:
    case "FAILED":
      return JobEvent_State.FAILED;
    case 3:
    case "CANCELLED":
      return JobEvent_State.CANCELLED;
    case 4:
    case "ABORTED":
      return JobEvent_State.ABORTED;
    case -1:
    case "UNRECOGNIZED":
    default:
      return JobEvent_State.UNRECOGNIZED;
  }
}

export function jobEvent_StateToJSON(object: JobEvent_State): string {
  switch (object) {
    case JobEvent_State.STATE_UNSPECIFIED:
      return "STATE_UNSPECIFIED";
    case JobEvent_State.SUCCEEDED:
      return "SUCCEEDED";
    case JobEvent_State.FAILED:
      return "FAILED";
    case JobEvent_State.CANCELLED:
      return "CANCELLED";
    case JobEvent_State.ABORTED:
      return "ABORTED";
    case JobEvent_State.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/** The service used to execute the job. */
export enum JobEvent_Service {
  /** SERVICE_UNSPECIFIED - Unspecified service. */
  SERVICE_UNSPECIFIED = 0,
  /** DATAPROC - Cloud Dataproc. */
  DATAPROC = 1,
  UNRECOGNIZED = -1,
}

export function jobEvent_ServiceFromJSON(object: any): JobEvent_Service {
  switch (object) {
    case 0:
    case "SERVICE_UNSPECIFIED":
      return JobEvent_Service.SERVICE_UNSPECIFIED;
    case 1:
    case "DATAPROC":
      return JobEvent_Service.DATAPROC;
    case -1:
    case "UNRECOGNIZED":
    default:
      return JobEvent_Service.UNRECOGNIZED;
  }
}

export function jobEvent_ServiceToJSON(object: JobEvent_Service): string {
  switch (object) {
    case JobEvent_Service.SERVICE_UNSPECIFIED:
      return "SERVICE_UNSPECIFIED";
    case JobEvent_Service.DATAPROC:
      return "DATAPROC";
    case JobEvent_Service.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/** Job Execution trigger. */
export enum JobEvent_ExecutionTrigger {
  /** EXECUTION_TRIGGER_UNSPECIFIED - The job execution trigger is unspecified. */
  EXECUTION_TRIGGER_UNSPECIFIED = 0,
  /**
   * TASK_CONFIG - The job was triggered by Dataplex based on trigger spec from task
   * definition.
   */
  TASK_CONFIG = 1,
  /** RUN_REQUEST - The job was triggered by the explicit call of Task API. */
  RUN_REQUEST = 2,
  UNRECOGNIZED = -1,
}

export function jobEvent_ExecutionTriggerFromJSON(object: any): JobEvent_ExecutionTrigger {
  switch (object) {
    case 0:
    case "EXECUTION_TRIGGER_UNSPECIFIED":
      return JobEvent_ExecutionTrigger.EXECUTION_TRIGGER_UNSPECIFIED;
    case 1:
    case "TASK_CONFIG":
      return JobEvent_ExecutionTrigger.TASK_CONFIG;
    case 2:
    case "RUN_REQUEST":
      return JobEvent_ExecutionTrigger.RUN_REQUEST;
    case -1:
    case "UNRECOGNIZED":
    default:
      return JobEvent_ExecutionTrigger.UNRECOGNIZED;
  }
}

export function jobEvent_ExecutionTriggerToJSON(object: JobEvent_ExecutionTrigger): string {
  switch (object) {
    case JobEvent_ExecutionTrigger.EXECUTION_TRIGGER_UNSPECIFIED:
      return "EXECUTION_TRIGGER_UNSPECIFIED";
    case JobEvent_ExecutionTrigger.TASK_CONFIG:
      return "TASK_CONFIG";
    case JobEvent_ExecutionTrigger.RUN_REQUEST:
      return "RUN_REQUEST";
    case JobEvent_ExecutionTrigger.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/**
 * These messages contain information about sessions within an environment.
 * The monitored resource is 'Environment'.
 */
export interface SessionEvent {
  /** The log message. */
  message: string;
  /**
   * The information about the user that created the session. It will be the
   * email address of the user.
   */
  userId: string;
  /** Unique identifier for the session. */
  sessionId: string;
  /** The type of the event. */
  type: SessionEvent_EventType;
  /** The execution details of the query. */
  query?:
    | SessionEvent_QueryDetail
    | undefined;
  /** The status of the event. */
  eventSucceeded: boolean;
  /**
   * If the session is associated with an environment with fast startup enabled,
   * and was created before being assigned to a user.
   */
  fastStartupEnabled: boolean;
  /** The idle duration of a warm pooled session before it is assigned to user. */
  unassignedDuration: Duration | undefined;
}

/** The type of the event. */
export enum SessionEvent_EventType {
  /** EVENT_TYPE_UNSPECIFIED - An unspecified event type. */
  EVENT_TYPE_UNSPECIFIED = 0,
  /** START - Event when the session is assigned to a user. */
  START = 1,
  /** STOP - Event for stop of a session. */
  STOP = 2,
  /** QUERY - Query events in the session. */
  QUERY = 3,
  /**
   * CREATE - Event for creation of a cluster. It is not yet assigned to a user.
   * This comes before START in the sequence
   */
  CREATE = 4,
  UNRECOGNIZED = -1,
}

export function sessionEvent_EventTypeFromJSON(object: any): SessionEvent_EventType {
  switch (object) {
    case 0:
    case "EVENT_TYPE_UNSPECIFIED":
      return SessionEvent_EventType.EVENT_TYPE_UNSPECIFIED;
    case 1:
    case "START":
      return SessionEvent_EventType.START;
    case 2:
    case "STOP":
      return SessionEvent_EventType.STOP;
    case 3:
    case "QUERY":
      return SessionEvent_EventType.QUERY;
    case 4:
    case "CREATE":
      return SessionEvent_EventType.CREATE;
    case -1:
    case "UNRECOGNIZED":
    default:
      return SessionEvent_EventType.UNRECOGNIZED;
  }
}

export function sessionEvent_EventTypeToJSON(object: SessionEvent_EventType): string {
  switch (object) {
    case SessionEvent_EventType.EVENT_TYPE_UNSPECIFIED:
      return "EVENT_TYPE_UNSPECIFIED";
    case SessionEvent_EventType.START:
      return "START";
    case SessionEvent_EventType.STOP:
      return "STOP";
    case SessionEvent_EventType.QUERY:
      return "QUERY";
    case SessionEvent_EventType.CREATE:
      return "CREATE";
    case SessionEvent_EventType.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/** Execution details of the query. */
export interface SessionEvent_QueryDetail {
  /** The unique Query id identifying the query. */
  queryId: string;
  /** The query text executed. */
  queryText: string;
  /** Query Execution engine. */
  engine: SessionEvent_QueryDetail_Engine;
  /** Time taken for execution of the query. */
  duration:
    | Duration
    | undefined;
  /** The size of results the query produced. */
  resultSizeBytes: Long;
  /** The data processed by the query. */
  dataProcessedBytes: Long;
}

/** Query Execution engine. */
export enum SessionEvent_QueryDetail_Engine {
  /** ENGINE_UNSPECIFIED - An unspecified Engine type. */
  ENGINE_UNSPECIFIED = 0,
  /** SPARK_SQL - Spark-sql engine is specified in Query. */
  SPARK_SQL = 1,
  /** BIGQUERY - BigQuery engine is specified in Query. */
  BIGQUERY = 2,
  UNRECOGNIZED = -1,
}

export function sessionEvent_QueryDetail_EngineFromJSON(object: any): SessionEvent_QueryDetail_Engine {
  switch (object) {
    case 0:
    case "ENGINE_UNSPECIFIED":
      return SessionEvent_QueryDetail_Engine.ENGINE_UNSPECIFIED;
    case 1:
    case "SPARK_SQL":
      return SessionEvent_QueryDetail_Engine.SPARK_SQL;
    case 2:
    case "BIGQUERY":
      return SessionEvent_QueryDetail_Engine.BIGQUERY;
    case -1:
    case "UNRECOGNIZED":
    default:
      return SessionEvent_QueryDetail_Engine.UNRECOGNIZED;
  }
}

export function sessionEvent_QueryDetail_EngineToJSON(object: SessionEvent_QueryDetail_Engine): string {
  switch (object) {
    case SessionEvent_QueryDetail_Engine.ENGINE_UNSPECIFIED:
      return "ENGINE_UNSPECIFIED";
    case SessionEvent_QueryDetail_Engine.SPARK_SQL:
      return "SPARK_SQL";
    case SessionEvent_QueryDetail_Engine.BIGQUERY:
      return "BIGQUERY";
    case SessionEvent_QueryDetail_Engine.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/** Payload associated with Governance related log events. */
export interface GovernanceEvent {
  /** The log message. */
  message: string;
  /** The type of the event. */
  eventType: GovernanceEvent_EventType;
  /**
   * Entity resource information if the log event is associated with a
   * specific entity.
   */
  entity?: GovernanceEvent_Entity | undefined;
}

/** Type of governance log event. */
export enum GovernanceEvent_EventType {
  /** EVENT_TYPE_UNSPECIFIED - An unspecified event type. */
  EVENT_TYPE_UNSPECIFIED = 0,
  /** RESOURCE_IAM_POLICY_UPDATE - Resource IAM policy update event. */
  RESOURCE_IAM_POLICY_UPDATE = 1,
  /** BIGQUERY_TABLE_CREATE - BigQuery table create event. */
  BIGQUERY_TABLE_CREATE = 2,
  /** BIGQUERY_TABLE_UPDATE - BigQuery table update event. */
  BIGQUERY_TABLE_UPDATE = 3,
  /** BIGQUERY_TABLE_DELETE - BigQuery table delete event. */
  BIGQUERY_TABLE_DELETE = 4,
  /** BIGQUERY_CONNECTION_CREATE - BigQuery connection create event. */
  BIGQUERY_CONNECTION_CREATE = 5,
  /** BIGQUERY_CONNECTION_UPDATE - BigQuery connection update event. */
  BIGQUERY_CONNECTION_UPDATE = 6,
  /** BIGQUERY_CONNECTION_DELETE - BigQuery connection delete event. */
  BIGQUERY_CONNECTION_DELETE = 7,
  /** BIGQUERY_TAXONOMY_CREATE - BigQuery taxonomy created. */
  BIGQUERY_TAXONOMY_CREATE = 10,
  /** BIGQUERY_POLICY_TAG_CREATE - BigQuery policy tag created. */
  BIGQUERY_POLICY_TAG_CREATE = 11,
  /** BIGQUERY_POLICY_TAG_DELETE - BigQuery policy tag deleted. */
  BIGQUERY_POLICY_TAG_DELETE = 12,
  /** BIGQUERY_POLICY_TAG_SET_IAM_POLICY - BigQuery set iam policy for policy tag. */
  BIGQUERY_POLICY_TAG_SET_IAM_POLICY = 13,
  /** ACCESS_POLICY_UPDATE - Access policy update event. */
  ACCESS_POLICY_UPDATE = 14,
  /** GOVERNANCE_RULE_MATCHED_RESOURCES - Number of resources matched with particular Query. */
  GOVERNANCE_RULE_MATCHED_RESOURCES = 15,
  /** GOVERNANCE_RULE_SEARCH_LIMIT_EXCEEDS - Rule processing exceeds the allowed limit. */
  GOVERNANCE_RULE_SEARCH_LIMIT_EXCEEDS = 16,
  /** GOVERNANCE_RULE_ERRORS - Rule processing errors. */
  GOVERNANCE_RULE_ERRORS = 17,
  /** GOVERNANCE_RULE_PROCESSING - Governance rule processing Event. */
  GOVERNANCE_RULE_PROCESSING = 18,
  UNRECOGNIZED = -1,
}

export function governanceEvent_EventTypeFromJSON(object: any): GovernanceEvent_EventType {
  switch (object) {
    case 0:
    case "EVENT_TYPE_UNSPECIFIED":
      return GovernanceEvent_EventType.EVENT_TYPE_UNSPECIFIED;
    case 1:
    case "RESOURCE_IAM_POLICY_UPDATE":
      return GovernanceEvent_EventType.RESOURCE_IAM_POLICY_UPDATE;
    case 2:
    case "BIGQUERY_TABLE_CREATE":
      return GovernanceEvent_EventType.BIGQUERY_TABLE_CREATE;
    case 3:
    case "BIGQUERY_TABLE_UPDATE":
      return GovernanceEvent_EventType.BIGQUERY_TABLE_UPDATE;
    case 4:
    case "BIGQUERY_TABLE_DELETE":
      return GovernanceEvent_EventType.BIGQUERY_TABLE_DELETE;
    case 5:
    case "BIGQUERY_CONNECTION_CREATE":
      return GovernanceEvent_EventType.BIGQUERY_CONNECTION_CREATE;
    case 6:
    case "BIGQUERY_CONNECTION_UPDATE":
      return GovernanceEvent_EventType.BIGQUERY_CONNECTION_UPDATE;
    case 7:
    case "BIGQUERY_CONNECTION_DELETE":
      return GovernanceEvent_EventType.BIGQUERY_CONNECTION_DELETE;
    case 10:
    case "BIGQUERY_TAXONOMY_CREATE":
      return GovernanceEvent_EventType.BIGQUERY_TAXONOMY_CREATE;
    case 11:
    case "BIGQUERY_POLICY_TAG_CREATE":
      return GovernanceEvent_EventType.BIGQUERY_POLICY_TAG_CREATE;
    case 12:
    case "BIGQUERY_POLICY_TAG_DELETE":
      return GovernanceEvent_EventType.BIGQUERY_POLICY_TAG_DELETE;
    case 13:
    case "BIGQUERY_POLICY_TAG_SET_IAM_POLICY":
      return GovernanceEvent_EventType.BIGQUERY_POLICY_TAG_SET_IAM_POLICY;
    case 14:
    case "ACCESS_POLICY_UPDATE":
      return GovernanceEvent_EventType.ACCESS_POLICY_UPDATE;
    case 15:
    case "GOVERNANCE_RULE_MATCHED_RESOURCES":
      return GovernanceEvent_EventType.GOVERNANCE_RULE_MATCHED_RESOURCES;
    case 16:
    case "GOVERNANCE_RULE_SEARCH_LIMIT_EXCEEDS":
      return GovernanceEvent_EventType.GOVERNANCE_RULE_SEARCH_LIMIT_EXCEEDS;
    case 17:
    case "GOVERNANCE_RULE_ERRORS":
      return GovernanceEvent_EventType.GOVERNANCE_RULE_ERRORS;
    case 18:
    case "GOVERNANCE_RULE_PROCESSING":
      return GovernanceEvent_EventType.GOVERNANCE_RULE_PROCESSING;
    case -1:
    case "UNRECOGNIZED":
    default:
      return GovernanceEvent_EventType.UNRECOGNIZED;
  }
}

export function governanceEvent_EventTypeToJSON(object: GovernanceEvent_EventType): string {
  switch (object) {
    case GovernanceEvent_EventType.EVENT_TYPE_UNSPECIFIED:
      return "EVENT_TYPE_UNSPECIFIED";
    case GovernanceEvent_EventType.RESOURCE_IAM_POLICY_UPDATE:
      return "RESOURCE_IAM_POLICY_UPDATE";
    case GovernanceEvent_EventType.BIGQUERY_TABLE_CREATE:
      return "BIGQUERY_TABLE_CREATE";
    case GovernanceEvent_EventType.BIGQUERY_TABLE_UPDATE:
      return "BIGQUERY_TABLE_UPDATE";
    case GovernanceEvent_EventType.BIGQUERY_TABLE_DELETE:
      return "BIGQUERY_TABLE_DELETE";
    case GovernanceEvent_EventType.BIGQUERY_CONNECTION_CREATE:
      return "BIGQUERY_CONNECTION_CREATE";
    case GovernanceEvent_EventType.BIGQUERY_CONNECTION_UPDATE:
      return "BIGQUERY_CONNECTION_UPDATE";
    case GovernanceEvent_EventType.BIGQUERY_CONNECTION_DELETE:
      return "BIGQUERY_CONNECTION_DELETE";
    case GovernanceEvent_EventType.BIGQUERY_TAXONOMY_CREATE:
      return "BIGQUERY_TAXONOMY_CREATE";
    case GovernanceEvent_EventType.BIGQUERY_POLICY_TAG_CREATE:
      return "BIGQUERY_POLICY_TAG_CREATE";
    case GovernanceEvent_EventType.BIGQUERY_POLICY_TAG_DELETE:
      return "BIGQUERY_POLICY_TAG_DELETE";
    case GovernanceEvent_EventType.BIGQUERY_POLICY_TAG_SET_IAM_POLICY:
      return "BIGQUERY_POLICY_TAG_SET_IAM_POLICY";
    case GovernanceEvent_EventType.ACCESS_POLICY_UPDATE:
      return "ACCESS_POLICY_UPDATE";
    case GovernanceEvent_EventType.GOVERNANCE_RULE_MATCHED_RESOURCES:
      return "GOVERNANCE_RULE_MATCHED_RESOURCES";
    case GovernanceEvent_EventType.GOVERNANCE_RULE_SEARCH_LIMIT_EXCEEDS:
      return "GOVERNANCE_RULE_SEARCH_LIMIT_EXCEEDS";
    case GovernanceEvent_EventType.GOVERNANCE_RULE_ERRORS:
      return "GOVERNANCE_RULE_ERRORS";
    case GovernanceEvent_EventType.GOVERNANCE_RULE_PROCESSING:
      return "GOVERNANCE_RULE_PROCESSING";
    case GovernanceEvent_EventType.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/** Information about Entity resource that the log event is associated with. */
export interface GovernanceEvent_Entity {
  /**
   * The Entity resource the log event is associated with.
   * Format:
   * `projects/{project_number}/locations/{location_id}/lakes/{lake_id}/zones/{zone_id}/entities/{entity_id}`
   */
  entity: string;
  /** Type of entity. */
  entityType: GovernanceEvent_Entity_EntityType;
}

/** Type of entity. */
export enum GovernanceEvent_Entity_EntityType {
  /** ENTITY_TYPE_UNSPECIFIED - An unspecified Entity type. */
  ENTITY_TYPE_UNSPECIFIED = 0,
  /** TABLE - Table entity type. */
  TABLE = 1,
  /** FILESET - Fileset entity type. */
  FILESET = 2,
  UNRECOGNIZED = -1,
}

export function governanceEvent_Entity_EntityTypeFromJSON(object: any): GovernanceEvent_Entity_EntityType {
  switch (object) {
    case 0:
    case "ENTITY_TYPE_UNSPECIFIED":
      return GovernanceEvent_Entity_EntityType.ENTITY_TYPE_UNSPECIFIED;
    case 1:
    case "TABLE":
      return GovernanceEvent_Entity_EntityType.TABLE;
    case 2:
    case "FILESET":
      return GovernanceEvent_Entity_EntityType.FILESET;
    case -1:
    case "UNRECOGNIZED":
    default:
      return GovernanceEvent_Entity_EntityType.UNRECOGNIZED;
  }
}

export function governanceEvent_Entity_EntityTypeToJSON(object: GovernanceEvent_Entity_EntityType): string {
  switch (object) {
    case GovernanceEvent_Entity_EntityType.ENTITY_TYPE_UNSPECIFIED:
      return "ENTITY_TYPE_UNSPECIFIED";
    case GovernanceEvent_Entity_EntityType.TABLE:
      return "TABLE";
    case GovernanceEvent_Entity_EntityType.FILESET:
      return "FILESET";
    case GovernanceEvent_Entity_EntityType.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/**
 * These messages contain information about the execution of a datascan.
 * The monitored resource is 'DataScan'
 * Next ID: 13
 */
export interface DataScanEvent {
  /** The data source of the data scan */
  dataSource: string;
  /** The identifier of the specific data scan job this log entry is for. */
  jobId: string;
  /** The time when the data scan job was created. */
  createTime:
    | Date
    | undefined;
  /** The time when the data scan job started to run. */
  startTime:
    | Date
    | undefined;
  /** The time when the data scan job finished. */
  endTime:
    | Date
    | undefined;
  /** The type of the data scan. */
  type: DataScanEvent_ScanType;
  /** The status of the data scan job. */
  state: DataScanEvent_State;
  /** The message describing the data scan job event. */
  message: string;
  /** A version identifier of the spec which was used to execute this job. */
  specVersion: string;
  /** The trigger type of the data scan job. */
  trigger: DataScanEvent_Trigger;
  /** The scope of the data scan (e.g. full, incremental). */
  scope: DataScanEvent_Scope;
  /** Data profile result for data profile type data scan. */
  dataProfile?:
    | DataScanEvent_DataProfileResult
    | undefined;
  /** Data quality result for data quality type data scan. */
  dataQuality?:
    | DataScanEvent_DataQualityResult
    | undefined;
  /** Applied configs for data profile type data scan. */
  dataProfileConfigs?:
    | DataScanEvent_DataProfileAppliedConfigs
    | undefined;
  /** Applied configs for data quality type data scan. */
  dataQualityConfigs?:
    | DataScanEvent_DataQualityAppliedConfigs
    | undefined;
  /** The result of post scan actions. */
  postScanActionsResult: DataScanEvent_PostScanActionsResult | undefined;
}

/** The type of the data scan. */
export enum DataScanEvent_ScanType {
  /** SCAN_TYPE_UNSPECIFIED - An unspecified data scan type. */
  SCAN_TYPE_UNSPECIFIED = 0,
  /** DATA_PROFILE - Data scan for data profile. */
  DATA_PROFILE = 1,
  /** DATA_QUALITY - Data scan for data quality. */
  DATA_QUALITY = 2,
  UNRECOGNIZED = -1,
}

export function dataScanEvent_ScanTypeFromJSON(object: any): DataScanEvent_ScanType {
  switch (object) {
    case 0:
    case "SCAN_TYPE_UNSPECIFIED":
      return DataScanEvent_ScanType.SCAN_TYPE_UNSPECIFIED;
    case 1:
    case "DATA_PROFILE":
      return DataScanEvent_ScanType.DATA_PROFILE;
    case 2:
    case "DATA_QUALITY":
      return DataScanEvent_ScanType.DATA_QUALITY;
    case -1:
    case "UNRECOGNIZED":
    default:
      return DataScanEvent_ScanType.UNRECOGNIZED;
  }
}

export function dataScanEvent_ScanTypeToJSON(object: DataScanEvent_ScanType): string {
  switch (object) {
    case DataScanEvent_ScanType.SCAN_TYPE_UNSPECIFIED:
      return "SCAN_TYPE_UNSPECIFIED";
    case DataScanEvent_ScanType.DATA_PROFILE:
      return "DATA_PROFILE";
    case DataScanEvent_ScanType.DATA_QUALITY:
      return "DATA_QUALITY";
    case DataScanEvent_ScanType.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/** The job state of the data scan. */
export enum DataScanEvent_State {
  /** STATE_UNSPECIFIED - Unspecified job state. */
  STATE_UNSPECIFIED = 0,
  /** STARTED - Data scan job started. */
  STARTED = 1,
  /** SUCCEEDED - Data scan job successfully completed. */
  SUCCEEDED = 2,
  /** FAILED - Data scan job was unsuccessful. */
  FAILED = 3,
  /** CANCELLED - Data scan job was cancelled. */
  CANCELLED = 4,
  /** CREATED - Data scan job was createed. */
  CREATED = 5,
  UNRECOGNIZED = -1,
}

export function dataScanEvent_StateFromJSON(object: any): DataScanEvent_State {
  switch (object) {
    case 0:
    case "STATE_UNSPECIFIED":
      return DataScanEvent_State.STATE_UNSPECIFIED;
    case 1:
    case "STARTED":
      return DataScanEvent_State.STARTED;
    case 2:
    case "SUCCEEDED":
      return DataScanEvent_State.SUCCEEDED;
    case 3:
    case "FAILED":
      return DataScanEvent_State.FAILED;
    case 4:
    case "CANCELLED":
      return DataScanEvent_State.CANCELLED;
    case 5:
    case "CREATED":
      return DataScanEvent_State.CREATED;
    case -1:
    case "UNRECOGNIZED":
    default:
      return DataScanEvent_State.UNRECOGNIZED;
  }
}

export function dataScanEvent_StateToJSON(object: DataScanEvent_State): string {
  switch (object) {
    case DataScanEvent_State.STATE_UNSPECIFIED:
      return "STATE_UNSPECIFIED";
    case DataScanEvent_State.STARTED:
      return "STARTED";
    case DataScanEvent_State.SUCCEEDED:
      return "SUCCEEDED";
    case DataScanEvent_State.FAILED:
      return "FAILED";
    case DataScanEvent_State.CANCELLED:
      return "CANCELLED";
    case DataScanEvent_State.CREATED:
      return "CREATED";
    case DataScanEvent_State.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/** The trigger type for the data scan. */
export enum DataScanEvent_Trigger {
  /** TRIGGER_UNSPECIFIED - An unspecified trigger type. */
  TRIGGER_UNSPECIFIED = 0,
  /** ON_DEMAND - Data scan triggers on demand. */
  ON_DEMAND = 1,
  /** SCHEDULE - Data scan triggers as per schedule. */
  SCHEDULE = 2,
  UNRECOGNIZED = -1,
}

export function dataScanEvent_TriggerFromJSON(object: any): DataScanEvent_Trigger {
  switch (object) {
    case 0:
    case "TRIGGER_UNSPECIFIED":
      return DataScanEvent_Trigger.TRIGGER_UNSPECIFIED;
    case 1:
    case "ON_DEMAND":
      return DataScanEvent_Trigger.ON_DEMAND;
    case 2:
    case "SCHEDULE":
      return DataScanEvent_Trigger.SCHEDULE;
    case -1:
    case "UNRECOGNIZED":
    default:
      return DataScanEvent_Trigger.UNRECOGNIZED;
  }
}

export function dataScanEvent_TriggerToJSON(object: DataScanEvent_Trigger): string {
  switch (object) {
    case DataScanEvent_Trigger.TRIGGER_UNSPECIFIED:
      return "TRIGGER_UNSPECIFIED";
    case DataScanEvent_Trigger.ON_DEMAND:
      return "ON_DEMAND";
    case DataScanEvent_Trigger.SCHEDULE:
      return "SCHEDULE";
    case DataScanEvent_Trigger.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/** The scope of job for the data scan. */
export enum DataScanEvent_Scope {
  /** SCOPE_UNSPECIFIED - An unspecified scope type. */
  SCOPE_UNSPECIFIED = 0,
  /** FULL - Data scan runs on all of the data. */
  FULL = 1,
  /** INCREMENTAL - Data scan runs on incremental data. */
  INCREMENTAL = 2,
  UNRECOGNIZED = -1,
}

export function dataScanEvent_ScopeFromJSON(object: any): DataScanEvent_Scope {
  switch (object) {
    case 0:
    case "SCOPE_UNSPECIFIED":
      return DataScanEvent_Scope.SCOPE_UNSPECIFIED;
    case 1:
    case "FULL":
      return DataScanEvent_Scope.FULL;
    case 2:
    case "INCREMENTAL":
      return DataScanEvent_Scope.INCREMENTAL;
    case -1:
    case "UNRECOGNIZED":
    default:
      return DataScanEvent_Scope.UNRECOGNIZED;
  }
}

export function dataScanEvent_ScopeToJSON(object: DataScanEvent_Scope): string {
  switch (object) {
    case DataScanEvent_Scope.SCOPE_UNSPECIFIED:
      return "SCOPE_UNSPECIFIED";
    case DataScanEvent_Scope.FULL:
      return "FULL";
    case DataScanEvent_Scope.INCREMENTAL:
      return "INCREMENTAL";
    case DataScanEvent_Scope.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/** Data profile result for data scan job. */
export interface DataScanEvent_DataProfileResult {
  /** The count of rows processed in the data scan job. */
  rowCount: Long;
}

/** Data quality result for data scan job. */
export interface DataScanEvent_DataQualityResult {
  /** The count of rows processed in the data scan job. */
  rowCount: Long;
  /** Whether the data quality result was `pass` or not. */
  passed: boolean;
  /**
   * The result of each dimension for data quality result.
   * The key of the map is the name of the dimension.
   * The value is the bool value depicting whether the dimension result was
   * `pass` or not.
   */
  dimensionPassed: { [key: string]: boolean };
  /**
   * The table-level data quality score for the data scan job.
   *
   * The data quality score ranges between [0, 100] (up to two decimal
   * points).
   */
  score: number;
  /**
   * The score of each dimension for data quality result.
   * The key of the map is the name of the dimension.
   * The value is the data quality score for the dimension.
   *
   * The score ranges between [0, 100] (up to two decimal
   * points).
   */
  dimensionScore: { [key: string]: number };
  /**
   * The score of each column scanned in the data scan job.
   * The key of the map is the name of the column.
   * The value is the data quality score for the column.
   *
   * The score ranges between [0, 100] (up to two decimal
   * points).
   */
  columnScore: { [key: string]: number };
}

export interface DataScanEvent_DataQualityResult_DimensionPassedEntry {
  key: string;
  value: boolean;
}

export interface DataScanEvent_DataQualityResult_DimensionScoreEntry {
  key: string;
  value: number;
}

export interface DataScanEvent_DataQualityResult_ColumnScoreEntry {
  key: string;
  value: number;
}

/** Applied configs for data profile type data scan job. */
export interface DataScanEvent_DataProfileAppliedConfigs {
  /**
   * The percentage of the records selected from the dataset for DataScan.
   *
   * * Value ranges between 0.0 and 100.0.
   * * Value 0.0 or 100.0 imply that sampling was not applied.
   */
  samplingPercent: number;
  /** Boolean indicating whether a row filter was applied in the DataScan job. */
  rowFilterApplied: boolean;
  /**
   * Boolean indicating whether a column filter was applied in the DataScan
   * job.
   */
  columnFilterApplied: boolean;
}

/** Applied configs for data quality type data scan job. */
export interface DataScanEvent_DataQualityAppliedConfigs {
  /**
   * The percentage of the records selected from the dataset for DataScan.
   *
   * * Value ranges between 0.0 and 100.0.
   * * Value 0.0 or 100.0 imply that sampling was not applied.
   */
  samplingPercent: number;
  /** Boolean indicating whether a row filter was applied in the DataScan job. */
  rowFilterApplied: boolean;
}

/** Post scan actions result for data scan job. */
export interface DataScanEvent_PostScanActionsResult {
  /** The result of BigQuery export post scan action. */
  bigqueryExportResult: DataScanEvent_PostScanActionsResult_BigQueryExportResult | undefined;
}

/** The result of BigQuery export post scan action. */
export interface DataScanEvent_PostScanActionsResult_BigQueryExportResult {
  /** Execution state for the BigQuery exporting. */
  state: DataScanEvent_PostScanActionsResult_BigQueryExportResult_State;
  /** Additional information about the BigQuery exporting. */
  message: string;
}

/** Execution state for the exporting. */
export enum DataScanEvent_PostScanActionsResult_BigQueryExportResult_State {
  /** STATE_UNSPECIFIED - The exporting state is unspecified. */
  STATE_UNSPECIFIED = 0,
  /** SUCCEEDED - The exporting completed successfully. */
  SUCCEEDED = 1,
  /** FAILED - The exporting is no longer running due to an error. */
  FAILED = 2,
  /**
   * SKIPPED - The exporting is skipped due to no valid scan result to export
   * (usually caused by scan failed).
   */
  SKIPPED = 3,
  UNRECOGNIZED = -1,
}

export function dataScanEvent_PostScanActionsResult_BigQueryExportResult_StateFromJSON(
  object: any,
): DataScanEvent_PostScanActionsResult_BigQueryExportResult_State {
  switch (object) {
    case 0:
    case "STATE_UNSPECIFIED":
      return DataScanEvent_PostScanActionsResult_BigQueryExportResult_State.STATE_UNSPECIFIED;
    case 1:
    case "SUCCEEDED":
      return DataScanEvent_PostScanActionsResult_BigQueryExportResult_State.SUCCEEDED;
    case 2:
    case "FAILED":
      return DataScanEvent_PostScanActionsResult_BigQueryExportResult_State.FAILED;
    case 3:
    case "SKIPPED":
      return DataScanEvent_PostScanActionsResult_BigQueryExportResult_State.SKIPPED;
    case -1:
    case "UNRECOGNIZED":
    default:
      return DataScanEvent_PostScanActionsResult_BigQueryExportResult_State.UNRECOGNIZED;
  }
}

export function dataScanEvent_PostScanActionsResult_BigQueryExportResult_StateToJSON(
  object: DataScanEvent_PostScanActionsResult_BigQueryExportResult_State,
): string {
  switch (object) {
    case DataScanEvent_PostScanActionsResult_BigQueryExportResult_State.STATE_UNSPECIFIED:
      return "STATE_UNSPECIFIED";
    case DataScanEvent_PostScanActionsResult_BigQueryExportResult_State.SUCCEEDED:
      return "SUCCEEDED";
    case DataScanEvent_PostScanActionsResult_BigQueryExportResult_State.FAILED:
      return "FAILED";
    case DataScanEvent_PostScanActionsResult_BigQueryExportResult_State.SKIPPED:
      return "SKIPPED";
    case DataScanEvent_PostScanActionsResult_BigQueryExportResult_State.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/**
 * Information about the result of a data quality rule for data quality scan.
 * The monitored resource is 'DataScan'.
 */
export interface DataQualityScanRuleResult {
  /** Identifier of the specific data scan job this log entry is for. */
  jobId: string;
  /** The data source of the data scan (e.g. BigQuery table name). */
  dataSource: string;
  /** The column which this rule is evaluated against. */
  column: string;
  /** The name of the data quality rule. */
  ruleName: string;
  /** The type of the data quality rule. */
  ruleType: DataQualityScanRuleResult_RuleType;
  /** The evaluation type of the data quality rule. */
  evalutionType: DataQualityScanRuleResult_EvaluationType;
  /** The dimension of the data quality rule. */
  ruleDimension: string;
  /** The passing threshold ([0.0, 100.0]) of the data quality rule. */
  thresholdPercent: number;
  /** The result of the data quality rule. */
  result: DataQualityScanRuleResult_Result;
  /**
   * The number of rows evaluated against the data quality rule.
   * This field is only valid for rules of PER_ROW evaluation type.
   */
  evaluatedRowCount: Long;
  /**
   * The number of rows which passed a rule evaluation.
   * This field is only valid for rules of PER_ROW evaluation type.
   */
  passedRowCount: Long;
  /** The number of rows with null values in the specified column. */
  nullRowCount: Long;
  /**
   * The number of rows returned by the SQL statement in a SQL assertion rule.
   * This field is only valid for SQL assertion rules.
   */
  assertionRowCount: Long;
}

/** The type of the data quality rule. */
export enum DataQualityScanRuleResult_RuleType {
  /** RULE_TYPE_UNSPECIFIED - An unspecified rule type. */
  RULE_TYPE_UNSPECIFIED = 0,
  /**
   * NON_NULL_EXPECTATION - See
   * [DataQualityRule.NonNullExpectation][google.cloud.dataplex.v1.DataQualityRule.NonNullExpectation].
   */
  NON_NULL_EXPECTATION = 1,
  /**
   * RANGE_EXPECTATION - See
   * [DataQualityRule.RangeExpectation][google.cloud.dataplex.v1.DataQualityRule.RangeExpectation].
   */
  RANGE_EXPECTATION = 2,
  /**
   * REGEX_EXPECTATION - See
   * [DataQualityRule.RegexExpectation][google.cloud.dataplex.v1.DataQualityRule.RegexExpectation].
   */
  REGEX_EXPECTATION = 3,
  /**
   * ROW_CONDITION_EXPECTATION - See
   * [DataQualityRule.RowConditionExpectation][google.cloud.dataplex.v1.DataQualityRule.RowConditionExpectation].
   */
  ROW_CONDITION_EXPECTATION = 4,
  /**
   * SET_EXPECTATION - See
   * [DataQualityRule.SetExpectation][google.cloud.dataplex.v1.DataQualityRule.SetExpectation].
   */
  SET_EXPECTATION = 5,
  /**
   * STATISTIC_RANGE_EXPECTATION - See
   * [DataQualityRule.StatisticRangeExpectation][google.cloud.dataplex.v1.DataQualityRule.StatisticRangeExpectation].
   */
  STATISTIC_RANGE_EXPECTATION = 6,
  /**
   * TABLE_CONDITION_EXPECTATION - See
   * [DataQualityRule.TableConditionExpectation][google.cloud.dataplex.v1.DataQualityRule.TableConditionExpectation].
   */
  TABLE_CONDITION_EXPECTATION = 7,
  /**
   * UNIQUENESS_EXPECTATION - See
   * [DataQualityRule.UniquenessExpectation][google.cloud.dataplex.v1.DataQualityRule.UniquenessExpectation].
   */
  UNIQUENESS_EXPECTATION = 8,
  /**
   * SQL_ASSERTION - See
   * [DataQualityRule.SqlAssertion][google.cloud.dataplex.v1.DataQualityRule.SqlAssertion].
   */
  SQL_ASSERTION = 9,
  UNRECOGNIZED = -1,
}

export function dataQualityScanRuleResult_RuleTypeFromJSON(object: any): DataQualityScanRuleResult_RuleType {
  switch (object) {
    case 0:
    case "RULE_TYPE_UNSPECIFIED":
      return DataQualityScanRuleResult_RuleType.RULE_TYPE_UNSPECIFIED;
    case 1:
    case "NON_NULL_EXPECTATION":
      return DataQualityScanRuleResult_RuleType.NON_NULL_EXPECTATION;
    case 2:
    case "RANGE_EXPECTATION":
      return DataQualityScanRuleResult_RuleType.RANGE_EXPECTATION;
    case 3:
    case "REGEX_EXPECTATION":
      return DataQualityScanRuleResult_RuleType.REGEX_EXPECTATION;
    case 4:
    case "ROW_CONDITION_EXPECTATION":
      return DataQualityScanRuleResult_RuleType.ROW_CONDITION_EXPECTATION;
    case 5:
    case "SET_EXPECTATION":
      return DataQualityScanRuleResult_RuleType.SET_EXPECTATION;
    case 6:
    case "STATISTIC_RANGE_EXPECTATION":
      return DataQualityScanRuleResult_RuleType.STATISTIC_RANGE_EXPECTATION;
    case 7:
    case "TABLE_CONDITION_EXPECTATION":
      return DataQualityScanRuleResult_RuleType.TABLE_CONDITION_EXPECTATION;
    case 8:
    case "UNIQUENESS_EXPECTATION":
      return DataQualityScanRuleResult_RuleType.UNIQUENESS_EXPECTATION;
    case 9:
    case "SQL_ASSERTION":
      return DataQualityScanRuleResult_RuleType.SQL_ASSERTION;
    case -1:
    case "UNRECOGNIZED":
    default:
      return DataQualityScanRuleResult_RuleType.UNRECOGNIZED;
  }
}

export function dataQualityScanRuleResult_RuleTypeToJSON(object: DataQualityScanRuleResult_RuleType): string {
  switch (object) {
    case DataQualityScanRuleResult_RuleType.RULE_TYPE_UNSPECIFIED:
      return "RULE_TYPE_UNSPECIFIED";
    case DataQualityScanRuleResult_RuleType.NON_NULL_EXPECTATION:
      return "NON_NULL_EXPECTATION";
    case DataQualityScanRuleResult_RuleType.RANGE_EXPECTATION:
      return "RANGE_EXPECTATION";
    case DataQualityScanRuleResult_RuleType.REGEX_EXPECTATION:
      return "REGEX_EXPECTATION";
    case DataQualityScanRuleResult_RuleType.ROW_CONDITION_EXPECTATION:
      return "ROW_CONDITION_EXPECTATION";
    case DataQualityScanRuleResult_RuleType.SET_EXPECTATION:
      return "SET_EXPECTATION";
    case DataQualityScanRuleResult_RuleType.STATISTIC_RANGE_EXPECTATION:
      return "STATISTIC_RANGE_EXPECTATION";
    case DataQualityScanRuleResult_RuleType.TABLE_CONDITION_EXPECTATION:
      return "TABLE_CONDITION_EXPECTATION";
    case DataQualityScanRuleResult_RuleType.UNIQUENESS_EXPECTATION:
      return "UNIQUENESS_EXPECTATION";
    case DataQualityScanRuleResult_RuleType.SQL_ASSERTION:
      return "SQL_ASSERTION";
    case DataQualityScanRuleResult_RuleType.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/** The evaluation type of the data quality rule. */
export enum DataQualityScanRuleResult_EvaluationType {
  /** EVALUATION_TYPE_UNSPECIFIED - An unspecified evaluation type. */
  EVALUATION_TYPE_UNSPECIFIED = 0,
  /** PER_ROW - The rule evaluation is done at per row level. */
  PER_ROW = 1,
  /** AGGREGATE - The rule evaluation is done for an aggregate of rows. */
  AGGREGATE = 2,
  UNRECOGNIZED = -1,
}

export function dataQualityScanRuleResult_EvaluationTypeFromJSON(
  object: any,
): DataQualityScanRuleResult_EvaluationType {
  switch (object) {
    case 0:
    case "EVALUATION_TYPE_UNSPECIFIED":
      return DataQualityScanRuleResult_EvaluationType.EVALUATION_TYPE_UNSPECIFIED;
    case 1:
    case "PER_ROW":
      return DataQualityScanRuleResult_EvaluationType.PER_ROW;
    case 2:
    case "AGGREGATE":
      return DataQualityScanRuleResult_EvaluationType.AGGREGATE;
    case -1:
    case "UNRECOGNIZED":
    default:
      return DataQualityScanRuleResult_EvaluationType.UNRECOGNIZED;
  }
}

export function dataQualityScanRuleResult_EvaluationTypeToJSON(
  object: DataQualityScanRuleResult_EvaluationType,
): string {
  switch (object) {
    case DataQualityScanRuleResult_EvaluationType.EVALUATION_TYPE_UNSPECIFIED:
      return "EVALUATION_TYPE_UNSPECIFIED";
    case DataQualityScanRuleResult_EvaluationType.PER_ROW:
      return "PER_ROW";
    case DataQualityScanRuleResult_EvaluationType.AGGREGATE:
      return "AGGREGATE";
    case DataQualityScanRuleResult_EvaluationType.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/** Whether the data quality rule passed or failed. */
export enum DataQualityScanRuleResult_Result {
  /** RESULT_UNSPECIFIED - An unspecified result. */
  RESULT_UNSPECIFIED = 0,
  /** PASSED - The data quality rule passed. */
  PASSED = 1,
  /** FAILED - The data quality rule failed. */
  FAILED = 2,
  UNRECOGNIZED = -1,
}

export function dataQualityScanRuleResult_ResultFromJSON(object: any): DataQualityScanRuleResult_Result {
  switch (object) {
    case 0:
    case "RESULT_UNSPECIFIED":
      return DataQualityScanRuleResult_Result.RESULT_UNSPECIFIED;
    case 1:
    case "PASSED":
      return DataQualityScanRuleResult_Result.PASSED;
    case 2:
    case "FAILED":
      return DataQualityScanRuleResult_Result.FAILED;
    case -1:
    case "UNRECOGNIZED":
    default:
      return DataQualityScanRuleResult_Result.UNRECOGNIZED;
  }
}

export function dataQualityScanRuleResult_ResultToJSON(object: DataQualityScanRuleResult_Result): string {
  switch (object) {
    case DataQualityScanRuleResult_Result.RESULT_UNSPECIFIED:
      return "RESULT_UNSPECIFIED";
    case DataQualityScanRuleResult_Result.PASSED:
      return "PASSED";
    case DataQualityScanRuleResult_Result.FAILED:
      return "FAILED";
    case DataQualityScanRuleResult_Result.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

function createBaseDiscoveryEvent(): DiscoveryEvent {
  return {
    message: "",
    lakeId: "",
    zoneId: "",
    assetId: "",
    dataLocation: "",
    type: 0,
    config: undefined,
    entity: undefined,
    partition: undefined,
    action: undefined,
  };
}

export const DiscoveryEvent: MessageFns<DiscoveryEvent> = {
  encode(message: DiscoveryEvent, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.message !== "") {
      writer.uint32(10).string(message.message);
    }
    if (message.lakeId !== "") {
      writer.uint32(18).string(message.lakeId);
    }
    if (message.zoneId !== "") {
      writer.uint32(26).string(message.zoneId);
    }
    if (message.assetId !== "") {
      writer.uint32(34).string(message.assetId);
    }
    if (message.dataLocation !== "") {
      writer.uint32(42).string(message.dataLocation);
    }
    if (message.type !== 0) {
      writer.uint32(80).int32(message.type);
    }
    if (message.config !== undefined) {
      DiscoveryEvent_ConfigDetails.encode(message.config, writer.uint32(162).fork()).join();
    }
    if (message.entity !== undefined) {
      DiscoveryEvent_EntityDetails.encode(message.entity, writer.uint32(170).fork()).join();
    }
    if (message.partition !== undefined) {
      DiscoveryEvent_PartitionDetails.encode(message.partition, writer.uint32(178).fork()).join();
    }
    if (message.action !== undefined) {
      DiscoveryEvent_ActionDetails.encode(message.action, writer.uint32(186).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): DiscoveryEvent {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDiscoveryEvent();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.message = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.lakeId = reader.string();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.zoneId = reader.string();
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.assetId = reader.string();
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.dataLocation = reader.string();
          continue;
        case 10:
          if (tag !== 80) {
            break;
          }

          message.type = reader.int32() as any;
          continue;
        case 20:
          if (tag !== 162) {
            break;
          }

          message.config = DiscoveryEvent_ConfigDetails.decode(reader, reader.uint32());
          continue;
        case 21:
          if (tag !== 170) {
            break;
          }

          message.entity = DiscoveryEvent_EntityDetails.decode(reader, reader.uint32());
          continue;
        case 22:
          if (tag !== 178) {
            break;
          }

          message.partition = DiscoveryEvent_PartitionDetails.decode(reader, reader.uint32());
          continue;
        case 23:
          if (tag !== 186) {
            break;
          }

          message.action = DiscoveryEvent_ActionDetails.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): DiscoveryEvent {
    return {
      message: isSet(object.message) ? globalThis.String(object.message) : "",
      lakeId: isSet(object.lakeId) ? globalThis.String(object.lakeId) : "",
      zoneId: isSet(object.zoneId) ? globalThis.String(object.zoneId) : "",
      assetId: isSet(object.assetId) ? globalThis.String(object.assetId) : "",
      dataLocation: isSet(object.dataLocation) ? globalThis.String(object.dataLocation) : "",
      type: isSet(object.type) ? discoveryEvent_EventTypeFromJSON(object.type) : 0,
      config: isSet(object.config) ? DiscoveryEvent_ConfigDetails.fromJSON(object.config) : undefined,
      entity: isSet(object.entity) ? DiscoveryEvent_EntityDetails.fromJSON(object.entity) : undefined,
      partition: isSet(object.partition) ? DiscoveryEvent_PartitionDetails.fromJSON(object.partition) : undefined,
      action: isSet(object.action) ? DiscoveryEvent_ActionDetails.fromJSON(object.action) : undefined,
    };
  },

  toJSON(message: DiscoveryEvent): unknown {
    const obj: any = {};
    if (message.message !== "") {
      obj.message = message.message;
    }
    if (message.lakeId !== "") {
      obj.lakeId = message.lakeId;
    }
    if (message.zoneId !== "") {
      obj.zoneId = message.zoneId;
    }
    if (message.assetId !== "") {
      obj.assetId = message.assetId;
    }
    if (message.dataLocation !== "") {
      obj.dataLocation = message.dataLocation;
    }
    if (message.type !== 0) {
      obj.type = discoveryEvent_EventTypeToJSON(message.type);
    }
    if (message.config !== undefined) {
      obj.config = DiscoveryEvent_ConfigDetails.toJSON(message.config);
    }
    if (message.entity !== undefined) {
      obj.entity = DiscoveryEvent_EntityDetails.toJSON(message.entity);
    }
    if (message.partition !== undefined) {
      obj.partition = DiscoveryEvent_PartitionDetails.toJSON(message.partition);
    }
    if (message.action !== undefined) {
      obj.action = DiscoveryEvent_ActionDetails.toJSON(message.action);
    }
    return obj;
  },

  create(base?: DeepPartial<DiscoveryEvent>): DiscoveryEvent {
    return DiscoveryEvent.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<DiscoveryEvent>): DiscoveryEvent {
    const message = createBaseDiscoveryEvent();
    message.message = object.message ?? "";
    message.lakeId = object.lakeId ?? "";
    message.zoneId = object.zoneId ?? "";
    message.assetId = object.assetId ?? "";
    message.dataLocation = object.dataLocation ?? "";
    message.type = object.type ?? 0;
    message.config = (object.config !== undefined && object.config !== null)
      ? DiscoveryEvent_ConfigDetails.fromPartial(object.config)
      : undefined;
    message.entity = (object.entity !== undefined && object.entity !== null)
      ? DiscoveryEvent_EntityDetails.fromPartial(object.entity)
      : undefined;
    message.partition = (object.partition !== undefined && object.partition !== null)
      ? DiscoveryEvent_PartitionDetails.fromPartial(object.partition)
      : undefined;
    message.action = (object.action !== undefined && object.action !== null)
      ? DiscoveryEvent_ActionDetails.fromPartial(object.action)
      : undefined;
    return message;
  },
};

function createBaseDiscoveryEvent_ConfigDetails(): DiscoveryEvent_ConfigDetails {
  return { parameters: {} };
}

export const DiscoveryEvent_ConfigDetails: MessageFns<DiscoveryEvent_ConfigDetails> = {
  encode(message: DiscoveryEvent_ConfigDetails, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    Object.entries(message.parameters).forEach(([key, value]) => {
      DiscoveryEvent_ConfigDetails_ParametersEntry.encode({ key: key as any, value }, writer.uint32(10).fork()).join();
    });
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): DiscoveryEvent_ConfigDetails {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDiscoveryEvent_ConfigDetails();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          const entry1 = DiscoveryEvent_ConfigDetails_ParametersEntry.decode(reader, reader.uint32());
          if (entry1.value !== undefined) {
            message.parameters[entry1.key] = entry1.value;
          }
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): DiscoveryEvent_ConfigDetails {
    return {
      parameters: isObject(object.parameters)
        ? Object.entries(object.parameters).reduce<{ [key: string]: string }>((acc, [key, value]) => {
          acc[key] = String(value);
          return acc;
        }, {})
        : {},
    };
  },

  toJSON(message: DiscoveryEvent_ConfigDetails): unknown {
    const obj: any = {};
    if (message.parameters) {
      const entries = Object.entries(message.parameters);
      if (entries.length > 0) {
        obj.parameters = {};
        entries.forEach(([k, v]) => {
          obj.parameters[k] = v;
        });
      }
    }
    return obj;
  },

  create(base?: DeepPartial<DiscoveryEvent_ConfigDetails>): DiscoveryEvent_ConfigDetails {
    return DiscoveryEvent_ConfigDetails.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<DiscoveryEvent_ConfigDetails>): DiscoveryEvent_ConfigDetails {
    const message = createBaseDiscoveryEvent_ConfigDetails();
    message.parameters = Object.entries(object.parameters ?? {}).reduce<{ [key: string]: string }>(
      (acc, [key, value]) => {
        if (value !== undefined) {
          acc[key] = globalThis.String(value);
        }
        return acc;
      },
      {},
    );
    return message;
  },
};

function createBaseDiscoveryEvent_ConfigDetails_ParametersEntry(): DiscoveryEvent_ConfigDetails_ParametersEntry {
  return { key: "", value: "" };
}

export const DiscoveryEvent_ConfigDetails_ParametersEntry: MessageFns<DiscoveryEvent_ConfigDetails_ParametersEntry> = {
  encode(
    message: DiscoveryEvent_ConfigDetails_ParametersEntry,
    writer: BinaryWriter = new BinaryWriter(),
  ): BinaryWriter {
    if (message.key !== "") {
      writer.uint32(10).string(message.key);
    }
    if (message.value !== "") {
      writer.uint32(18).string(message.value);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): DiscoveryEvent_ConfigDetails_ParametersEntry {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDiscoveryEvent_ConfigDetails_ParametersEntry();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.key = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.value = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): DiscoveryEvent_ConfigDetails_ParametersEntry {
    return {
      key: isSet(object.key) ? globalThis.String(object.key) : "",
      value: isSet(object.value) ? globalThis.String(object.value) : "",
    };
  },

  toJSON(message: DiscoveryEvent_ConfigDetails_ParametersEntry): unknown {
    const obj: any = {};
    if (message.key !== "") {
      obj.key = message.key;
    }
    if (message.value !== "") {
      obj.value = message.value;
    }
    return obj;
  },

  create(
    base?: DeepPartial<DiscoveryEvent_ConfigDetails_ParametersEntry>,
  ): DiscoveryEvent_ConfigDetails_ParametersEntry {
    return DiscoveryEvent_ConfigDetails_ParametersEntry.fromPartial(base ?? {});
  },
  fromPartial(
    object: DeepPartial<DiscoveryEvent_ConfigDetails_ParametersEntry>,
  ): DiscoveryEvent_ConfigDetails_ParametersEntry {
    const message = createBaseDiscoveryEvent_ConfigDetails_ParametersEntry();
    message.key = object.key ?? "";
    message.value = object.value ?? "";
    return message;
  },
};

function createBaseDiscoveryEvent_EntityDetails(): DiscoveryEvent_EntityDetails {
  return { entity: "", type: 0 };
}

export const DiscoveryEvent_EntityDetails: MessageFns<DiscoveryEvent_EntityDetails> = {
  encode(message: DiscoveryEvent_EntityDetails, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.entity !== "") {
      writer.uint32(10).string(message.entity);
    }
    if (message.type !== 0) {
      writer.uint32(16).int32(message.type);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): DiscoveryEvent_EntityDetails {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDiscoveryEvent_EntityDetails();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.entity = reader.string();
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.type = reader.int32() as any;
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): DiscoveryEvent_EntityDetails {
    return {
      entity: isSet(object.entity) ? globalThis.String(object.entity) : "",
      type: isSet(object.type) ? discoveryEvent_EntityTypeFromJSON(object.type) : 0,
    };
  },

  toJSON(message: DiscoveryEvent_EntityDetails): unknown {
    const obj: any = {};
    if (message.entity !== "") {
      obj.entity = message.entity;
    }
    if (message.type !== 0) {
      obj.type = discoveryEvent_EntityTypeToJSON(message.type);
    }
    return obj;
  },

  create(base?: DeepPartial<DiscoveryEvent_EntityDetails>): DiscoveryEvent_EntityDetails {
    return DiscoveryEvent_EntityDetails.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<DiscoveryEvent_EntityDetails>): DiscoveryEvent_EntityDetails {
    const message = createBaseDiscoveryEvent_EntityDetails();
    message.entity = object.entity ?? "";
    message.type = object.type ?? 0;
    return message;
  },
};

function createBaseDiscoveryEvent_PartitionDetails(): DiscoveryEvent_PartitionDetails {
  return { partition: "", entity: "", type: 0, sampledDataLocations: [] };
}

export const DiscoveryEvent_PartitionDetails: MessageFns<DiscoveryEvent_PartitionDetails> = {
  encode(message: DiscoveryEvent_PartitionDetails, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.partition !== "") {
      writer.uint32(10).string(message.partition);
    }
    if (message.entity !== "") {
      writer.uint32(18).string(message.entity);
    }
    if (message.type !== 0) {
      writer.uint32(24).int32(message.type);
    }
    for (const v of message.sampledDataLocations) {
      writer.uint32(34).string(v!);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): DiscoveryEvent_PartitionDetails {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDiscoveryEvent_PartitionDetails();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.partition = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.entity = reader.string();
          continue;
        case 3:
          if (tag !== 24) {
            break;
          }

          message.type = reader.int32() as any;
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.sampledDataLocations.push(reader.string());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): DiscoveryEvent_PartitionDetails {
    return {
      partition: isSet(object.partition) ? globalThis.String(object.partition) : "",
      entity: isSet(object.entity) ? globalThis.String(object.entity) : "",
      type: isSet(object.type) ? discoveryEvent_EntityTypeFromJSON(object.type) : 0,
      sampledDataLocations: globalThis.Array.isArray(object?.sampledDataLocations)
        ? object.sampledDataLocations.map((e: any) => globalThis.String(e))
        : [],
    };
  },

  toJSON(message: DiscoveryEvent_PartitionDetails): unknown {
    const obj: any = {};
    if (message.partition !== "") {
      obj.partition = message.partition;
    }
    if (message.entity !== "") {
      obj.entity = message.entity;
    }
    if (message.type !== 0) {
      obj.type = discoveryEvent_EntityTypeToJSON(message.type);
    }
    if (message.sampledDataLocations?.length) {
      obj.sampledDataLocations = message.sampledDataLocations;
    }
    return obj;
  },

  create(base?: DeepPartial<DiscoveryEvent_PartitionDetails>): DiscoveryEvent_PartitionDetails {
    return DiscoveryEvent_PartitionDetails.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<DiscoveryEvent_PartitionDetails>): DiscoveryEvent_PartitionDetails {
    const message = createBaseDiscoveryEvent_PartitionDetails();
    message.partition = object.partition ?? "";
    message.entity = object.entity ?? "";
    message.type = object.type ?? 0;
    message.sampledDataLocations = object.sampledDataLocations?.map((e) => e) || [];
    return message;
  },
};

function createBaseDiscoveryEvent_ActionDetails(): DiscoveryEvent_ActionDetails {
  return { type: "" };
}

export const DiscoveryEvent_ActionDetails: MessageFns<DiscoveryEvent_ActionDetails> = {
  encode(message: DiscoveryEvent_ActionDetails, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.type !== "") {
      writer.uint32(10).string(message.type);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): DiscoveryEvent_ActionDetails {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDiscoveryEvent_ActionDetails();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.type = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): DiscoveryEvent_ActionDetails {
    return { type: isSet(object.type) ? globalThis.String(object.type) : "" };
  },

  toJSON(message: DiscoveryEvent_ActionDetails): unknown {
    const obj: any = {};
    if (message.type !== "") {
      obj.type = message.type;
    }
    return obj;
  },

  create(base?: DeepPartial<DiscoveryEvent_ActionDetails>): DiscoveryEvent_ActionDetails {
    return DiscoveryEvent_ActionDetails.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<DiscoveryEvent_ActionDetails>): DiscoveryEvent_ActionDetails {
    const message = createBaseDiscoveryEvent_ActionDetails();
    message.type = object.type ?? "";
    return message;
  },
};

function createBaseJobEvent(): JobEvent {
  return {
    message: "",
    jobId: "",
    startTime: undefined,
    endTime: undefined,
    state: 0,
    retries: 0,
    type: 0,
    service: 0,
    serviceJob: "",
    executionTrigger: 0,
  };
}

export const JobEvent: MessageFns<JobEvent> = {
  encode(message: JobEvent, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.message !== "") {
      writer.uint32(10).string(message.message);
    }
    if (message.jobId !== "") {
      writer.uint32(18).string(message.jobId);
    }
    if (message.startTime !== undefined) {
      Timestamp.encode(toTimestamp(message.startTime), writer.uint32(26).fork()).join();
    }
    if (message.endTime !== undefined) {
      Timestamp.encode(toTimestamp(message.endTime), writer.uint32(34).fork()).join();
    }
    if (message.state !== 0) {
      writer.uint32(40).int32(message.state);
    }
    if (message.retries !== 0) {
      writer.uint32(48).int32(message.retries);
    }
    if (message.type !== 0) {
      writer.uint32(56).int32(message.type);
    }
    if (message.service !== 0) {
      writer.uint32(64).int32(message.service);
    }
    if (message.serviceJob !== "") {
      writer.uint32(74).string(message.serviceJob);
    }
    if (message.executionTrigger !== 0) {
      writer.uint32(88).int32(message.executionTrigger);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): JobEvent {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseJobEvent();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.message = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.jobId = reader.string();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.startTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.endTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        case 5:
          if (tag !== 40) {
            break;
          }

          message.state = reader.int32() as any;
          continue;
        case 6:
          if (tag !== 48) {
            break;
          }

          message.retries = reader.int32();
          continue;
        case 7:
          if (tag !== 56) {
            break;
          }

          message.type = reader.int32() as any;
          continue;
        case 8:
          if (tag !== 64) {
            break;
          }

          message.service = reader.int32() as any;
          continue;
        case 9:
          if (tag !== 74) {
            break;
          }

          message.serviceJob = reader.string();
          continue;
        case 11:
          if (tag !== 88) {
            break;
          }

          message.executionTrigger = reader.int32() as any;
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): JobEvent {
    return {
      message: isSet(object.message) ? globalThis.String(object.message) : "",
      jobId: isSet(object.jobId) ? globalThis.String(object.jobId) : "",
      startTime: isSet(object.startTime) ? fromJsonTimestamp(object.startTime) : undefined,
      endTime: isSet(object.endTime) ? fromJsonTimestamp(object.endTime) : undefined,
      state: isSet(object.state) ? jobEvent_StateFromJSON(object.state) : 0,
      retries: isSet(object.retries) ? globalThis.Number(object.retries) : 0,
      type: isSet(object.type) ? jobEvent_TypeFromJSON(object.type) : 0,
      service: isSet(object.service) ? jobEvent_ServiceFromJSON(object.service) : 0,
      serviceJob: isSet(object.serviceJob) ? globalThis.String(object.serviceJob) : "",
      executionTrigger: isSet(object.executionTrigger) ? jobEvent_ExecutionTriggerFromJSON(object.executionTrigger) : 0,
    };
  },

  toJSON(message: JobEvent): unknown {
    const obj: any = {};
    if (message.message !== "") {
      obj.message = message.message;
    }
    if (message.jobId !== "") {
      obj.jobId = message.jobId;
    }
    if (message.startTime !== undefined) {
      obj.startTime = message.startTime.toISOString();
    }
    if (message.endTime !== undefined) {
      obj.endTime = message.endTime.toISOString();
    }
    if (message.state !== 0) {
      obj.state = jobEvent_StateToJSON(message.state);
    }
    if (message.retries !== 0) {
      obj.retries = Math.round(message.retries);
    }
    if (message.type !== 0) {
      obj.type = jobEvent_TypeToJSON(message.type);
    }
    if (message.service !== 0) {
      obj.service = jobEvent_ServiceToJSON(message.service);
    }
    if (message.serviceJob !== "") {
      obj.serviceJob = message.serviceJob;
    }
    if (message.executionTrigger !== 0) {
      obj.executionTrigger = jobEvent_ExecutionTriggerToJSON(message.executionTrigger);
    }
    return obj;
  },

  create(base?: DeepPartial<JobEvent>): JobEvent {
    return JobEvent.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<JobEvent>): JobEvent {
    const message = createBaseJobEvent();
    message.message = object.message ?? "";
    message.jobId = object.jobId ?? "";
    message.startTime = object.startTime ?? undefined;
    message.endTime = object.endTime ?? undefined;
    message.state = object.state ?? 0;
    message.retries = object.retries ?? 0;
    message.type = object.type ?? 0;
    message.service = object.service ?? 0;
    message.serviceJob = object.serviceJob ?? "";
    message.executionTrigger = object.executionTrigger ?? 0;
    return message;
  },
};

function createBaseSessionEvent(): SessionEvent {
  return {
    message: "",
    userId: "",
    sessionId: "",
    type: 0,
    query: undefined,
    eventSucceeded: false,
    fastStartupEnabled: false,
    unassignedDuration: undefined,
  };
}

export const SessionEvent: MessageFns<SessionEvent> = {
  encode(message: SessionEvent, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.message !== "") {
      writer.uint32(10).string(message.message);
    }
    if (message.userId !== "") {
      writer.uint32(18).string(message.userId);
    }
    if (message.sessionId !== "") {
      writer.uint32(26).string(message.sessionId);
    }
    if (message.type !== 0) {
      writer.uint32(32).int32(message.type);
    }
    if (message.query !== undefined) {
      SessionEvent_QueryDetail.encode(message.query, writer.uint32(42).fork()).join();
    }
    if (message.eventSucceeded !== false) {
      writer.uint32(48).bool(message.eventSucceeded);
    }
    if (message.fastStartupEnabled !== false) {
      writer.uint32(56).bool(message.fastStartupEnabled);
    }
    if (message.unassignedDuration !== undefined) {
      Duration.encode(message.unassignedDuration, writer.uint32(66).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): SessionEvent {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseSessionEvent();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.message = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.userId = reader.string();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.sessionId = reader.string();
          continue;
        case 4:
          if (tag !== 32) {
            break;
          }

          message.type = reader.int32() as any;
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.query = SessionEvent_QueryDetail.decode(reader, reader.uint32());
          continue;
        case 6:
          if (tag !== 48) {
            break;
          }

          message.eventSucceeded = reader.bool();
          continue;
        case 7:
          if (tag !== 56) {
            break;
          }

          message.fastStartupEnabled = reader.bool();
          continue;
        case 8:
          if (tag !== 66) {
            break;
          }

          message.unassignedDuration = Duration.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): SessionEvent {
    return {
      message: isSet(object.message) ? globalThis.String(object.message) : "",
      userId: isSet(object.userId) ? globalThis.String(object.userId) : "",
      sessionId: isSet(object.sessionId) ? globalThis.String(object.sessionId) : "",
      type: isSet(object.type) ? sessionEvent_EventTypeFromJSON(object.type) : 0,
      query: isSet(object.query) ? SessionEvent_QueryDetail.fromJSON(object.query) : undefined,
      eventSucceeded: isSet(object.eventSucceeded) ? globalThis.Boolean(object.eventSucceeded) : false,
      fastStartupEnabled: isSet(object.fastStartupEnabled) ? globalThis.Boolean(object.fastStartupEnabled) : false,
      unassignedDuration: isSet(object.unassignedDuration) ? Duration.fromJSON(object.unassignedDuration) : undefined,
    };
  },

  toJSON(message: SessionEvent): unknown {
    const obj: any = {};
    if (message.message !== "") {
      obj.message = message.message;
    }
    if (message.userId !== "") {
      obj.userId = message.userId;
    }
    if (message.sessionId !== "") {
      obj.sessionId = message.sessionId;
    }
    if (message.type !== 0) {
      obj.type = sessionEvent_EventTypeToJSON(message.type);
    }
    if (message.query !== undefined) {
      obj.query = SessionEvent_QueryDetail.toJSON(message.query);
    }
    if (message.eventSucceeded !== false) {
      obj.eventSucceeded = message.eventSucceeded;
    }
    if (message.fastStartupEnabled !== false) {
      obj.fastStartupEnabled = message.fastStartupEnabled;
    }
    if (message.unassignedDuration !== undefined) {
      obj.unassignedDuration = Duration.toJSON(message.unassignedDuration);
    }
    return obj;
  },

  create(base?: DeepPartial<SessionEvent>): SessionEvent {
    return SessionEvent.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<SessionEvent>): SessionEvent {
    const message = createBaseSessionEvent();
    message.message = object.message ?? "";
    message.userId = object.userId ?? "";
    message.sessionId = object.sessionId ?? "";
    message.type = object.type ?? 0;
    message.query = (object.query !== undefined && object.query !== null)
      ? SessionEvent_QueryDetail.fromPartial(object.query)
      : undefined;
    message.eventSucceeded = object.eventSucceeded ?? false;
    message.fastStartupEnabled = object.fastStartupEnabled ?? false;
    message.unassignedDuration = (object.unassignedDuration !== undefined && object.unassignedDuration !== null)
      ? Duration.fromPartial(object.unassignedDuration)
      : undefined;
    return message;
  },
};

function createBaseSessionEvent_QueryDetail(): SessionEvent_QueryDetail {
  return {
    queryId: "",
    queryText: "",
    engine: 0,
    duration: undefined,
    resultSizeBytes: Long.ZERO,
    dataProcessedBytes: Long.ZERO,
  };
}

export const SessionEvent_QueryDetail: MessageFns<SessionEvent_QueryDetail> = {
  encode(message: SessionEvent_QueryDetail, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.queryId !== "") {
      writer.uint32(10).string(message.queryId);
    }
    if (message.queryText !== "") {
      writer.uint32(18).string(message.queryText);
    }
    if (message.engine !== 0) {
      writer.uint32(24).int32(message.engine);
    }
    if (message.duration !== undefined) {
      Duration.encode(message.duration, writer.uint32(34).fork()).join();
    }
    if (!message.resultSizeBytes.equals(Long.ZERO)) {
      writer.uint32(40).int64(message.resultSizeBytes.toString());
    }
    if (!message.dataProcessedBytes.equals(Long.ZERO)) {
      writer.uint32(48).int64(message.dataProcessedBytes.toString());
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): SessionEvent_QueryDetail {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseSessionEvent_QueryDetail();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.queryId = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.queryText = reader.string();
          continue;
        case 3:
          if (tag !== 24) {
            break;
          }

          message.engine = reader.int32() as any;
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.duration = Duration.decode(reader, reader.uint32());
          continue;
        case 5:
          if (tag !== 40) {
            break;
          }

          message.resultSizeBytes = Long.fromString(reader.int64().toString());
          continue;
        case 6:
          if (tag !== 48) {
            break;
          }

          message.dataProcessedBytes = Long.fromString(reader.int64().toString());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): SessionEvent_QueryDetail {
    return {
      queryId: isSet(object.queryId) ? globalThis.String(object.queryId) : "",
      queryText: isSet(object.queryText) ? globalThis.String(object.queryText) : "",
      engine: isSet(object.engine) ? sessionEvent_QueryDetail_EngineFromJSON(object.engine) : 0,
      duration: isSet(object.duration) ? Duration.fromJSON(object.duration) : undefined,
      resultSizeBytes: isSet(object.resultSizeBytes) ? Long.fromValue(object.resultSizeBytes) : Long.ZERO,
      dataProcessedBytes: isSet(object.dataProcessedBytes) ? Long.fromValue(object.dataProcessedBytes) : Long.ZERO,
    };
  },

  toJSON(message: SessionEvent_QueryDetail): unknown {
    const obj: any = {};
    if (message.queryId !== "") {
      obj.queryId = message.queryId;
    }
    if (message.queryText !== "") {
      obj.queryText = message.queryText;
    }
    if (message.engine !== 0) {
      obj.engine = sessionEvent_QueryDetail_EngineToJSON(message.engine);
    }
    if (message.duration !== undefined) {
      obj.duration = Duration.toJSON(message.duration);
    }
    if (!message.resultSizeBytes.equals(Long.ZERO)) {
      obj.resultSizeBytes = (message.resultSizeBytes || Long.ZERO).toString();
    }
    if (!message.dataProcessedBytes.equals(Long.ZERO)) {
      obj.dataProcessedBytes = (message.dataProcessedBytes || Long.ZERO).toString();
    }
    return obj;
  },

  create(base?: DeepPartial<SessionEvent_QueryDetail>): SessionEvent_QueryDetail {
    return SessionEvent_QueryDetail.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<SessionEvent_QueryDetail>): SessionEvent_QueryDetail {
    const message = createBaseSessionEvent_QueryDetail();
    message.queryId = object.queryId ?? "";
    message.queryText = object.queryText ?? "";
    message.engine = object.engine ?? 0;
    message.duration = (object.duration !== undefined && object.duration !== null)
      ? Duration.fromPartial(object.duration)
      : undefined;
    message.resultSizeBytes = (object.resultSizeBytes !== undefined && object.resultSizeBytes !== null)
      ? Long.fromValue(object.resultSizeBytes)
      : Long.ZERO;
    message.dataProcessedBytes = (object.dataProcessedBytes !== undefined && object.dataProcessedBytes !== null)
      ? Long.fromValue(object.dataProcessedBytes)
      : Long.ZERO;
    return message;
  },
};

function createBaseGovernanceEvent(): GovernanceEvent {
  return { message: "", eventType: 0, entity: undefined };
}

export const GovernanceEvent: MessageFns<GovernanceEvent> = {
  encode(message: GovernanceEvent, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.message !== "") {
      writer.uint32(10).string(message.message);
    }
    if (message.eventType !== 0) {
      writer.uint32(16).int32(message.eventType);
    }
    if (message.entity !== undefined) {
      GovernanceEvent_Entity.encode(message.entity, writer.uint32(26).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): GovernanceEvent {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseGovernanceEvent();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.message = reader.string();
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.eventType = reader.int32() as any;
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.entity = GovernanceEvent_Entity.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): GovernanceEvent {
    return {
      message: isSet(object.message) ? globalThis.String(object.message) : "",
      eventType: isSet(object.eventType) ? governanceEvent_EventTypeFromJSON(object.eventType) : 0,
      entity: isSet(object.entity) ? GovernanceEvent_Entity.fromJSON(object.entity) : undefined,
    };
  },

  toJSON(message: GovernanceEvent): unknown {
    const obj: any = {};
    if (message.message !== "") {
      obj.message = message.message;
    }
    if (message.eventType !== 0) {
      obj.eventType = governanceEvent_EventTypeToJSON(message.eventType);
    }
    if (message.entity !== undefined) {
      obj.entity = GovernanceEvent_Entity.toJSON(message.entity);
    }
    return obj;
  },

  create(base?: DeepPartial<GovernanceEvent>): GovernanceEvent {
    return GovernanceEvent.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<GovernanceEvent>): GovernanceEvent {
    const message = createBaseGovernanceEvent();
    message.message = object.message ?? "";
    message.eventType = object.eventType ?? 0;
    message.entity = (object.entity !== undefined && object.entity !== null)
      ? GovernanceEvent_Entity.fromPartial(object.entity)
      : undefined;
    return message;
  },
};

function createBaseGovernanceEvent_Entity(): GovernanceEvent_Entity {
  return { entity: "", entityType: 0 };
}

export const GovernanceEvent_Entity: MessageFns<GovernanceEvent_Entity> = {
  encode(message: GovernanceEvent_Entity, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.entity !== "") {
      writer.uint32(10).string(message.entity);
    }
    if (message.entityType !== 0) {
      writer.uint32(16).int32(message.entityType);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): GovernanceEvent_Entity {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseGovernanceEvent_Entity();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.entity = reader.string();
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.entityType = reader.int32() as any;
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): GovernanceEvent_Entity {
    return {
      entity: isSet(object.entity) ? globalThis.String(object.entity) : "",
      entityType: isSet(object.entityType) ? governanceEvent_Entity_EntityTypeFromJSON(object.entityType) : 0,
    };
  },

  toJSON(message: GovernanceEvent_Entity): unknown {
    const obj: any = {};
    if (message.entity !== "") {
      obj.entity = message.entity;
    }
    if (message.entityType !== 0) {
      obj.entityType = governanceEvent_Entity_EntityTypeToJSON(message.entityType);
    }
    return obj;
  },

  create(base?: DeepPartial<GovernanceEvent_Entity>): GovernanceEvent_Entity {
    return GovernanceEvent_Entity.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<GovernanceEvent_Entity>): GovernanceEvent_Entity {
    const message = createBaseGovernanceEvent_Entity();
    message.entity = object.entity ?? "";
    message.entityType = object.entityType ?? 0;
    return message;
  },
};

function createBaseDataScanEvent(): DataScanEvent {
  return {
    dataSource: "",
    jobId: "",
    createTime: undefined,
    startTime: undefined,
    endTime: undefined,
    type: 0,
    state: 0,
    message: "",
    specVersion: "",
    trigger: 0,
    scope: 0,
    dataProfile: undefined,
    dataQuality: undefined,
    dataProfileConfigs: undefined,
    dataQualityConfigs: undefined,
    postScanActionsResult: undefined,
  };
}

export const DataScanEvent: MessageFns<DataScanEvent> = {
  encode(message: DataScanEvent, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.dataSource !== "") {
      writer.uint32(10).string(message.dataSource);
    }
    if (message.jobId !== "") {
      writer.uint32(18).string(message.jobId);
    }
    if (message.createTime !== undefined) {
      Timestamp.encode(toTimestamp(message.createTime), writer.uint32(98).fork()).join();
    }
    if (message.startTime !== undefined) {
      Timestamp.encode(toTimestamp(message.startTime), writer.uint32(26).fork()).join();
    }
    if (message.endTime !== undefined) {
      Timestamp.encode(toTimestamp(message.endTime), writer.uint32(34).fork()).join();
    }
    if (message.type !== 0) {
      writer.uint32(40).int32(message.type);
    }
    if (message.state !== 0) {
      writer.uint32(48).int32(message.state);
    }
    if (message.message !== "") {
      writer.uint32(58).string(message.message);
    }
    if (message.specVersion !== "") {
      writer.uint32(66).string(message.specVersion);
    }
    if (message.trigger !== 0) {
      writer.uint32(72).int32(message.trigger);
    }
    if (message.scope !== 0) {
      writer.uint32(80).int32(message.scope);
    }
    if (message.dataProfile !== undefined) {
      DataScanEvent_DataProfileResult.encode(message.dataProfile, writer.uint32(810).fork()).join();
    }
    if (message.dataQuality !== undefined) {
      DataScanEvent_DataQualityResult.encode(message.dataQuality, writer.uint32(818).fork()).join();
    }
    if (message.dataProfileConfigs !== undefined) {
      DataScanEvent_DataProfileAppliedConfigs.encode(message.dataProfileConfigs, writer.uint32(1610).fork()).join();
    }
    if (message.dataQualityConfigs !== undefined) {
      DataScanEvent_DataQualityAppliedConfigs.encode(message.dataQualityConfigs, writer.uint32(1618).fork()).join();
    }
    if (message.postScanActionsResult !== undefined) {
      DataScanEvent_PostScanActionsResult.encode(message.postScanActionsResult, writer.uint32(90).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): DataScanEvent {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDataScanEvent();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.dataSource = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.jobId = reader.string();
          continue;
        case 12:
          if (tag !== 98) {
            break;
          }

          message.createTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.startTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.endTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        case 5:
          if (tag !== 40) {
            break;
          }

          message.type = reader.int32() as any;
          continue;
        case 6:
          if (tag !== 48) {
            break;
          }

          message.state = reader.int32() as any;
          continue;
        case 7:
          if (tag !== 58) {
            break;
          }

          message.message = reader.string();
          continue;
        case 8:
          if (tag !== 66) {
            break;
          }

          message.specVersion = reader.string();
          continue;
        case 9:
          if (tag !== 72) {
            break;
          }

          message.trigger = reader.int32() as any;
          continue;
        case 10:
          if (tag !== 80) {
            break;
          }

          message.scope = reader.int32() as any;
          continue;
        case 101:
          if (tag !== 810) {
            break;
          }

          message.dataProfile = DataScanEvent_DataProfileResult.decode(reader, reader.uint32());
          continue;
        case 102:
          if (tag !== 818) {
            break;
          }

          message.dataQuality = DataScanEvent_DataQualityResult.decode(reader, reader.uint32());
          continue;
        case 201:
          if (tag !== 1610) {
            break;
          }

          message.dataProfileConfigs = DataScanEvent_DataProfileAppliedConfigs.decode(reader, reader.uint32());
          continue;
        case 202:
          if (tag !== 1618) {
            break;
          }

          message.dataQualityConfigs = DataScanEvent_DataQualityAppliedConfigs.decode(reader, reader.uint32());
          continue;
        case 11:
          if (tag !== 90) {
            break;
          }

          message.postScanActionsResult = DataScanEvent_PostScanActionsResult.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): DataScanEvent {
    return {
      dataSource: isSet(object.dataSource) ? globalThis.String(object.dataSource) : "",
      jobId: isSet(object.jobId) ? globalThis.String(object.jobId) : "",
      createTime: isSet(object.createTime) ? fromJsonTimestamp(object.createTime) : undefined,
      startTime: isSet(object.startTime) ? fromJsonTimestamp(object.startTime) : undefined,
      endTime: isSet(object.endTime) ? fromJsonTimestamp(object.endTime) : undefined,
      type: isSet(object.type) ? dataScanEvent_ScanTypeFromJSON(object.type) : 0,
      state: isSet(object.state) ? dataScanEvent_StateFromJSON(object.state) : 0,
      message: isSet(object.message) ? globalThis.String(object.message) : "",
      specVersion: isSet(object.specVersion) ? globalThis.String(object.specVersion) : "",
      trigger: isSet(object.trigger) ? dataScanEvent_TriggerFromJSON(object.trigger) : 0,
      scope: isSet(object.scope) ? dataScanEvent_ScopeFromJSON(object.scope) : 0,
      dataProfile: isSet(object.dataProfile) ? DataScanEvent_DataProfileResult.fromJSON(object.dataProfile) : undefined,
      dataQuality: isSet(object.dataQuality) ? DataScanEvent_DataQualityResult.fromJSON(object.dataQuality) : undefined,
      dataProfileConfigs: isSet(object.dataProfileConfigs)
        ? DataScanEvent_DataProfileAppliedConfigs.fromJSON(object.dataProfileConfigs)
        : undefined,
      dataQualityConfigs: isSet(object.dataQualityConfigs)
        ? DataScanEvent_DataQualityAppliedConfigs.fromJSON(object.dataQualityConfigs)
        : undefined,
      postScanActionsResult: isSet(object.postScanActionsResult)
        ? DataScanEvent_PostScanActionsResult.fromJSON(object.postScanActionsResult)
        : undefined,
    };
  },

  toJSON(message: DataScanEvent): unknown {
    const obj: any = {};
    if (message.dataSource !== "") {
      obj.dataSource = message.dataSource;
    }
    if (message.jobId !== "") {
      obj.jobId = message.jobId;
    }
    if (message.createTime !== undefined) {
      obj.createTime = message.createTime.toISOString();
    }
    if (message.startTime !== undefined) {
      obj.startTime = message.startTime.toISOString();
    }
    if (message.endTime !== undefined) {
      obj.endTime = message.endTime.toISOString();
    }
    if (message.type !== 0) {
      obj.type = dataScanEvent_ScanTypeToJSON(message.type);
    }
    if (message.state !== 0) {
      obj.state = dataScanEvent_StateToJSON(message.state);
    }
    if (message.message !== "") {
      obj.message = message.message;
    }
    if (message.specVersion !== "") {
      obj.specVersion = message.specVersion;
    }
    if (message.trigger !== 0) {
      obj.trigger = dataScanEvent_TriggerToJSON(message.trigger);
    }
    if (message.scope !== 0) {
      obj.scope = dataScanEvent_ScopeToJSON(message.scope);
    }
    if (message.dataProfile !== undefined) {
      obj.dataProfile = DataScanEvent_DataProfileResult.toJSON(message.dataProfile);
    }
    if (message.dataQuality !== undefined) {
      obj.dataQuality = DataScanEvent_DataQualityResult.toJSON(message.dataQuality);
    }
    if (message.dataProfileConfigs !== undefined) {
      obj.dataProfileConfigs = DataScanEvent_DataProfileAppliedConfigs.toJSON(message.dataProfileConfigs);
    }
    if (message.dataQualityConfigs !== undefined) {
      obj.dataQualityConfigs = DataScanEvent_DataQualityAppliedConfigs.toJSON(message.dataQualityConfigs);
    }
    if (message.postScanActionsResult !== undefined) {
      obj.postScanActionsResult = DataScanEvent_PostScanActionsResult.toJSON(message.postScanActionsResult);
    }
    return obj;
  },

  create(base?: DeepPartial<DataScanEvent>): DataScanEvent {
    return DataScanEvent.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<DataScanEvent>): DataScanEvent {
    const message = createBaseDataScanEvent();
    message.dataSource = object.dataSource ?? "";
    message.jobId = object.jobId ?? "";
    message.createTime = object.createTime ?? undefined;
    message.startTime = object.startTime ?? undefined;
    message.endTime = object.endTime ?? undefined;
    message.type = object.type ?? 0;
    message.state = object.state ?? 0;
    message.message = object.message ?? "";
    message.specVersion = object.specVersion ?? "";
    message.trigger = object.trigger ?? 0;
    message.scope = object.scope ?? 0;
    message.dataProfile = (object.dataProfile !== undefined && object.dataProfile !== null)
      ? DataScanEvent_DataProfileResult.fromPartial(object.dataProfile)
      : undefined;
    message.dataQuality = (object.dataQuality !== undefined && object.dataQuality !== null)
      ? DataScanEvent_DataQualityResult.fromPartial(object.dataQuality)
      : undefined;
    message.dataProfileConfigs = (object.dataProfileConfigs !== undefined && object.dataProfileConfigs !== null)
      ? DataScanEvent_DataProfileAppliedConfigs.fromPartial(object.dataProfileConfigs)
      : undefined;
    message.dataQualityConfigs = (object.dataQualityConfigs !== undefined && object.dataQualityConfigs !== null)
      ? DataScanEvent_DataQualityAppliedConfigs.fromPartial(object.dataQualityConfigs)
      : undefined;
    message.postScanActionsResult =
      (object.postScanActionsResult !== undefined && object.postScanActionsResult !== null)
        ? DataScanEvent_PostScanActionsResult.fromPartial(object.postScanActionsResult)
        : undefined;
    return message;
  },
};

function createBaseDataScanEvent_DataProfileResult(): DataScanEvent_DataProfileResult {
  return { rowCount: Long.ZERO };
}

export const DataScanEvent_DataProfileResult: MessageFns<DataScanEvent_DataProfileResult> = {
  encode(message: DataScanEvent_DataProfileResult, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (!message.rowCount.equals(Long.ZERO)) {
      writer.uint32(8).int64(message.rowCount.toString());
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): DataScanEvent_DataProfileResult {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDataScanEvent_DataProfileResult();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 8) {
            break;
          }

          message.rowCount = Long.fromString(reader.int64().toString());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): DataScanEvent_DataProfileResult {
    return { rowCount: isSet(object.rowCount) ? Long.fromValue(object.rowCount) : Long.ZERO };
  },

  toJSON(message: DataScanEvent_DataProfileResult): unknown {
    const obj: any = {};
    if (!message.rowCount.equals(Long.ZERO)) {
      obj.rowCount = (message.rowCount || Long.ZERO).toString();
    }
    return obj;
  },

  create(base?: DeepPartial<DataScanEvent_DataProfileResult>): DataScanEvent_DataProfileResult {
    return DataScanEvent_DataProfileResult.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<DataScanEvent_DataProfileResult>): DataScanEvent_DataProfileResult {
    const message = createBaseDataScanEvent_DataProfileResult();
    message.rowCount = (object.rowCount !== undefined && object.rowCount !== null)
      ? Long.fromValue(object.rowCount)
      : Long.ZERO;
    return message;
  },
};

function createBaseDataScanEvent_DataQualityResult(): DataScanEvent_DataQualityResult {
  return { rowCount: Long.ZERO, passed: false, dimensionPassed: {}, score: 0, dimensionScore: {}, columnScore: {} };
}

export const DataScanEvent_DataQualityResult: MessageFns<DataScanEvent_DataQualityResult> = {
  encode(message: DataScanEvent_DataQualityResult, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (!message.rowCount.equals(Long.ZERO)) {
      writer.uint32(8).int64(message.rowCount.toString());
    }
    if (message.passed !== false) {
      writer.uint32(16).bool(message.passed);
    }
    Object.entries(message.dimensionPassed).forEach(([key, value]) => {
      DataScanEvent_DataQualityResult_DimensionPassedEntry.encode({ key: key as any, value }, writer.uint32(26).fork())
        .join();
    });
    if (message.score !== 0) {
      writer.uint32(37).float(message.score);
    }
    Object.entries(message.dimensionScore).forEach(([key, value]) => {
      DataScanEvent_DataQualityResult_DimensionScoreEntry.encode({ key: key as any, value }, writer.uint32(42).fork())
        .join();
    });
    Object.entries(message.columnScore).forEach(([key, value]) => {
      DataScanEvent_DataQualityResult_ColumnScoreEntry.encode({ key: key as any, value }, writer.uint32(50).fork())
        .join();
    });
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): DataScanEvent_DataQualityResult {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDataScanEvent_DataQualityResult();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 8) {
            break;
          }

          message.rowCount = Long.fromString(reader.int64().toString());
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.passed = reader.bool();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          const entry3 = DataScanEvent_DataQualityResult_DimensionPassedEntry.decode(reader, reader.uint32());
          if (entry3.value !== undefined) {
            message.dimensionPassed[entry3.key] = entry3.value;
          }
          continue;
        case 4:
          if (tag !== 37) {
            break;
          }

          message.score = reader.float();
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          const entry5 = DataScanEvent_DataQualityResult_DimensionScoreEntry.decode(reader, reader.uint32());
          if (entry5.value !== undefined) {
            message.dimensionScore[entry5.key] = entry5.value;
          }
          continue;
        case 6:
          if (tag !== 50) {
            break;
          }

          const entry6 = DataScanEvent_DataQualityResult_ColumnScoreEntry.decode(reader, reader.uint32());
          if (entry6.value !== undefined) {
            message.columnScore[entry6.key] = entry6.value;
          }
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): DataScanEvent_DataQualityResult {
    return {
      rowCount: isSet(object.rowCount) ? Long.fromValue(object.rowCount) : Long.ZERO,
      passed: isSet(object.passed) ? globalThis.Boolean(object.passed) : false,
      dimensionPassed: isObject(object.dimensionPassed)
        ? Object.entries(object.dimensionPassed).reduce<{ [key: string]: boolean }>((acc, [key, value]) => {
          acc[key] = Boolean(value);
          return acc;
        }, {})
        : {},
      score: isSet(object.score) ? globalThis.Number(object.score) : 0,
      dimensionScore: isObject(object.dimensionScore)
        ? Object.entries(object.dimensionScore).reduce<{ [key: string]: number }>((acc, [key, value]) => {
          acc[key] = Number(value);
          return acc;
        }, {})
        : {},
      columnScore: isObject(object.columnScore)
        ? Object.entries(object.columnScore).reduce<{ [key: string]: number }>((acc, [key, value]) => {
          acc[key] = Number(value);
          return acc;
        }, {})
        : {},
    };
  },

  toJSON(message: DataScanEvent_DataQualityResult): unknown {
    const obj: any = {};
    if (!message.rowCount.equals(Long.ZERO)) {
      obj.rowCount = (message.rowCount || Long.ZERO).toString();
    }
    if (message.passed !== false) {
      obj.passed = message.passed;
    }
    if (message.dimensionPassed) {
      const entries = Object.entries(message.dimensionPassed);
      if (entries.length > 0) {
        obj.dimensionPassed = {};
        entries.forEach(([k, v]) => {
          obj.dimensionPassed[k] = v;
        });
      }
    }
    if (message.score !== 0) {
      obj.score = message.score;
    }
    if (message.dimensionScore) {
      const entries = Object.entries(message.dimensionScore);
      if (entries.length > 0) {
        obj.dimensionScore = {};
        entries.forEach(([k, v]) => {
          obj.dimensionScore[k] = v;
        });
      }
    }
    if (message.columnScore) {
      const entries = Object.entries(message.columnScore);
      if (entries.length > 0) {
        obj.columnScore = {};
        entries.forEach(([k, v]) => {
          obj.columnScore[k] = v;
        });
      }
    }
    return obj;
  },

  create(base?: DeepPartial<DataScanEvent_DataQualityResult>): DataScanEvent_DataQualityResult {
    return DataScanEvent_DataQualityResult.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<DataScanEvent_DataQualityResult>): DataScanEvent_DataQualityResult {
    const message = createBaseDataScanEvent_DataQualityResult();
    message.rowCount = (object.rowCount !== undefined && object.rowCount !== null)
      ? Long.fromValue(object.rowCount)
      : Long.ZERO;
    message.passed = object.passed ?? false;
    message.dimensionPassed = Object.entries(object.dimensionPassed ?? {}).reduce<{ [key: string]: boolean }>(
      (acc, [key, value]) => {
        if (value !== undefined) {
          acc[key] = globalThis.Boolean(value);
        }
        return acc;
      },
      {},
    );
    message.score = object.score ?? 0;
    message.dimensionScore = Object.entries(object.dimensionScore ?? {}).reduce<{ [key: string]: number }>(
      (acc, [key, value]) => {
        if (value !== undefined) {
          acc[key] = globalThis.Number(value);
        }
        return acc;
      },
      {},
    );
    message.columnScore = Object.entries(object.columnScore ?? {}).reduce<{ [key: string]: number }>(
      (acc, [key, value]) => {
        if (value !== undefined) {
          acc[key] = globalThis.Number(value);
        }
        return acc;
      },
      {},
    );
    return message;
  },
};

function createBaseDataScanEvent_DataQualityResult_DimensionPassedEntry(): DataScanEvent_DataQualityResult_DimensionPassedEntry {
  return { key: "", value: false };
}

export const DataScanEvent_DataQualityResult_DimensionPassedEntry: MessageFns<
  DataScanEvent_DataQualityResult_DimensionPassedEntry
> = {
  encode(
    message: DataScanEvent_DataQualityResult_DimensionPassedEntry,
    writer: BinaryWriter = new BinaryWriter(),
  ): BinaryWriter {
    if (message.key !== "") {
      writer.uint32(10).string(message.key);
    }
    if (message.value !== false) {
      writer.uint32(16).bool(message.value);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): DataScanEvent_DataQualityResult_DimensionPassedEntry {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDataScanEvent_DataQualityResult_DimensionPassedEntry();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.key = reader.string();
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.value = reader.bool();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): DataScanEvent_DataQualityResult_DimensionPassedEntry {
    return {
      key: isSet(object.key) ? globalThis.String(object.key) : "",
      value: isSet(object.value) ? globalThis.Boolean(object.value) : false,
    };
  },

  toJSON(message: DataScanEvent_DataQualityResult_DimensionPassedEntry): unknown {
    const obj: any = {};
    if (message.key !== "") {
      obj.key = message.key;
    }
    if (message.value !== false) {
      obj.value = message.value;
    }
    return obj;
  },

  create(
    base?: DeepPartial<DataScanEvent_DataQualityResult_DimensionPassedEntry>,
  ): DataScanEvent_DataQualityResult_DimensionPassedEntry {
    return DataScanEvent_DataQualityResult_DimensionPassedEntry.fromPartial(base ?? {});
  },
  fromPartial(
    object: DeepPartial<DataScanEvent_DataQualityResult_DimensionPassedEntry>,
  ): DataScanEvent_DataQualityResult_DimensionPassedEntry {
    const message = createBaseDataScanEvent_DataQualityResult_DimensionPassedEntry();
    message.key = object.key ?? "";
    message.value = object.value ?? false;
    return message;
  },
};

function createBaseDataScanEvent_DataQualityResult_DimensionScoreEntry(): DataScanEvent_DataQualityResult_DimensionScoreEntry {
  return { key: "", value: 0 };
}

export const DataScanEvent_DataQualityResult_DimensionScoreEntry: MessageFns<
  DataScanEvent_DataQualityResult_DimensionScoreEntry
> = {
  encode(
    message: DataScanEvent_DataQualityResult_DimensionScoreEntry,
    writer: BinaryWriter = new BinaryWriter(),
  ): BinaryWriter {
    if (message.key !== "") {
      writer.uint32(10).string(message.key);
    }
    if (message.value !== 0) {
      writer.uint32(21).float(message.value);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): DataScanEvent_DataQualityResult_DimensionScoreEntry {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDataScanEvent_DataQualityResult_DimensionScoreEntry();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.key = reader.string();
          continue;
        case 2:
          if (tag !== 21) {
            break;
          }

          message.value = reader.float();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): DataScanEvent_DataQualityResult_DimensionScoreEntry {
    return {
      key: isSet(object.key) ? globalThis.String(object.key) : "",
      value: isSet(object.value) ? globalThis.Number(object.value) : 0,
    };
  },

  toJSON(message: DataScanEvent_DataQualityResult_DimensionScoreEntry): unknown {
    const obj: any = {};
    if (message.key !== "") {
      obj.key = message.key;
    }
    if (message.value !== 0) {
      obj.value = message.value;
    }
    return obj;
  },

  create(
    base?: DeepPartial<DataScanEvent_DataQualityResult_DimensionScoreEntry>,
  ): DataScanEvent_DataQualityResult_DimensionScoreEntry {
    return DataScanEvent_DataQualityResult_DimensionScoreEntry.fromPartial(base ?? {});
  },
  fromPartial(
    object: DeepPartial<DataScanEvent_DataQualityResult_DimensionScoreEntry>,
  ): DataScanEvent_DataQualityResult_DimensionScoreEntry {
    const message = createBaseDataScanEvent_DataQualityResult_DimensionScoreEntry();
    message.key = object.key ?? "";
    message.value = object.value ?? 0;
    return message;
  },
};

function createBaseDataScanEvent_DataQualityResult_ColumnScoreEntry(): DataScanEvent_DataQualityResult_ColumnScoreEntry {
  return { key: "", value: 0 };
}

export const DataScanEvent_DataQualityResult_ColumnScoreEntry: MessageFns<
  DataScanEvent_DataQualityResult_ColumnScoreEntry
> = {
  encode(
    message: DataScanEvent_DataQualityResult_ColumnScoreEntry,
    writer: BinaryWriter = new BinaryWriter(),
  ): BinaryWriter {
    if (message.key !== "") {
      writer.uint32(10).string(message.key);
    }
    if (message.value !== 0) {
      writer.uint32(21).float(message.value);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): DataScanEvent_DataQualityResult_ColumnScoreEntry {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDataScanEvent_DataQualityResult_ColumnScoreEntry();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.key = reader.string();
          continue;
        case 2:
          if (tag !== 21) {
            break;
          }

          message.value = reader.float();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): DataScanEvent_DataQualityResult_ColumnScoreEntry {
    return {
      key: isSet(object.key) ? globalThis.String(object.key) : "",
      value: isSet(object.value) ? globalThis.Number(object.value) : 0,
    };
  },

  toJSON(message: DataScanEvent_DataQualityResult_ColumnScoreEntry): unknown {
    const obj: any = {};
    if (message.key !== "") {
      obj.key = message.key;
    }
    if (message.value !== 0) {
      obj.value = message.value;
    }
    return obj;
  },

  create(
    base?: DeepPartial<DataScanEvent_DataQualityResult_ColumnScoreEntry>,
  ): DataScanEvent_DataQualityResult_ColumnScoreEntry {
    return DataScanEvent_DataQualityResult_ColumnScoreEntry.fromPartial(base ?? {});
  },
  fromPartial(
    object: DeepPartial<DataScanEvent_DataQualityResult_ColumnScoreEntry>,
  ): DataScanEvent_DataQualityResult_ColumnScoreEntry {
    const message = createBaseDataScanEvent_DataQualityResult_ColumnScoreEntry();
    message.key = object.key ?? "";
    message.value = object.value ?? 0;
    return message;
  },
};

function createBaseDataScanEvent_DataProfileAppliedConfigs(): DataScanEvent_DataProfileAppliedConfigs {
  return { samplingPercent: 0, rowFilterApplied: false, columnFilterApplied: false };
}

export const DataScanEvent_DataProfileAppliedConfigs: MessageFns<DataScanEvent_DataProfileAppliedConfigs> = {
  encode(message: DataScanEvent_DataProfileAppliedConfigs, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.samplingPercent !== 0) {
      writer.uint32(13).float(message.samplingPercent);
    }
    if (message.rowFilterApplied !== false) {
      writer.uint32(16).bool(message.rowFilterApplied);
    }
    if (message.columnFilterApplied !== false) {
      writer.uint32(24).bool(message.columnFilterApplied);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): DataScanEvent_DataProfileAppliedConfigs {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDataScanEvent_DataProfileAppliedConfigs();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 13) {
            break;
          }

          message.samplingPercent = reader.float();
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.rowFilterApplied = reader.bool();
          continue;
        case 3:
          if (tag !== 24) {
            break;
          }

          message.columnFilterApplied = reader.bool();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): DataScanEvent_DataProfileAppliedConfigs {
    return {
      samplingPercent: isSet(object.samplingPercent) ? globalThis.Number(object.samplingPercent) : 0,
      rowFilterApplied: isSet(object.rowFilterApplied) ? globalThis.Boolean(object.rowFilterApplied) : false,
      columnFilterApplied: isSet(object.columnFilterApplied) ? globalThis.Boolean(object.columnFilterApplied) : false,
    };
  },

  toJSON(message: DataScanEvent_DataProfileAppliedConfigs): unknown {
    const obj: any = {};
    if (message.samplingPercent !== 0) {
      obj.samplingPercent = message.samplingPercent;
    }
    if (message.rowFilterApplied !== false) {
      obj.rowFilterApplied = message.rowFilterApplied;
    }
    if (message.columnFilterApplied !== false) {
      obj.columnFilterApplied = message.columnFilterApplied;
    }
    return obj;
  },

  create(base?: DeepPartial<DataScanEvent_DataProfileAppliedConfigs>): DataScanEvent_DataProfileAppliedConfigs {
    return DataScanEvent_DataProfileAppliedConfigs.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<DataScanEvent_DataProfileAppliedConfigs>): DataScanEvent_DataProfileAppliedConfigs {
    const message = createBaseDataScanEvent_DataProfileAppliedConfigs();
    message.samplingPercent = object.samplingPercent ?? 0;
    message.rowFilterApplied = object.rowFilterApplied ?? false;
    message.columnFilterApplied = object.columnFilterApplied ?? false;
    return message;
  },
};

function createBaseDataScanEvent_DataQualityAppliedConfigs(): DataScanEvent_DataQualityAppliedConfigs {
  return { samplingPercent: 0, rowFilterApplied: false };
}

export const DataScanEvent_DataQualityAppliedConfigs: MessageFns<DataScanEvent_DataQualityAppliedConfigs> = {
  encode(message: DataScanEvent_DataQualityAppliedConfigs, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.samplingPercent !== 0) {
      writer.uint32(13).float(message.samplingPercent);
    }
    if (message.rowFilterApplied !== false) {
      writer.uint32(16).bool(message.rowFilterApplied);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): DataScanEvent_DataQualityAppliedConfigs {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDataScanEvent_DataQualityAppliedConfigs();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 13) {
            break;
          }

          message.samplingPercent = reader.float();
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.rowFilterApplied = reader.bool();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): DataScanEvent_DataQualityAppliedConfigs {
    return {
      samplingPercent: isSet(object.samplingPercent) ? globalThis.Number(object.samplingPercent) : 0,
      rowFilterApplied: isSet(object.rowFilterApplied) ? globalThis.Boolean(object.rowFilterApplied) : false,
    };
  },

  toJSON(message: DataScanEvent_DataQualityAppliedConfigs): unknown {
    const obj: any = {};
    if (message.samplingPercent !== 0) {
      obj.samplingPercent = message.samplingPercent;
    }
    if (message.rowFilterApplied !== false) {
      obj.rowFilterApplied = message.rowFilterApplied;
    }
    return obj;
  },

  create(base?: DeepPartial<DataScanEvent_DataQualityAppliedConfigs>): DataScanEvent_DataQualityAppliedConfigs {
    return DataScanEvent_DataQualityAppliedConfigs.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<DataScanEvent_DataQualityAppliedConfigs>): DataScanEvent_DataQualityAppliedConfigs {
    const message = createBaseDataScanEvent_DataQualityAppliedConfigs();
    message.samplingPercent = object.samplingPercent ?? 0;
    message.rowFilterApplied = object.rowFilterApplied ?? false;
    return message;
  },
};

function createBaseDataScanEvent_PostScanActionsResult(): DataScanEvent_PostScanActionsResult {
  return { bigqueryExportResult: undefined };
}

export const DataScanEvent_PostScanActionsResult: MessageFns<DataScanEvent_PostScanActionsResult> = {
  encode(message: DataScanEvent_PostScanActionsResult, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.bigqueryExportResult !== undefined) {
      DataScanEvent_PostScanActionsResult_BigQueryExportResult.encode(
        message.bigqueryExportResult,
        writer.uint32(10).fork(),
      ).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): DataScanEvent_PostScanActionsResult {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDataScanEvent_PostScanActionsResult();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.bigqueryExportResult = DataScanEvent_PostScanActionsResult_BigQueryExportResult.decode(
            reader,
            reader.uint32(),
          );
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): DataScanEvent_PostScanActionsResult {
    return {
      bigqueryExportResult: isSet(object.bigqueryExportResult)
        ? DataScanEvent_PostScanActionsResult_BigQueryExportResult.fromJSON(object.bigqueryExportResult)
        : undefined,
    };
  },

  toJSON(message: DataScanEvent_PostScanActionsResult): unknown {
    const obj: any = {};
    if (message.bigqueryExportResult !== undefined) {
      obj.bigqueryExportResult = DataScanEvent_PostScanActionsResult_BigQueryExportResult.toJSON(
        message.bigqueryExportResult,
      );
    }
    return obj;
  },

  create(base?: DeepPartial<DataScanEvent_PostScanActionsResult>): DataScanEvent_PostScanActionsResult {
    return DataScanEvent_PostScanActionsResult.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<DataScanEvent_PostScanActionsResult>): DataScanEvent_PostScanActionsResult {
    const message = createBaseDataScanEvent_PostScanActionsResult();
    message.bigqueryExportResult = (object.bigqueryExportResult !== undefined && object.bigqueryExportResult !== null)
      ? DataScanEvent_PostScanActionsResult_BigQueryExportResult.fromPartial(object.bigqueryExportResult)
      : undefined;
    return message;
  },
};

function createBaseDataScanEvent_PostScanActionsResult_BigQueryExportResult(): DataScanEvent_PostScanActionsResult_BigQueryExportResult {
  return { state: 0, message: "" };
}

export const DataScanEvent_PostScanActionsResult_BigQueryExportResult: MessageFns<
  DataScanEvent_PostScanActionsResult_BigQueryExportResult
> = {
  encode(
    message: DataScanEvent_PostScanActionsResult_BigQueryExportResult,
    writer: BinaryWriter = new BinaryWriter(),
  ): BinaryWriter {
    if (message.state !== 0) {
      writer.uint32(8).int32(message.state);
    }
    if (message.message !== "") {
      writer.uint32(18).string(message.message);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): DataScanEvent_PostScanActionsResult_BigQueryExportResult {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDataScanEvent_PostScanActionsResult_BigQueryExportResult();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 8) {
            break;
          }

          message.state = reader.int32() as any;
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.message = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): DataScanEvent_PostScanActionsResult_BigQueryExportResult {
    return {
      state: isSet(object.state)
        ? dataScanEvent_PostScanActionsResult_BigQueryExportResult_StateFromJSON(object.state)
        : 0,
      message: isSet(object.message) ? globalThis.String(object.message) : "",
    };
  },

  toJSON(message: DataScanEvent_PostScanActionsResult_BigQueryExportResult): unknown {
    const obj: any = {};
    if (message.state !== 0) {
      obj.state = dataScanEvent_PostScanActionsResult_BigQueryExportResult_StateToJSON(message.state);
    }
    if (message.message !== "") {
      obj.message = message.message;
    }
    return obj;
  },

  create(
    base?: DeepPartial<DataScanEvent_PostScanActionsResult_BigQueryExportResult>,
  ): DataScanEvent_PostScanActionsResult_BigQueryExportResult {
    return DataScanEvent_PostScanActionsResult_BigQueryExportResult.fromPartial(base ?? {});
  },
  fromPartial(
    object: DeepPartial<DataScanEvent_PostScanActionsResult_BigQueryExportResult>,
  ): DataScanEvent_PostScanActionsResult_BigQueryExportResult {
    const message = createBaseDataScanEvent_PostScanActionsResult_BigQueryExportResult();
    message.state = object.state ?? 0;
    message.message = object.message ?? "";
    return message;
  },
};

function createBaseDataQualityScanRuleResult(): DataQualityScanRuleResult {
  return {
    jobId: "",
    dataSource: "",
    column: "",
    ruleName: "",
    ruleType: 0,
    evalutionType: 0,
    ruleDimension: "",
    thresholdPercent: 0,
    result: 0,
    evaluatedRowCount: Long.ZERO,
    passedRowCount: Long.ZERO,
    nullRowCount: Long.ZERO,
    assertionRowCount: Long.ZERO,
  };
}

export const DataQualityScanRuleResult: MessageFns<DataQualityScanRuleResult> = {
  encode(message: DataQualityScanRuleResult, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.jobId !== "") {
      writer.uint32(10).string(message.jobId);
    }
    if (message.dataSource !== "") {
      writer.uint32(18).string(message.dataSource);
    }
    if (message.column !== "") {
      writer.uint32(26).string(message.column);
    }
    if (message.ruleName !== "") {
      writer.uint32(34).string(message.ruleName);
    }
    if (message.ruleType !== 0) {
      writer.uint32(40).int32(message.ruleType);
    }
    if (message.evalutionType !== 0) {
      writer.uint32(48).int32(message.evalutionType);
    }
    if (message.ruleDimension !== "") {
      writer.uint32(58).string(message.ruleDimension);
    }
    if (message.thresholdPercent !== 0) {
      writer.uint32(65).double(message.thresholdPercent);
    }
    if (message.result !== 0) {
      writer.uint32(72).int32(message.result);
    }
    if (!message.evaluatedRowCount.equals(Long.ZERO)) {
      writer.uint32(80).int64(message.evaluatedRowCount.toString());
    }
    if (!message.passedRowCount.equals(Long.ZERO)) {
      writer.uint32(88).int64(message.passedRowCount.toString());
    }
    if (!message.nullRowCount.equals(Long.ZERO)) {
      writer.uint32(96).int64(message.nullRowCount.toString());
    }
    if (!message.assertionRowCount.equals(Long.ZERO)) {
      writer.uint32(104).int64(message.assertionRowCount.toString());
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): DataQualityScanRuleResult {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDataQualityScanRuleResult();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.jobId = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.dataSource = reader.string();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.column = reader.string();
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.ruleName = reader.string();
          continue;
        case 5:
          if (tag !== 40) {
            break;
          }

          message.ruleType = reader.int32() as any;
          continue;
        case 6:
          if (tag !== 48) {
            break;
          }

          message.evalutionType = reader.int32() as any;
          continue;
        case 7:
          if (tag !== 58) {
            break;
          }

          message.ruleDimension = reader.string();
          continue;
        case 8:
          if (tag !== 65) {
            break;
          }

          message.thresholdPercent = reader.double();
          continue;
        case 9:
          if (tag !== 72) {
            break;
          }

          message.result = reader.int32() as any;
          continue;
        case 10:
          if (tag !== 80) {
            break;
          }

          message.evaluatedRowCount = Long.fromString(reader.int64().toString());
          continue;
        case 11:
          if (tag !== 88) {
            break;
          }

          message.passedRowCount = Long.fromString(reader.int64().toString());
          continue;
        case 12:
          if (tag !== 96) {
            break;
          }

          message.nullRowCount = Long.fromString(reader.int64().toString());
          continue;
        case 13:
          if (tag !== 104) {
            break;
          }

          message.assertionRowCount = Long.fromString(reader.int64().toString());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): DataQualityScanRuleResult {
    return {
      jobId: isSet(object.jobId) ? globalThis.String(object.jobId) : "",
      dataSource: isSet(object.dataSource) ? globalThis.String(object.dataSource) : "",
      column: isSet(object.column) ? globalThis.String(object.column) : "",
      ruleName: isSet(object.ruleName) ? globalThis.String(object.ruleName) : "",
      ruleType: isSet(object.ruleType) ? dataQualityScanRuleResult_RuleTypeFromJSON(object.ruleType) : 0,
      evalutionType: isSet(object.evalutionType)
        ? dataQualityScanRuleResult_EvaluationTypeFromJSON(object.evalutionType)
        : 0,
      ruleDimension: isSet(object.ruleDimension) ? globalThis.String(object.ruleDimension) : "",
      thresholdPercent: isSet(object.thresholdPercent) ? globalThis.Number(object.thresholdPercent) : 0,
      result: isSet(object.result) ? dataQualityScanRuleResult_ResultFromJSON(object.result) : 0,
      evaluatedRowCount: isSet(object.evaluatedRowCount) ? Long.fromValue(object.evaluatedRowCount) : Long.ZERO,
      passedRowCount: isSet(object.passedRowCount) ? Long.fromValue(object.passedRowCount) : Long.ZERO,
      nullRowCount: isSet(object.nullRowCount) ? Long.fromValue(object.nullRowCount) : Long.ZERO,
      assertionRowCount: isSet(object.assertionRowCount) ? Long.fromValue(object.assertionRowCount) : Long.ZERO,
    };
  },

  toJSON(message: DataQualityScanRuleResult): unknown {
    const obj: any = {};
    if (message.jobId !== "") {
      obj.jobId = message.jobId;
    }
    if (message.dataSource !== "") {
      obj.dataSource = message.dataSource;
    }
    if (message.column !== "") {
      obj.column = message.column;
    }
    if (message.ruleName !== "") {
      obj.ruleName = message.ruleName;
    }
    if (message.ruleType !== 0) {
      obj.ruleType = dataQualityScanRuleResult_RuleTypeToJSON(message.ruleType);
    }
    if (message.evalutionType !== 0) {
      obj.evalutionType = dataQualityScanRuleResult_EvaluationTypeToJSON(message.evalutionType);
    }
    if (message.ruleDimension !== "") {
      obj.ruleDimension = message.ruleDimension;
    }
    if (message.thresholdPercent !== 0) {
      obj.thresholdPercent = message.thresholdPercent;
    }
    if (message.result !== 0) {
      obj.result = dataQualityScanRuleResult_ResultToJSON(message.result);
    }
    if (!message.evaluatedRowCount.equals(Long.ZERO)) {
      obj.evaluatedRowCount = (message.evaluatedRowCount || Long.ZERO).toString();
    }
    if (!message.passedRowCount.equals(Long.ZERO)) {
      obj.passedRowCount = (message.passedRowCount || Long.ZERO).toString();
    }
    if (!message.nullRowCount.equals(Long.ZERO)) {
      obj.nullRowCount = (message.nullRowCount || Long.ZERO).toString();
    }
    if (!message.assertionRowCount.equals(Long.ZERO)) {
      obj.assertionRowCount = (message.assertionRowCount || Long.ZERO).toString();
    }
    return obj;
  },

  create(base?: DeepPartial<DataQualityScanRuleResult>): DataQualityScanRuleResult {
    return DataQualityScanRuleResult.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<DataQualityScanRuleResult>): DataQualityScanRuleResult {
    const message = createBaseDataQualityScanRuleResult();
    message.jobId = object.jobId ?? "";
    message.dataSource = object.dataSource ?? "";
    message.column = object.column ?? "";
    message.ruleName = object.ruleName ?? "";
    message.ruleType = object.ruleType ?? 0;
    message.evalutionType = object.evalutionType ?? 0;
    message.ruleDimension = object.ruleDimension ?? "";
    message.thresholdPercent = object.thresholdPercent ?? 0;
    message.result = object.result ?? 0;
    message.evaluatedRowCount = (object.evaluatedRowCount !== undefined && object.evaluatedRowCount !== null)
      ? Long.fromValue(object.evaluatedRowCount)
      : Long.ZERO;
    message.passedRowCount = (object.passedRowCount !== undefined && object.passedRowCount !== null)
      ? Long.fromValue(object.passedRowCount)
      : Long.ZERO;
    message.nullRowCount = (object.nullRowCount !== undefined && object.nullRowCount !== null)
      ? Long.fromValue(object.nullRowCount)
      : Long.ZERO;
    message.assertionRowCount = (object.assertionRowCount !== undefined && object.assertionRowCount !== null)
      ? Long.fromValue(object.assertionRowCount)
      : Long.ZERO;
    return message;
  },
};

type Builtin = Date | Function | Uint8Array | string | number | boolean | undefined;

export type DeepPartial<T> = T extends Builtin ? T
  : T extends Long ? string | number | Long : T extends globalThis.Array<infer U> ? globalThis.Array<DeepPartial<U>>
  : T extends ReadonlyArray<infer U> ? ReadonlyArray<DeepPartial<U>>
  : T extends {} ? { [K in keyof T]?: DeepPartial<T[K]> }
  : Partial<T>;

function toTimestamp(date: Date): Timestamp {
  const seconds = numberToLong(Math.trunc(date.getTime() / 1_000));
  const nanos = (date.getTime() % 1_000) * 1_000_000;
  return { seconds, nanos };
}

function fromTimestamp(t: Timestamp): Date {
  let millis = (t.seconds.toNumber() || 0) * 1_000;
  millis += (t.nanos || 0) / 1_000_000;
  return new globalThis.Date(millis);
}

function fromJsonTimestamp(o: any): Date {
  if (o instanceof globalThis.Date) {
    return o;
  } else if (typeof o === "string") {
    return new globalThis.Date(o);
  } else {
    return fromTimestamp(Timestamp.fromJSON(o));
  }
}

function numberToLong(number: number) {
  return Long.fromNumber(number);
}

function isObject(value: any): boolean {
  return typeof value === "object" && value !== null;
}

function isSet(value: any): boolean {
  return value !== null && value !== undefined;
}

export interface MessageFns<T> {
  encode(message: T, writer?: BinaryWriter): BinaryWriter;
  decode(input: BinaryReader | Uint8Array, length?: number): T;
  fromJSON(object: any): T;
  toJSON(message: T): unknown;
  create(base?: DeepPartial<T>): T;
  fromPartial(object: DeepPartial<T>): T;
}
