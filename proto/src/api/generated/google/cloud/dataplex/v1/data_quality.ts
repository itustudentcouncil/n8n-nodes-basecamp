// Code generated by protoc-gen-ts_proto. DO NOT EDIT.
// versions:
//   protoc-gen-ts_proto  v2.2.0
//   protoc               unknown
// source: google/cloud/dataplex/v1/data_quality.proto

/* eslint-disable */
import { BinaryReader, BinaryWriter } from "@bufbuild/protobuf/wire";
import Long from "long";
import { ScannedData } from "./processing.js";

export const protobufPackage = "google.cloud.dataplex.v1";

/** DataQualityScan related setting. */
export interface DataQualitySpec {
  /**
   * Required. The list of rules to evaluate against a data source. At least one
   * rule is required.
   */
  rules: DataQualityRule[];
  /**
   * Optional. The percentage of the records to be selected from the dataset for
   * DataScan.
   *
   * * Value can range between 0.0 and 100.0 with up to 3 significant decimal
   * digits.
   * * Sampling is not applied if `sampling_percent` is not specified, 0 or
   * 100.
   */
  samplingPercent: number;
  /**
   * Optional. A filter applied to all rows in a single DataScan job.
   * The filter needs to be a valid SQL expression for a WHERE clause in
   * BigQuery standard SQL syntax.
   * Example: col1 >= 0 AND col2 < 10
   */
  rowFilter: string;
  /** Optional. Actions to take upon job completion. */
  postScanActions: DataQualitySpec_PostScanActions | undefined;
}

/** The configuration of post scan actions of DataQualityScan. */
export interface DataQualitySpec_PostScanActions {
  /**
   * Optional. If set, results will be exported to the provided BigQuery
   * table.
   */
  bigqueryExport:
    | DataQualitySpec_PostScanActions_BigQueryExport
    | undefined;
  /**
   * Optional. If set, results will be sent to the provided notification
   * receipts upon triggers.
   */
  notificationReport: DataQualitySpec_PostScanActions_NotificationReport | undefined;
}

/** The configuration of BigQuery export post scan action. */
export interface DataQualitySpec_PostScanActions_BigQueryExport {
  /**
   * Optional. The BigQuery table to export DataQualityScan results to.
   * Format:
   * //bigquery.googleapis.com/projects/PROJECT_ID/datasets/DATASET_ID/tables/TABLE_ID
   */
  resultsTable: string;
}

/**
 * The individuals or groups who are designated to receive notifications
 * upon triggers.
 */
export interface DataQualitySpec_PostScanActions_Recipients {
  /**
   * Optional. The email recipients who will receive the DataQualityScan
   * results report.
   */
  emails: string[];
}

/**
 * This trigger is triggered when the DQ score in the job result is less
 * than a specified input score.
 */
export interface DataQualitySpec_PostScanActions_ScoreThresholdTrigger {
  /** Optional. The score range is in [0,100]. */
  scoreThreshold: number;
}

/**
 * This trigger is triggered when the scan job itself fails, regardless of
 * the result.
 */
export interface DataQualitySpec_PostScanActions_JobFailureTrigger {
}

/**
 * This trigger is triggered whenever a scan job run ends, regardless
 * of the result.
 */
export interface DataQualitySpec_PostScanActions_JobEndTrigger {
}

/** The configuration of notification report post scan action. */
export interface DataQualitySpec_PostScanActions_NotificationReport {
  /** Required. The recipients who will receive the notification report. */
  recipients:
    | DataQualitySpec_PostScanActions_Recipients
    | undefined;
  /** Optional. If set, report will be sent when score threshold is met. */
  scoreThresholdTrigger:
    | DataQualitySpec_PostScanActions_ScoreThresholdTrigger
    | undefined;
  /** Optional. If set, report will be sent when a scan job fails. */
  jobFailureTrigger:
    | DataQualitySpec_PostScanActions_JobFailureTrigger
    | undefined;
  /** Optional. If set, report will be sent when a scan job ends. */
  jobEndTrigger: DataQualitySpec_PostScanActions_JobEndTrigger | undefined;
}

/** The output of a DataQualityScan. */
export interface DataQualityResult {
  /** Overall data quality result -- `true` if all rules passed. */
  passed: boolean;
  /**
   * Output only. The overall data quality score.
   *
   * The score ranges between [0, 100] (up to two decimal points).
   */
  score?:
    | number
    | undefined;
  /**
   * A list of results at the dimension level.
   *
   * A dimension will have a corresponding `DataQualityDimensionResult` if and
   * only if there is at least one rule with the 'dimension' field set to it.
   */
  dimensions: DataQualityDimensionResult[];
  /**
   * Output only. A list of results at the column level.
   *
   * A column will have a corresponding `DataQualityColumnResult` if and only if
   * there is at least one rule with the 'column' field set to it.
   */
  columns: DataQualityColumnResult[];
  /** A list of all the rules in a job, and their results. */
  rules: DataQualityRuleResult[];
  /** The count of rows processed. */
  rowCount: Long;
  /** The data scanned for this result. */
  scannedData:
    | ScannedData
    | undefined;
  /** Output only. The result of post scan actions. */
  postScanActionsResult: DataQualityResult_PostScanActionsResult | undefined;
}

/** The result of post scan actions of DataQualityScan job. */
export interface DataQualityResult_PostScanActionsResult {
  /** Output only. The result of BigQuery export post scan action. */
  bigqueryExportResult: DataQualityResult_PostScanActionsResult_BigQueryExportResult | undefined;
}

/** The result of BigQuery export post scan action. */
export interface DataQualityResult_PostScanActionsResult_BigQueryExportResult {
  /** Output only. Execution state for the BigQuery exporting. */
  state: DataQualityResult_PostScanActionsResult_BigQueryExportResult_State;
  /** Output only. Additional information about the BigQuery exporting. */
  message: string;
}

/** Execution state for the exporting. */
export enum DataQualityResult_PostScanActionsResult_BigQueryExportResult_State {
  /** STATE_UNSPECIFIED - The exporting state is unspecified. */
  STATE_UNSPECIFIED = 0,
  /** SUCCEEDED - The exporting completed successfully. */
  SUCCEEDED = 1,
  /** FAILED - The exporting is no longer running due to an error. */
  FAILED = 2,
  /**
   * SKIPPED - The exporting is skipped due to no valid scan result to export
   * (usually caused by scan failed).
   */
  SKIPPED = 3,
  UNRECOGNIZED = -1,
}

export function dataQualityResult_PostScanActionsResult_BigQueryExportResult_StateFromJSON(
  object: any,
): DataQualityResult_PostScanActionsResult_BigQueryExportResult_State {
  switch (object) {
    case 0:
    case "STATE_UNSPECIFIED":
      return DataQualityResult_PostScanActionsResult_BigQueryExportResult_State.STATE_UNSPECIFIED;
    case 1:
    case "SUCCEEDED":
      return DataQualityResult_PostScanActionsResult_BigQueryExportResult_State.SUCCEEDED;
    case 2:
    case "FAILED":
      return DataQualityResult_PostScanActionsResult_BigQueryExportResult_State.FAILED;
    case 3:
    case "SKIPPED":
      return DataQualityResult_PostScanActionsResult_BigQueryExportResult_State.SKIPPED;
    case -1:
    case "UNRECOGNIZED":
    default:
      return DataQualityResult_PostScanActionsResult_BigQueryExportResult_State.UNRECOGNIZED;
  }
}

export function dataQualityResult_PostScanActionsResult_BigQueryExportResult_StateToJSON(
  object: DataQualityResult_PostScanActionsResult_BigQueryExportResult_State,
): string {
  switch (object) {
    case DataQualityResult_PostScanActionsResult_BigQueryExportResult_State.STATE_UNSPECIFIED:
      return "STATE_UNSPECIFIED";
    case DataQualityResult_PostScanActionsResult_BigQueryExportResult_State.SUCCEEDED:
      return "SUCCEEDED";
    case DataQualityResult_PostScanActionsResult_BigQueryExportResult_State.FAILED:
      return "FAILED";
    case DataQualityResult_PostScanActionsResult_BigQueryExportResult_State.SKIPPED:
      return "SKIPPED";
    case DataQualityResult_PostScanActionsResult_BigQueryExportResult_State.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/** DataQualityRuleResult provides a more detailed, per-rule view of the results. */
export interface DataQualityRuleResult {
  /** The rule specified in the DataQualitySpec, as is. */
  rule:
    | DataQualityRule
    | undefined;
  /** Whether the rule passed or failed. */
  passed: boolean;
  /**
   * The number of rows a rule was evaluated against.
   *
   * This field is only valid for row-level type rules.
   *
   * Evaluated count can be configured to either
   *
   * * include all rows (default) - with `null` rows automatically failing rule
   * evaluation, or
   * * exclude `null` rows from the `evaluated_count`, by setting
   * `ignore_nulls = true`.
   */
  evaluatedCount: Long;
  /**
   * The number of rows which passed a rule evaluation.
   *
   * This field is only valid for row-level type rules.
   */
  passedCount: Long;
  /** The number of rows with null values in the specified column. */
  nullCount: Long;
  /**
   * The ratio of **passed_count / evaluated_count**.
   *
   * This field is only valid for row-level type rules.
   */
  passRatio: number;
  /**
   * The query to find rows that did not pass this rule.
   *
   * This field is only valid for row-level type rules.
   */
  failingRowsQuery: string;
  /**
   * Output only. The number of rows returned by the SQL statement in a SQL
   * assertion rule.
   *
   * This field is only valid for SQL assertion rules.
   */
  assertionRowCount: Long;
}

/**
 * DataQualityDimensionResult provides a more detailed, per-dimension view of
 * the results.
 */
export interface DataQualityDimensionResult {
  /** Output only. The dimension config specified in the DataQualitySpec, as is. */
  dimension:
    | DataQualityDimension
    | undefined;
  /** Whether the dimension passed or failed. */
  passed: boolean;
  /**
   * Output only. The dimension-level data quality score for this data scan job
   * if and only if the 'dimension' field is set.
   *
   * The score ranges between [0, 100] (up to two decimal
   * points).
   */
  score?: number | undefined;
}

/**
 * A dimension captures data quality intent about a defined subset of the rules
 * specified.
 */
export interface DataQualityDimension {
  /**
   * The dimension name a rule belongs to. Supported dimensions are
   * ["COMPLETENESS", "ACCURACY", "CONSISTENCY", "VALIDITY", "UNIQUENESS",
   * "INTEGRITY"]
   */
  name: string;
}

/** A rule captures data quality intent about a data source. */
export interface DataQualityRule {
  /**
   * Row-level rule which evaluates whether each column value lies between a
   * specified range.
   */
  rangeExpectation?:
    | DataQualityRule_RangeExpectation
    | undefined;
  /** Row-level rule which evaluates whether each column value is null. */
  nonNullExpectation?:
    | DataQualityRule_NonNullExpectation
    | undefined;
  /**
   * Row-level rule which evaluates whether each column value is contained by
   * a specified set.
   */
  setExpectation?:
    | DataQualityRule_SetExpectation
    | undefined;
  /**
   * Row-level rule which evaluates whether each column value matches a
   * specified regex.
   */
  regexExpectation?:
    | DataQualityRule_RegexExpectation
    | undefined;
  /** Row-level rule which evaluates whether each column value is unique. */
  uniquenessExpectation?:
    | DataQualityRule_UniquenessExpectation
    | undefined;
  /**
   * Aggregate rule which evaluates whether the column aggregate
   * statistic lies between a specified range.
   */
  statisticRangeExpectation?:
    | DataQualityRule_StatisticRangeExpectation
    | undefined;
  /**
   * Row-level rule which evaluates whether each row in a table passes the
   * specified condition.
   */
  rowConditionExpectation?:
    | DataQualityRule_RowConditionExpectation
    | undefined;
  /**
   * Aggregate rule which evaluates whether the provided expression is true
   * for a table.
   */
  tableConditionExpectation?:
    | DataQualityRule_TableConditionExpectation
    | undefined;
  /**
   * Aggregate rule which evaluates the number of rows returned for the
   * provided statement. If any rows are returned, this rule fails.
   */
  sqlAssertion?:
    | DataQualityRule_SqlAssertion
    | undefined;
  /** Optional. The unnested column which this rule is evaluated against. */
  column: string;
  /**
   * Optional. Rows with `null` values will automatically fail a rule, unless
   * `ignore_null` is `true`. In that case, such `null` rows are trivially
   * considered passing.
   *
   * This field is only valid for the following type of rules:
   *
   * * RangeExpectation
   * * RegexExpectation
   * * SetExpectation
   * * UniquenessExpectation
   */
  ignoreNull: boolean;
  /**
   * Required. The dimension a rule belongs to. Results are also aggregated at
   * the dimension level. Supported dimensions are **["COMPLETENESS",
   * "ACCURACY", "CONSISTENCY", "VALIDITY", "UNIQUENESS", "INTEGRITY"]**
   */
  dimension: string;
  /**
   * Optional. The minimum ratio of **passing_rows / total_rows** required to
   * pass this rule, with a range of [0.0, 1.0].
   *
   * 0 indicates default value (i.e. 1.0).
   *
   * This field is only valid for row-level type rules.
   */
  threshold: number;
  /**
   * Optional. A mutable name for the rule.
   *
   * * The name must contain only letters (a-z, A-Z), numbers (0-9), or
   * hyphens (-).
   * * The maximum length is 63 characters.
   * * Must start with a letter.
   * * Must end with a number or a letter.
   */
  name: string;
  /**
   * Optional. Description of the rule.
   *
   * * The maximum length is 1,024 characters.
   */
  description: string;
}

/** Evaluates whether each column value lies between a specified range. */
export interface DataQualityRule_RangeExpectation {
  /**
   * Optional. The minimum column value allowed for a row to pass this
   * validation. At least one of `min_value` and `max_value` need to be
   * provided.
   */
  minValue: string;
  /**
   * Optional. The maximum column value allowed for a row to pass this
   * validation. At least one of `min_value` and `max_value` need to be
   * provided.
   */
  maxValue: string;
  /**
   * Optional. Whether each value needs to be strictly greater than ('>') the
   * minimum, or if equality is allowed.
   *
   * Only relevant if a `min_value` has been defined. Default = false.
   */
  strictMinEnabled: boolean;
  /**
   * Optional. Whether each value needs to be strictly lesser than ('<') the
   * maximum, or if equality is allowed.
   *
   * Only relevant if a `max_value` has been defined. Default = false.
   */
  strictMaxEnabled: boolean;
}

/** Evaluates whether each column value is null. */
export interface DataQualityRule_NonNullExpectation {
}

/** Evaluates whether each column value is contained by a specified set. */
export interface DataQualityRule_SetExpectation {
  /** Optional. Expected values for the column value. */
  values: string[];
}

/** Evaluates whether each column value matches a specified regex. */
export interface DataQualityRule_RegexExpectation {
  /** Optional. A regular expression the column value is expected to match. */
  regex: string;
}

/** Evaluates whether the column has duplicates. */
export interface DataQualityRule_UniquenessExpectation {
}

/**
 * Evaluates whether the column aggregate statistic lies between a specified
 * range.
 */
export interface DataQualityRule_StatisticRangeExpectation {
  /** Optional. The aggregate metric to evaluate. */
  statistic: DataQualityRule_StatisticRangeExpectation_ColumnStatistic;
  /**
   * Optional. The minimum column statistic value allowed for a row to pass
   * this validation.
   *
   * At least one of `min_value` and `max_value` need to be provided.
   */
  minValue: string;
  /**
   * Optional. The maximum column statistic value allowed for a row to pass
   * this validation.
   *
   * At least one of `min_value` and `max_value` need to be provided.
   */
  maxValue: string;
  /**
   * Optional. Whether column statistic needs to be strictly greater than
   * ('>') the minimum, or if equality is allowed.
   *
   * Only relevant if a `min_value` has been defined. Default = false.
   */
  strictMinEnabled: boolean;
  /**
   * Optional. Whether column statistic needs to be strictly lesser than ('<')
   * the maximum, or if equality is allowed.
   *
   * Only relevant if a `max_value` has been defined. Default = false.
   */
  strictMaxEnabled: boolean;
}

/** The list of aggregate metrics a rule can be evaluated against. */
export enum DataQualityRule_StatisticRangeExpectation_ColumnStatistic {
  /** STATISTIC_UNDEFINED - Unspecified statistic type */
  STATISTIC_UNDEFINED = 0,
  /** MEAN - Evaluate the column mean */
  MEAN = 1,
  /** MIN - Evaluate the column min */
  MIN = 2,
  /** MAX - Evaluate the column max */
  MAX = 3,
  UNRECOGNIZED = -1,
}

export function dataQualityRule_StatisticRangeExpectation_ColumnStatisticFromJSON(
  object: any,
): DataQualityRule_StatisticRangeExpectation_ColumnStatistic {
  switch (object) {
    case 0:
    case "STATISTIC_UNDEFINED":
      return DataQualityRule_StatisticRangeExpectation_ColumnStatistic.STATISTIC_UNDEFINED;
    case 1:
    case "MEAN":
      return DataQualityRule_StatisticRangeExpectation_ColumnStatistic.MEAN;
    case 2:
    case "MIN":
      return DataQualityRule_StatisticRangeExpectation_ColumnStatistic.MIN;
    case 3:
    case "MAX":
      return DataQualityRule_StatisticRangeExpectation_ColumnStatistic.MAX;
    case -1:
    case "UNRECOGNIZED":
    default:
      return DataQualityRule_StatisticRangeExpectation_ColumnStatistic.UNRECOGNIZED;
  }
}

export function dataQualityRule_StatisticRangeExpectation_ColumnStatisticToJSON(
  object: DataQualityRule_StatisticRangeExpectation_ColumnStatistic,
): string {
  switch (object) {
    case DataQualityRule_StatisticRangeExpectation_ColumnStatistic.STATISTIC_UNDEFINED:
      return "STATISTIC_UNDEFINED";
    case DataQualityRule_StatisticRangeExpectation_ColumnStatistic.MEAN:
      return "MEAN";
    case DataQualityRule_StatisticRangeExpectation_ColumnStatistic.MIN:
      return "MIN";
    case DataQualityRule_StatisticRangeExpectation_ColumnStatistic.MAX:
      return "MAX";
    case DataQualityRule_StatisticRangeExpectation_ColumnStatistic.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/**
 * Evaluates whether each row passes the specified condition.
 *
 * The SQL expression needs to use BigQuery standard SQL syntax and should
 * produce a boolean value per row as the result.
 *
 * Example: col1 >= 0 AND col2 < 10
 */
export interface DataQualityRule_RowConditionExpectation {
  /** Optional. The SQL expression. */
  sqlExpression: string;
}

/**
 * Evaluates whether the provided expression is true.
 *
 * The SQL expression needs to use BigQuery standard SQL syntax and should
 * produce a scalar boolean result.
 *
 * Example: MIN(col1) >= 0
 */
export interface DataQualityRule_TableConditionExpectation {
  /** Optional. The SQL expression. */
  sqlExpression: string;
}

/**
 * A SQL statement that is evaluated to return rows that match an invalid
 * state. If any rows are are returned, this rule fails.
 *
 * The SQL statement must use BigQuery standard SQL syntax, and must not
 * contain any semicolons.
 *
 * You can use the data reference parameter `${data()}` to reference the
 * source table with all of its precondition filters applied. Examples of
 * precondition filters include row filters, incremental data filters, and
 * sampling. For more information, see [Data reference
 * parameter](https://cloud.google.com/dataplex/docs/auto-data-quality-overview#data-reference-parameter).
 *
 * Example: `SELECT * FROM ${data()} WHERE price < 0`
 */
export interface DataQualityRule_SqlAssertion {
  /** Optional. The SQL statement. */
  sqlStatement: string;
}

/**
 * DataQualityColumnResult provides a more detailed, per-column view of
 * the results.
 */
export interface DataQualityColumnResult {
  /** Output only. The column specified in the DataQualityRule. */
  column: string;
  /**
   * Output only. The column-level data quality score for this data scan job if
   * and only if the 'column' field is set.
   *
   * The score ranges between between [0, 100] (up to two decimal
   * points).
   */
  score?: number | undefined;
}

function createBaseDataQualitySpec(): DataQualitySpec {
  return { rules: [], samplingPercent: 0, rowFilter: "", postScanActions: undefined };
}

export const DataQualitySpec: MessageFns<DataQualitySpec> = {
  encode(message: DataQualitySpec, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.rules) {
      DataQualityRule.encode(v!, writer.uint32(10).fork()).join();
    }
    if (message.samplingPercent !== 0) {
      writer.uint32(37).float(message.samplingPercent);
    }
    if (message.rowFilter !== "") {
      writer.uint32(42).string(message.rowFilter);
    }
    if (message.postScanActions !== undefined) {
      DataQualitySpec_PostScanActions.encode(message.postScanActions, writer.uint32(50).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): DataQualitySpec {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDataQualitySpec();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.rules.push(DataQualityRule.decode(reader, reader.uint32()));
          continue;
        case 4:
          if (tag !== 37) {
            break;
          }

          message.samplingPercent = reader.float();
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.rowFilter = reader.string();
          continue;
        case 6:
          if (tag !== 50) {
            break;
          }

          message.postScanActions = DataQualitySpec_PostScanActions.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): DataQualitySpec {
    return {
      rules: globalThis.Array.isArray(object?.rules) ? object.rules.map((e: any) => DataQualityRule.fromJSON(e)) : [],
      samplingPercent: isSet(object.samplingPercent) ? globalThis.Number(object.samplingPercent) : 0,
      rowFilter: isSet(object.rowFilter) ? globalThis.String(object.rowFilter) : "",
      postScanActions: isSet(object.postScanActions)
        ? DataQualitySpec_PostScanActions.fromJSON(object.postScanActions)
        : undefined,
    };
  },

  toJSON(message: DataQualitySpec): unknown {
    const obj: any = {};
    if (message.rules?.length) {
      obj.rules = message.rules.map((e) => DataQualityRule.toJSON(e));
    }
    if (message.samplingPercent !== 0) {
      obj.samplingPercent = message.samplingPercent;
    }
    if (message.rowFilter !== "") {
      obj.rowFilter = message.rowFilter;
    }
    if (message.postScanActions !== undefined) {
      obj.postScanActions = DataQualitySpec_PostScanActions.toJSON(message.postScanActions);
    }
    return obj;
  },

  create(base?: DeepPartial<DataQualitySpec>): DataQualitySpec {
    return DataQualitySpec.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<DataQualitySpec>): DataQualitySpec {
    const message = createBaseDataQualitySpec();
    message.rules = object.rules?.map((e) => DataQualityRule.fromPartial(e)) || [];
    message.samplingPercent = object.samplingPercent ?? 0;
    message.rowFilter = object.rowFilter ?? "";
    message.postScanActions = (object.postScanActions !== undefined && object.postScanActions !== null)
      ? DataQualitySpec_PostScanActions.fromPartial(object.postScanActions)
      : undefined;
    return message;
  },
};

function createBaseDataQualitySpec_PostScanActions(): DataQualitySpec_PostScanActions {
  return { bigqueryExport: undefined, notificationReport: undefined };
}

export const DataQualitySpec_PostScanActions: MessageFns<DataQualitySpec_PostScanActions> = {
  encode(message: DataQualitySpec_PostScanActions, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.bigqueryExport !== undefined) {
      DataQualitySpec_PostScanActions_BigQueryExport.encode(message.bigqueryExport, writer.uint32(10).fork()).join();
    }
    if (message.notificationReport !== undefined) {
      DataQualitySpec_PostScanActions_NotificationReport.encode(message.notificationReport, writer.uint32(18).fork())
        .join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): DataQualitySpec_PostScanActions {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDataQualitySpec_PostScanActions();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.bigqueryExport = DataQualitySpec_PostScanActions_BigQueryExport.decode(reader, reader.uint32());
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.notificationReport = DataQualitySpec_PostScanActions_NotificationReport.decode(
            reader,
            reader.uint32(),
          );
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): DataQualitySpec_PostScanActions {
    return {
      bigqueryExport: isSet(object.bigqueryExport)
        ? DataQualitySpec_PostScanActions_BigQueryExport.fromJSON(object.bigqueryExport)
        : undefined,
      notificationReport: isSet(object.notificationReport)
        ? DataQualitySpec_PostScanActions_NotificationReport.fromJSON(object.notificationReport)
        : undefined,
    };
  },

  toJSON(message: DataQualitySpec_PostScanActions): unknown {
    const obj: any = {};
    if (message.bigqueryExport !== undefined) {
      obj.bigqueryExport = DataQualitySpec_PostScanActions_BigQueryExport.toJSON(message.bigqueryExport);
    }
    if (message.notificationReport !== undefined) {
      obj.notificationReport = DataQualitySpec_PostScanActions_NotificationReport.toJSON(message.notificationReport);
    }
    return obj;
  },

  create(base?: DeepPartial<DataQualitySpec_PostScanActions>): DataQualitySpec_PostScanActions {
    return DataQualitySpec_PostScanActions.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<DataQualitySpec_PostScanActions>): DataQualitySpec_PostScanActions {
    const message = createBaseDataQualitySpec_PostScanActions();
    message.bigqueryExport = (object.bigqueryExport !== undefined && object.bigqueryExport !== null)
      ? DataQualitySpec_PostScanActions_BigQueryExport.fromPartial(object.bigqueryExport)
      : undefined;
    message.notificationReport = (object.notificationReport !== undefined && object.notificationReport !== null)
      ? DataQualitySpec_PostScanActions_NotificationReport.fromPartial(object.notificationReport)
      : undefined;
    return message;
  },
};

function createBaseDataQualitySpec_PostScanActions_BigQueryExport(): DataQualitySpec_PostScanActions_BigQueryExport {
  return { resultsTable: "" };
}

export const DataQualitySpec_PostScanActions_BigQueryExport: MessageFns<
  DataQualitySpec_PostScanActions_BigQueryExport
> = {
  encode(
    message: DataQualitySpec_PostScanActions_BigQueryExport,
    writer: BinaryWriter = new BinaryWriter(),
  ): BinaryWriter {
    if (message.resultsTable !== "") {
      writer.uint32(10).string(message.resultsTable);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): DataQualitySpec_PostScanActions_BigQueryExport {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDataQualitySpec_PostScanActions_BigQueryExport();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.resultsTable = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): DataQualitySpec_PostScanActions_BigQueryExport {
    return { resultsTable: isSet(object.resultsTable) ? globalThis.String(object.resultsTable) : "" };
  },

  toJSON(message: DataQualitySpec_PostScanActions_BigQueryExport): unknown {
    const obj: any = {};
    if (message.resultsTable !== "") {
      obj.resultsTable = message.resultsTable;
    }
    return obj;
  },

  create(
    base?: DeepPartial<DataQualitySpec_PostScanActions_BigQueryExport>,
  ): DataQualitySpec_PostScanActions_BigQueryExport {
    return DataQualitySpec_PostScanActions_BigQueryExport.fromPartial(base ?? {});
  },
  fromPartial(
    object: DeepPartial<DataQualitySpec_PostScanActions_BigQueryExport>,
  ): DataQualitySpec_PostScanActions_BigQueryExport {
    const message = createBaseDataQualitySpec_PostScanActions_BigQueryExport();
    message.resultsTable = object.resultsTable ?? "";
    return message;
  },
};

function createBaseDataQualitySpec_PostScanActions_Recipients(): DataQualitySpec_PostScanActions_Recipients {
  return { emails: [] };
}

export const DataQualitySpec_PostScanActions_Recipients: MessageFns<DataQualitySpec_PostScanActions_Recipients> = {
  encode(message: DataQualitySpec_PostScanActions_Recipients, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.emails) {
      writer.uint32(10).string(v!);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): DataQualitySpec_PostScanActions_Recipients {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDataQualitySpec_PostScanActions_Recipients();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.emails.push(reader.string());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): DataQualitySpec_PostScanActions_Recipients {
    return {
      emails: globalThis.Array.isArray(object?.emails) ? object.emails.map((e: any) => globalThis.String(e)) : [],
    };
  },

  toJSON(message: DataQualitySpec_PostScanActions_Recipients): unknown {
    const obj: any = {};
    if (message.emails?.length) {
      obj.emails = message.emails;
    }
    return obj;
  },

  create(base?: DeepPartial<DataQualitySpec_PostScanActions_Recipients>): DataQualitySpec_PostScanActions_Recipients {
    return DataQualitySpec_PostScanActions_Recipients.fromPartial(base ?? {});
  },
  fromPartial(
    object: DeepPartial<DataQualitySpec_PostScanActions_Recipients>,
  ): DataQualitySpec_PostScanActions_Recipients {
    const message = createBaseDataQualitySpec_PostScanActions_Recipients();
    message.emails = object.emails?.map((e) => e) || [];
    return message;
  },
};

function createBaseDataQualitySpec_PostScanActions_ScoreThresholdTrigger(): DataQualitySpec_PostScanActions_ScoreThresholdTrigger {
  return { scoreThreshold: 0 };
}

export const DataQualitySpec_PostScanActions_ScoreThresholdTrigger: MessageFns<
  DataQualitySpec_PostScanActions_ScoreThresholdTrigger
> = {
  encode(
    message: DataQualitySpec_PostScanActions_ScoreThresholdTrigger,
    writer: BinaryWriter = new BinaryWriter(),
  ): BinaryWriter {
    if (message.scoreThreshold !== 0) {
      writer.uint32(21).float(message.scoreThreshold);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): DataQualitySpec_PostScanActions_ScoreThresholdTrigger {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDataQualitySpec_PostScanActions_ScoreThresholdTrigger();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 2:
          if (tag !== 21) {
            break;
          }

          message.scoreThreshold = reader.float();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): DataQualitySpec_PostScanActions_ScoreThresholdTrigger {
    return { scoreThreshold: isSet(object.scoreThreshold) ? globalThis.Number(object.scoreThreshold) : 0 };
  },

  toJSON(message: DataQualitySpec_PostScanActions_ScoreThresholdTrigger): unknown {
    const obj: any = {};
    if (message.scoreThreshold !== 0) {
      obj.scoreThreshold = message.scoreThreshold;
    }
    return obj;
  },

  create(
    base?: DeepPartial<DataQualitySpec_PostScanActions_ScoreThresholdTrigger>,
  ): DataQualitySpec_PostScanActions_ScoreThresholdTrigger {
    return DataQualitySpec_PostScanActions_ScoreThresholdTrigger.fromPartial(base ?? {});
  },
  fromPartial(
    object: DeepPartial<DataQualitySpec_PostScanActions_ScoreThresholdTrigger>,
  ): DataQualitySpec_PostScanActions_ScoreThresholdTrigger {
    const message = createBaseDataQualitySpec_PostScanActions_ScoreThresholdTrigger();
    message.scoreThreshold = object.scoreThreshold ?? 0;
    return message;
  },
};

function createBaseDataQualitySpec_PostScanActions_JobFailureTrigger(): DataQualitySpec_PostScanActions_JobFailureTrigger {
  return {};
}

export const DataQualitySpec_PostScanActions_JobFailureTrigger: MessageFns<
  DataQualitySpec_PostScanActions_JobFailureTrigger
> = {
  encode(
    _: DataQualitySpec_PostScanActions_JobFailureTrigger,
    writer: BinaryWriter = new BinaryWriter(),
  ): BinaryWriter {
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): DataQualitySpec_PostScanActions_JobFailureTrigger {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDataQualitySpec_PostScanActions_JobFailureTrigger();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(_: any): DataQualitySpec_PostScanActions_JobFailureTrigger {
    return {};
  },

  toJSON(_: DataQualitySpec_PostScanActions_JobFailureTrigger): unknown {
    const obj: any = {};
    return obj;
  },

  create(
    base?: DeepPartial<DataQualitySpec_PostScanActions_JobFailureTrigger>,
  ): DataQualitySpec_PostScanActions_JobFailureTrigger {
    return DataQualitySpec_PostScanActions_JobFailureTrigger.fromPartial(base ?? {});
  },
  fromPartial(
    _: DeepPartial<DataQualitySpec_PostScanActions_JobFailureTrigger>,
  ): DataQualitySpec_PostScanActions_JobFailureTrigger {
    const message = createBaseDataQualitySpec_PostScanActions_JobFailureTrigger();
    return message;
  },
};

function createBaseDataQualitySpec_PostScanActions_JobEndTrigger(): DataQualitySpec_PostScanActions_JobEndTrigger {
  return {};
}

export const DataQualitySpec_PostScanActions_JobEndTrigger: MessageFns<DataQualitySpec_PostScanActions_JobEndTrigger> =
  {
    encode(_: DataQualitySpec_PostScanActions_JobEndTrigger, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
      return writer;
    },

    decode(input: BinaryReader | Uint8Array, length?: number): DataQualitySpec_PostScanActions_JobEndTrigger {
      const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
      let end = length === undefined ? reader.len : reader.pos + length;
      const message = createBaseDataQualitySpec_PostScanActions_JobEndTrigger();
      while (reader.pos < end) {
        const tag = reader.uint32();
        switch (tag >>> 3) {
        }
        if ((tag & 7) === 4 || tag === 0) {
          break;
        }
        reader.skip(tag & 7);
      }
      return message;
    },

    fromJSON(_: any): DataQualitySpec_PostScanActions_JobEndTrigger {
      return {};
    },

    toJSON(_: DataQualitySpec_PostScanActions_JobEndTrigger): unknown {
      const obj: any = {};
      return obj;
    },

    create(
      base?: DeepPartial<DataQualitySpec_PostScanActions_JobEndTrigger>,
    ): DataQualitySpec_PostScanActions_JobEndTrigger {
      return DataQualitySpec_PostScanActions_JobEndTrigger.fromPartial(base ?? {});
    },
    fromPartial(
      _: DeepPartial<DataQualitySpec_PostScanActions_JobEndTrigger>,
    ): DataQualitySpec_PostScanActions_JobEndTrigger {
      const message = createBaseDataQualitySpec_PostScanActions_JobEndTrigger();
      return message;
    },
  };

function createBaseDataQualitySpec_PostScanActions_NotificationReport(): DataQualitySpec_PostScanActions_NotificationReport {
  return {
    recipients: undefined,
    scoreThresholdTrigger: undefined,
    jobFailureTrigger: undefined,
    jobEndTrigger: undefined,
  };
}

export const DataQualitySpec_PostScanActions_NotificationReport: MessageFns<
  DataQualitySpec_PostScanActions_NotificationReport
> = {
  encode(
    message: DataQualitySpec_PostScanActions_NotificationReport,
    writer: BinaryWriter = new BinaryWriter(),
  ): BinaryWriter {
    if (message.recipients !== undefined) {
      DataQualitySpec_PostScanActions_Recipients.encode(message.recipients, writer.uint32(10).fork()).join();
    }
    if (message.scoreThresholdTrigger !== undefined) {
      DataQualitySpec_PostScanActions_ScoreThresholdTrigger.encode(
        message.scoreThresholdTrigger,
        writer.uint32(18).fork(),
      ).join();
    }
    if (message.jobFailureTrigger !== undefined) {
      DataQualitySpec_PostScanActions_JobFailureTrigger.encode(message.jobFailureTrigger, writer.uint32(34).fork())
        .join();
    }
    if (message.jobEndTrigger !== undefined) {
      DataQualitySpec_PostScanActions_JobEndTrigger.encode(message.jobEndTrigger, writer.uint32(42).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): DataQualitySpec_PostScanActions_NotificationReport {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDataQualitySpec_PostScanActions_NotificationReport();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.recipients = DataQualitySpec_PostScanActions_Recipients.decode(reader, reader.uint32());
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.scoreThresholdTrigger = DataQualitySpec_PostScanActions_ScoreThresholdTrigger.decode(
            reader,
            reader.uint32(),
          );
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.jobFailureTrigger = DataQualitySpec_PostScanActions_JobFailureTrigger.decode(reader, reader.uint32());
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.jobEndTrigger = DataQualitySpec_PostScanActions_JobEndTrigger.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): DataQualitySpec_PostScanActions_NotificationReport {
    return {
      recipients: isSet(object.recipients)
        ? DataQualitySpec_PostScanActions_Recipients.fromJSON(object.recipients)
        : undefined,
      scoreThresholdTrigger: isSet(object.scoreThresholdTrigger)
        ? DataQualitySpec_PostScanActions_ScoreThresholdTrigger.fromJSON(object.scoreThresholdTrigger)
        : undefined,
      jobFailureTrigger: isSet(object.jobFailureTrigger)
        ? DataQualitySpec_PostScanActions_JobFailureTrigger.fromJSON(object.jobFailureTrigger)
        : undefined,
      jobEndTrigger: isSet(object.jobEndTrigger)
        ? DataQualitySpec_PostScanActions_JobEndTrigger.fromJSON(object.jobEndTrigger)
        : undefined,
    };
  },

  toJSON(message: DataQualitySpec_PostScanActions_NotificationReport): unknown {
    const obj: any = {};
    if (message.recipients !== undefined) {
      obj.recipients = DataQualitySpec_PostScanActions_Recipients.toJSON(message.recipients);
    }
    if (message.scoreThresholdTrigger !== undefined) {
      obj.scoreThresholdTrigger = DataQualitySpec_PostScanActions_ScoreThresholdTrigger.toJSON(
        message.scoreThresholdTrigger,
      );
    }
    if (message.jobFailureTrigger !== undefined) {
      obj.jobFailureTrigger = DataQualitySpec_PostScanActions_JobFailureTrigger.toJSON(message.jobFailureTrigger);
    }
    if (message.jobEndTrigger !== undefined) {
      obj.jobEndTrigger = DataQualitySpec_PostScanActions_JobEndTrigger.toJSON(message.jobEndTrigger);
    }
    return obj;
  },

  create(
    base?: DeepPartial<DataQualitySpec_PostScanActions_NotificationReport>,
  ): DataQualitySpec_PostScanActions_NotificationReport {
    return DataQualitySpec_PostScanActions_NotificationReport.fromPartial(base ?? {});
  },
  fromPartial(
    object: DeepPartial<DataQualitySpec_PostScanActions_NotificationReport>,
  ): DataQualitySpec_PostScanActions_NotificationReport {
    const message = createBaseDataQualitySpec_PostScanActions_NotificationReport();
    message.recipients = (object.recipients !== undefined && object.recipients !== null)
      ? DataQualitySpec_PostScanActions_Recipients.fromPartial(object.recipients)
      : undefined;
    message.scoreThresholdTrigger =
      (object.scoreThresholdTrigger !== undefined && object.scoreThresholdTrigger !== null)
        ? DataQualitySpec_PostScanActions_ScoreThresholdTrigger.fromPartial(object.scoreThresholdTrigger)
        : undefined;
    message.jobFailureTrigger = (object.jobFailureTrigger !== undefined && object.jobFailureTrigger !== null)
      ? DataQualitySpec_PostScanActions_JobFailureTrigger.fromPartial(object.jobFailureTrigger)
      : undefined;
    message.jobEndTrigger = (object.jobEndTrigger !== undefined && object.jobEndTrigger !== null)
      ? DataQualitySpec_PostScanActions_JobEndTrigger.fromPartial(object.jobEndTrigger)
      : undefined;
    return message;
  },
};

function createBaseDataQualityResult(): DataQualityResult {
  return {
    passed: false,
    score: undefined,
    dimensions: [],
    columns: [],
    rules: [],
    rowCount: Long.ZERO,
    scannedData: undefined,
    postScanActionsResult: undefined,
  };
}

export const DataQualityResult: MessageFns<DataQualityResult> = {
  encode(message: DataQualityResult, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.passed !== false) {
      writer.uint32(40).bool(message.passed);
    }
    if (message.score !== undefined) {
      writer.uint32(77).float(message.score);
    }
    for (const v of message.dimensions) {
      DataQualityDimensionResult.encode(v!, writer.uint32(18).fork()).join();
    }
    for (const v of message.columns) {
      DataQualityColumnResult.encode(v!, writer.uint32(82).fork()).join();
    }
    for (const v of message.rules) {
      DataQualityRuleResult.encode(v!, writer.uint32(26).fork()).join();
    }
    if (!message.rowCount.equals(Long.ZERO)) {
      writer.uint32(32).int64(message.rowCount.toString());
    }
    if (message.scannedData !== undefined) {
      ScannedData.encode(message.scannedData, writer.uint32(58).fork()).join();
    }
    if (message.postScanActionsResult !== undefined) {
      DataQualityResult_PostScanActionsResult.encode(message.postScanActionsResult, writer.uint32(66).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): DataQualityResult {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDataQualityResult();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 5:
          if (tag !== 40) {
            break;
          }

          message.passed = reader.bool();
          continue;
        case 9:
          if (tag !== 77) {
            break;
          }

          message.score = reader.float();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.dimensions.push(DataQualityDimensionResult.decode(reader, reader.uint32()));
          continue;
        case 10:
          if (tag !== 82) {
            break;
          }

          message.columns.push(DataQualityColumnResult.decode(reader, reader.uint32()));
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.rules.push(DataQualityRuleResult.decode(reader, reader.uint32()));
          continue;
        case 4:
          if (tag !== 32) {
            break;
          }

          message.rowCount = Long.fromString(reader.int64().toString());
          continue;
        case 7:
          if (tag !== 58) {
            break;
          }

          message.scannedData = ScannedData.decode(reader, reader.uint32());
          continue;
        case 8:
          if (tag !== 66) {
            break;
          }

          message.postScanActionsResult = DataQualityResult_PostScanActionsResult.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): DataQualityResult {
    return {
      passed: isSet(object.passed) ? globalThis.Boolean(object.passed) : false,
      score: isSet(object.score) ? globalThis.Number(object.score) : undefined,
      dimensions: globalThis.Array.isArray(object?.dimensions)
        ? object.dimensions.map((e: any) => DataQualityDimensionResult.fromJSON(e))
        : [],
      columns: globalThis.Array.isArray(object?.columns)
        ? object.columns.map((e: any) => DataQualityColumnResult.fromJSON(e))
        : [],
      rules: globalThis.Array.isArray(object?.rules)
        ? object.rules.map((e: any) => DataQualityRuleResult.fromJSON(e))
        : [],
      rowCount: isSet(object.rowCount) ? Long.fromValue(object.rowCount) : Long.ZERO,
      scannedData: isSet(object.scannedData) ? ScannedData.fromJSON(object.scannedData) : undefined,
      postScanActionsResult: isSet(object.postScanActionsResult)
        ? DataQualityResult_PostScanActionsResult.fromJSON(object.postScanActionsResult)
        : undefined,
    };
  },

  toJSON(message: DataQualityResult): unknown {
    const obj: any = {};
    if (message.passed !== false) {
      obj.passed = message.passed;
    }
    if (message.score !== undefined) {
      obj.score = message.score;
    }
    if (message.dimensions?.length) {
      obj.dimensions = message.dimensions.map((e) => DataQualityDimensionResult.toJSON(e));
    }
    if (message.columns?.length) {
      obj.columns = message.columns.map((e) => DataQualityColumnResult.toJSON(e));
    }
    if (message.rules?.length) {
      obj.rules = message.rules.map((e) => DataQualityRuleResult.toJSON(e));
    }
    if (!message.rowCount.equals(Long.ZERO)) {
      obj.rowCount = (message.rowCount || Long.ZERO).toString();
    }
    if (message.scannedData !== undefined) {
      obj.scannedData = ScannedData.toJSON(message.scannedData);
    }
    if (message.postScanActionsResult !== undefined) {
      obj.postScanActionsResult = DataQualityResult_PostScanActionsResult.toJSON(message.postScanActionsResult);
    }
    return obj;
  },

  create(base?: DeepPartial<DataQualityResult>): DataQualityResult {
    return DataQualityResult.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<DataQualityResult>): DataQualityResult {
    const message = createBaseDataQualityResult();
    message.passed = object.passed ?? false;
    message.score = object.score ?? undefined;
    message.dimensions = object.dimensions?.map((e) => DataQualityDimensionResult.fromPartial(e)) || [];
    message.columns = object.columns?.map((e) => DataQualityColumnResult.fromPartial(e)) || [];
    message.rules = object.rules?.map((e) => DataQualityRuleResult.fromPartial(e)) || [];
    message.rowCount = (object.rowCount !== undefined && object.rowCount !== null)
      ? Long.fromValue(object.rowCount)
      : Long.ZERO;
    message.scannedData = (object.scannedData !== undefined && object.scannedData !== null)
      ? ScannedData.fromPartial(object.scannedData)
      : undefined;
    message.postScanActionsResult =
      (object.postScanActionsResult !== undefined && object.postScanActionsResult !== null)
        ? DataQualityResult_PostScanActionsResult.fromPartial(object.postScanActionsResult)
        : undefined;
    return message;
  },
};

function createBaseDataQualityResult_PostScanActionsResult(): DataQualityResult_PostScanActionsResult {
  return { bigqueryExportResult: undefined };
}

export const DataQualityResult_PostScanActionsResult: MessageFns<DataQualityResult_PostScanActionsResult> = {
  encode(message: DataQualityResult_PostScanActionsResult, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.bigqueryExportResult !== undefined) {
      DataQualityResult_PostScanActionsResult_BigQueryExportResult.encode(
        message.bigqueryExportResult,
        writer.uint32(10).fork(),
      ).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): DataQualityResult_PostScanActionsResult {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDataQualityResult_PostScanActionsResult();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.bigqueryExportResult = DataQualityResult_PostScanActionsResult_BigQueryExportResult.decode(
            reader,
            reader.uint32(),
          );
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): DataQualityResult_PostScanActionsResult {
    return {
      bigqueryExportResult: isSet(object.bigqueryExportResult)
        ? DataQualityResult_PostScanActionsResult_BigQueryExportResult.fromJSON(object.bigqueryExportResult)
        : undefined,
    };
  },

  toJSON(message: DataQualityResult_PostScanActionsResult): unknown {
    const obj: any = {};
    if (message.bigqueryExportResult !== undefined) {
      obj.bigqueryExportResult = DataQualityResult_PostScanActionsResult_BigQueryExportResult.toJSON(
        message.bigqueryExportResult,
      );
    }
    return obj;
  },

  create(base?: DeepPartial<DataQualityResult_PostScanActionsResult>): DataQualityResult_PostScanActionsResult {
    return DataQualityResult_PostScanActionsResult.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<DataQualityResult_PostScanActionsResult>): DataQualityResult_PostScanActionsResult {
    const message = createBaseDataQualityResult_PostScanActionsResult();
    message.bigqueryExportResult = (object.bigqueryExportResult !== undefined && object.bigqueryExportResult !== null)
      ? DataQualityResult_PostScanActionsResult_BigQueryExportResult.fromPartial(object.bigqueryExportResult)
      : undefined;
    return message;
  },
};

function createBaseDataQualityResult_PostScanActionsResult_BigQueryExportResult(): DataQualityResult_PostScanActionsResult_BigQueryExportResult {
  return { state: 0, message: "" };
}

export const DataQualityResult_PostScanActionsResult_BigQueryExportResult: MessageFns<
  DataQualityResult_PostScanActionsResult_BigQueryExportResult
> = {
  encode(
    message: DataQualityResult_PostScanActionsResult_BigQueryExportResult,
    writer: BinaryWriter = new BinaryWriter(),
  ): BinaryWriter {
    if (message.state !== 0) {
      writer.uint32(8).int32(message.state);
    }
    if (message.message !== "") {
      writer.uint32(18).string(message.message);
    }
    return writer;
  },

  decode(
    input: BinaryReader | Uint8Array,
    length?: number,
  ): DataQualityResult_PostScanActionsResult_BigQueryExportResult {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDataQualityResult_PostScanActionsResult_BigQueryExportResult();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 8) {
            break;
          }

          message.state = reader.int32() as any;
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.message = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): DataQualityResult_PostScanActionsResult_BigQueryExportResult {
    return {
      state: isSet(object.state)
        ? dataQualityResult_PostScanActionsResult_BigQueryExportResult_StateFromJSON(object.state)
        : 0,
      message: isSet(object.message) ? globalThis.String(object.message) : "",
    };
  },

  toJSON(message: DataQualityResult_PostScanActionsResult_BigQueryExportResult): unknown {
    const obj: any = {};
    if (message.state !== 0) {
      obj.state = dataQualityResult_PostScanActionsResult_BigQueryExportResult_StateToJSON(message.state);
    }
    if (message.message !== "") {
      obj.message = message.message;
    }
    return obj;
  },

  create(
    base?: DeepPartial<DataQualityResult_PostScanActionsResult_BigQueryExportResult>,
  ): DataQualityResult_PostScanActionsResult_BigQueryExportResult {
    return DataQualityResult_PostScanActionsResult_BigQueryExportResult.fromPartial(base ?? {});
  },
  fromPartial(
    object: DeepPartial<DataQualityResult_PostScanActionsResult_BigQueryExportResult>,
  ): DataQualityResult_PostScanActionsResult_BigQueryExportResult {
    const message = createBaseDataQualityResult_PostScanActionsResult_BigQueryExportResult();
    message.state = object.state ?? 0;
    message.message = object.message ?? "";
    return message;
  },
};

function createBaseDataQualityRuleResult(): DataQualityRuleResult {
  return {
    rule: undefined,
    passed: false,
    evaluatedCount: Long.ZERO,
    passedCount: Long.ZERO,
    nullCount: Long.ZERO,
    passRatio: 0,
    failingRowsQuery: "",
    assertionRowCount: Long.ZERO,
  };
}

export const DataQualityRuleResult: MessageFns<DataQualityRuleResult> = {
  encode(message: DataQualityRuleResult, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.rule !== undefined) {
      DataQualityRule.encode(message.rule, writer.uint32(10).fork()).join();
    }
    if (message.passed !== false) {
      writer.uint32(56).bool(message.passed);
    }
    if (!message.evaluatedCount.equals(Long.ZERO)) {
      writer.uint32(72).int64(message.evaluatedCount.toString());
    }
    if (!message.passedCount.equals(Long.ZERO)) {
      writer.uint32(64).int64(message.passedCount.toString());
    }
    if (!message.nullCount.equals(Long.ZERO)) {
      writer.uint32(40).int64(message.nullCount.toString());
    }
    if (message.passRatio !== 0) {
      writer.uint32(49).double(message.passRatio);
    }
    if (message.failingRowsQuery !== "") {
      writer.uint32(82).string(message.failingRowsQuery);
    }
    if (!message.assertionRowCount.equals(Long.ZERO)) {
      writer.uint32(88).int64(message.assertionRowCount.toString());
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): DataQualityRuleResult {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDataQualityRuleResult();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.rule = DataQualityRule.decode(reader, reader.uint32());
          continue;
        case 7:
          if (tag !== 56) {
            break;
          }

          message.passed = reader.bool();
          continue;
        case 9:
          if (tag !== 72) {
            break;
          }

          message.evaluatedCount = Long.fromString(reader.int64().toString());
          continue;
        case 8:
          if (tag !== 64) {
            break;
          }

          message.passedCount = Long.fromString(reader.int64().toString());
          continue;
        case 5:
          if (tag !== 40) {
            break;
          }

          message.nullCount = Long.fromString(reader.int64().toString());
          continue;
        case 6:
          if (tag !== 49) {
            break;
          }

          message.passRatio = reader.double();
          continue;
        case 10:
          if (tag !== 82) {
            break;
          }

          message.failingRowsQuery = reader.string();
          continue;
        case 11:
          if (tag !== 88) {
            break;
          }

          message.assertionRowCount = Long.fromString(reader.int64().toString());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): DataQualityRuleResult {
    return {
      rule: isSet(object.rule) ? DataQualityRule.fromJSON(object.rule) : undefined,
      passed: isSet(object.passed) ? globalThis.Boolean(object.passed) : false,
      evaluatedCount: isSet(object.evaluatedCount) ? Long.fromValue(object.evaluatedCount) : Long.ZERO,
      passedCount: isSet(object.passedCount) ? Long.fromValue(object.passedCount) : Long.ZERO,
      nullCount: isSet(object.nullCount) ? Long.fromValue(object.nullCount) : Long.ZERO,
      passRatio: isSet(object.passRatio) ? globalThis.Number(object.passRatio) : 0,
      failingRowsQuery: isSet(object.failingRowsQuery) ? globalThis.String(object.failingRowsQuery) : "",
      assertionRowCount: isSet(object.assertionRowCount) ? Long.fromValue(object.assertionRowCount) : Long.ZERO,
    };
  },

  toJSON(message: DataQualityRuleResult): unknown {
    const obj: any = {};
    if (message.rule !== undefined) {
      obj.rule = DataQualityRule.toJSON(message.rule);
    }
    if (message.passed !== false) {
      obj.passed = message.passed;
    }
    if (!message.evaluatedCount.equals(Long.ZERO)) {
      obj.evaluatedCount = (message.evaluatedCount || Long.ZERO).toString();
    }
    if (!message.passedCount.equals(Long.ZERO)) {
      obj.passedCount = (message.passedCount || Long.ZERO).toString();
    }
    if (!message.nullCount.equals(Long.ZERO)) {
      obj.nullCount = (message.nullCount || Long.ZERO).toString();
    }
    if (message.passRatio !== 0) {
      obj.passRatio = message.passRatio;
    }
    if (message.failingRowsQuery !== "") {
      obj.failingRowsQuery = message.failingRowsQuery;
    }
    if (!message.assertionRowCount.equals(Long.ZERO)) {
      obj.assertionRowCount = (message.assertionRowCount || Long.ZERO).toString();
    }
    return obj;
  },

  create(base?: DeepPartial<DataQualityRuleResult>): DataQualityRuleResult {
    return DataQualityRuleResult.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<DataQualityRuleResult>): DataQualityRuleResult {
    const message = createBaseDataQualityRuleResult();
    message.rule = (object.rule !== undefined && object.rule !== null)
      ? DataQualityRule.fromPartial(object.rule)
      : undefined;
    message.passed = object.passed ?? false;
    message.evaluatedCount = (object.evaluatedCount !== undefined && object.evaluatedCount !== null)
      ? Long.fromValue(object.evaluatedCount)
      : Long.ZERO;
    message.passedCount = (object.passedCount !== undefined && object.passedCount !== null)
      ? Long.fromValue(object.passedCount)
      : Long.ZERO;
    message.nullCount = (object.nullCount !== undefined && object.nullCount !== null)
      ? Long.fromValue(object.nullCount)
      : Long.ZERO;
    message.passRatio = object.passRatio ?? 0;
    message.failingRowsQuery = object.failingRowsQuery ?? "";
    message.assertionRowCount = (object.assertionRowCount !== undefined && object.assertionRowCount !== null)
      ? Long.fromValue(object.assertionRowCount)
      : Long.ZERO;
    return message;
  },
};

function createBaseDataQualityDimensionResult(): DataQualityDimensionResult {
  return { dimension: undefined, passed: false, score: undefined };
}

export const DataQualityDimensionResult: MessageFns<DataQualityDimensionResult> = {
  encode(message: DataQualityDimensionResult, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.dimension !== undefined) {
      DataQualityDimension.encode(message.dimension, writer.uint32(10).fork()).join();
    }
    if (message.passed !== false) {
      writer.uint32(24).bool(message.passed);
    }
    if (message.score !== undefined) {
      writer.uint32(37).float(message.score);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): DataQualityDimensionResult {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDataQualityDimensionResult();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.dimension = DataQualityDimension.decode(reader, reader.uint32());
          continue;
        case 3:
          if (tag !== 24) {
            break;
          }

          message.passed = reader.bool();
          continue;
        case 4:
          if (tag !== 37) {
            break;
          }

          message.score = reader.float();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): DataQualityDimensionResult {
    return {
      dimension: isSet(object.dimension) ? DataQualityDimension.fromJSON(object.dimension) : undefined,
      passed: isSet(object.passed) ? globalThis.Boolean(object.passed) : false,
      score: isSet(object.score) ? globalThis.Number(object.score) : undefined,
    };
  },

  toJSON(message: DataQualityDimensionResult): unknown {
    const obj: any = {};
    if (message.dimension !== undefined) {
      obj.dimension = DataQualityDimension.toJSON(message.dimension);
    }
    if (message.passed !== false) {
      obj.passed = message.passed;
    }
    if (message.score !== undefined) {
      obj.score = message.score;
    }
    return obj;
  },

  create(base?: DeepPartial<DataQualityDimensionResult>): DataQualityDimensionResult {
    return DataQualityDimensionResult.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<DataQualityDimensionResult>): DataQualityDimensionResult {
    const message = createBaseDataQualityDimensionResult();
    message.dimension = (object.dimension !== undefined && object.dimension !== null)
      ? DataQualityDimension.fromPartial(object.dimension)
      : undefined;
    message.passed = object.passed ?? false;
    message.score = object.score ?? undefined;
    return message;
  },
};

function createBaseDataQualityDimension(): DataQualityDimension {
  return { name: "" };
}

export const DataQualityDimension: MessageFns<DataQualityDimension> = {
  encode(message: DataQualityDimension, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): DataQualityDimension {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDataQualityDimension();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): DataQualityDimension {
    return { name: isSet(object.name) ? globalThis.String(object.name) : "" };
  },

  toJSON(message: DataQualityDimension): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    return obj;
  },

  create(base?: DeepPartial<DataQualityDimension>): DataQualityDimension {
    return DataQualityDimension.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<DataQualityDimension>): DataQualityDimension {
    const message = createBaseDataQualityDimension();
    message.name = object.name ?? "";
    return message;
  },
};

function createBaseDataQualityRule(): DataQualityRule {
  return {
    rangeExpectation: undefined,
    nonNullExpectation: undefined,
    setExpectation: undefined,
    regexExpectation: undefined,
    uniquenessExpectation: undefined,
    statisticRangeExpectation: undefined,
    rowConditionExpectation: undefined,
    tableConditionExpectation: undefined,
    sqlAssertion: undefined,
    column: "",
    ignoreNull: false,
    dimension: "",
    threshold: 0,
    name: "",
    description: "",
  };
}

export const DataQualityRule: MessageFns<DataQualityRule> = {
  encode(message: DataQualityRule, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.rangeExpectation !== undefined) {
      DataQualityRule_RangeExpectation.encode(message.rangeExpectation, writer.uint32(10).fork()).join();
    }
    if (message.nonNullExpectation !== undefined) {
      DataQualityRule_NonNullExpectation.encode(message.nonNullExpectation, writer.uint32(18).fork()).join();
    }
    if (message.setExpectation !== undefined) {
      DataQualityRule_SetExpectation.encode(message.setExpectation, writer.uint32(26).fork()).join();
    }
    if (message.regexExpectation !== undefined) {
      DataQualityRule_RegexExpectation.encode(message.regexExpectation, writer.uint32(34).fork()).join();
    }
    if (message.uniquenessExpectation !== undefined) {
      DataQualityRule_UniquenessExpectation.encode(message.uniquenessExpectation, writer.uint32(802).fork()).join();
    }
    if (message.statisticRangeExpectation !== undefined) {
      DataQualityRule_StatisticRangeExpectation.encode(message.statisticRangeExpectation, writer.uint32(810).fork())
        .join();
    }
    if (message.rowConditionExpectation !== undefined) {
      DataQualityRule_RowConditionExpectation.encode(message.rowConditionExpectation, writer.uint32(1602).fork())
        .join();
    }
    if (message.tableConditionExpectation !== undefined) {
      DataQualityRule_TableConditionExpectation.encode(message.tableConditionExpectation, writer.uint32(1610).fork())
        .join();
    }
    if (message.sqlAssertion !== undefined) {
      DataQualityRule_SqlAssertion.encode(message.sqlAssertion, writer.uint32(1618).fork()).join();
    }
    if (message.column !== "") {
      writer.uint32(4002).string(message.column);
    }
    if (message.ignoreNull !== false) {
      writer.uint32(4008).bool(message.ignoreNull);
    }
    if (message.dimension !== "") {
      writer.uint32(4018).string(message.dimension);
    }
    if (message.threshold !== 0) {
      writer.uint32(4025).double(message.threshold);
    }
    if (message.name !== "") {
      writer.uint32(4034).string(message.name);
    }
    if (message.description !== "") {
      writer.uint32(4042).string(message.description);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): DataQualityRule {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDataQualityRule();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.rangeExpectation = DataQualityRule_RangeExpectation.decode(reader, reader.uint32());
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.nonNullExpectation = DataQualityRule_NonNullExpectation.decode(reader, reader.uint32());
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.setExpectation = DataQualityRule_SetExpectation.decode(reader, reader.uint32());
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.regexExpectation = DataQualityRule_RegexExpectation.decode(reader, reader.uint32());
          continue;
        case 100:
          if (tag !== 802) {
            break;
          }

          message.uniquenessExpectation = DataQualityRule_UniquenessExpectation.decode(reader, reader.uint32());
          continue;
        case 101:
          if (tag !== 810) {
            break;
          }

          message.statisticRangeExpectation = DataQualityRule_StatisticRangeExpectation.decode(reader, reader.uint32());
          continue;
        case 200:
          if (tag !== 1602) {
            break;
          }

          message.rowConditionExpectation = DataQualityRule_RowConditionExpectation.decode(reader, reader.uint32());
          continue;
        case 201:
          if (tag !== 1610) {
            break;
          }

          message.tableConditionExpectation = DataQualityRule_TableConditionExpectation.decode(reader, reader.uint32());
          continue;
        case 202:
          if (tag !== 1618) {
            break;
          }

          message.sqlAssertion = DataQualityRule_SqlAssertion.decode(reader, reader.uint32());
          continue;
        case 500:
          if (tag !== 4002) {
            break;
          }

          message.column = reader.string();
          continue;
        case 501:
          if (tag !== 4008) {
            break;
          }

          message.ignoreNull = reader.bool();
          continue;
        case 502:
          if (tag !== 4018) {
            break;
          }

          message.dimension = reader.string();
          continue;
        case 503:
          if (tag !== 4025) {
            break;
          }

          message.threshold = reader.double();
          continue;
        case 504:
          if (tag !== 4034) {
            break;
          }

          message.name = reader.string();
          continue;
        case 505:
          if (tag !== 4042) {
            break;
          }

          message.description = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): DataQualityRule {
    return {
      rangeExpectation: isSet(object.rangeExpectation)
        ? DataQualityRule_RangeExpectation.fromJSON(object.rangeExpectation)
        : undefined,
      nonNullExpectation: isSet(object.nonNullExpectation)
        ? DataQualityRule_NonNullExpectation.fromJSON(object.nonNullExpectation)
        : undefined,
      setExpectation: isSet(object.setExpectation)
        ? DataQualityRule_SetExpectation.fromJSON(object.setExpectation)
        : undefined,
      regexExpectation: isSet(object.regexExpectation)
        ? DataQualityRule_RegexExpectation.fromJSON(object.regexExpectation)
        : undefined,
      uniquenessExpectation: isSet(object.uniquenessExpectation)
        ? DataQualityRule_UniquenessExpectation.fromJSON(object.uniquenessExpectation)
        : undefined,
      statisticRangeExpectation: isSet(object.statisticRangeExpectation)
        ? DataQualityRule_StatisticRangeExpectation.fromJSON(object.statisticRangeExpectation)
        : undefined,
      rowConditionExpectation: isSet(object.rowConditionExpectation)
        ? DataQualityRule_RowConditionExpectation.fromJSON(object.rowConditionExpectation)
        : undefined,
      tableConditionExpectation: isSet(object.tableConditionExpectation)
        ? DataQualityRule_TableConditionExpectation.fromJSON(object.tableConditionExpectation)
        : undefined,
      sqlAssertion: isSet(object.sqlAssertion) ? DataQualityRule_SqlAssertion.fromJSON(object.sqlAssertion) : undefined,
      column: isSet(object.column) ? globalThis.String(object.column) : "",
      ignoreNull: isSet(object.ignoreNull) ? globalThis.Boolean(object.ignoreNull) : false,
      dimension: isSet(object.dimension) ? globalThis.String(object.dimension) : "",
      threshold: isSet(object.threshold) ? globalThis.Number(object.threshold) : 0,
      name: isSet(object.name) ? globalThis.String(object.name) : "",
      description: isSet(object.description) ? globalThis.String(object.description) : "",
    };
  },

  toJSON(message: DataQualityRule): unknown {
    const obj: any = {};
    if (message.rangeExpectation !== undefined) {
      obj.rangeExpectation = DataQualityRule_RangeExpectation.toJSON(message.rangeExpectation);
    }
    if (message.nonNullExpectation !== undefined) {
      obj.nonNullExpectation = DataQualityRule_NonNullExpectation.toJSON(message.nonNullExpectation);
    }
    if (message.setExpectation !== undefined) {
      obj.setExpectation = DataQualityRule_SetExpectation.toJSON(message.setExpectation);
    }
    if (message.regexExpectation !== undefined) {
      obj.regexExpectation = DataQualityRule_RegexExpectation.toJSON(message.regexExpectation);
    }
    if (message.uniquenessExpectation !== undefined) {
      obj.uniquenessExpectation = DataQualityRule_UniquenessExpectation.toJSON(message.uniquenessExpectation);
    }
    if (message.statisticRangeExpectation !== undefined) {
      obj.statisticRangeExpectation = DataQualityRule_StatisticRangeExpectation.toJSON(
        message.statisticRangeExpectation,
      );
    }
    if (message.rowConditionExpectation !== undefined) {
      obj.rowConditionExpectation = DataQualityRule_RowConditionExpectation.toJSON(message.rowConditionExpectation);
    }
    if (message.tableConditionExpectation !== undefined) {
      obj.tableConditionExpectation = DataQualityRule_TableConditionExpectation.toJSON(
        message.tableConditionExpectation,
      );
    }
    if (message.sqlAssertion !== undefined) {
      obj.sqlAssertion = DataQualityRule_SqlAssertion.toJSON(message.sqlAssertion);
    }
    if (message.column !== "") {
      obj.column = message.column;
    }
    if (message.ignoreNull !== false) {
      obj.ignoreNull = message.ignoreNull;
    }
    if (message.dimension !== "") {
      obj.dimension = message.dimension;
    }
    if (message.threshold !== 0) {
      obj.threshold = message.threshold;
    }
    if (message.name !== "") {
      obj.name = message.name;
    }
    if (message.description !== "") {
      obj.description = message.description;
    }
    return obj;
  },

  create(base?: DeepPartial<DataQualityRule>): DataQualityRule {
    return DataQualityRule.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<DataQualityRule>): DataQualityRule {
    const message = createBaseDataQualityRule();
    message.rangeExpectation = (object.rangeExpectation !== undefined && object.rangeExpectation !== null)
      ? DataQualityRule_RangeExpectation.fromPartial(object.rangeExpectation)
      : undefined;
    message.nonNullExpectation = (object.nonNullExpectation !== undefined && object.nonNullExpectation !== null)
      ? DataQualityRule_NonNullExpectation.fromPartial(object.nonNullExpectation)
      : undefined;
    message.setExpectation = (object.setExpectation !== undefined && object.setExpectation !== null)
      ? DataQualityRule_SetExpectation.fromPartial(object.setExpectation)
      : undefined;
    message.regexExpectation = (object.regexExpectation !== undefined && object.regexExpectation !== null)
      ? DataQualityRule_RegexExpectation.fromPartial(object.regexExpectation)
      : undefined;
    message.uniquenessExpectation =
      (object.uniquenessExpectation !== undefined && object.uniquenessExpectation !== null)
        ? DataQualityRule_UniquenessExpectation.fromPartial(object.uniquenessExpectation)
        : undefined;
    message.statisticRangeExpectation =
      (object.statisticRangeExpectation !== undefined && object.statisticRangeExpectation !== null)
        ? DataQualityRule_StatisticRangeExpectation.fromPartial(object.statisticRangeExpectation)
        : undefined;
    message.rowConditionExpectation =
      (object.rowConditionExpectation !== undefined && object.rowConditionExpectation !== null)
        ? DataQualityRule_RowConditionExpectation.fromPartial(object.rowConditionExpectation)
        : undefined;
    message.tableConditionExpectation =
      (object.tableConditionExpectation !== undefined && object.tableConditionExpectation !== null)
        ? DataQualityRule_TableConditionExpectation.fromPartial(object.tableConditionExpectation)
        : undefined;
    message.sqlAssertion = (object.sqlAssertion !== undefined && object.sqlAssertion !== null)
      ? DataQualityRule_SqlAssertion.fromPartial(object.sqlAssertion)
      : undefined;
    message.column = object.column ?? "";
    message.ignoreNull = object.ignoreNull ?? false;
    message.dimension = object.dimension ?? "";
    message.threshold = object.threshold ?? 0;
    message.name = object.name ?? "";
    message.description = object.description ?? "";
    return message;
  },
};

function createBaseDataQualityRule_RangeExpectation(): DataQualityRule_RangeExpectation {
  return { minValue: "", maxValue: "", strictMinEnabled: false, strictMaxEnabled: false };
}

export const DataQualityRule_RangeExpectation: MessageFns<DataQualityRule_RangeExpectation> = {
  encode(message: DataQualityRule_RangeExpectation, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.minValue !== "") {
      writer.uint32(10).string(message.minValue);
    }
    if (message.maxValue !== "") {
      writer.uint32(18).string(message.maxValue);
    }
    if (message.strictMinEnabled !== false) {
      writer.uint32(24).bool(message.strictMinEnabled);
    }
    if (message.strictMaxEnabled !== false) {
      writer.uint32(32).bool(message.strictMaxEnabled);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): DataQualityRule_RangeExpectation {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDataQualityRule_RangeExpectation();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.minValue = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.maxValue = reader.string();
          continue;
        case 3:
          if (tag !== 24) {
            break;
          }

          message.strictMinEnabled = reader.bool();
          continue;
        case 4:
          if (tag !== 32) {
            break;
          }

          message.strictMaxEnabled = reader.bool();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): DataQualityRule_RangeExpectation {
    return {
      minValue: isSet(object.minValue) ? globalThis.String(object.minValue) : "",
      maxValue: isSet(object.maxValue) ? globalThis.String(object.maxValue) : "",
      strictMinEnabled: isSet(object.strictMinEnabled) ? globalThis.Boolean(object.strictMinEnabled) : false,
      strictMaxEnabled: isSet(object.strictMaxEnabled) ? globalThis.Boolean(object.strictMaxEnabled) : false,
    };
  },

  toJSON(message: DataQualityRule_RangeExpectation): unknown {
    const obj: any = {};
    if (message.minValue !== "") {
      obj.minValue = message.minValue;
    }
    if (message.maxValue !== "") {
      obj.maxValue = message.maxValue;
    }
    if (message.strictMinEnabled !== false) {
      obj.strictMinEnabled = message.strictMinEnabled;
    }
    if (message.strictMaxEnabled !== false) {
      obj.strictMaxEnabled = message.strictMaxEnabled;
    }
    return obj;
  },

  create(base?: DeepPartial<DataQualityRule_RangeExpectation>): DataQualityRule_RangeExpectation {
    return DataQualityRule_RangeExpectation.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<DataQualityRule_RangeExpectation>): DataQualityRule_RangeExpectation {
    const message = createBaseDataQualityRule_RangeExpectation();
    message.minValue = object.minValue ?? "";
    message.maxValue = object.maxValue ?? "";
    message.strictMinEnabled = object.strictMinEnabled ?? false;
    message.strictMaxEnabled = object.strictMaxEnabled ?? false;
    return message;
  },
};

function createBaseDataQualityRule_NonNullExpectation(): DataQualityRule_NonNullExpectation {
  return {};
}

export const DataQualityRule_NonNullExpectation: MessageFns<DataQualityRule_NonNullExpectation> = {
  encode(_: DataQualityRule_NonNullExpectation, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): DataQualityRule_NonNullExpectation {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDataQualityRule_NonNullExpectation();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(_: any): DataQualityRule_NonNullExpectation {
    return {};
  },

  toJSON(_: DataQualityRule_NonNullExpectation): unknown {
    const obj: any = {};
    return obj;
  },

  create(base?: DeepPartial<DataQualityRule_NonNullExpectation>): DataQualityRule_NonNullExpectation {
    return DataQualityRule_NonNullExpectation.fromPartial(base ?? {});
  },
  fromPartial(_: DeepPartial<DataQualityRule_NonNullExpectation>): DataQualityRule_NonNullExpectation {
    const message = createBaseDataQualityRule_NonNullExpectation();
    return message;
  },
};

function createBaseDataQualityRule_SetExpectation(): DataQualityRule_SetExpectation {
  return { values: [] };
}

export const DataQualityRule_SetExpectation: MessageFns<DataQualityRule_SetExpectation> = {
  encode(message: DataQualityRule_SetExpectation, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.values) {
      writer.uint32(10).string(v!);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): DataQualityRule_SetExpectation {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDataQualityRule_SetExpectation();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.values.push(reader.string());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): DataQualityRule_SetExpectation {
    return {
      values: globalThis.Array.isArray(object?.values) ? object.values.map((e: any) => globalThis.String(e)) : [],
    };
  },

  toJSON(message: DataQualityRule_SetExpectation): unknown {
    const obj: any = {};
    if (message.values?.length) {
      obj.values = message.values;
    }
    return obj;
  },

  create(base?: DeepPartial<DataQualityRule_SetExpectation>): DataQualityRule_SetExpectation {
    return DataQualityRule_SetExpectation.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<DataQualityRule_SetExpectation>): DataQualityRule_SetExpectation {
    const message = createBaseDataQualityRule_SetExpectation();
    message.values = object.values?.map((e) => e) || [];
    return message;
  },
};

function createBaseDataQualityRule_RegexExpectation(): DataQualityRule_RegexExpectation {
  return { regex: "" };
}

export const DataQualityRule_RegexExpectation: MessageFns<DataQualityRule_RegexExpectation> = {
  encode(message: DataQualityRule_RegexExpectation, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.regex !== "") {
      writer.uint32(10).string(message.regex);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): DataQualityRule_RegexExpectation {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDataQualityRule_RegexExpectation();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.regex = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): DataQualityRule_RegexExpectation {
    return { regex: isSet(object.regex) ? globalThis.String(object.regex) : "" };
  },

  toJSON(message: DataQualityRule_RegexExpectation): unknown {
    const obj: any = {};
    if (message.regex !== "") {
      obj.regex = message.regex;
    }
    return obj;
  },

  create(base?: DeepPartial<DataQualityRule_RegexExpectation>): DataQualityRule_RegexExpectation {
    return DataQualityRule_RegexExpectation.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<DataQualityRule_RegexExpectation>): DataQualityRule_RegexExpectation {
    const message = createBaseDataQualityRule_RegexExpectation();
    message.regex = object.regex ?? "";
    return message;
  },
};

function createBaseDataQualityRule_UniquenessExpectation(): DataQualityRule_UniquenessExpectation {
  return {};
}

export const DataQualityRule_UniquenessExpectation: MessageFns<DataQualityRule_UniquenessExpectation> = {
  encode(_: DataQualityRule_UniquenessExpectation, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): DataQualityRule_UniquenessExpectation {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDataQualityRule_UniquenessExpectation();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(_: any): DataQualityRule_UniquenessExpectation {
    return {};
  },

  toJSON(_: DataQualityRule_UniquenessExpectation): unknown {
    const obj: any = {};
    return obj;
  },

  create(base?: DeepPartial<DataQualityRule_UniquenessExpectation>): DataQualityRule_UniquenessExpectation {
    return DataQualityRule_UniquenessExpectation.fromPartial(base ?? {});
  },
  fromPartial(_: DeepPartial<DataQualityRule_UniquenessExpectation>): DataQualityRule_UniquenessExpectation {
    const message = createBaseDataQualityRule_UniquenessExpectation();
    return message;
  },
};

function createBaseDataQualityRule_StatisticRangeExpectation(): DataQualityRule_StatisticRangeExpectation {
  return { statistic: 0, minValue: "", maxValue: "", strictMinEnabled: false, strictMaxEnabled: false };
}

export const DataQualityRule_StatisticRangeExpectation: MessageFns<DataQualityRule_StatisticRangeExpectation> = {
  encode(message: DataQualityRule_StatisticRangeExpectation, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.statistic !== 0) {
      writer.uint32(8).int32(message.statistic);
    }
    if (message.minValue !== "") {
      writer.uint32(18).string(message.minValue);
    }
    if (message.maxValue !== "") {
      writer.uint32(26).string(message.maxValue);
    }
    if (message.strictMinEnabled !== false) {
      writer.uint32(32).bool(message.strictMinEnabled);
    }
    if (message.strictMaxEnabled !== false) {
      writer.uint32(40).bool(message.strictMaxEnabled);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): DataQualityRule_StatisticRangeExpectation {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDataQualityRule_StatisticRangeExpectation();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 8) {
            break;
          }

          message.statistic = reader.int32() as any;
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.minValue = reader.string();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.maxValue = reader.string();
          continue;
        case 4:
          if (tag !== 32) {
            break;
          }

          message.strictMinEnabled = reader.bool();
          continue;
        case 5:
          if (tag !== 40) {
            break;
          }

          message.strictMaxEnabled = reader.bool();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): DataQualityRule_StatisticRangeExpectation {
    return {
      statistic: isSet(object.statistic)
        ? dataQualityRule_StatisticRangeExpectation_ColumnStatisticFromJSON(object.statistic)
        : 0,
      minValue: isSet(object.minValue) ? globalThis.String(object.minValue) : "",
      maxValue: isSet(object.maxValue) ? globalThis.String(object.maxValue) : "",
      strictMinEnabled: isSet(object.strictMinEnabled) ? globalThis.Boolean(object.strictMinEnabled) : false,
      strictMaxEnabled: isSet(object.strictMaxEnabled) ? globalThis.Boolean(object.strictMaxEnabled) : false,
    };
  },

  toJSON(message: DataQualityRule_StatisticRangeExpectation): unknown {
    const obj: any = {};
    if (message.statistic !== 0) {
      obj.statistic = dataQualityRule_StatisticRangeExpectation_ColumnStatisticToJSON(message.statistic);
    }
    if (message.minValue !== "") {
      obj.minValue = message.minValue;
    }
    if (message.maxValue !== "") {
      obj.maxValue = message.maxValue;
    }
    if (message.strictMinEnabled !== false) {
      obj.strictMinEnabled = message.strictMinEnabled;
    }
    if (message.strictMaxEnabled !== false) {
      obj.strictMaxEnabled = message.strictMaxEnabled;
    }
    return obj;
  },

  create(base?: DeepPartial<DataQualityRule_StatisticRangeExpectation>): DataQualityRule_StatisticRangeExpectation {
    return DataQualityRule_StatisticRangeExpectation.fromPartial(base ?? {});
  },
  fromPartial(
    object: DeepPartial<DataQualityRule_StatisticRangeExpectation>,
  ): DataQualityRule_StatisticRangeExpectation {
    const message = createBaseDataQualityRule_StatisticRangeExpectation();
    message.statistic = object.statistic ?? 0;
    message.minValue = object.minValue ?? "";
    message.maxValue = object.maxValue ?? "";
    message.strictMinEnabled = object.strictMinEnabled ?? false;
    message.strictMaxEnabled = object.strictMaxEnabled ?? false;
    return message;
  },
};

function createBaseDataQualityRule_RowConditionExpectation(): DataQualityRule_RowConditionExpectation {
  return { sqlExpression: "" };
}

export const DataQualityRule_RowConditionExpectation: MessageFns<DataQualityRule_RowConditionExpectation> = {
  encode(message: DataQualityRule_RowConditionExpectation, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.sqlExpression !== "") {
      writer.uint32(10).string(message.sqlExpression);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): DataQualityRule_RowConditionExpectation {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDataQualityRule_RowConditionExpectation();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.sqlExpression = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): DataQualityRule_RowConditionExpectation {
    return { sqlExpression: isSet(object.sqlExpression) ? globalThis.String(object.sqlExpression) : "" };
  },

  toJSON(message: DataQualityRule_RowConditionExpectation): unknown {
    const obj: any = {};
    if (message.sqlExpression !== "") {
      obj.sqlExpression = message.sqlExpression;
    }
    return obj;
  },

  create(base?: DeepPartial<DataQualityRule_RowConditionExpectation>): DataQualityRule_RowConditionExpectation {
    return DataQualityRule_RowConditionExpectation.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<DataQualityRule_RowConditionExpectation>): DataQualityRule_RowConditionExpectation {
    const message = createBaseDataQualityRule_RowConditionExpectation();
    message.sqlExpression = object.sqlExpression ?? "";
    return message;
  },
};

function createBaseDataQualityRule_TableConditionExpectation(): DataQualityRule_TableConditionExpectation {
  return { sqlExpression: "" };
}

export const DataQualityRule_TableConditionExpectation: MessageFns<DataQualityRule_TableConditionExpectation> = {
  encode(message: DataQualityRule_TableConditionExpectation, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.sqlExpression !== "") {
      writer.uint32(10).string(message.sqlExpression);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): DataQualityRule_TableConditionExpectation {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDataQualityRule_TableConditionExpectation();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.sqlExpression = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): DataQualityRule_TableConditionExpectation {
    return { sqlExpression: isSet(object.sqlExpression) ? globalThis.String(object.sqlExpression) : "" };
  },

  toJSON(message: DataQualityRule_TableConditionExpectation): unknown {
    const obj: any = {};
    if (message.sqlExpression !== "") {
      obj.sqlExpression = message.sqlExpression;
    }
    return obj;
  },

  create(base?: DeepPartial<DataQualityRule_TableConditionExpectation>): DataQualityRule_TableConditionExpectation {
    return DataQualityRule_TableConditionExpectation.fromPartial(base ?? {});
  },
  fromPartial(
    object: DeepPartial<DataQualityRule_TableConditionExpectation>,
  ): DataQualityRule_TableConditionExpectation {
    const message = createBaseDataQualityRule_TableConditionExpectation();
    message.sqlExpression = object.sqlExpression ?? "";
    return message;
  },
};

function createBaseDataQualityRule_SqlAssertion(): DataQualityRule_SqlAssertion {
  return { sqlStatement: "" };
}

export const DataQualityRule_SqlAssertion: MessageFns<DataQualityRule_SqlAssertion> = {
  encode(message: DataQualityRule_SqlAssertion, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.sqlStatement !== "") {
      writer.uint32(10).string(message.sqlStatement);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): DataQualityRule_SqlAssertion {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDataQualityRule_SqlAssertion();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.sqlStatement = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): DataQualityRule_SqlAssertion {
    return { sqlStatement: isSet(object.sqlStatement) ? globalThis.String(object.sqlStatement) : "" };
  },

  toJSON(message: DataQualityRule_SqlAssertion): unknown {
    const obj: any = {};
    if (message.sqlStatement !== "") {
      obj.sqlStatement = message.sqlStatement;
    }
    return obj;
  },

  create(base?: DeepPartial<DataQualityRule_SqlAssertion>): DataQualityRule_SqlAssertion {
    return DataQualityRule_SqlAssertion.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<DataQualityRule_SqlAssertion>): DataQualityRule_SqlAssertion {
    const message = createBaseDataQualityRule_SqlAssertion();
    message.sqlStatement = object.sqlStatement ?? "";
    return message;
  },
};

function createBaseDataQualityColumnResult(): DataQualityColumnResult {
  return { column: "", score: undefined };
}

export const DataQualityColumnResult: MessageFns<DataQualityColumnResult> = {
  encode(message: DataQualityColumnResult, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.column !== "") {
      writer.uint32(10).string(message.column);
    }
    if (message.score !== undefined) {
      writer.uint32(21).float(message.score);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): DataQualityColumnResult {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDataQualityColumnResult();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.column = reader.string();
          continue;
        case 2:
          if (tag !== 21) {
            break;
          }

          message.score = reader.float();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): DataQualityColumnResult {
    return {
      column: isSet(object.column) ? globalThis.String(object.column) : "",
      score: isSet(object.score) ? globalThis.Number(object.score) : undefined,
    };
  },

  toJSON(message: DataQualityColumnResult): unknown {
    const obj: any = {};
    if (message.column !== "") {
      obj.column = message.column;
    }
    if (message.score !== undefined) {
      obj.score = message.score;
    }
    return obj;
  },

  create(base?: DeepPartial<DataQualityColumnResult>): DataQualityColumnResult {
    return DataQualityColumnResult.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<DataQualityColumnResult>): DataQualityColumnResult {
    const message = createBaseDataQualityColumnResult();
    message.column = object.column ?? "";
    message.score = object.score ?? undefined;
    return message;
  },
};

type Builtin = Date | Function | Uint8Array | string | number | boolean | undefined;

export type DeepPartial<T> = T extends Builtin ? T
  : T extends Long ? string | number | Long : T extends globalThis.Array<infer U> ? globalThis.Array<DeepPartial<U>>
  : T extends ReadonlyArray<infer U> ? ReadonlyArray<DeepPartial<U>>
  : T extends {} ? { [K in keyof T]?: DeepPartial<T[K]> }
  : Partial<T>;

function isSet(value: any): boolean {
  return value !== null && value !== undefined;
}

export interface MessageFns<T> {
  encode(message: T, writer?: BinaryWriter): BinaryWriter;
  decode(input: BinaryReader | Uint8Array, length?: number): T;
  fromJSON(object: any): T;
  toJSON(message: T): unknown;
  create(base?: DeepPartial<T>): T;
  fromPartial(object: DeepPartial<T>): T;
}
