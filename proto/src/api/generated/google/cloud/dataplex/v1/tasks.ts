// Code generated by protoc-gen-ts_proto. DO NOT EDIT.
// versions:
//   protoc-gen-ts_proto  v2.2.0
//   protoc               unknown
// source: google/cloud/dataplex/v1/tasks.proto

/* eslint-disable */
import { BinaryReader, BinaryWriter } from "@bufbuild/protobuf/wire";
import Long from "long";
import { Duration } from "../../../protobuf/duration.js";
import { Timestamp } from "../../../protobuf/timestamp.js";
import { State, stateFromJSON, stateToJSON } from "./resources.js";

export const protobufPackage = "google.cloud.dataplex.v1";

/** A task represents a user-visible job. */
export interface Task {
  /**
   * Output only. The relative resource name of the task, of the form:
   * projects/{project_number}/locations/{location_id}/lakes/{lake_id}/
   * tasks/{task_id}.
   */
  name: string;
  /**
   * Output only. System generated globally unique ID for the task. This ID will
   * be different if the task is deleted and re-created with the same name.
   */
  uid: string;
  /** Output only. The time when the task was created. */
  createTime:
    | Date
    | undefined;
  /** Output only. The time when the task was last updated. */
  updateTime:
    | Date
    | undefined;
  /** Optional. Description of the task. */
  description: string;
  /** Optional. User friendly display name. */
  displayName: string;
  /** Output only. Current state of the task. */
  state: State;
  /** Optional. User-defined labels for the task. */
  labels: { [key: string]: string };
  /** Required. Spec related to how often and when a task should be triggered. */
  triggerSpec:
    | Task_TriggerSpec
    | undefined;
  /** Required. Spec related to how a task is executed. */
  executionSpec:
    | Task_ExecutionSpec
    | undefined;
  /** Output only. Status of the latest task executions. */
  executionStatus:
    | Task_ExecutionStatus
    | undefined;
  /** Config related to running custom Spark tasks. */
  spark?:
    | Task_SparkTaskConfig
    | undefined;
  /** Config related to running scheduled Notebooks. */
  notebook?: Task_NotebookTaskConfig | undefined;
}

/** Configuration for the underlying infrastructure used to run workloads. */
export interface Task_InfrastructureSpec {
  /** Compute resources needed for a Task when using Dataproc Serverless. */
  batch?:
    | Task_InfrastructureSpec_BatchComputeResources
    | undefined;
  /** Container Image Runtime Configuration. */
  containerImage?:
    | Task_InfrastructureSpec_ContainerImageRuntime
    | undefined;
  /** Vpc network. */
  vpcNetwork?: Task_InfrastructureSpec_VpcNetwork | undefined;
}

/** Batch compute resources associated with the task. */
export interface Task_InfrastructureSpec_BatchComputeResources {
  /**
   * Optional. Total number of job executors.
   * Executor Count should be between 2 and 100. [Default=2]
   */
  executorsCount: number;
  /**
   * Optional. Max configurable executors.
   * If max_executors_count > executors_count, then auto-scaling is enabled.
   * Max Executor Count should be between 2 and 1000. [Default=1000]
   */
  maxExecutorsCount: number;
}

/** Container Image Runtime Configuration used with Batch execution. */
export interface Task_InfrastructureSpec_ContainerImageRuntime {
  /** Optional. Container image to use. */
  image: string;
  /**
   * Optional. A list of Java JARS to add to the classpath.
   * Valid input includes Cloud Storage URIs to Jar binaries.
   * For example, gs://bucket-name/my/path/to/file.jar
   */
  javaJars: string[];
  /**
   * Optional. A list of python packages to be installed.
   * Valid formats include Cloud Storage URI to a PIP installable library.
   * For example, gs://bucket-name/my/path/to/lib.tar.gz
   */
  pythonPackages: string[];
  /**
   * Optional. Override to common configuration of open source components
   * installed on the Dataproc cluster. The properties to set on daemon
   * config files. Property keys are specified in `prefix:property` format,
   * for example `core:hadoop.tmp.dir`. For more information, see [Cluster
   * properties](https://cloud.google.com/dataproc/docs/concepts/cluster-properties).
   */
  properties: { [key: string]: string };
}

export interface Task_InfrastructureSpec_ContainerImageRuntime_PropertiesEntry {
  key: string;
  value: string;
}

/** Cloud VPC Network used to run the infrastructure. */
export interface Task_InfrastructureSpec_VpcNetwork {
  /**
   * Optional. The Cloud VPC network in which the job is run. By default,
   * the Cloud VPC network named Default within the project is used.
   */
  network?:
    | string
    | undefined;
  /** Optional. The Cloud VPC sub-network in which the job is run. */
  subNetwork?:
    | string
    | undefined;
  /** Optional. List of network tags to apply to the job. */
  networkTags: string[];
}

/** Task scheduling and trigger settings. */
export interface Task_TriggerSpec {
  /** Required. Immutable. Trigger type of the user-specified Task. */
  type: Task_TriggerSpec_Type;
  /**
   * Optional. The first run of the task will be after this time.
   * If not specified, the task will run shortly after being submitted if
   * ON_DEMAND and based on the schedule if RECURRING.
   */
  startTime:
    | Date
    | undefined;
  /**
   * Optional. Prevent the task from executing.
   * This does not cancel already running tasks. It is intended to temporarily
   * disable RECURRING tasks.
   */
  disabled: boolean;
  /**
   * Optional. Number of retry attempts before aborting.
   * Set to zero to never attempt to retry a failed task.
   */
  maxRetries: number;
  /**
   * Optional. Cron schedule (https://en.wikipedia.org/wiki/Cron) for
   * running tasks periodically. To explicitly set a timezone to the cron
   * tab, apply a prefix in the cron tab: "CRON_TZ=${IANA_TIME_ZONE}" or
   * "TZ=${IANA_TIME_ZONE}". The ${IANA_TIME_ZONE} may only be a valid
   * string from IANA time zone database. For example,
   * `CRON_TZ=America/New_York 1 * * * *`, or `TZ=America/New_York 1 * * *
   * *`. This field is required for RECURRING tasks.
   */
  schedule?: string | undefined;
}

/** Determines how often and when the job will run. */
export enum Task_TriggerSpec_Type {
  /** TYPE_UNSPECIFIED - Unspecified trigger type. */
  TYPE_UNSPECIFIED = 0,
  /** ON_DEMAND - The task runs one-time shortly after Task Creation. */
  ON_DEMAND = 1,
  /** RECURRING - The task is scheduled to run periodically. */
  RECURRING = 2,
  UNRECOGNIZED = -1,
}

export function task_TriggerSpec_TypeFromJSON(object: any): Task_TriggerSpec_Type {
  switch (object) {
    case 0:
    case "TYPE_UNSPECIFIED":
      return Task_TriggerSpec_Type.TYPE_UNSPECIFIED;
    case 1:
    case "ON_DEMAND":
      return Task_TriggerSpec_Type.ON_DEMAND;
    case 2:
    case "RECURRING":
      return Task_TriggerSpec_Type.RECURRING;
    case -1:
    case "UNRECOGNIZED":
    default:
      return Task_TriggerSpec_Type.UNRECOGNIZED;
  }
}

export function task_TriggerSpec_TypeToJSON(object: Task_TriggerSpec_Type): string {
  switch (object) {
    case Task_TriggerSpec_Type.TYPE_UNSPECIFIED:
      return "TYPE_UNSPECIFIED";
    case Task_TriggerSpec_Type.ON_DEMAND:
      return "ON_DEMAND";
    case Task_TriggerSpec_Type.RECURRING:
      return "RECURRING";
    case Task_TriggerSpec_Type.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/** Execution related settings, like retry and service_account. */
export interface Task_ExecutionSpec {
  /**
   * Optional. The arguments to pass to the task.
   * The args can use placeholders of the format ${placeholder} as
   * part of key/value string. These will be interpolated before passing the
   * args to the driver. Currently supported placeholders:
   * - ${task_id}
   * - ${job_time}
   * To pass positional args, set the key as TASK_ARGS. The value should be a
   * comma-separated string of all the positional arguments. To use a
   * delimiter other than comma, refer to
   * https://cloud.google.com/sdk/gcloud/reference/topic/escaping. In case of
   * other keys being present in the args, then TASK_ARGS will be passed as
   * the last argument.
   */
  args: { [key: string]: string };
  /**
   * Required. Service account to use to execute a task.
   * If not provided, the default Compute service account for the project is
   * used.
   */
  serviceAccount: string;
  /**
   * Optional. The project in which jobs are run. By default, the project
   * containing the Lake is used. If a project is provided, the
   * [ExecutionSpec.service_account][google.cloud.dataplex.v1.Task.ExecutionSpec.service_account]
   * must belong to this project.
   */
  project: string;
  /** Optional. The maximum duration after which the job execution is expired. */
  maxJobExecutionLifetime:
    | Duration
    | undefined;
  /**
   * Optional. The Cloud KMS key to use for encryption, of the form:
   * `projects/{project_number}/locations/{location_id}/keyRings/{key-ring-name}/cryptoKeys/{key-name}`.
   */
  kmsKey: string;
}

export interface Task_ExecutionSpec_ArgsEntry {
  key: string;
  value: string;
}

/** User-specified config for running a Spark task. */
export interface Task_SparkTaskConfig {
  /**
   * The Cloud Storage URI of the jar file that contains the main class.
   * The execution args are passed in as a sequence of named process
   * arguments (`--key=value`).
   */
  mainJarFileUri?:
    | string
    | undefined;
  /**
   * The name of the driver's main class. The jar file that contains the
   * class must be in the default CLASSPATH or specified in
   * `jar_file_uris`.
   * The execution args are passed in as a sequence of named process
   * arguments (`--key=value`).
   */
  mainClass?:
    | string
    | undefined;
  /**
   * The Gcloud Storage URI of the main Python file to use as the driver.
   * Must be a .py file. The execution args are passed in as a sequence of
   * named process arguments (`--key=value`).
   */
  pythonScriptFile?:
    | string
    | undefined;
  /**
   * A reference to a query file. This can be the Cloud Storage URI of the
   * query file or it can the path to a SqlScript Content. The execution
   * args are used to declare a set of script variables
   * (`set key="value";`).
   */
  sqlScriptFile?:
    | string
    | undefined;
  /**
   * The query text.
   * The execution args are used to declare a set of script variables
   * (`set key="value";`).
   */
  sqlScript?:
    | string
    | undefined;
  /**
   * Optional. Cloud Storage URIs of files to be placed in the working
   * directory of each executor.
   */
  fileUris: string[];
  /**
   * Optional. Cloud Storage URIs of archives to be extracted into the working
   * directory of each executor. Supported file types: .jar, .tar, .tar.gz,
   * .tgz, and .zip.
   */
  archiveUris: string[];
  /** Optional. Infrastructure specification for the execution. */
  infrastructureSpec: Task_InfrastructureSpec | undefined;
}

/** Config for running scheduled notebooks. */
export interface Task_NotebookTaskConfig {
  /**
   * Required. Path to input notebook. This can be the Cloud Storage URI of
   * the notebook file or the path to a Notebook Content. The execution args
   * are accessible as environment variables
   * (`TASK_key=value`).
   */
  notebook: string;
  /** Optional. Infrastructure specification for the execution. */
  infrastructureSpec:
    | Task_InfrastructureSpec
    | undefined;
  /**
   * Optional. Cloud Storage URIs of files to be placed in the working
   * directory of each executor.
   */
  fileUris: string[];
  /**
   * Optional. Cloud Storage URIs of archives to be extracted into the working
   * directory of each executor. Supported file types: .jar, .tar, .tar.gz,
   * .tgz, and .zip.
   */
  archiveUris: string[];
}

/** Status of the task execution (e.g. Jobs). */
export interface Task_ExecutionStatus {
  /** Output only. Last update time of the status. */
  updateTime:
    | Date
    | undefined;
  /** Output only. latest job execution */
  latestJob: Job | undefined;
}

export interface Task_LabelsEntry {
  key: string;
  value: string;
}

/** A job represents an instance of a task. */
export interface Job {
  /**
   * Output only. The relative resource name of the job, of the form:
   * `projects/{project_number}/locations/{location_id}/lakes/{lake_id}/tasks/{task_id}/jobs/{job_id}`.
   */
  name: string;
  /** Output only. System generated globally unique ID for the job. */
  uid: string;
  /** Output only. The time when the job was started. */
  startTime:
    | Date
    | undefined;
  /** Output only. The time when the job ended. */
  endTime:
    | Date
    | undefined;
  /** Output only. Execution state for the job. */
  state: Job_State;
  /**
   * Output only. The number of times the job has been retried (excluding the
   * initial attempt).
   */
  retryCount: number;
  /** Output only. The underlying service running a job. */
  service: Job_Service;
  /**
   * Output only. The full resource name for the job run under a particular
   * service.
   */
  serviceJob: string;
  /** Output only. Additional information about the current state. */
  message: string;
  /** Output only. User-defined labels for the task. */
  labels: { [key: string]: string };
  /** Output only. Job execution trigger. */
  trigger: Job_Trigger;
  /** Output only. Spec related to how a task is executed. */
  executionSpec: Task_ExecutionSpec | undefined;
}

export enum Job_Service {
  /** SERVICE_UNSPECIFIED - Service used to run the job is unspecified. */
  SERVICE_UNSPECIFIED = 0,
  /** DATAPROC - Dataproc service is used to run this job. */
  DATAPROC = 1,
  UNRECOGNIZED = -1,
}

export function job_ServiceFromJSON(object: any): Job_Service {
  switch (object) {
    case 0:
    case "SERVICE_UNSPECIFIED":
      return Job_Service.SERVICE_UNSPECIFIED;
    case 1:
    case "DATAPROC":
      return Job_Service.DATAPROC;
    case -1:
    case "UNRECOGNIZED":
    default:
      return Job_Service.UNRECOGNIZED;
  }
}

export function job_ServiceToJSON(object: Job_Service): string {
  switch (object) {
    case Job_Service.SERVICE_UNSPECIFIED:
      return "SERVICE_UNSPECIFIED";
    case Job_Service.DATAPROC:
      return "DATAPROC";
    case Job_Service.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

export enum Job_State {
  /** STATE_UNSPECIFIED - The job state is unknown. */
  STATE_UNSPECIFIED = 0,
  /** RUNNING - The job is running. */
  RUNNING = 1,
  /** CANCELLING - The job is cancelling. */
  CANCELLING = 2,
  /** CANCELLED - The job cancellation was successful. */
  CANCELLED = 3,
  /** SUCCEEDED - The job completed successfully. */
  SUCCEEDED = 4,
  /** FAILED - The job is no longer running due to an error. */
  FAILED = 5,
  /** ABORTED - The job was cancelled outside of Dataplex. */
  ABORTED = 6,
  UNRECOGNIZED = -1,
}

export function job_StateFromJSON(object: any): Job_State {
  switch (object) {
    case 0:
    case "STATE_UNSPECIFIED":
      return Job_State.STATE_UNSPECIFIED;
    case 1:
    case "RUNNING":
      return Job_State.RUNNING;
    case 2:
    case "CANCELLING":
      return Job_State.CANCELLING;
    case 3:
    case "CANCELLED":
      return Job_State.CANCELLED;
    case 4:
    case "SUCCEEDED":
      return Job_State.SUCCEEDED;
    case 5:
    case "FAILED":
      return Job_State.FAILED;
    case 6:
    case "ABORTED":
      return Job_State.ABORTED;
    case -1:
    case "UNRECOGNIZED":
    default:
      return Job_State.UNRECOGNIZED;
  }
}

export function job_StateToJSON(object: Job_State): string {
  switch (object) {
    case Job_State.STATE_UNSPECIFIED:
      return "STATE_UNSPECIFIED";
    case Job_State.RUNNING:
      return "RUNNING";
    case Job_State.CANCELLING:
      return "CANCELLING";
    case Job_State.CANCELLED:
      return "CANCELLED";
    case Job_State.SUCCEEDED:
      return "SUCCEEDED";
    case Job_State.FAILED:
      return "FAILED";
    case Job_State.ABORTED:
      return "ABORTED";
    case Job_State.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/** Job execution trigger. */
export enum Job_Trigger {
  /** TRIGGER_UNSPECIFIED - The trigger is unspecified. */
  TRIGGER_UNSPECIFIED = 0,
  /**
   * TASK_CONFIG - The job was triggered by Dataplex based on trigger spec from task
   * definition.
   */
  TASK_CONFIG = 1,
  /** RUN_REQUEST - The job was triggered by the explicit call of Task API. */
  RUN_REQUEST = 2,
  UNRECOGNIZED = -1,
}

export function job_TriggerFromJSON(object: any): Job_Trigger {
  switch (object) {
    case 0:
    case "TRIGGER_UNSPECIFIED":
      return Job_Trigger.TRIGGER_UNSPECIFIED;
    case 1:
    case "TASK_CONFIG":
      return Job_Trigger.TASK_CONFIG;
    case 2:
    case "RUN_REQUEST":
      return Job_Trigger.RUN_REQUEST;
    case -1:
    case "UNRECOGNIZED":
    default:
      return Job_Trigger.UNRECOGNIZED;
  }
}

export function job_TriggerToJSON(object: Job_Trigger): string {
  switch (object) {
    case Job_Trigger.TRIGGER_UNSPECIFIED:
      return "TRIGGER_UNSPECIFIED";
    case Job_Trigger.TASK_CONFIG:
      return "TASK_CONFIG";
    case Job_Trigger.RUN_REQUEST:
      return "RUN_REQUEST";
    case Job_Trigger.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

export interface Job_LabelsEntry {
  key: string;
  value: string;
}

function createBaseTask(): Task {
  return {
    name: "",
    uid: "",
    createTime: undefined,
    updateTime: undefined,
    description: "",
    displayName: "",
    state: 0,
    labels: {},
    triggerSpec: undefined,
    executionSpec: undefined,
    executionStatus: undefined,
    spark: undefined,
    notebook: undefined,
  };
}

export const Task: MessageFns<Task> = {
  encode(message: Task, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    if (message.uid !== "") {
      writer.uint32(18).string(message.uid);
    }
    if (message.createTime !== undefined) {
      Timestamp.encode(toTimestamp(message.createTime), writer.uint32(26).fork()).join();
    }
    if (message.updateTime !== undefined) {
      Timestamp.encode(toTimestamp(message.updateTime), writer.uint32(34).fork()).join();
    }
    if (message.description !== "") {
      writer.uint32(42).string(message.description);
    }
    if (message.displayName !== "") {
      writer.uint32(50).string(message.displayName);
    }
    if (message.state !== 0) {
      writer.uint32(56).int32(message.state);
    }
    Object.entries(message.labels).forEach(([key, value]) => {
      Task_LabelsEntry.encode({ key: key as any, value }, writer.uint32(66).fork()).join();
    });
    if (message.triggerSpec !== undefined) {
      Task_TriggerSpec.encode(message.triggerSpec, writer.uint32(802).fork()).join();
    }
    if (message.executionSpec !== undefined) {
      Task_ExecutionSpec.encode(message.executionSpec, writer.uint32(810).fork()).join();
    }
    if (message.executionStatus !== undefined) {
      Task_ExecutionStatus.encode(message.executionStatus, writer.uint32(1610).fork()).join();
    }
    if (message.spark !== undefined) {
      Task_SparkTaskConfig.encode(message.spark, writer.uint32(2402).fork()).join();
    }
    if (message.notebook !== undefined) {
      Task_NotebookTaskConfig.encode(message.notebook, writer.uint32(2418).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Task {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseTask();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.uid = reader.string();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.createTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.updateTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.description = reader.string();
          continue;
        case 6:
          if (tag !== 50) {
            break;
          }

          message.displayName = reader.string();
          continue;
        case 7:
          if (tag !== 56) {
            break;
          }

          message.state = reader.int32() as any;
          continue;
        case 8:
          if (tag !== 66) {
            break;
          }

          const entry8 = Task_LabelsEntry.decode(reader, reader.uint32());
          if (entry8.value !== undefined) {
            message.labels[entry8.key] = entry8.value;
          }
          continue;
        case 100:
          if (tag !== 802) {
            break;
          }

          message.triggerSpec = Task_TriggerSpec.decode(reader, reader.uint32());
          continue;
        case 101:
          if (tag !== 810) {
            break;
          }

          message.executionSpec = Task_ExecutionSpec.decode(reader, reader.uint32());
          continue;
        case 201:
          if (tag !== 1610) {
            break;
          }

          message.executionStatus = Task_ExecutionStatus.decode(reader, reader.uint32());
          continue;
        case 300:
          if (tag !== 2402) {
            break;
          }

          message.spark = Task_SparkTaskConfig.decode(reader, reader.uint32());
          continue;
        case 302:
          if (tag !== 2418) {
            break;
          }

          message.notebook = Task_NotebookTaskConfig.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Task {
    return {
      name: isSet(object.name) ? globalThis.String(object.name) : "",
      uid: isSet(object.uid) ? globalThis.String(object.uid) : "",
      createTime: isSet(object.createTime) ? fromJsonTimestamp(object.createTime) : undefined,
      updateTime: isSet(object.updateTime) ? fromJsonTimestamp(object.updateTime) : undefined,
      description: isSet(object.description) ? globalThis.String(object.description) : "",
      displayName: isSet(object.displayName) ? globalThis.String(object.displayName) : "",
      state: isSet(object.state) ? stateFromJSON(object.state) : 0,
      labels: isObject(object.labels)
        ? Object.entries(object.labels).reduce<{ [key: string]: string }>((acc, [key, value]) => {
          acc[key] = String(value);
          return acc;
        }, {})
        : {},
      triggerSpec: isSet(object.triggerSpec) ? Task_TriggerSpec.fromJSON(object.triggerSpec) : undefined,
      executionSpec: isSet(object.executionSpec) ? Task_ExecutionSpec.fromJSON(object.executionSpec) : undefined,
      executionStatus: isSet(object.executionStatus)
        ? Task_ExecutionStatus.fromJSON(object.executionStatus)
        : undefined,
      spark: isSet(object.spark) ? Task_SparkTaskConfig.fromJSON(object.spark) : undefined,
      notebook: isSet(object.notebook) ? Task_NotebookTaskConfig.fromJSON(object.notebook) : undefined,
    };
  },

  toJSON(message: Task): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    if (message.uid !== "") {
      obj.uid = message.uid;
    }
    if (message.createTime !== undefined) {
      obj.createTime = message.createTime.toISOString();
    }
    if (message.updateTime !== undefined) {
      obj.updateTime = message.updateTime.toISOString();
    }
    if (message.description !== "") {
      obj.description = message.description;
    }
    if (message.displayName !== "") {
      obj.displayName = message.displayName;
    }
    if (message.state !== 0) {
      obj.state = stateToJSON(message.state);
    }
    if (message.labels) {
      const entries = Object.entries(message.labels);
      if (entries.length > 0) {
        obj.labels = {};
        entries.forEach(([k, v]) => {
          obj.labels[k] = v;
        });
      }
    }
    if (message.triggerSpec !== undefined) {
      obj.triggerSpec = Task_TriggerSpec.toJSON(message.triggerSpec);
    }
    if (message.executionSpec !== undefined) {
      obj.executionSpec = Task_ExecutionSpec.toJSON(message.executionSpec);
    }
    if (message.executionStatus !== undefined) {
      obj.executionStatus = Task_ExecutionStatus.toJSON(message.executionStatus);
    }
    if (message.spark !== undefined) {
      obj.spark = Task_SparkTaskConfig.toJSON(message.spark);
    }
    if (message.notebook !== undefined) {
      obj.notebook = Task_NotebookTaskConfig.toJSON(message.notebook);
    }
    return obj;
  },

  create(base?: DeepPartial<Task>): Task {
    return Task.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<Task>): Task {
    const message = createBaseTask();
    message.name = object.name ?? "";
    message.uid = object.uid ?? "";
    message.createTime = object.createTime ?? undefined;
    message.updateTime = object.updateTime ?? undefined;
    message.description = object.description ?? "";
    message.displayName = object.displayName ?? "";
    message.state = object.state ?? 0;
    message.labels = Object.entries(object.labels ?? {}).reduce<{ [key: string]: string }>((acc, [key, value]) => {
      if (value !== undefined) {
        acc[key] = globalThis.String(value);
      }
      return acc;
    }, {});
    message.triggerSpec = (object.triggerSpec !== undefined && object.triggerSpec !== null)
      ? Task_TriggerSpec.fromPartial(object.triggerSpec)
      : undefined;
    message.executionSpec = (object.executionSpec !== undefined && object.executionSpec !== null)
      ? Task_ExecutionSpec.fromPartial(object.executionSpec)
      : undefined;
    message.executionStatus = (object.executionStatus !== undefined && object.executionStatus !== null)
      ? Task_ExecutionStatus.fromPartial(object.executionStatus)
      : undefined;
    message.spark = (object.spark !== undefined && object.spark !== null)
      ? Task_SparkTaskConfig.fromPartial(object.spark)
      : undefined;
    message.notebook = (object.notebook !== undefined && object.notebook !== null)
      ? Task_NotebookTaskConfig.fromPartial(object.notebook)
      : undefined;
    return message;
  },
};

function createBaseTask_InfrastructureSpec(): Task_InfrastructureSpec {
  return { batch: undefined, containerImage: undefined, vpcNetwork: undefined };
}

export const Task_InfrastructureSpec: MessageFns<Task_InfrastructureSpec> = {
  encode(message: Task_InfrastructureSpec, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.batch !== undefined) {
      Task_InfrastructureSpec_BatchComputeResources.encode(message.batch, writer.uint32(418).fork()).join();
    }
    if (message.containerImage !== undefined) {
      Task_InfrastructureSpec_ContainerImageRuntime.encode(message.containerImage, writer.uint32(810).fork()).join();
    }
    if (message.vpcNetwork !== undefined) {
      Task_InfrastructureSpec_VpcNetwork.encode(message.vpcNetwork, writer.uint32(1202).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Task_InfrastructureSpec {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseTask_InfrastructureSpec();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 52:
          if (tag !== 418) {
            break;
          }

          message.batch = Task_InfrastructureSpec_BatchComputeResources.decode(reader, reader.uint32());
          continue;
        case 101:
          if (tag !== 810) {
            break;
          }

          message.containerImage = Task_InfrastructureSpec_ContainerImageRuntime.decode(reader, reader.uint32());
          continue;
        case 150:
          if (tag !== 1202) {
            break;
          }

          message.vpcNetwork = Task_InfrastructureSpec_VpcNetwork.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Task_InfrastructureSpec {
    return {
      batch: isSet(object.batch) ? Task_InfrastructureSpec_BatchComputeResources.fromJSON(object.batch) : undefined,
      containerImage: isSet(object.containerImage)
        ? Task_InfrastructureSpec_ContainerImageRuntime.fromJSON(object.containerImage)
        : undefined,
      vpcNetwork: isSet(object.vpcNetwork) ? Task_InfrastructureSpec_VpcNetwork.fromJSON(object.vpcNetwork) : undefined,
    };
  },

  toJSON(message: Task_InfrastructureSpec): unknown {
    const obj: any = {};
    if (message.batch !== undefined) {
      obj.batch = Task_InfrastructureSpec_BatchComputeResources.toJSON(message.batch);
    }
    if (message.containerImage !== undefined) {
      obj.containerImage = Task_InfrastructureSpec_ContainerImageRuntime.toJSON(message.containerImage);
    }
    if (message.vpcNetwork !== undefined) {
      obj.vpcNetwork = Task_InfrastructureSpec_VpcNetwork.toJSON(message.vpcNetwork);
    }
    return obj;
  },

  create(base?: DeepPartial<Task_InfrastructureSpec>): Task_InfrastructureSpec {
    return Task_InfrastructureSpec.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<Task_InfrastructureSpec>): Task_InfrastructureSpec {
    const message = createBaseTask_InfrastructureSpec();
    message.batch = (object.batch !== undefined && object.batch !== null)
      ? Task_InfrastructureSpec_BatchComputeResources.fromPartial(object.batch)
      : undefined;
    message.containerImage = (object.containerImage !== undefined && object.containerImage !== null)
      ? Task_InfrastructureSpec_ContainerImageRuntime.fromPartial(object.containerImage)
      : undefined;
    message.vpcNetwork = (object.vpcNetwork !== undefined && object.vpcNetwork !== null)
      ? Task_InfrastructureSpec_VpcNetwork.fromPartial(object.vpcNetwork)
      : undefined;
    return message;
  },
};

function createBaseTask_InfrastructureSpec_BatchComputeResources(): Task_InfrastructureSpec_BatchComputeResources {
  return { executorsCount: 0, maxExecutorsCount: 0 };
}

export const Task_InfrastructureSpec_BatchComputeResources: MessageFns<Task_InfrastructureSpec_BatchComputeResources> =
  {
    encode(
      message: Task_InfrastructureSpec_BatchComputeResources,
      writer: BinaryWriter = new BinaryWriter(),
    ): BinaryWriter {
      if (message.executorsCount !== 0) {
        writer.uint32(8).int32(message.executorsCount);
      }
      if (message.maxExecutorsCount !== 0) {
        writer.uint32(16).int32(message.maxExecutorsCount);
      }
      return writer;
    },

    decode(input: BinaryReader | Uint8Array, length?: number): Task_InfrastructureSpec_BatchComputeResources {
      const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
      let end = length === undefined ? reader.len : reader.pos + length;
      const message = createBaseTask_InfrastructureSpec_BatchComputeResources();
      while (reader.pos < end) {
        const tag = reader.uint32();
        switch (tag >>> 3) {
          case 1:
            if (tag !== 8) {
              break;
            }

            message.executorsCount = reader.int32();
            continue;
          case 2:
            if (tag !== 16) {
              break;
            }

            message.maxExecutorsCount = reader.int32();
            continue;
        }
        if ((tag & 7) === 4 || tag === 0) {
          break;
        }
        reader.skip(tag & 7);
      }
      return message;
    },

    fromJSON(object: any): Task_InfrastructureSpec_BatchComputeResources {
      return {
        executorsCount: isSet(object.executorsCount) ? globalThis.Number(object.executorsCount) : 0,
        maxExecutorsCount: isSet(object.maxExecutorsCount) ? globalThis.Number(object.maxExecutorsCount) : 0,
      };
    },

    toJSON(message: Task_InfrastructureSpec_BatchComputeResources): unknown {
      const obj: any = {};
      if (message.executorsCount !== 0) {
        obj.executorsCount = Math.round(message.executorsCount);
      }
      if (message.maxExecutorsCount !== 0) {
        obj.maxExecutorsCount = Math.round(message.maxExecutorsCount);
      }
      return obj;
    },

    create(
      base?: DeepPartial<Task_InfrastructureSpec_BatchComputeResources>,
    ): Task_InfrastructureSpec_BatchComputeResources {
      return Task_InfrastructureSpec_BatchComputeResources.fromPartial(base ?? {});
    },
    fromPartial(
      object: DeepPartial<Task_InfrastructureSpec_BatchComputeResources>,
    ): Task_InfrastructureSpec_BatchComputeResources {
      const message = createBaseTask_InfrastructureSpec_BatchComputeResources();
      message.executorsCount = object.executorsCount ?? 0;
      message.maxExecutorsCount = object.maxExecutorsCount ?? 0;
      return message;
    },
  };

function createBaseTask_InfrastructureSpec_ContainerImageRuntime(): Task_InfrastructureSpec_ContainerImageRuntime {
  return { image: "", javaJars: [], pythonPackages: [], properties: {} };
}

export const Task_InfrastructureSpec_ContainerImageRuntime: MessageFns<Task_InfrastructureSpec_ContainerImageRuntime> =
  {
    encode(
      message: Task_InfrastructureSpec_ContainerImageRuntime,
      writer: BinaryWriter = new BinaryWriter(),
    ): BinaryWriter {
      if (message.image !== "") {
        writer.uint32(10).string(message.image);
      }
      for (const v of message.javaJars) {
        writer.uint32(18).string(v!);
      }
      for (const v of message.pythonPackages) {
        writer.uint32(26).string(v!);
      }
      Object.entries(message.properties).forEach(([key, value]) => {
        Task_InfrastructureSpec_ContainerImageRuntime_PropertiesEntry.encode(
          { key: key as any, value },
          writer.uint32(34).fork(),
        ).join();
      });
      return writer;
    },

    decode(input: BinaryReader | Uint8Array, length?: number): Task_InfrastructureSpec_ContainerImageRuntime {
      const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
      let end = length === undefined ? reader.len : reader.pos + length;
      const message = createBaseTask_InfrastructureSpec_ContainerImageRuntime();
      while (reader.pos < end) {
        const tag = reader.uint32();
        switch (tag >>> 3) {
          case 1:
            if (tag !== 10) {
              break;
            }

            message.image = reader.string();
            continue;
          case 2:
            if (tag !== 18) {
              break;
            }

            message.javaJars.push(reader.string());
            continue;
          case 3:
            if (tag !== 26) {
              break;
            }

            message.pythonPackages.push(reader.string());
            continue;
          case 4:
            if (tag !== 34) {
              break;
            }

            const entry4 = Task_InfrastructureSpec_ContainerImageRuntime_PropertiesEntry.decode(
              reader,
              reader.uint32(),
            );
            if (entry4.value !== undefined) {
              message.properties[entry4.key] = entry4.value;
            }
            continue;
        }
        if ((tag & 7) === 4 || tag === 0) {
          break;
        }
        reader.skip(tag & 7);
      }
      return message;
    },

    fromJSON(object: any): Task_InfrastructureSpec_ContainerImageRuntime {
      return {
        image: isSet(object.image) ? globalThis.String(object.image) : "",
        javaJars: globalThis.Array.isArray(object?.javaJars)
          ? object.javaJars.map((e: any) => globalThis.String(e))
          : [],
        pythonPackages: globalThis.Array.isArray(object?.pythonPackages)
          ? object.pythonPackages.map((e: any) => globalThis.String(e))
          : [],
        properties: isObject(object.properties)
          ? Object.entries(object.properties).reduce<{ [key: string]: string }>((acc, [key, value]) => {
            acc[key] = String(value);
            return acc;
          }, {})
          : {},
      };
    },

    toJSON(message: Task_InfrastructureSpec_ContainerImageRuntime): unknown {
      const obj: any = {};
      if (message.image !== "") {
        obj.image = message.image;
      }
      if (message.javaJars?.length) {
        obj.javaJars = message.javaJars;
      }
      if (message.pythonPackages?.length) {
        obj.pythonPackages = message.pythonPackages;
      }
      if (message.properties) {
        const entries = Object.entries(message.properties);
        if (entries.length > 0) {
          obj.properties = {};
          entries.forEach(([k, v]) => {
            obj.properties[k] = v;
          });
        }
      }
      return obj;
    },

    create(
      base?: DeepPartial<Task_InfrastructureSpec_ContainerImageRuntime>,
    ): Task_InfrastructureSpec_ContainerImageRuntime {
      return Task_InfrastructureSpec_ContainerImageRuntime.fromPartial(base ?? {});
    },
    fromPartial(
      object: DeepPartial<Task_InfrastructureSpec_ContainerImageRuntime>,
    ): Task_InfrastructureSpec_ContainerImageRuntime {
      const message = createBaseTask_InfrastructureSpec_ContainerImageRuntime();
      message.image = object.image ?? "";
      message.javaJars = object.javaJars?.map((e) => e) || [];
      message.pythonPackages = object.pythonPackages?.map((e) => e) || [];
      message.properties = Object.entries(object.properties ?? {}).reduce<{ [key: string]: string }>(
        (acc, [key, value]) => {
          if (value !== undefined) {
            acc[key] = globalThis.String(value);
          }
          return acc;
        },
        {},
      );
      return message;
    },
  };

function createBaseTask_InfrastructureSpec_ContainerImageRuntime_PropertiesEntry(): Task_InfrastructureSpec_ContainerImageRuntime_PropertiesEntry {
  return { key: "", value: "" };
}

export const Task_InfrastructureSpec_ContainerImageRuntime_PropertiesEntry: MessageFns<
  Task_InfrastructureSpec_ContainerImageRuntime_PropertiesEntry
> = {
  encode(
    message: Task_InfrastructureSpec_ContainerImageRuntime_PropertiesEntry,
    writer: BinaryWriter = new BinaryWriter(),
  ): BinaryWriter {
    if (message.key !== "") {
      writer.uint32(10).string(message.key);
    }
    if (message.value !== "") {
      writer.uint32(18).string(message.value);
    }
    return writer;
  },

  decode(
    input: BinaryReader | Uint8Array,
    length?: number,
  ): Task_InfrastructureSpec_ContainerImageRuntime_PropertiesEntry {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseTask_InfrastructureSpec_ContainerImageRuntime_PropertiesEntry();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.key = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.value = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Task_InfrastructureSpec_ContainerImageRuntime_PropertiesEntry {
    return {
      key: isSet(object.key) ? globalThis.String(object.key) : "",
      value: isSet(object.value) ? globalThis.String(object.value) : "",
    };
  },

  toJSON(message: Task_InfrastructureSpec_ContainerImageRuntime_PropertiesEntry): unknown {
    const obj: any = {};
    if (message.key !== "") {
      obj.key = message.key;
    }
    if (message.value !== "") {
      obj.value = message.value;
    }
    return obj;
  },

  create(
    base?: DeepPartial<Task_InfrastructureSpec_ContainerImageRuntime_PropertiesEntry>,
  ): Task_InfrastructureSpec_ContainerImageRuntime_PropertiesEntry {
    return Task_InfrastructureSpec_ContainerImageRuntime_PropertiesEntry.fromPartial(base ?? {});
  },
  fromPartial(
    object: DeepPartial<Task_InfrastructureSpec_ContainerImageRuntime_PropertiesEntry>,
  ): Task_InfrastructureSpec_ContainerImageRuntime_PropertiesEntry {
    const message = createBaseTask_InfrastructureSpec_ContainerImageRuntime_PropertiesEntry();
    message.key = object.key ?? "";
    message.value = object.value ?? "";
    return message;
  },
};

function createBaseTask_InfrastructureSpec_VpcNetwork(): Task_InfrastructureSpec_VpcNetwork {
  return { network: undefined, subNetwork: undefined, networkTags: [] };
}

export const Task_InfrastructureSpec_VpcNetwork: MessageFns<Task_InfrastructureSpec_VpcNetwork> = {
  encode(message: Task_InfrastructureSpec_VpcNetwork, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.network !== undefined) {
      writer.uint32(10).string(message.network);
    }
    if (message.subNetwork !== undefined) {
      writer.uint32(18).string(message.subNetwork);
    }
    for (const v of message.networkTags) {
      writer.uint32(26).string(v!);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Task_InfrastructureSpec_VpcNetwork {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseTask_InfrastructureSpec_VpcNetwork();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.network = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.subNetwork = reader.string();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.networkTags.push(reader.string());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Task_InfrastructureSpec_VpcNetwork {
    return {
      network: isSet(object.network) ? globalThis.String(object.network) : undefined,
      subNetwork: isSet(object.subNetwork) ? globalThis.String(object.subNetwork) : undefined,
      networkTags: globalThis.Array.isArray(object?.networkTags)
        ? object.networkTags.map((e: any) => globalThis.String(e))
        : [],
    };
  },

  toJSON(message: Task_InfrastructureSpec_VpcNetwork): unknown {
    const obj: any = {};
    if (message.network !== undefined) {
      obj.network = message.network;
    }
    if (message.subNetwork !== undefined) {
      obj.subNetwork = message.subNetwork;
    }
    if (message.networkTags?.length) {
      obj.networkTags = message.networkTags;
    }
    return obj;
  },

  create(base?: DeepPartial<Task_InfrastructureSpec_VpcNetwork>): Task_InfrastructureSpec_VpcNetwork {
    return Task_InfrastructureSpec_VpcNetwork.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<Task_InfrastructureSpec_VpcNetwork>): Task_InfrastructureSpec_VpcNetwork {
    const message = createBaseTask_InfrastructureSpec_VpcNetwork();
    message.network = object.network ?? undefined;
    message.subNetwork = object.subNetwork ?? undefined;
    message.networkTags = object.networkTags?.map((e) => e) || [];
    return message;
  },
};

function createBaseTask_TriggerSpec(): Task_TriggerSpec {
  return { type: 0, startTime: undefined, disabled: false, maxRetries: 0, schedule: undefined };
}

export const Task_TriggerSpec: MessageFns<Task_TriggerSpec> = {
  encode(message: Task_TriggerSpec, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.type !== 0) {
      writer.uint32(40).int32(message.type);
    }
    if (message.startTime !== undefined) {
      Timestamp.encode(toTimestamp(message.startTime), writer.uint32(50).fork()).join();
    }
    if (message.disabled !== false) {
      writer.uint32(32).bool(message.disabled);
    }
    if (message.maxRetries !== 0) {
      writer.uint32(56).int32(message.maxRetries);
    }
    if (message.schedule !== undefined) {
      writer.uint32(802).string(message.schedule);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Task_TriggerSpec {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseTask_TriggerSpec();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 5:
          if (tag !== 40) {
            break;
          }

          message.type = reader.int32() as any;
          continue;
        case 6:
          if (tag !== 50) {
            break;
          }

          message.startTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        case 4:
          if (tag !== 32) {
            break;
          }

          message.disabled = reader.bool();
          continue;
        case 7:
          if (tag !== 56) {
            break;
          }

          message.maxRetries = reader.int32();
          continue;
        case 100:
          if (tag !== 802) {
            break;
          }

          message.schedule = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Task_TriggerSpec {
    return {
      type: isSet(object.type) ? task_TriggerSpec_TypeFromJSON(object.type) : 0,
      startTime: isSet(object.startTime) ? fromJsonTimestamp(object.startTime) : undefined,
      disabled: isSet(object.disabled) ? globalThis.Boolean(object.disabled) : false,
      maxRetries: isSet(object.maxRetries) ? globalThis.Number(object.maxRetries) : 0,
      schedule: isSet(object.schedule) ? globalThis.String(object.schedule) : undefined,
    };
  },

  toJSON(message: Task_TriggerSpec): unknown {
    const obj: any = {};
    if (message.type !== 0) {
      obj.type = task_TriggerSpec_TypeToJSON(message.type);
    }
    if (message.startTime !== undefined) {
      obj.startTime = message.startTime.toISOString();
    }
    if (message.disabled !== false) {
      obj.disabled = message.disabled;
    }
    if (message.maxRetries !== 0) {
      obj.maxRetries = Math.round(message.maxRetries);
    }
    if (message.schedule !== undefined) {
      obj.schedule = message.schedule;
    }
    return obj;
  },

  create(base?: DeepPartial<Task_TriggerSpec>): Task_TriggerSpec {
    return Task_TriggerSpec.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<Task_TriggerSpec>): Task_TriggerSpec {
    const message = createBaseTask_TriggerSpec();
    message.type = object.type ?? 0;
    message.startTime = object.startTime ?? undefined;
    message.disabled = object.disabled ?? false;
    message.maxRetries = object.maxRetries ?? 0;
    message.schedule = object.schedule ?? undefined;
    return message;
  },
};

function createBaseTask_ExecutionSpec(): Task_ExecutionSpec {
  return { args: {}, serviceAccount: "", project: "", maxJobExecutionLifetime: undefined, kmsKey: "" };
}

export const Task_ExecutionSpec: MessageFns<Task_ExecutionSpec> = {
  encode(message: Task_ExecutionSpec, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    Object.entries(message.args).forEach(([key, value]) => {
      Task_ExecutionSpec_ArgsEntry.encode({ key: key as any, value }, writer.uint32(34).fork()).join();
    });
    if (message.serviceAccount !== "") {
      writer.uint32(42).string(message.serviceAccount);
    }
    if (message.project !== "") {
      writer.uint32(58).string(message.project);
    }
    if (message.maxJobExecutionLifetime !== undefined) {
      Duration.encode(message.maxJobExecutionLifetime, writer.uint32(66).fork()).join();
    }
    if (message.kmsKey !== "") {
      writer.uint32(74).string(message.kmsKey);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Task_ExecutionSpec {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseTask_ExecutionSpec();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 4:
          if (tag !== 34) {
            break;
          }

          const entry4 = Task_ExecutionSpec_ArgsEntry.decode(reader, reader.uint32());
          if (entry4.value !== undefined) {
            message.args[entry4.key] = entry4.value;
          }
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.serviceAccount = reader.string();
          continue;
        case 7:
          if (tag !== 58) {
            break;
          }

          message.project = reader.string();
          continue;
        case 8:
          if (tag !== 66) {
            break;
          }

          message.maxJobExecutionLifetime = Duration.decode(reader, reader.uint32());
          continue;
        case 9:
          if (tag !== 74) {
            break;
          }

          message.kmsKey = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Task_ExecutionSpec {
    return {
      args: isObject(object.args)
        ? Object.entries(object.args).reduce<{ [key: string]: string }>((acc, [key, value]) => {
          acc[key] = String(value);
          return acc;
        }, {})
        : {},
      serviceAccount: isSet(object.serviceAccount) ? globalThis.String(object.serviceAccount) : "",
      project: isSet(object.project) ? globalThis.String(object.project) : "",
      maxJobExecutionLifetime: isSet(object.maxJobExecutionLifetime)
        ? Duration.fromJSON(object.maxJobExecutionLifetime)
        : undefined,
      kmsKey: isSet(object.kmsKey) ? globalThis.String(object.kmsKey) : "",
    };
  },

  toJSON(message: Task_ExecutionSpec): unknown {
    const obj: any = {};
    if (message.args) {
      const entries = Object.entries(message.args);
      if (entries.length > 0) {
        obj.args = {};
        entries.forEach(([k, v]) => {
          obj.args[k] = v;
        });
      }
    }
    if (message.serviceAccount !== "") {
      obj.serviceAccount = message.serviceAccount;
    }
    if (message.project !== "") {
      obj.project = message.project;
    }
    if (message.maxJobExecutionLifetime !== undefined) {
      obj.maxJobExecutionLifetime = Duration.toJSON(message.maxJobExecutionLifetime);
    }
    if (message.kmsKey !== "") {
      obj.kmsKey = message.kmsKey;
    }
    return obj;
  },

  create(base?: DeepPartial<Task_ExecutionSpec>): Task_ExecutionSpec {
    return Task_ExecutionSpec.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<Task_ExecutionSpec>): Task_ExecutionSpec {
    const message = createBaseTask_ExecutionSpec();
    message.args = Object.entries(object.args ?? {}).reduce<{ [key: string]: string }>((acc, [key, value]) => {
      if (value !== undefined) {
        acc[key] = globalThis.String(value);
      }
      return acc;
    }, {});
    message.serviceAccount = object.serviceAccount ?? "";
    message.project = object.project ?? "";
    message.maxJobExecutionLifetime =
      (object.maxJobExecutionLifetime !== undefined && object.maxJobExecutionLifetime !== null)
        ? Duration.fromPartial(object.maxJobExecutionLifetime)
        : undefined;
    message.kmsKey = object.kmsKey ?? "";
    return message;
  },
};

function createBaseTask_ExecutionSpec_ArgsEntry(): Task_ExecutionSpec_ArgsEntry {
  return { key: "", value: "" };
}

export const Task_ExecutionSpec_ArgsEntry: MessageFns<Task_ExecutionSpec_ArgsEntry> = {
  encode(message: Task_ExecutionSpec_ArgsEntry, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.key !== "") {
      writer.uint32(10).string(message.key);
    }
    if (message.value !== "") {
      writer.uint32(18).string(message.value);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Task_ExecutionSpec_ArgsEntry {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseTask_ExecutionSpec_ArgsEntry();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.key = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.value = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Task_ExecutionSpec_ArgsEntry {
    return {
      key: isSet(object.key) ? globalThis.String(object.key) : "",
      value: isSet(object.value) ? globalThis.String(object.value) : "",
    };
  },

  toJSON(message: Task_ExecutionSpec_ArgsEntry): unknown {
    const obj: any = {};
    if (message.key !== "") {
      obj.key = message.key;
    }
    if (message.value !== "") {
      obj.value = message.value;
    }
    return obj;
  },

  create(base?: DeepPartial<Task_ExecutionSpec_ArgsEntry>): Task_ExecutionSpec_ArgsEntry {
    return Task_ExecutionSpec_ArgsEntry.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<Task_ExecutionSpec_ArgsEntry>): Task_ExecutionSpec_ArgsEntry {
    const message = createBaseTask_ExecutionSpec_ArgsEntry();
    message.key = object.key ?? "";
    message.value = object.value ?? "";
    return message;
  },
};

function createBaseTask_SparkTaskConfig(): Task_SparkTaskConfig {
  return {
    mainJarFileUri: undefined,
    mainClass: undefined,
    pythonScriptFile: undefined,
    sqlScriptFile: undefined,
    sqlScript: undefined,
    fileUris: [],
    archiveUris: [],
    infrastructureSpec: undefined,
  };
}

export const Task_SparkTaskConfig: MessageFns<Task_SparkTaskConfig> = {
  encode(message: Task_SparkTaskConfig, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.mainJarFileUri !== undefined) {
      writer.uint32(802).string(message.mainJarFileUri);
    }
    if (message.mainClass !== undefined) {
      writer.uint32(810).string(message.mainClass);
    }
    if (message.pythonScriptFile !== undefined) {
      writer.uint32(818).string(message.pythonScriptFile);
    }
    if (message.sqlScriptFile !== undefined) {
      writer.uint32(834).string(message.sqlScriptFile);
    }
    if (message.sqlScript !== undefined) {
      writer.uint32(842).string(message.sqlScript);
    }
    for (const v of message.fileUris) {
      writer.uint32(26).string(v!);
    }
    for (const v of message.archiveUris) {
      writer.uint32(34).string(v!);
    }
    if (message.infrastructureSpec !== undefined) {
      Task_InfrastructureSpec.encode(message.infrastructureSpec, writer.uint32(50).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Task_SparkTaskConfig {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseTask_SparkTaskConfig();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 100:
          if (tag !== 802) {
            break;
          }

          message.mainJarFileUri = reader.string();
          continue;
        case 101:
          if (tag !== 810) {
            break;
          }

          message.mainClass = reader.string();
          continue;
        case 102:
          if (tag !== 818) {
            break;
          }

          message.pythonScriptFile = reader.string();
          continue;
        case 104:
          if (tag !== 834) {
            break;
          }

          message.sqlScriptFile = reader.string();
          continue;
        case 105:
          if (tag !== 842) {
            break;
          }

          message.sqlScript = reader.string();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.fileUris.push(reader.string());
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.archiveUris.push(reader.string());
          continue;
        case 6:
          if (tag !== 50) {
            break;
          }

          message.infrastructureSpec = Task_InfrastructureSpec.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Task_SparkTaskConfig {
    return {
      mainJarFileUri: isSet(object.mainJarFileUri) ? globalThis.String(object.mainJarFileUri) : undefined,
      mainClass: isSet(object.mainClass) ? globalThis.String(object.mainClass) : undefined,
      pythonScriptFile: isSet(object.pythonScriptFile) ? globalThis.String(object.pythonScriptFile) : undefined,
      sqlScriptFile: isSet(object.sqlScriptFile) ? globalThis.String(object.sqlScriptFile) : undefined,
      sqlScript: isSet(object.sqlScript) ? globalThis.String(object.sqlScript) : undefined,
      fileUris: globalThis.Array.isArray(object?.fileUris) ? object.fileUris.map((e: any) => globalThis.String(e)) : [],
      archiveUris: globalThis.Array.isArray(object?.archiveUris)
        ? object.archiveUris.map((e: any) => globalThis.String(e))
        : [],
      infrastructureSpec: isSet(object.infrastructureSpec)
        ? Task_InfrastructureSpec.fromJSON(object.infrastructureSpec)
        : undefined,
    };
  },

  toJSON(message: Task_SparkTaskConfig): unknown {
    const obj: any = {};
    if (message.mainJarFileUri !== undefined) {
      obj.mainJarFileUri = message.mainJarFileUri;
    }
    if (message.mainClass !== undefined) {
      obj.mainClass = message.mainClass;
    }
    if (message.pythonScriptFile !== undefined) {
      obj.pythonScriptFile = message.pythonScriptFile;
    }
    if (message.sqlScriptFile !== undefined) {
      obj.sqlScriptFile = message.sqlScriptFile;
    }
    if (message.sqlScript !== undefined) {
      obj.sqlScript = message.sqlScript;
    }
    if (message.fileUris?.length) {
      obj.fileUris = message.fileUris;
    }
    if (message.archiveUris?.length) {
      obj.archiveUris = message.archiveUris;
    }
    if (message.infrastructureSpec !== undefined) {
      obj.infrastructureSpec = Task_InfrastructureSpec.toJSON(message.infrastructureSpec);
    }
    return obj;
  },

  create(base?: DeepPartial<Task_SparkTaskConfig>): Task_SparkTaskConfig {
    return Task_SparkTaskConfig.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<Task_SparkTaskConfig>): Task_SparkTaskConfig {
    const message = createBaseTask_SparkTaskConfig();
    message.mainJarFileUri = object.mainJarFileUri ?? undefined;
    message.mainClass = object.mainClass ?? undefined;
    message.pythonScriptFile = object.pythonScriptFile ?? undefined;
    message.sqlScriptFile = object.sqlScriptFile ?? undefined;
    message.sqlScript = object.sqlScript ?? undefined;
    message.fileUris = object.fileUris?.map((e) => e) || [];
    message.archiveUris = object.archiveUris?.map((e) => e) || [];
    message.infrastructureSpec = (object.infrastructureSpec !== undefined && object.infrastructureSpec !== null)
      ? Task_InfrastructureSpec.fromPartial(object.infrastructureSpec)
      : undefined;
    return message;
  },
};

function createBaseTask_NotebookTaskConfig(): Task_NotebookTaskConfig {
  return { notebook: "", infrastructureSpec: undefined, fileUris: [], archiveUris: [] };
}

export const Task_NotebookTaskConfig: MessageFns<Task_NotebookTaskConfig> = {
  encode(message: Task_NotebookTaskConfig, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.notebook !== "") {
      writer.uint32(34).string(message.notebook);
    }
    if (message.infrastructureSpec !== undefined) {
      Task_InfrastructureSpec.encode(message.infrastructureSpec, writer.uint32(26).fork()).join();
    }
    for (const v of message.fileUris) {
      writer.uint32(42).string(v!);
    }
    for (const v of message.archiveUris) {
      writer.uint32(50).string(v!);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Task_NotebookTaskConfig {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseTask_NotebookTaskConfig();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 4:
          if (tag !== 34) {
            break;
          }

          message.notebook = reader.string();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.infrastructureSpec = Task_InfrastructureSpec.decode(reader, reader.uint32());
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.fileUris.push(reader.string());
          continue;
        case 6:
          if (tag !== 50) {
            break;
          }

          message.archiveUris.push(reader.string());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Task_NotebookTaskConfig {
    return {
      notebook: isSet(object.notebook) ? globalThis.String(object.notebook) : "",
      infrastructureSpec: isSet(object.infrastructureSpec)
        ? Task_InfrastructureSpec.fromJSON(object.infrastructureSpec)
        : undefined,
      fileUris: globalThis.Array.isArray(object?.fileUris) ? object.fileUris.map((e: any) => globalThis.String(e)) : [],
      archiveUris: globalThis.Array.isArray(object?.archiveUris)
        ? object.archiveUris.map((e: any) => globalThis.String(e))
        : [],
    };
  },

  toJSON(message: Task_NotebookTaskConfig): unknown {
    const obj: any = {};
    if (message.notebook !== "") {
      obj.notebook = message.notebook;
    }
    if (message.infrastructureSpec !== undefined) {
      obj.infrastructureSpec = Task_InfrastructureSpec.toJSON(message.infrastructureSpec);
    }
    if (message.fileUris?.length) {
      obj.fileUris = message.fileUris;
    }
    if (message.archiveUris?.length) {
      obj.archiveUris = message.archiveUris;
    }
    return obj;
  },

  create(base?: DeepPartial<Task_NotebookTaskConfig>): Task_NotebookTaskConfig {
    return Task_NotebookTaskConfig.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<Task_NotebookTaskConfig>): Task_NotebookTaskConfig {
    const message = createBaseTask_NotebookTaskConfig();
    message.notebook = object.notebook ?? "";
    message.infrastructureSpec = (object.infrastructureSpec !== undefined && object.infrastructureSpec !== null)
      ? Task_InfrastructureSpec.fromPartial(object.infrastructureSpec)
      : undefined;
    message.fileUris = object.fileUris?.map((e) => e) || [];
    message.archiveUris = object.archiveUris?.map((e) => e) || [];
    return message;
  },
};

function createBaseTask_ExecutionStatus(): Task_ExecutionStatus {
  return { updateTime: undefined, latestJob: undefined };
}

export const Task_ExecutionStatus: MessageFns<Task_ExecutionStatus> = {
  encode(message: Task_ExecutionStatus, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.updateTime !== undefined) {
      Timestamp.encode(toTimestamp(message.updateTime), writer.uint32(26).fork()).join();
    }
    if (message.latestJob !== undefined) {
      Job.encode(message.latestJob, writer.uint32(74).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Task_ExecutionStatus {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseTask_ExecutionStatus();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 3:
          if (tag !== 26) {
            break;
          }

          message.updateTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        case 9:
          if (tag !== 74) {
            break;
          }

          message.latestJob = Job.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Task_ExecutionStatus {
    return {
      updateTime: isSet(object.updateTime) ? fromJsonTimestamp(object.updateTime) : undefined,
      latestJob: isSet(object.latestJob) ? Job.fromJSON(object.latestJob) : undefined,
    };
  },

  toJSON(message: Task_ExecutionStatus): unknown {
    const obj: any = {};
    if (message.updateTime !== undefined) {
      obj.updateTime = message.updateTime.toISOString();
    }
    if (message.latestJob !== undefined) {
      obj.latestJob = Job.toJSON(message.latestJob);
    }
    return obj;
  },

  create(base?: DeepPartial<Task_ExecutionStatus>): Task_ExecutionStatus {
    return Task_ExecutionStatus.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<Task_ExecutionStatus>): Task_ExecutionStatus {
    const message = createBaseTask_ExecutionStatus();
    message.updateTime = object.updateTime ?? undefined;
    message.latestJob = (object.latestJob !== undefined && object.latestJob !== null)
      ? Job.fromPartial(object.latestJob)
      : undefined;
    return message;
  },
};

function createBaseTask_LabelsEntry(): Task_LabelsEntry {
  return { key: "", value: "" };
}

export const Task_LabelsEntry: MessageFns<Task_LabelsEntry> = {
  encode(message: Task_LabelsEntry, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.key !== "") {
      writer.uint32(10).string(message.key);
    }
    if (message.value !== "") {
      writer.uint32(18).string(message.value);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Task_LabelsEntry {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseTask_LabelsEntry();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.key = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.value = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Task_LabelsEntry {
    return {
      key: isSet(object.key) ? globalThis.String(object.key) : "",
      value: isSet(object.value) ? globalThis.String(object.value) : "",
    };
  },

  toJSON(message: Task_LabelsEntry): unknown {
    const obj: any = {};
    if (message.key !== "") {
      obj.key = message.key;
    }
    if (message.value !== "") {
      obj.value = message.value;
    }
    return obj;
  },

  create(base?: DeepPartial<Task_LabelsEntry>): Task_LabelsEntry {
    return Task_LabelsEntry.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<Task_LabelsEntry>): Task_LabelsEntry {
    const message = createBaseTask_LabelsEntry();
    message.key = object.key ?? "";
    message.value = object.value ?? "";
    return message;
  },
};

function createBaseJob(): Job {
  return {
    name: "",
    uid: "",
    startTime: undefined,
    endTime: undefined,
    state: 0,
    retryCount: 0,
    service: 0,
    serviceJob: "",
    message: "",
    labels: {},
    trigger: 0,
    executionSpec: undefined,
  };
}

export const Job: MessageFns<Job> = {
  encode(message: Job, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    if (message.uid !== "") {
      writer.uint32(18).string(message.uid);
    }
    if (message.startTime !== undefined) {
      Timestamp.encode(toTimestamp(message.startTime), writer.uint32(26).fork()).join();
    }
    if (message.endTime !== undefined) {
      Timestamp.encode(toTimestamp(message.endTime), writer.uint32(34).fork()).join();
    }
    if (message.state !== 0) {
      writer.uint32(40).int32(message.state);
    }
    if (message.retryCount !== 0) {
      writer.uint32(48).uint32(message.retryCount);
    }
    if (message.service !== 0) {
      writer.uint32(56).int32(message.service);
    }
    if (message.serviceJob !== "") {
      writer.uint32(66).string(message.serviceJob);
    }
    if (message.message !== "") {
      writer.uint32(74).string(message.message);
    }
    Object.entries(message.labels).forEach(([key, value]) => {
      Job_LabelsEntry.encode({ key: key as any, value }, writer.uint32(82).fork()).join();
    });
    if (message.trigger !== 0) {
      writer.uint32(88).int32(message.trigger);
    }
    if (message.executionSpec !== undefined) {
      Task_ExecutionSpec.encode(message.executionSpec, writer.uint32(802).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Job {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseJob();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.uid = reader.string();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.startTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.endTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        case 5:
          if (tag !== 40) {
            break;
          }

          message.state = reader.int32() as any;
          continue;
        case 6:
          if (tag !== 48) {
            break;
          }

          message.retryCount = reader.uint32();
          continue;
        case 7:
          if (tag !== 56) {
            break;
          }

          message.service = reader.int32() as any;
          continue;
        case 8:
          if (tag !== 66) {
            break;
          }

          message.serviceJob = reader.string();
          continue;
        case 9:
          if (tag !== 74) {
            break;
          }

          message.message = reader.string();
          continue;
        case 10:
          if (tag !== 82) {
            break;
          }

          const entry10 = Job_LabelsEntry.decode(reader, reader.uint32());
          if (entry10.value !== undefined) {
            message.labels[entry10.key] = entry10.value;
          }
          continue;
        case 11:
          if (tag !== 88) {
            break;
          }

          message.trigger = reader.int32() as any;
          continue;
        case 100:
          if (tag !== 802) {
            break;
          }

          message.executionSpec = Task_ExecutionSpec.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Job {
    return {
      name: isSet(object.name) ? globalThis.String(object.name) : "",
      uid: isSet(object.uid) ? globalThis.String(object.uid) : "",
      startTime: isSet(object.startTime) ? fromJsonTimestamp(object.startTime) : undefined,
      endTime: isSet(object.endTime) ? fromJsonTimestamp(object.endTime) : undefined,
      state: isSet(object.state) ? job_StateFromJSON(object.state) : 0,
      retryCount: isSet(object.retryCount) ? globalThis.Number(object.retryCount) : 0,
      service: isSet(object.service) ? job_ServiceFromJSON(object.service) : 0,
      serviceJob: isSet(object.serviceJob) ? globalThis.String(object.serviceJob) : "",
      message: isSet(object.message) ? globalThis.String(object.message) : "",
      labels: isObject(object.labels)
        ? Object.entries(object.labels).reduce<{ [key: string]: string }>((acc, [key, value]) => {
          acc[key] = String(value);
          return acc;
        }, {})
        : {},
      trigger: isSet(object.trigger) ? job_TriggerFromJSON(object.trigger) : 0,
      executionSpec: isSet(object.executionSpec) ? Task_ExecutionSpec.fromJSON(object.executionSpec) : undefined,
    };
  },

  toJSON(message: Job): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    if (message.uid !== "") {
      obj.uid = message.uid;
    }
    if (message.startTime !== undefined) {
      obj.startTime = message.startTime.toISOString();
    }
    if (message.endTime !== undefined) {
      obj.endTime = message.endTime.toISOString();
    }
    if (message.state !== 0) {
      obj.state = job_StateToJSON(message.state);
    }
    if (message.retryCount !== 0) {
      obj.retryCount = Math.round(message.retryCount);
    }
    if (message.service !== 0) {
      obj.service = job_ServiceToJSON(message.service);
    }
    if (message.serviceJob !== "") {
      obj.serviceJob = message.serviceJob;
    }
    if (message.message !== "") {
      obj.message = message.message;
    }
    if (message.labels) {
      const entries = Object.entries(message.labels);
      if (entries.length > 0) {
        obj.labels = {};
        entries.forEach(([k, v]) => {
          obj.labels[k] = v;
        });
      }
    }
    if (message.trigger !== 0) {
      obj.trigger = job_TriggerToJSON(message.trigger);
    }
    if (message.executionSpec !== undefined) {
      obj.executionSpec = Task_ExecutionSpec.toJSON(message.executionSpec);
    }
    return obj;
  },

  create(base?: DeepPartial<Job>): Job {
    return Job.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<Job>): Job {
    const message = createBaseJob();
    message.name = object.name ?? "";
    message.uid = object.uid ?? "";
    message.startTime = object.startTime ?? undefined;
    message.endTime = object.endTime ?? undefined;
    message.state = object.state ?? 0;
    message.retryCount = object.retryCount ?? 0;
    message.service = object.service ?? 0;
    message.serviceJob = object.serviceJob ?? "";
    message.message = object.message ?? "";
    message.labels = Object.entries(object.labels ?? {}).reduce<{ [key: string]: string }>((acc, [key, value]) => {
      if (value !== undefined) {
        acc[key] = globalThis.String(value);
      }
      return acc;
    }, {});
    message.trigger = object.trigger ?? 0;
    message.executionSpec = (object.executionSpec !== undefined && object.executionSpec !== null)
      ? Task_ExecutionSpec.fromPartial(object.executionSpec)
      : undefined;
    return message;
  },
};

function createBaseJob_LabelsEntry(): Job_LabelsEntry {
  return { key: "", value: "" };
}

export const Job_LabelsEntry: MessageFns<Job_LabelsEntry> = {
  encode(message: Job_LabelsEntry, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.key !== "") {
      writer.uint32(10).string(message.key);
    }
    if (message.value !== "") {
      writer.uint32(18).string(message.value);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Job_LabelsEntry {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseJob_LabelsEntry();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.key = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.value = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Job_LabelsEntry {
    return {
      key: isSet(object.key) ? globalThis.String(object.key) : "",
      value: isSet(object.value) ? globalThis.String(object.value) : "",
    };
  },

  toJSON(message: Job_LabelsEntry): unknown {
    const obj: any = {};
    if (message.key !== "") {
      obj.key = message.key;
    }
    if (message.value !== "") {
      obj.value = message.value;
    }
    return obj;
  },

  create(base?: DeepPartial<Job_LabelsEntry>): Job_LabelsEntry {
    return Job_LabelsEntry.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<Job_LabelsEntry>): Job_LabelsEntry {
    const message = createBaseJob_LabelsEntry();
    message.key = object.key ?? "";
    message.value = object.value ?? "";
    return message;
  },
};

type Builtin = Date | Function | Uint8Array | string | number | boolean | undefined;

export type DeepPartial<T> = T extends Builtin ? T
  : T extends Long ? string | number | Long : T extends globalThis.Array<infer U> ? globalThis.Array<DeepPartial<U>>
  : T extends ReadonlyArray<infer U> ? ReadonlyArray<DeepPartial<U>>
  : T extends {} ? { [K in keyof T]?: DeepPartial<T[K]> }
  : Partial<T>;

function toTimestamp(date: Date): Timestamp {
  const seconds = numberToLong(Math.trunc(date.getTime() / 1_000));
  const nanos = (date.getTime() % 1_000) * 1_000_000;
  return { seconds, nanos };
}

function fromTimestamp(t: Timestamp): Date {
  let millis = (t.seconds.toNumber() || 0) * 1_000;
  millis += (t.nanos || 0) / 1_000_000;
  return new globalThis.Date(millis);
}

function fromJsonTimestamp(o: any): Date {
  if (o instanceof globalThis.Date) {
    return o;
  } else if (typeof o === "string") {
    return new globalThis.Date(o);
  } else {
    return fromTimestamp(Timestamp.fromJSON(o));
  }
}

function numberToLong(number: number) {
  return Long.fromNumber(number);
}

function isObject(value: any): boolean {
  return typeof value === "object" && value !== null;
}

function isSet(value: any): boolean {
  return value !== null && value !== undefined;
}

export interface MessageFns<T> {
  encode(message: T, writer?: BinaryWriter): BinaryWriter;
  decode(input: BinaryReader | Uint8Array, length?: number): T;
  fromJSON(object: any): T;
  toJSON(message: T): unknown;
  create(base?: DeepPartial<T>): T;
  fromPartial(object: DeepPartial<T>): T;
}
