// Code generated by protoc-gen-ts_proto. DO NOT EDIT.
// versions:
//   protoc-gen-ts_proto  v2.2.0
//   protoc               unknown
// source: google/cloud/dataplex/v1/resources.proto

/* eslint-disable */
import { BinaryReader, BinaryWriter } from "@bufbuild/protobuf/wire";
import Long from "long";
import { Duration } from "../../../protobuf/duration.js";
import { Timestamp } from "../../../protobuf/timestamp.js";

export const protobufPackage = "google.cloud.dataplex.v1";

/** State of a resource. */
export enum State {
  /** STATE_UNSPECIFIED - State is not specified. */
  STATE_UNSPECIFIED = 0,
  /** ACTIVE - Resource is active, i.e., ready to use. */
  ACTIVE = 1,
  /** CREATING - Resource is under creation. */
  CREATING = 2,
  /** DELETING - Resource is under deletion. */
  DELETING = 3,
  /** ACTION_REQUIRED - Resource is active but has unresolved actions. */
  ACTION_REQUIRED = 4,
  UNRECOGNIZED = -1,
}

export function stateFromJSON(object: any): State {
  switch (object) {
    case 0:
    case "STATE_UNSPECIFIED":
      return State.STATE_UNSPECIFIED;
    case 1:
    case "ACTIVE":
      return State.ACTIVE;
    case 2:
    case "CREATING":
      return State.CREATING;
    case 3:
    case "DELETING":
      return State.DELETING;
    case 4:
    case "ACTION_REQUIRED":
      return State.ACTION_REQUIRED;
    case -1:
    case "UNRECOGNIZED":
    default:
      return State.UNRECOGNIZED;
  }
}

export function stateToJSON(object: State): string {
  switch (object) {
    case State.STATE_UNSPECIFIED:
      return "STATE_UNSPECIFIED";
    case State.ACTIVE:
      return "ACTIVE";
    case State.CREATING:
      return "CREATING";
    case State.DELETING:
      return "DELETING";
    case State.ACTION_REQUIRED:
      return "ACTION_REQUIRED";
    case State.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/**
 * A lake is a centralized repository for managing enterprise data across the
 * organization distributed across many cloud projects, and stored in a variety
 * of storage services such as Google Cloud Storage and BigQuery. The resources
 * attached to a lake are referred to as managed resources. Data within these
 * managed resources can be structured or unstructured. A lake provides data
 * admins with tools to organize, secure and manage their data at scale, and
 * provides data scientists and data engineers an integrated experience to
 * easily search, discover, analyze and transform data and associated metadata.
 */
export interface Lake {
  /**
   * Output only. The relative resource name of the lake, of the form:
   * `projects/{project_number}/locations/{location_id}/lakes/{lake_id}`.
   */
  name: string;
  /** Optional. User friendly display name. */
  displayName: string;
  /**
   * Output only. System generated globally unique ID for the lake. This ID will
   * be different if the lake is deleted and re-created with the same name.
   */
  uid: string;
  /** Output only. The time when the lake was created. */
  createTime:
    | Date
    | undefined;
  /** Output only. The time when the lake was last updated. */
  updateTime:
    | Date
    | undefined;
  /** Optional. User-defined labels for the lake. */
  labels: { [key: string]: string };
  /** Optional. Description of the lake. */
  description: string;
  /** Output only. Current state of the lake. */
  state: State;
  /**
   * Output only. Service account associated with this lake. This service
   * account must be authorized to access or operate on resources managed by the
   * lake.
   */
  serviceAccount: string;
  /**
   * Optional. Settings to manage lake and Dataproc Metastore service instance
   * association.
   */
  metastore:
    | Lake_Metastore
    | undefined;
  /** Output only. Aggregated status of the underlying assets of the lake. */
  assetStatus:
    | AssetStatus
    | undefined;
  /** Output only. Metastore status of the lake. */
  metastoreStatus: Lake_MetastoreStatus | undefined;
}

/** Settings to manage association of Dataproc Metastore with a lake. */
export interface Lake_Metastore {
  /**
   * Optional. A relative reference to the Dataproc Metastore
   * (https://cloud.google.com/dataproc-metastore/docs) service associated
   * with the lake:
   * `projects/{project_id}/locations/{location_id}/services/{service_id}`
   */
  service: string;
}

/** Status of Lake and Dataproc Metastore service instance association. */
export interface Lake_MetastoreStatus {
  /** Current state of association. */
  state: Lake_MetastoreStatus_State;
  /** Additional information about the current status. */
  message: string;
  /** Last update time of the metastore status of the lake. */
  updateTime:
    | Date
    | undefined;
  /** The URI of the endpoint used to access the Metastore service. */
  endpoint: string;
}

/** Current state of association. */
export enum Lake_MetastoreStatus_State {
  /** STATE_UNSPECIFIED - Unspecified. */
  STATE_UNSPECIFIED = 0,
  /** NONE - A Metastore service instance is not associated with the lake. */
  NONE = 1,
  /** READY - A Metastore service instance is attached to the lake. */
  READY = 2,
  /** UPDATING - Attach/detach is in progress. */
  UPDATING = 3,
  /** ERROR - Attach/detach could not be done due to errors. */
  ERROR = 4,
  UNRECOGNIZED = -1,
}

export function lake_MetastoreStatus_StateFromJSON(object: any): Lake_MetastoreStatus_State {
  switch (object) {
    case 0:
    case "STATE_UNSPECIFIED":
      return Lake_MetastoreStatus_State.STATE_UNSPECIFIED;
    case 1:
    case "NONE":
      return Lake_MetastoreStatus_State.NONE;
    case 2:
    case "READY":
      return Lake_MetastoreStatus_State.READY;
    case 3:
    case "UPDATING":
      return Lake_MetastoreStatus_State.UPDATING;
    case 4:
    case "ERROR":
      return Lake_MetastoreStatus_State.ERROR;
    case -1:
    case "UNRECOGNIZED":
    default:
      return Lake_MetastoreStatus_State.UNRECOGNIZED;
  }
}

export function lake_MetastoreStatus_StateToJSON(object: Lake_MetastoreStatus_State): string {
  switch (object) {
    case Lake_MetastoreStatus_State.STATE_UNSPECIFIED:
      return "STATE_UNSPECIFIED";
    case Lake_MetastoreStatus_State.NONE:
      return "NONE";
    case Lake_MetastoreStatus_State.READY:
      return "READY";
    case Lake_MetastoreStatus_State.UPDATING:
      return "UPDATING";
    case Lake_MetastoreStatus_State.ERROR:
      return "ERROR";
    case Lake_MetastoreStatus_State.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

export interface Lake_LabelsEntry {
  key: string;
  value: string;
}

/** Aggregated status of the underlying assets of a lake or zone. */
export interface AssetStatus {
  /** Last update time of the status. */
  updateTime:
    | Date
    | undefined;
  /** Number of active assets. */
  activeAssets: number;
  /**
   * Number of assets that are in process of updating the security policy on
   * attached resources.
   */
  securityPolicyApplyingAssets: number;
}

/**
 * A zone represents a logical group of related assets within a lake. A zone can
 * be used to map to organizational structure or represent stages of data
 * readiness from raw to curated. It provides managing behavior that is shared
 * or inherited by all contained assets.
 */
export interface Zone {
  /**
   * Output only. The relative resource name of the zone, of the form:
   * `projects/{project_number}/locations/{location_id}/lakes/{lake_id}/zones/{zone_id}`.
   */
  name: string;
  /** Optional. User friendly display name. */
  displayName: string;
  /**
   * Output only. System generated globally unique ID for the zone. This ID will
   * be different if the zone is deleted and re-created with the same name.
   */
  uid: string;
  /** Output only. The time when the zone was created. */
  createTime:
    | Date
    | undefined;
  /** Output only. The time when the zone was last updated. */
  updateTime:
    | Date
    | undefined;
  /** Optional. User defined labels for the zone. */
  labels: { [key: string]: string };
  /** Optional. Description of the zone. */
  description: string;
  /** Output only. Current state of the zone. */
  state: State;
  /** Required. Immutable. The type of the zone. */
  type: Zone_Type;
  /**
   * Optional. Specification of the discovery feature applied to data in this
   * zone.
   */
  discoverySpec:
    | Zone_DiscoverySpec
    | undefined;
  /**
   * Required. Specification of the resources that are referenced by the assets
   * within this zone.
   */
  resourceSpec:
    | Zone_ResourceSpec
    | undefined;
  /** Output only. Aggregated status of the underlying assets of the zone. */
  assetStatus: AssetStatus | undefined;
}

/** Type of zone. */
export enum Zone_Type {
  /** TYPE_UNSPECIFIED - Zone type not specified. */
  TYPE_UNSPECIFIED = 0,
  /**
   * RAW - A zone that contains data that needs further processing before it is
   * considered generally ready for consumption and analytics workloads.
   */
  RAW = 1,
  /**
   * CURATED - A zone that contains data that is considered to be ready for broader
   * consumption and analytics workloads. Curated structured data stored in
   * Cloud Storage must conform to certain file formats (parquet, avro and
   * orc) and organized in a hive-compatible directory layout.
   */
  CURATED = 2,
  UNRECOGNIZED = -1,
}

export function zone_TypeFromJSON(object: any): Zone_Type {
  switch (object) {
    case 0:
    case "TYPE_UNSPECIFIED":
      return Zone_Type.TYPE_UNSPECIFIED;
    case 1:
    case "RAW":
      return Zone_Type.RAW;
    case 2:
    case "CURATED":
      return Zone_Type.CURATED;
    case -1:
    case "UNRECOGNIZED":
    default:
      return Zone_Type.UNRECOGNIZED;
  }
}

export function zone_TypeToJSON(object: Zone_Type): string {
  switch (object) {
    case Zone_Type.TYPE_UNSPECIFIED:
      return "TYPE_UNSPECIFIED";
    case Zone_Type.RAW:
      return "RAW";
    case Zone_Type.CURATED:
      return "CURATED";
    case Zone_Type.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/** Settings for resources attached as assets within a zone. */
export interface Zone_ResourceSpec {
  /**
   * Required. Immutable. The location type of the resources that are allowed
   * to be attached to the assets within this zone.
   */
  locationType: Zone_ResourceSpec_LocationType;
}

/** Location type of the resources attached to a zone. */
export enum Zone_ResourceSpec_LocationType {
  /** LOCATION_TYPE_UNSPECIFIED - Unspecified location type. */
  LOCATION_TYPE_UNSPECIFIED = 0,
  /** SINGLE_REGION - Resources that are associated with a single region. */
  SINGLE_REGION = 1,
  /** MULTI_REGION - Resources that are associated with a multi-region location. */
  MULTI_REGION = 2,
  UNRECOGNIZED = -1,
}

export function zone_ResourceSpec_LocationTypeFromJSON(object: any): Zone_ResourceSpec_LocationType {
  switch (object) {
    case 0:
    case "LOCATION_TYPE_UNSPECIFIED":
      return Zone_ResourceSpec_LocationType.LOCATION_TYPE_UNSPECIFIED;
    case 1:
    case "SINGLE_REGION":
      return Zone_ResourceSpec_LocationType.SINGLE_REGION;
    case 2:
    case "MULTI_REGION":
      return Zone_ResourceSpec_LocationType.MULTI_REGION;
    case -1:
    case "UNRECOGNIZED":
    default:
      return Zone_ResourceSpec_LocationType.UNRECOGNIZED;
  }
}

export function zone_ResourceSpec_LocationTypeToJSON(object: Zone_ResourceSpec_LocationType): string {
  switch (object) {
    case Zone_ResourceSpec_LocationType.LOCATION_TYPE_UNSPECIFIED:
      return "LOCATION_TYPE_UNSPECIFIED";
    case Zone_ResourceSpec_LocationType.SINGLE_REGION:
      return "SINGLE_REGION";
    case Zone_ResourceSpec_LocationType.MULTI_REGION:
      return "MULTI_REGION";
    case Zone_ResourceSpec_LocationType.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/** Settings to manage the metadata discovery and publishing in a zone. */
export interface Zone_DiscoverySpec {
  /** Required. Whether discovery is enabled. */
  enabled: boolean;
  /**
   * Optional. The list of patterns to apply for selecting data to include
   * during discovery if only a subset of the data should considered. For
   * Cloud Storage bucket assets, these are interpreted as glob patterns used
   * to match object names. For BigQuery dataset assets, these are interpreted
   * as patterns to match table names.
   */
  includePatterns: string[];
  /**
   * Optional. The list of patterns to apply for selecting data to exclude
   * during discovery.  For Cloud Storage bucket assets, these are interpreted
   * as glob patterns used to match object names. For BigQuery dataset assets,
   * these are interpreted as patterns to match table names.
   */
  excludePatterns: string[];
  /** Optional. Configuration for CSV data. */
  csvOptions:
    | Zone_DiscoverySpec_CsvOptions
    | undefined;
  /** Optional. Configuration for Json data. */
  jsonOptions:
    | Zone_DiscoverySpec_JsonOptions
    | undefined;
  /**
   * Optional. Cron schedule (https://en.wikipedia.org/wiki/Cron) for
   * running discovery periodically. Successive discovery runs must be
   * scheduled at least 60 minutes apart. The default value is to run
   * discovery every 60 minutes. To explicitly set a timezone to the cron
   * tab, apply a prefix in the cron tab: "CRON_TZ=${IANA_TIME_ZONE}" or
   * TZ=${IANA_TIME_ZONE}". The ${IANA_TIME_ZONE} may only be a valid string
   * from IANA time zone database. For example, `CRON_TZ=America/New_York 1
   * * * * *`, or `TZ=America/New_York 1 * * * *`.
   */
  schedule?: string | undefined;
}

/** Describe CSV and similar semi-structured data formats. */
export interface Zone_DiscoverySpec_CsvOptions {
  /**
   * Optional. The number of rows to interpret as header rows that should be
   * skipped when reading data rows.
   */
  headerRows: number;
  /**
   * Optional. The delimiter being used to separate values. This defaults to
   * ','.
   */
  delimiter: string;
  /** Optional. The character encoding of the data. The default is UTF-8. */
  encoding: string;
  /**
   * Optional. Whether to disable the inference of data type for CSV data.
   * If true, all columns will be registered as strings.
   */
  disableTypeInference: boolean;
}

/** Describe JSON data format. */
export interface Zone_DiscoverySpec_JsonOptions {
  /** Optional. The character encoding of the data. The default is UTF-8. */
  encoding: string;
  /**
   * Optional. Whether to disable the inference of data type for Json data.
   * If true, all columns will be registered as their primitive types
   * (strings, number or boolean).
   */
  disableTypeInference: boolean;
}

export interface Zone_LabelsEntry {
  key: string;
  value: string;
}

/** Action represents an issue requiring administrator action for resolution. */
export interface Action {
  /** The category of issue associated with the action. */
  category: Action_Category;
  /** Detailed description of the issue requiring action. */
  issue: string;
  /** The time that the issue was detected. */
  detectTime:
    | Date
    | undefined;
  /**
   * Output only. The relative resource name of the action, of the form:
   * `projects/{project}/locations/{location}/lakes/{lake}/actions/{action}`
   * `projects/{project}/locations/{location}/lakes/{lake}/zones/{zone}/actions/{action}`
   * `projects/{project}/locations/{location}/lakes/{lake}/zones/{zone}/assets/{asset}/actions/{action}`.
   */
  name: string;
  /**
   * Output only. The relative resource name of the lake, of the form:
   * `projects/{project_number}/locations/{location_id}/lakes/{lake_id}`.
   */
  lake: string;
  /**
   * Output only. The relative resource name of the zone, of the form:
   * `projects/{project_number}/locations/{location_id}/lakes/{lake_id}/zones/{zone_id}`.
   */
  zone: string;
  /**
   * Output only. The relative resource name of the asset, of the form:
   * `projects/{project_number}/locations/{location_id}/lakes/{lake_id}/zones/{zone_id}/assets/{asset_id}`.
   */
  asset: string;
  /**
   * The list of data locations associated with this action. Cloud Storage
   * locations are represented as URI paths(E.g.
   * `gs://bucket/table1/year=2020/month=Jan/`). BigQuery locations refer to
   * resource names(E.g.
   * `bigquery.googleapis.com/projects/project-id/datasets/dataset-id`).
   */
  dataLocations: string[];
  /** Details for issues related to invalid or unsupported data formats. */
  invalidDataFormat?:
    | Action_InvalidDataFormat
    | undefined;
  /** Details for issues related to incompatible schemas detected within data. */
  incompatibleDataSchema?:
    | Action_IncompatibleDataSchema
    | undefined;
  /**
   * Details for issues related to invalid or unsupported data partition
   * structure.
   */
  invalidDataPartition?:
    | Action_InvalidDataPartition
    | undefined;
  /** Details for issues related to absence of data within managed resources. */
  missingData?:
    | Action_MissingData
    | undefined;
  /** Details for issues related to absence of a managed resource. */
  missingResource?:
    | Action_MissingResource
    | undefined;
  /**
   * Details for issues related to lack of permissions to access data
   * resources.
   */
  unauthorizedResource?:
    | Action_UnauthorizedResource
    | undefined;
  /** Details for issues related to applying security policy. */
  failedSecurityPolicyApply?:
    | Action_FailedSecurityPolicyApply
    | undefined;
  /** Details for issues related to invalid data arrangement. */
  invalidDataOrganization?: Action_InvalidDataOrganization | undefined;
}

/** The category of issues. */
export enum Action_Category {
  /** CATEGORY_UNSPECIFIED - Unspecified category. */
  CATEGORY_UNSPECIFIED = 0,
  /** RESOURCE_MANAGEMENT - Resource management related issues. */
  RESOURCE_MANAGEMENT = 1,
  /** SECURITY_POLICY - Security policy related issues. */
  SECURITY_POLICY = 2,
  /** DATA_DISCOVERY - Data and discovery related issues. */
  DATA_DISCOVERY = 3,
  UNRECOGNIZED = -1,
}

export function action_CategoryFromJSON(object: any): Action_Category {
  switch (object) {
    case 0:
    case "CATEGORY_UNSPECIFIED":
      return Action_Category.CATEGORY_UNSPECIFIED;
    case 1:
    case "RESOURCE_MANAGEMENT":
      return Action_Category.RESOURCE_MANAGEMENT;
    case 2:
    case "SECURITY_POLICY":
      return Action_Category.SECURITY_POLICY;
    case 3:
    case "DATA_DISCOVERY":
      return Action_Category.DATA_DISCOVERY;
    case -1:
    case "UNRECOGNIZED":
    default:
      return Action_Category.UNRECOGNIZED;
  }
}

export function action_CategoryToJSON(object: Action_Category): string {
  switch (object) {
    case Action_Category.CATEGORY_UNSPECIFIED:
      return "CATEGORY_UNSPECIFIED";
    case Action_Category.RESOURCE_MANAGEMENT:
      return "RESOURCE_MANAGEMENT";
    case Action_Category.SECURITY_POLICY:
      return "SECURITY_POLICY";
    case Action_Category.DATA_DISCOVERY:
      return "DATA_DISCOVERY";
    case Action_Category.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/** Action details for resource references in assets that cannot be located. */
export interface Action_MissingResource {
}

/**
 * Action details for unauthorized resource issues raised to indicate that the
 * service account associated with the lake instance is not authorized to
 * access or manage the resource associated with an asset.
 */
export interface Action_UnauthorizedResource {
}

/**
 * Failed to apply security policy to the managed resource(s) under a
 * lake, zone or an asset. For a lake or zone resource, one or more underlying
 * assets has a failure applying security policy to the associated managed
 * resource.
 */
export interface Action_FailedSecurityPolicyApply {
  /**
   * Resource name of one of the assets with failing security policy
   * application. Populated for a lake or zone resource only.
   */
  asset: string;
}

/** Action details for invalid or unsupported data files detected by discovery. */
export interface Action_InvalidDataFormat {
  /**
   * The list of data locations sampled and used for format/schema
   * inference.
   */
  sampledDataLocations: string[];
  /** The expected data format of the entity. */
  expectedFormat: string;
  /** The new unexpected data format within the entity. */
  newFormat: string;
}

/** Action details for incompatible schemas detected by discovery. */
export interface Action_IncompatibleDataSchema {
  /** The name of the table containing invalid data. */
  table: string;
  /**
   * The existing and expected schema of the table. The schema is provided as
   * a JSON formatted structure listing columns and data types.
   */
  existingSchema: string;
  /**
   * The new and incompatible schema within the table. The schema is provided
   * as a JSON formatted structured listing columns and data types.
   */
  newSchema: string;
  /**
   * The list of data locations sampled and used for format/schema
   * inference.
   */
  sampledDataLocations: string[];
  /** Whether the action relates to a schema that is incompatible or modified. */
  schemaChange: Action_IncompatibleDataSchema_SchemaChange;
}

/** Whether the action relates to a schema that is incompatible or modified. */
export enum Action_IncompatibleDataSchema_SchemaChange {
  /** SCHEMA_CHANGE_UNSPECIFIED - Schema change unspecified. */
  SCHEMA_CHANGE_UNSPECIFIED = 0,
  /** INCOMPATIBLE - Newly discovered schema is incompatible with existing schema. */
  INCOMPATIBLE = 1,
  /**
   * MODIFIED - Newly discovered schema has changed from existing schema for data in a
   * curated zone.
   */
  MODIFIED = 2,
  UNRECOGNIZED = -1,
}

export function action_IncompatibleDataSchema_SchemaChangeFromJSON(
  object: any,
): Action_IncompatibleDataSchema_SchemaChange {
  switch (object) {
    case 0:
    case "SCHEMA_CHANGE_UNSPECIFIED":
      return Action_IncompatibleDataSchema_SchemaChange.SCHEMA_CHANGE_UNSPECIFIED;
    case 1:
    case "INCOMPATIBLE":
      return Action_IncompatibleDataSchema_SchemaChange.INCOMPATIBLE;
    case 2:
    case "MODIFIED":
      return Action_IncompatibleDataSchema_SchemaChange.MODIFIED;
    case -1:
    case "UNRECOGNIZED":
    default:
      return Action_IncompatibleDataSchema_SchemaChange.UNRECOGNIZED;
  }
}

export function action_IncompatibleDataSchema_SchemaChangeToJSON(
  object: Action_IncompatibleDataSchema_SchemaChange,
): string {
  switch (object) {
    case Action_IncompatibleDataSchema_SchemaChange.SCHEMA_CHANGE_UNSPECIFIED:
      return "SCHEMA_CHANGE_UNSPECIFIED";
    case Action_IncompatibleDataSchema_SchemaChange.INCOMPATIBLE:
      return "INCOMPATIBLE";
    case Action_IncompatibleDataSchema_SchemaChange.MODIFIED:
      return "MODIFIED";
    case Action_IncompatibleDataSchema_SchemaChange.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/** Action details for invalid or unsupported partitions detected by discovery. */
export interface Action_InvalidDataPartition {
  /** The issue type of InvalidDataPartition. */
  expectedStructure: Action_InvalidDataPartition_PartitionStructure;
}

/** The expected partition structure. */
export enum Action_InvalidDataPartition_PartitionStructure {
  /** PARTITION_STRUCTURE_UNSPECIFIED - PartitionStructure unspecified. */
  PARTITION_STRUCTURE_UNSPECIFIED = 0,
  /** CONSISTENT_KEYS - Consistent hive-style partition definition (both raw and curated zone). */
  CONSISTENT_KEYS = 1,
  /** HIVE_STYLE_KEYS - Hive style partition definition (curated zone only). */
  HIVE_STYLE_KEYS = 2,
  UNRECOGNIZED = -1,
}

export function action_InvalidDataPartition_PartitionStructureFromJSON(
  object: any,
): Action_InvalidDataPartition_PartitionStructure {
  switch (object) {
    case 0:
    case "PARTITION_STRUCTURE_UNSPECIFIED":
      return Action_InvalidDataPartition_PartitionStructure.PARTITION_STRUCTURE_UNSPECIFIED;
    case 1:
    case "CONSISTENT_KEYS":
      return Action_InvalidDataPartition_PartitionStructure.CONSISTENT_KEYS;
    case 2:
    case "HIVE_STYLE_KEYS":
      return Action_InvalidDataPartition_PartitionStructure.HIVE_STYLE_KEYS;
    case -1:
    case "UNRECOGNIZED":
    default:
      return Action_InvalidDataPartition_PartitionStructure.UNRECOGNIZED;
  }
}

export function action_InvalidDataPartition_PartitionStructureToJSON(
  object: Action_InvalidDataPartition_PartitionStructure,
): string {
  switch (object) {
    case Action_InvalidDataPartition_PartitionStructure.PARTITION_STRUCTURE_UNSPECIFIED:
      return "PARTITION_STRUCTURE_UNSPECIFIED";
    case Action_InvalidDataPartition_PartitionStructure.CONSISTENT_KEYS:
      return "CONSISTENT_KEYS";
    case Action_InvalidDataPartition_PartitionStructure.HIVE_STYLE_KEYS:
      return "HIVE_STYLE_KEYS";
    case Action_InvalidDataPartition_PartitionStructure.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/** Action details for absence of data detected by discovery. */
export interface Action_MissingData {
}

/** Action details for invalid data arrangement. */
export interface Action_InvalidDataOrganization {
}

/**
 * An asset represents a cloud resource that is being managed within a lake as a
 * member of a zone.
 */
export interface Asset {
  /**
   * Output only. The relative resource name of the asset, of the form:
   * `projects/{project_number}/locations/{location_id}/lakes/{lake_id}/zones/{zone_id}/assets/{asset_id}`.
   */
  name: string;
  /** Optional. User friendly display name. */
  displayName: string;
  /**
   * Output only. System generated globally unique ID for the asset. This ID
   * will be different if the asset is deleted and re-created with the same
   * name.
   */
  uid: string;
  /** Output only. The time when the asset was created. */
  createTime:
    | Date
    | undefined;
  /** Output only. The time when the asset was last updated. */
  updateTime:
    | Date
    | undefined;
  /** Optional. User defined labels for the asset. */
  labels: { [key: string]: string };
  /** Optional. Description of the asset. */
  description: string;
  /** Output only. Current state of the asset. */
  state: State;
  /** Required. Specification of the resource that is referenced by this asset. */
  resourceSpec:
    | Asset_ResourceSpec
    | undefined;
  /** Output only. Status of the resource referenced by this asset. */
  resourceStatus:
    | Asset_ResourceStatus
    | undefined;
  /**
   * Output only. Status of the security policy applied to resource referenced
   * by this asset.
   */
  securityStatus:
    | Asset_SecurityStatus
    | undefined;
  /**
   * Optional. Specification of the discovery feature applied to data referenced
   * by this asset. When this spec is left unset, the asset will use the spec
   * set on the parent zone.
   */
  discoverySpec:
    | Asset_DiscoverySpec
    | undefined;
  /**
   * Output only. Status of the discovery feature applied to data referenced by
   * this asset.
   */
  discoveryStatus: Asset_DiscoveryStatus | undefined;
}

/**
 * Security policy status of the asset. Data security policy, i.e., readers,
 * writers & owners, should be specified in the lake/zone/asset IAM policy.
 */
export interface Asset_SecurityStatus {
  /**
   * The current state of the security policy applied to the attached
   * resource.
   */
  state: Asset_SecurityStatus_State;
  /** Additional information about the current state. */
  message: string;
  /** Last update time of the status. */
  updateTime: Date | undefined;
}

/** The state of the security policy. */
export enum Asset_SecurityStatus_State {
  /** STATE_UNSPECIFIED - State unspecified. */
  STATE_UNSPECIFIED = 0,
  /** READY - Security policy has been successfully applied to the attached resource. */
  READY = 1,
  /**
   * APPLYING - Security policy is in the process of being applied to the attached
   * resource.
   */
  APPLYING = 2,
  /**
   * ERROR - Security policy could not be applied to the attached resource due to
   * errors.
   */
  ERROR = 3,
  UNRECOGNIZED = -1,
}

export function asset_SecurityStatus_StateFromJSON(object: any): Asset_SecurityStatus_State {
  switch (object) {
    case 0:
    case "STATE_UNSPECIFIED":
      return Asset_SecurityStatus_State.STATE_UNSPECIFIED;
    case 1:
    case "READY":
      return Asset_SecurityStatus_State.READY;
    case 2:
    case "APPLYING":
      return Asset_SecurityStatus_State.APPLYING;
    case 3:
    case "ERROR":
      return Asset_SecurityStatus_State.ERROR;
    case -1:
    case "UNRECOGNIZED":
    default:
      return Asset_SecurityStatus_State.UNRECOGNIZED;
  }
}

export function asset_SecurityStatus_StateToJSON(object: Asset_SecurityStatus_State): string {
  switch (object) {
    case Asset_SecurityStatus_State.STATE_UNSPECIFIED:
      return "STATE_UNSPECIFIED";
    case Asset_SecurityStatus_State.READY:
      return "READY";
    case Asset_SecurityStatus_State.APPLYING:
      return "APPLYING";
    case Asset_SecurityStatus_State.ERROR:
      return "ERROR";
    case Asset_SecurityStatus_State.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/** Settings to manage the metadata discovery and publishing for an asset. */
export interface Asset_DiscoverySpec {
  /** Optional. Whether discovery is enabled. */
  enabled: boolean;
  /**
   * Optional. The list of patterns to apply for selecting data to include
   * during discovery if only a subset of the data should considered.  For
   * Cloud Storage bucket assets, these are interpreted as glob patterns used
   * to match object names. For BigQuery dataset assets, these are interpreted
   * as patterns to match table names.
   */
  includePatterns: string[];
  /**
   * Optional. The list of patterns to apply for selecting data to exclude
   * during discovery.  For Cloud Storage bucket assets, these are interpreted
   * as glob patterns used to match object names. For BigQuery dataset assets,
   * these are interpreted as patterns to match table names.
   */
  excludePatterns: string[];
  /** Optional. Configuration for CSV data. */
  csvOptions:
    | Asset_DiscoverySpec_CsvOptions
    | undefined;
  /** Optional. Configuration for Json data. */
  jsonOptions:
    | Asset_DiscoverySpec_JsonOptions
    | undefined;
  /**
   * Optional. Cron schedule (https://en.wikipedia.org/wiki/Cron) for
   * running discovery periodically. Successive discovery runs must be
   * scheduled at least 60 minutes apart. The default value is to run
   * discovery every 60 minutes. To explicitly set a timezone to the cron
   * tab, apply a prefix in the cron tab: "CRON_TZ=${IANA_TIME_ZONE}" or
   * TZ=${IANA_TIME_ZONE}". The ${IANA_TIME_ZONE} may only be a valid string
   * from IANA time zone database. For example, `CRON_TZ=America/New_York 1
   * * * * *`, or `TZ=America/New_York 1 * * * *`.
   */
  schedule?: string | undefined;
}

/** Describe CSV and similar semi-structured data formats. */
export interface Asset_DiscoverySpec_CsvOptions {
  /**
   * Optional. The number of rows to interpret as header rows that should be
   * skipped when reading data rows.
   */
  headerRows: number;
  /**
   * Optional. The delimiter being used to separate values. This defaults to
   * ','.
   */
  delimiter: string;
  /** Optional. The character encoding of the data. The default is UTF-8. */
  encoding: string;
  /**
   * Optional. Whether to disable the inference of data type for CSV data.
   * If true, all columns will be registered as strings.
   */
  disableTypeInference: boolean;
}

/** Describe JSON data format. */
export interface Asset_DiscoverySpec_JsonOptions {
  /** Optional. The character encoding of the data. The default is UTF-8. */
  encoding: string;
  /**
   * Optional. Whether to disable the inference of data type for Json data.
   * If true, all columns will be registered as their primitive types
   * (strings, number or boolean).
   */
  disableTypeInference: boolean;
}

/** Identifies the cloud resource that is referenced by this asset. */
export interface Asset_ResourceSpec {
  /**
   * Immutable. Relative name of the cloud resource that contains the data
   * that is being managed within a lake. For example:
   *   `projects/{project_number}/buckets/{bucket_id}`
   *   `projects/{project_number}/datasets/{dataset_id}`
   */
  name: string;
  /** Required. Immutable. Type of resource. */
  type: Asset_ResourceSpec_Type;
  /**
   * Optional. Determines how read permissions are handled for each asset and
   * their associated tables. Only available to storage buckets assets.
   */
  readAccessMode: Asset_ResourceSpec_AccessMode;
}

/** Type of resource. */
export enum Asset_ResourceSpec_Type {
  /** TYPE_UNSPECIFIED - Type not specified. */
  TYPE_UNSPECIFIED = 0,
  /** STORAGE_BUCKET - Cloud Storage bucket. */
  STORAGE_BUCKET = 1,
  /** BIGQUERY_DATASET - BigQuery dataset. */
  BIGQUERY_DATASET = 2,
  UNRECOGNIZED = -1,
}

export function asset_ResourceSpec_TypeFromJSON(object: any): Asset_ResourceSpec_Type {
  switch (object) {
    case 0:
    case "TYPE_UNSPECIFIED":
      return Asset_ResourceSpec_Type.TYPE_UNSPECIFIED;
    case 1:
    case "STORAGE_BUCKET":
      return Asset_ResourceSpec_Type.STORAGE_BUCKET;
    case 2:
    case "BIGQUERY_DATASET":
      return Asset_ResourceSpec_Type.BIGQUERY_DATASET;
    case -1:
    case "UNRECOGNIZED":
    default:
      return Asset_ResourceSpec_Type.UNRECOGNIZED;
  }
}

export function asset_ResourceSpec_TypeToJSON(object: Asset_ResourceSpec_Type): string {
  switch (object) {
    case Asset_ResourceSpec_Type.TYPE_UNSPECIFIED:
      return "TYPE_UNSPECIFIED";
    case Asset_ResourceSpec_Type.STORAGE_BUCKET:
      return "STORAGE_BUCKET";
    case Asset_ResourceSpec_Type.BIGQUERY_DATASET:
      return "BIGQUERY_DATASET";
    case Asset_ResourceSpec_Type.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/**
 * Access Mode determines how data stored within the resource is read. This
 * is only applicable to storage bucket assets.
 */
export enum Asset_ResourceSpec_AccessMode {
  /** ACCESS_MODE_UNSPECIFIED - Access mode unspecified. */
  ACCESS_MODE_UNSPECIFIED = 0,
  /** DIRECT - Default. Data is accessed directly using storage APIs. */
  DIRECT = 1,
  /** MANAGED - Data is accessed through a managed interface using BigQuery APIs. */
  MANAGED = 2,
  UNRECOGNIZED = -1,
}

export function asset_ResourceSpec_AccessModeFromJSON(object: any): Asset_ResourceSpec_AccessMode {
  switch (object) {
    case 0:
    case "ACCESS_MODE_UNSPECIFIED":
      return Asset_ResourceSpec_AccessMode.ACCESS_MODE_UNSPECIFIED;
    case 1:
    case "DIRECT":
      return Asset_ResourceSpec_AccessMode.DIRECT;
    case 2:
    case "MANAGED":
      return Asset_ResourceSpec_AccessMode.MANAGED;
    case -1:
    case "UNRECOGNIZED":
    default:
      return Asset_ResourceSpec_AccessMode.UNRECOGNIZED;
  }
}

export function asset_ResourceSpec_AccessModeToJSON(object: Asset_ResourceSpec_AccessMode): string {
  switch (object) {
    case Asset_ResourceSpec_AccessMode.ACCESS_MODE_UNSPECIFIED:
      return "ACCESS_MODE_UNSPECIFIED";
    case Asset_ResourceSpec_AccessMode.DIRECT:
      return "DIRECT";
    case Asset_ResourceSpec_AccessMode.MANAGED:
      return "MANAGED";
    case Asset_ResourceSpec_AccessMode.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/** Status of the resource referenced by an asset. */
export interface Asset_ResourceStatus {
  /** The current state of the managed resource. */
  state: Asset_ResourceStatus_State;
  /** Additional information about the current state. */
  message: string;
  /** Last update time of the status. */
  updateTime:
    | Date
    | undefined;
  /** Output only. Service account associated with the BigQuery Connection. */
  managedAccessIdentity: string;
}

/** The state of a resource. */
export enum Asset_ResourceStatus_State {
  /** STATE_UNSPECIFIED - State unspecified. */
  STATE_UNSPECIFIED = 0,
  /** READY - Resource does not have any errors. */
  READY = 1,
  /** ERROR - Resource has errors. */
  ERROR = 2,
  UNRECOGNIZED = -1,
}

export function asset_ResourceStatus_StateFromJSON(object: any): Asset_ResourceStatus_State {
  switch (object) {
    case 0:
    case "STATE_UNSPECIFIED":
      return Asset_ResourceStatus_State.STATE_UNSPECIFIED;
    case 1:
    case "READY":
      return Asset_ResourceStatus_State.READY;
    case 2:
    case "ERROR":
      return Asset_ResourceStatus_State.ERROR;
    case -1:
    case "UNRECOGNIZED":
    default:
      return Asset_ResourceStatus_State.UNRECOGNIZED;
  }
}

export function asset_ResourceStatus_StateToJSON(object: Asset_ResourceStatus_State): string {
  switch (object) {
    case Asset_ResourceStatus_State.STATE_UNSPECIFIED:
      return "STATE_UNSPECIFIED";
    case Asset_ResourceStatus_State.READY:
      return "READY";
    case Asset_ResourceStatus_State.ERROR:
      return "ERROR";
    case Asset_ResourceStatus_State.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/** Status of discovery for an asset. */
export interface Asset_DiscoveryStatus {
  /** The current status of the discovery feature. */
  state: Asset_DiscoveryStatus_State;
  /** Additional information about the current state. */
  message: string;
  /** Last update time of the status. */
  updateTime:
    | Date
    | undefined;
  /** The start time of the last discovery run. */
  lastRunTime:
    | Date
    | undefined;
  /** Data Stats of the asset reported by discovery. */
  stats:
    | Asset_DiscoveryStatus_Stats
    | undefined;
  /** The duration of the last discovery run. */
  lastRunDuration: Duration | undefined;
}

/** Current state of discovery. */
export enum Asset_DiscoveryStatus_State {
  /** STATE_UNSPECIFIED - State is unspecified. */
  STATE_UNSPECIFIED = 0,
  /** SCHEDULED - Discovery for the asset is scheduled. */
  SCHEDULED = 1,
  /** IN_PROGRESS - Discovery for the asset is running. */
  IN_PROGRESS = 2,
  /**
   * PAUSED - Discovery for the asset is currently paused (e.g. due to a lack
   * of available resources). It will be automatically resumed.
   */
  PAUSED = 3,
  /** DISABLED - Discovery for the asset is disabled. */
  DISABLED = 5,
  UNRECOGNIZED = -1,
}

export function asset_DiscoveryStatus_StateFromJSON(object: any): Asset_DiscoveryStatus_State {
  switch (object) {
    case 0:
    case "STATE_UNSPECIFIED":
      return Asset_DiscoveryStatus_State.STATE_UNSPECIFIED;
    case 1:
    case "SCHEDULED":
      return Asset_DiscoveryStatus_State.SCHEDULED;
    case 2:
    case "IN_PROGRESS":
      return Asset_DiscoveryStatus_State.IN_PROGRESS;
    case 3:
    case "PAUSED":
      return Asset_DiscoveryStatus_State.PAUSED;
    case 5:
    case "DISABLED":
      return Asset_DiscoveryStatus_State.DISABLED;
    case -1:
    case "UNRECOGNIZED":
    default:
      return Asset_DiscoveryStatus_State.UNRECOGNIZED;
  }
}

export function asset_DiscoveryStatus_StateToJSON(object: Asset_DiscoveryStatus_State): string {
  switch (object) {
    case Asset_DiscoveryStatus_State.STATE_UNSPECIFIED:
      return "STATE_UNSPECIFIED";
    case Asset_DiscoveryStatus_State.SCHEDULED:
      return "SCHEDULED";
    case Asset_DiscoveryStatus_State.IN_PROGRESS:
      return "IN_PROGRESS";
    case Asset_DiscoveryStatus_State.PAUSED:
      return "PAUSED";
    case Asset_DiscoveryStatus_State.DISABLED:
      return "DISABLED";
    case Asset_DiscoveryStatus_State.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/** The aggregated data statistics for the asset reported by discovery. */
export interface Asset_DiscoveryStatus_Stats {
  /** The count of data items within the referenced resource. */
  dataItems: Long;
  /** The number of stored data bytes within the referenced resource. */
  dataSize: Long;
  /** The count of table entities within the referenced resource. */
  tables: Long;
  /** The count of fileset entities within the referenced resource. */
  filesets: Long;
}

export interface Asset_LabelsEntry {
  key: string;
  value: string;
}

function createBaseLake(): Lake {
  return {
    name: "",
    displayName: "",
    uid: "",
    createTime: undefined,
    updateTime: undefined,
    labels: {},
    description: "",
    state: 0,
    serviceAccount: "",
    metastore: undefined,
    assetStatus: undefined,
    metastoreStatus: undefined,
  };
}

export const Lake: MessageFns<Lake> = {
  encode(message: Lake, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    if (message.displayName !== "") {
      writer.uint32(18).string(message.displayName);
    }
    if (message.uid !== "") {
      writer.uint32(26).string(message.uid);
    }
    if (message.createTime !== undefined) {
      Timestamp.encode(toTimestamp(message.createTime), writer.uint32(34).fork()).join();
    }
    if (message.updateTime !== undefined) {
      Timestamp.encode(toTimestamp(message.updateTime), writer.uint32(42).fork()).join();
    }
    Object.entries(message.labels).forEach(([key, value]) => {
      Lake_LabelsEntry.encode({ key: key as any, value }, writer.uint32(50).fork()).join();
    });
    if (message.description !== "") {
      writer.uint32(58).string(message.description);
    }
    if (message.state !== 0) {
      writer.uint32(64).int32(message.state);
    }
    if (message.serviceAccount !== "") {
      writer.uint32(74).string(message.serviceAccount);
    }
    if (message.metastore !== undefined) {
      Lake_Metastore.encode(message.metastore, writer.uint32(818).fork()).join();
    }
    if (message.assetStatus !== undefined) {
      AssetStatus.encode(message.assetStatus, writer.uint32(826).fork()).join();
    }
    if (message.metastoreStatus !== undefined) {
      Lake_MetastoreStatus.encode(message.metastoreStatus, writer.uint32(834).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Lake {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseLake();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.displayName = reader.string();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.uid = reader.string();
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.createTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.updateTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        case 6:
          if (tag !== 50) {
            break;
          }

          const entry6 = Lake_LabelsEntry.decode(reader, reader.uint32());
          if (entry6.value !== undefined) {
            message.labels[entry6.key] = entry6.value;
          }
          continue;
        case 7:
          if (tag !== 58) {
            break;
          }

          message.description = reader.string();
          continue;
        case 8:
          if (tag !== 64) {
            break;
          }

          message.state = reader.int32() as any;
          continue;
        case 9:
          if (tag !== 74) {
            break;
          }

          message.serviceAccount = reader.string();
          continue;
        case 102:
          if (tag !== 818) {
            break;
          }

          message.metastore = Lake_Metastore.decode(reader, reader.uint32());
          continue;
        case 103:
          if (tag !== 826) {
            break;
          }

          message.assetStatus = AssetStatus.decode(reader, reader.uint32());
          continue;
        case 104:
          if (tag !== 834) {
            break;
          }

          message.metastoreStatus = Lake_MetastoreStatus.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Lake {
    return {
      name: isSet(object.name) ? globalThis.String(object.name) : "",
      displayName: isSet(object.displayName) ? globalThis.String(object.displayName) : "",
      uid: isSet(object.uid) ? globalThis.String(object.uid) : "",
      createTime: isSet(object.createTime) ? fromJsonTimestamp(object.createTime) : undefined,
      updateTime: isSet(object.updateTime) ? fromJsonTimestamp(object.updateTime) : undefined,
      labels: isObject(object.labels)
        ? Object.entries(object.labels).reduce<{ [key: string]: string }>((acc, [key, value]) => {
          acc[key] = String(value);
          return acc;
        }, {})
        : {},
      description: isSet(object.description) ? globalThis.String(object.description) : "",
      state: isSet(object.state) ? stateFromJSON(object.state) : 0,
      serviceAccount: isSet(object.serviceAccount) ? globalThis.String(object.serviceAccount) : "",
      metastore: isSet(object.metastore) ? Lake_Metastore.fromJSON(object.metastore) : undefined,
      assetStatus: isSet(object.assetStatus) ? AssetStatus.fromJSON(object.assetStatus) : undefined,
      metastoreStatus: isSet(object.metastoreStatus)
        ? Lake_MetastoreStatus.fromJSON(object.metastoreStatus)
        : undefined,
    };
  },

  toJSON(message: Lake): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    if (message.displayName !== "") {
      obj.displayName = message.displayName;
    }
    if (message.uid !== "") {
      obj.uid = message.uid;
    }
    if (message.createTime !== undefined) {
      obj.createTime = message.createTime.toISOString();
    }
    if (message.updateTime !== undefined) {
      obj.updateTime = message.updateTime.toISOString();
    }
    if (message.labels) {
      const entries = Object.entries(message.labels);
      if (entries.length > 0) {
        obj.labels = {};
        entries.forEach(([k, v]) => {
          obj.labels[k] = v;
        });
      }
    }
    if (message.description !== "") {
      obj.description = message.description;
    }
    if (message.state !== 0) {
      obj.state = stateToJSON(message.state);
    }
    if (message.serviceAccount !== "") {
      obj.serviceAccount = message.serviceAccount;
    }
    if (message.metastore !== undefined) {
      obj.metastore = Lake_Metastore.toJSON(message.metastore);
    }
    if (message.assetStatus !== undefined) {
      obj.assetStatus = AssetStatus.toJSON(message.assetStatus);
    }
    if (message.metastoreStatus !== undefined) {
      obj.metastoreStatus = Lake_MetastoreStatus.toJSON(message.metastoreStatus);
    }
    return obj;
  },

  create(base?: DeepPartial<Lake>): Lake {
    return Lake.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<Lake>): Lake {
    const message = createBaseLake();
    message.name = object.name ?? "";
    message.displayName = object.displayName ?? "";
    message.uid = object.uid ?? "";
    message.createTime = object.createTime ?? undefined;
    message.updateTime = object.updateTime ?? undefined;
    message.labels = Object.entries(object.labels ?? {}).reduce<{ [key: string]: string }>((acc, [key, value]) => {
      if (value !== undefined) {
        acc[key] = globalThis.String(value);
      }
      return acc;
    }, {});
    message.description = object.description ?? "";
    message.state = object.state ?? 0;
    message.serviceAccount = object.serviceAccount ?? "";
    message.metastore = (object.metastore !== undefined && object.metastore !== null)
      ? Lake_Metastore.fromPartial(object.metastore)
      : undefined;
    message.assetStatus = (object.assetStatus !== undefined && object.assetStatus !== null)
      ? AssetStatus.fromPartial(object.assetStatus)
      : undefined;
    message.metastoreStatus = (object.metastoreStatus !== undefined && object.metastoreStatus !== null)
      ? Lake_MetastoreStatus.fromPartial(object.metastoreStatus)
      : undefined;
    return message;
  },
};

function createBaseLake_Metastore(): Lake_Metastore {
  return { service: "" };
}

export const Lake_Metastore: MessageFns<Lake_Metastore> = {
  encode(message: Lake_Metastore, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.service !== "") {
      writer.uint32(10).string(message.service);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Lake_Metastore {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseLake_Metastore();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.service = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Lake_Metastore {
    return { service: isSet(object.service) ? globalThis.String(object.service) : "" };
  },

  toJSON(message: Lake_Metastore): unknown {
    const obj: any = {};
    if (message.service !== "") {
      obj.service = message.service;
    }
    return obj;
  },

  create(base?: DeepPartial<Lake_Metastore>): Lake_Metastore {
    return Lake_Metastore.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<Lake_Metastore>): Lake_Metastore {
    const message = createBaseLake_Metastore();
    message.service = object.service ?? "";
    return message;
  },
};

function createBaseLake_MetastoreStatus(): Lake_MetastoreStatus {
  return { state: 0, message: "", updateTime: undefined, endpoint: "" };
}

export const Lake_MetastoreStatus: MessageFns<Lake_MetastoreStatus> = {
  encode(message: Lake_MetastoreStatus, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.state !== 0) {
      writer.uint32(8).int32(message.state);
    }
    if (message.message !== "") {
      writer.uint32(18).string(message.message);
    }
    if (message.updateTime !== undefined) {
      Timestamp.encode(toTimestamp(message.updateTime), writer.uint32(26).fork()).join();
    }
    if (message.endpoint !== "") {
      writer.uint32(34).string(message.endpoint);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Lake_MetastoreStatus {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseLake_MetastoreStatus();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 8) {
            break;
          }

          message.state = reader.int32() as any;
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.message = reader.string();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.updateTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.endpoint = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Lake_MetastoreStatus {
    return {
      state: isSet(object.state) ? lake_MetastoreStatus_StateFromJSON(object.state) : 0,
      message: isSet(object.message) ? globalThis.String(object.message) : "",
      updateTime: isSet(object.updateTime) ? fromJsonTimestamp(object.updateTime) : undefined,
      endpoint: isSet(object.endpoint) ? globalThis.String(object.endpoint) : "",
    };
  },

  toJSON(message: Lake_MetastoreStatus): unknown {
    const obj: any = {};
    if (message.state !== 0) {
      obj.state = lake_MetastoreStatus_StateToJSON(message.state);
    }
    if (message.message !== "") {
      obj.message = message.message;
    }
    if (message.updateTime !== undefined) {
      obj.updateTime = message.updateTime.toISOString();
    }
    if (message.endpoint !== "") {
      obj.endpoint = message.endpoint;
    }
    return obj;
  },

  create(base?: DeepPartial<Lake_MetastoreStatus>): Lake_MetastoreStatus {
    return Lake_MetastoreStatus.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<Lake_MetastoreStatus>): Lake_MetastoreStatus {
    const message = createBaseLake_MetastoreStatus();
    message.state = object.state ?? 0;
    message.message = object.message ?? "";
    message.updateTime = object.updateTime ?? undefined;
    message.endpoint = object.endpoint ?? "";
    return message;
  },
};

function createBaseLake_LabelsEntry(): Lake_LabelsEntry {
  return { key: "", value: "" };
}

export const Lake_LabelsEntry: MessageFns<Lake_LabelsEntry> = {
  encode(message: Lake_LabelsEntry, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.key !== "") {
      writer.uint32(10).string(message.key);
    }
    if (message.value !== "") {
      writer.uint32(18).string(message.value);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Lake_LabelsEntry {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseLake_LabelsEntry();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.key = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.value = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Lake_LabelsEntry {
    return {
      key: isSet(object.key) ? globalThis.String(object.key) : "",
      value: isSet(object.value) ? globalThis.String(object.value) : "",
    };
  },

  toJSON(message: Lake_LabelsEntry): unknown {
    const obj: any = {};
    if (message.key !== "") {
      obj.key = message.key;
    }
    if (message.value !== "") {
      obj.value = message.value;
    }
    return obj;
  },

  create(base?: DeepPartial<Lake_LabelsEntry>): Lake_LabelsEntry {
    return Lake_LabelsEntry.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<Lake_LabelsEntry>): Lake_LabelsEntry {
    const message = createBaseLake_LabelsEntry();
    message.key = object.key ?? "";
    message.value = object.value ?? "";
    return message;
  },
};

function createBaseAssetStatus(): AssetStatus {
  return { updateTime: undefined, activeAssets: 0, securityPolicyApplyingAssets: 0 };
}

export const AssetStatus: MessageFns<AssetStatus> = {
  encode(message: AssetStatus, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.updateTime !== undefined) {
      Timestamp.encode(toTimestamp(message.updateTime), writer.uint32(10).fork()).join();
    }
    if (message.activeAssets !== 0) {
      writer.uint32(16).int32(message.activeAssets);
    }
    if (message.securityPolicyApplyingAssets !== 0) {
      writer.uint32(24).int32(message.securityPolicyApplyingAssets);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): AssetStatus {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseAssetStatus();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.updateTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.activeAssets = reader.int32();
          continue;
        case 3:
          if (tag !== 24) {
            break;
          }

          message.securityPolicyApplyingAssets = reader.int32();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): AssetStatus {
    return {
      updateTime: isSet(object.updateTime) ? fromJsonTimestamp(object.updateTime) : undefined,
      activeAssets: isSet(object.activeAssets) ? globalThis.Number(object.activeAssets) : 0,
      securityPolicyApplyingAssets: isSet(object.securityPolicyApplyingAssets)
        ? globalThis.Number(object.securityPolicyApplyingAssets)
        : 0,
    };
  },

  toJSON(message: AssetStatus): unknown {
    const obj: any = {};
    if (message.updateTime !== undefined) {
      obj.updateTime = message.updateTime.toISOString();
    }
    if (message.activeAssets !== 0) {
      obj.activeAssets = Math.round(message.activeAssets);
    }
    if (message.securityPolicyApplyingAssets !== 0) {
      obj.securityPolicyApplyingAssets = Math.round(message.securityPolicyApplyingAssets);
    }
    return obj;
  },

  create(base?: DeepPartial<AssetStatus>): AssetStatus {
    return AssetStatus.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<AssetStatus>): AssetStatus {
    const message = createBaseAssetStatus();
    message.updateTime = object.updateTime ?? undefined;
    message.activeAssets = object.activeAssets ?? 0;
    message.securityPolicyApplyingAssets = object.securityPolicyApplyingAssets ?? 0;
    return message;
  },
};

function createBaseZone(): Zone {
  return {
    name: "",
    displayName: "",
    uid: "",
    createTime: undefined,
    updateTime: undefined,
    labels: {},
    description: "",
    state: 0,
    type: 0,
    discoverySpec: undefined,
    resourceSpec: undefined,
    assetStatus: undefined,
  };
}

export const Zone: MessageFns<Zone> = {
  encode(message: Zone, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    if (message.displayName !== "") {
      writer.uint32(18).string(message.displayName);
    }
    if (message.uid !== "") {
      writer.uint32(26).string(message.uid);
    }
    if (message.createTime !== undefined) {
      Timestamp.encode(toTimestamp(message.createTime), writer.uint32(34).fork()).join();
    }
    if (message.updateTime !== undefined) {
      Timestamp.encode(toTimestamp(message.updateTime), writer.uint32(42).fork()).join();
    }
    Object.entries(message.labels).forEach(([key, value]) => {
      Zone_LabelsEntry.encode({ key: key as any, value }, writer.uint32(50).fork()).join();
    });
    if (message.description !== "") {
      writer.uint32(58).string(message.description);
    }
    if (message.state !== 0) {
      writer.uint32(64).int32(message.state);
    }
    if (message.type !== 0) {
      writer.uint32(72).int32(message.type);
    }
    if (message.discoverySpec !== undefined) {
      Zone_DiscoverySpec.encode(message.discoverySpec, writer.uint32(826).fork()).join();
    }
    if (message.resourceSpec !== undefined) {
      Zone_ResourceSpec.encode(message.resourceSpec, writer.uint32(834).fork()).join();
    }
    if (message.assetStatus !== undefined) {
      AssetStatus.encode(message.assetStatus, writer.uint32(842).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Zone {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseZone();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.displayName = reader.string();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.uid = reader.string();
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.createTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.updateTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        case 6:
          if (tag !== 50) {
            break;
          }

          const entry6 = Zone_LabelsEntry.decode(reader, reader.uint32());
          if (entry6.value !== undefined) {
            message.labels[entry6.key] = entry6.value;
          }
          continue;
        case 7:
          if (tag !== 58) {
            break;
          }

          message.description = reader.string();
          continue;
        case 8:
          if (tag !== 64) {
            break;
          }

          message.state = reader.int32() as any;
          continue;
        case 9:
          if (tag !== 72) {
            break;
          }

          message.type = reader.int32() as any;
          continue;
        case 103:
          if (tag !== 826) {
            break;
          }

          message.discoverySpec = Zone_DiscoverySpec.decode(reader, reader.uint32());
          continue;
        case 104:
          if (tag !== 834) {
            break;
          }

          message.resourceSpec = Zone_ResourceSpec.decode(reader, reader.uint32());
          continue;
        case 105:
          if (tag !== 842) {
            break;
          }

          message.assetStatus = AssetStatus.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Zone {
    return {
      name: isSet(object.name) ? globalThis.String(object.name) : "",
      displayName: isSet(object.displayName) ? globalThis.String(object.displayName) : "",
      uid: isSet(object.uid) ? globalThis.String(object.uid) : "",
      createTime: isSet(object.createTime) ? fromJsonTimestamp(object.createTime) : undefined,
      updateTime: isSet(object.updateTime) ? fromJsonTimestamp(object.updateTime) : undefined,
      labels: isObject(object.labels)
        ? Object.entries(object.labels).reduce<{ [key: string]: string }>((acc, [key, value]) => {
          acc[key] = String(value);
          return acc;
        }, {})
        : {},
      description: isSet(object.description) ? globalThis.String(object.description) : "",
      state: isSet(object.state) ? stateFromJSON(object.state) : 0,
      type: isSet(object.type) ? zone_TypeFromJSON(object.type) : 0,
      discoverySpec: isSet(object.discoverySpec) ? Zone_DiscoverySpec.fromJSON(object.discoverySpec) : undefined,
      resourceSpec: isSet(object.resourceSpec) ? Zone_ResourceSpec.fromJSON(object.resourceSpec) : undefined,
      assetStatus: isSet(object.assetStatus) ? AssetStatus.fromJSON(object.assetStatus) : undefined,
    };
  },

  toJSON(message: Zone): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    if (message.displayName !== "") {
      obj.displayName = message.displayName;
    }
    if (message.uid !== "") {
      obj.uid = message.uid;
    }
    if (message.createTime !== undefined) {
      obj.createTime = message.createTime.toISOString();
    }
    if (message.updateTime !== undefined) {
      obj.updateTime = message.updateTime.toISOString();
    }
    if (message.labels) {
      const entries = Object.entries(message.labels);
      if (entries.length > 0) {
        obj.labels = {};
        entries.forEach(([k, v]) => {
          obj.labels[k] = v;
        });
      }
    }
    if (message.description !== "") {
      obj.description = message.description;
    }
    if (message.state !== 0) {
      obj.state = stateToJSON(message.state);
    }
    if (message.type !== 0) {
      obj.type = zone_TypeToJSON(message.type);
    }
    if (message.discoverySpec !== undefined) {
      obj.discoverySpec = Zone_DiscoverySpec.toJSON(message.discoverySpec);
    }
    if (message.resourceSpec !== undefined) {
      obj.resourceSpec = Zone_ResourceSpec.toJSON(message.resourceSpec);
    }
    if (message.assetStatus !== undefined) {
      obj.assetStatus = AssetStatus.toJSON(message.assetStatus);
    }
    return obj;
  },

  create(base?: DeepPartial<Zone>): Zone {
    return Zone.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<Zone>): Zone {
    const message = createBaseZone();
    message.name = object.name ?? "";
    message.displayName = object.displayName ?? "";
    message.uid = object.uid ?? "";
    message.createTime = object.createTime ?? undefined;
    message.updateTime = object.updateTime ?? undefined;
    message.labels = Object.entries(object.labels ?? {}).reduce<{ [key: string]: string }>((acc, [key, value]) => {
      if (value !== undefined) {
        acc[key] = globalThis.String(value);
      }
      return acc;
    }, {});
    message.description = object.description ?? "";
    message.state = object.state ?? 0;
    message.type = object.type ?? 0;
    message.discoverySpec = (object.discoverySpec !== undefined && object.discoverySpec !== null)
      ? Zone_DiscoverySpec.fromPartial(object.discoverySpec)
      : undefined;
    message.resourceSpec = (object.resourceSpec !== undefined && object.resourceSpec !== null)
      ? Zone_ResourceSpec.fromPartial(object.resourceSpec)
      : undefined;
    message.assetStatus = (object.assetStatus !== undefined && object.assetStatus !== null)
      ? AssetStatus.fromPartial(object.assetStatus)
      : undefined;
    return message;
  },
};

function createBaseZone_ResourceSpec(): Zone_ResourceSpec {
  return { locationType: 0 };
}

export const Zone_ResourceSpec: MessageFns<Zone_ResourceSpec> = {
  encode(message: Zone_ResourceSpec, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.locationType !== 0) {
      writer.uint32(8).int32(message.locationType);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Zone_ResourceSpec {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseZone_ResourceSpec();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 8) {
            break;
          }

          message.locationType = reader.int32() as any;
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Zone_ResourceSpec {
    return {
      locationType: isSet(object.locationType) ? zone_ResourceSpec_LocationTypeFromJSON(object.locationType) : 0,
    };
  },

  toJSON(message: Zone_ResourceSpec): unknown {
    const obj: any = {};
    if (message.locationType !== 0) {
      obj.locationType = zone_ResourceSpec_LocationTypeToJSON(message.locationType);
    }
    return obj;
  },

  create(base?: DeepPartial<Zone_ResourceSpec>): Zone_ResourceSpec {
    return Zone_ResourceSpec.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<Zone_ResourceSpec>): Zone_ResourceSpec {
    const message = createBaseZone_ResourceSpec();
    message.locationType = object.locationType ?? 0;
    return message;
  },
};

function createBaseZone_DiscoverySpec(): Zone_DiscoverySpec {
  return {
    enabled: false,
    includePatterns: [],
    excludePatterns: [],
    csvOptions: undefined,
    jsonOptions: undefined,
    schedule: undefined,
  };
}

export const Zone_DiscoverySpec: MessageFns<Zone_DiscoverySpec> = {
  encode(message: Zone_DiscoverySpec, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.enabled !== false) {
      writer.uint32(8).bool(message.enabled);
    }
    for (const v of message.includePatterns) {
      writer.uint32(18).string(v!);
    }
    for (const v of message.excludePatterns) {
      writer.uint32(26).string(v!);
    }
    if (message.csvOptions !== undefined) {
      Zone_DiscoverySpec_CsvOptions.encode(message.csvOptions, writer.uint32(34).fork()).join();
    }
    if (message.jsonOptions !== undefined) {
      Zone_DiscoverySpec_JsonOptions.encode(message.jsonOptions, writer.uint32(42).fork()).join();
    }
    if (message.schedule !== undefined) {
      writer.uint32(82).string(message.schedule);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Zone_DiscoverySpec {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseZone_DiscoverySpec();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 8) {
            break;
          }

          message.enabled = reader.bool();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.includePatterns.push(reader.string());
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.excludePatterns.push(reader.string());
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.csvOptions = Zone_DiscoverySpec_CsvOptions.decode(reader, reader.uint32());
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.jsonOptions = Zone_DiscoverySpec_JsonOptions.decode(reader, reader.uint32());
          continue;
        case 10:
          if (tag !== 82) {
            break;
          }

          message.schedule = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Zone_DiscoverySpec {
    return {
      enabled: isSet(object.enabled) ? globalThis.Boolean(object.enabled) : false,
      includePatterns: globalThis.Array.isArray(object?.includePatterns)
        ? object.includePatterns.map((e: any) => globalThis.String(e))
        : [],
      excludePatterns: globalThis.Array.isArray(object?.excludePatterns)
        ? object.excludePatterns.map((e: any) => globalThis.String(e))
        : [],
      csvOptions: isSet(object.csvOptions) ? Zone_DiscoverySpec_CsvOptions.fromJSON(object.csvOptions) : undefined,
      jsonOptions: isSet(object.jsonOptions) ? Zone_DiscoverySpec_JsonOptions.fromJSON(object.jsonOptions) : undefined,
      schedule: isSet(object.schedule) ? globalThis.String(object.schedule) : undefined,
    };
  },

  toJSON(message: Zone_DiscoverySpec): unknown {
    const obj: any = {};
    if (message.enabled !== false) {
      obj.enabled = message.enabled;
    }
    if (message.includePatterns?.length) {
      obj.includePatterns = message.includePatterns;
    }
    if (message.excludePatterns?.length) {
      obj.excludePatterns = message.excludePatterns;
    }
    if (message.csvOptions !== undefined) {
      obj.csvOptions = Zone_DiscoverySpec_CsvOptions.toJSON(message.csvOptions);
    }
    if (message.jsonOptions !== undefined) {
      obj.jsonOptions = Zone_DiscoverySpec_JsonOptions.toJSON(message.jsonOptions);
    }
    if (message.schedule !== undefined) {
      obj.schedule = message.schedule;
    }
    return obj;
  },

  create(base?: DeepPartial<Zone_DiscoverySpec>): Zone_DiscoverySpec {
    return Zone_DiscoverySpec.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<Zone_DiscoverySpec>): Zone_DiscoverySpec {
    const message = createBaseZone_DiscoverySpec();
    message.enabled = object.enabled ?? false;
    message.includePatterns = object.includePatterns?.map((e) => e) || [];
    message.excludePatterns = object.excludePatterns?.map((e) => e) || [];
    message.csvOptions = (object.csvOptions !== undefined && object.csvOptions !== null)
      ? Zone_DiscoverySpec_CsvOptions.fromPartial(object.csvOptions)
      : undefined;
    message.jsonOptions = (object.jsonOptions !== undefined && object.jsonOptions !== null)
      ? Zone_DiscoverySpec_JsonOptions.fromPartial(object.jsonOptions)
      : undefined;
    message.schedule = object.schedule ?? undefined;
    return message;
  },
};

function createBaseZone_DiscoverySpec_CsvOptions(): Zone_DiscoverySpec_CsvOptions {
  return { headerRows: 0, delimiter: "", encoding: "", disableTypeInference: false };
}

export const Zone_DiscoverySpec_CsvOptions: MessageFns<Zone_DiscoverySpec_CsvOptions> = {
  encode(message: Zone_DiscoverySpec_CsvOptions, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.headerRows !== 0) {
      writer.uint32(8).int32(message.headerRows);
    }
    if (message.delimiter !== "") {
      writer.uint32(18).string(message.delimiter);
    }
    if (message.encoding !== "") {
      writer.uint32(26).string(message.encoding);
    }
    if (message.disableTypeInference !== false) {
      writer.uint32(32).bool(message.disableTypeInference);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Zone_DiscoverySpec_CsvOptions {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseZone_DiscoverySpec_CsvOptions();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 8) {
            break;
          }

          message.headerRows = reader.int32();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.delimiter = reader.string();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.encoding = reader.string();
          continue;
        case 4:
          if (tag !== 32) {
            break;
          }

          message.disableTypeInference = reader.bool();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Zone_DiscoverySpec_CsvOptions {
    return {
      headerRows: isSet(object.headerRows) ? globalThis.Number(object.headerRows) : 0,
      delimiter: isSet(object.delimiter) ? globalThis.String(object.delimiter) : "",
      encoding: isSet(object.encoding) ? globalThis.String(object.encoding) : "",
      disableTypeInference: isSet(object.disableTypeInference)
        ? globalThis.Boolean(object.disableTypeInference)
        : false,
    };
  },

  toJSON(message: Zone_DiscoverySpec_CsvOptions): unknown {
    const obj: any = {};
    if (message.headerRows !== 0) {
      obj.headerRows = Math.round(message.headerRows);
    }
    if (message.delimiter !== "") {
      obj.delimiter = message.delimiter;
    }
    if (message.encoding !== "") {
      obj.encoding = message.encoding;
    }
    if (message.disableTypeInference !== false) {
      obj.disableTypeInference = message.disableTypeInference;
    }
    return obj;
  },

  create(base?: DeepPartial<Zone_DiscoverySpec_CsvOptions>): Zone_DiscoverySpec_CsvOptions {
    return Zone_DiscoverySpec_CsvOptions.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<Zone_DiscoverySpec_CsvOptions>): Zone_DiscoverySpec_CsvOptions {
    const message = createBaseZone_DiscoverySpec_CsvOptions();
    message.headerRows = object.headerRows ?? 0;
    message.delimiter = object.delimiter ?? "";
    message.encoding = object.encoding ?? "";
    message.disableTypeInference = object.disableTypeInference ?? false;
    return message;
  },
};

function createBaseZone_DiscoverySpec_JsonOptions(): Zone_DiscoverySpec_JsonOptions {
  return { encoding: "", disableTypeInference: false };
}

export const Zone_DiscoverySpec_JsonOptions: MessageFns<Zone_DiscoverySpec_JsonOptions> = {
  encode(message: Zone_DiscoverySpec_JsonOptions, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.encoding !== "") {
      writer.uint32(10).string(message.encoding);
    }
    if (message.disableTypeInference !== false) {
      writer.uint32(16).bool(message.disableTypeInference);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Zone_DiscoverySpec_JsonOptions {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseZone_DiscoverySpec_JsonOptions();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.encoding = reader.string();
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.disableTypeInference = reader.bool();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Zone_DiscoverySpec_JsonOptions {
    return {
      encoding: isSet(object.encoding) ? globalThis.String(object.encoding) : "",
      disableTypeInference: isSet(object.disableTypeInference)
        ? globalThis.Boolean(object.disableTypeInference)
        : false,
    };
  },

  toJSON(message: Zone_DiscoverySpec_JsonOptions): unknown {
    const obj: any = {};
    if (message.encoding !== "") {
      obj.encoding = message.encoding;
    }
    if (message.disableTypeInference !== false) {
      obj.disableTypeInference = message.disableTypeInference;
    }
    return obj;
  },

  create(base?: DeepPartial<Zone_DiscoverySpec_JsonOptions>): Zone_DiscoverySpec_JsonOptions {
    return Zone_DiscoverySpec_JsonOptions.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<Zone_DiscoverySpec_JsonOptions>): Zone_DiscoverySpec_JsonOptions {
    const message = createBaseZone_DiscoverySpec_JsonOptions();
    message.encoding = object.encoding ?? "";
    message.disableTypeInference = object.disableTypeInference ?? false;
    return message;
  },
};

function createBaseZone_LabelsEntry(): Zone_LabelsEntry {
  return { key: "", value: "" };
}

export const Zone_LabelsEntry: MessageFns<Zone_LabelsEntry> = {
  encode(message: Zone_LabelsEntry, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.key !== "") {
      writer.uint32(10).string(message.key);
    }
    if (message.value !== "") {
      writer.uint32(18).string(message.value);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Zone_LabelsEntry {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseZone_LabelsEntry();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.key = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.value = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Zone_LabelsEntry {
    return {
      key: isSet(object.key) ? globalThis.String(object.key) : "",
      value: isSet(object.value) ? globalThis.String(object.value) : "",
    };
  },

  toJSON(message: Zone_LabelsEntry): unknown {
    const obj: any = {};
    if (message.key !== "") {
      obj.key = message.key;
    }
    if (message.value !== "") {
      obj.value = message.value;
    }
    return obj;
  },

  create(base?: DeepPartial<Zone_LabelsEntry>): Zone_LabelsEntry {
    return Zone_LabelsEntry.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<Zone_LabelsEntry>): Zone_LabelsEntry {
    const message = createBaseZone_LabelsEntry();
    message.key = object.key ?? "";
    message.value = object.value ?? "";
    return message;
  },
};

function createBaseAction(): Action {
  return {
    category: 0,
    issue: "",
    detectTime: undefined,
    name: "",
    lake: "",
    zone: "",
    asset: "",
    dataLocations: [],
    invalidDataFormat: undefined,
    incompatibleDataSchema: undefined,
    invalidDataPartition: undefined,
    missingData: undefined,
    missingResource: undefined,
    unauthorizedResource: undefined,
    failedSecurityPolicyApply: undefined,
    invalidDataOrganization: undefined,
  };
}

export const Action: MessageFns<Action> = {
  encode(message: Action, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.category !== 0) {
      writer.uint32(8).int32(message.category);
    }
    if (message.issue !== "") {
      writer.uint32(18).string(message.issue);
    }
    if (message.detectTime !== undefined) {
      Timestamp.encode(toTimestamp(message.detectTime), writer.uint32(34).fork()).join();
    }
    if (message.name !== "") {
      writer.uint32(42).string(message.name);
    }
    if (message.lake !== "") {
      writer.uint32(50).string(message.lake);
    }
    if (message.zone !== "") {
      writer.uint32(58).string(message.zone);
    }
    if (message.asset !== "") {
      writer.uint32(66).string(message.asset);
    }
    for (const v of message.dataLocations) {
      writer.uint32(74).string(v!);
    }
    if (message.invalidDataFormat !== undefined) {
      Action_InvalidDataFormat.encode(message.invalidDataFormat, writer.uint32(82).fork()).join();
    }
    if (message.incompatibleDataSchema !== undefined) {
      Action_IncompatibleDataSchema.encode(message.incompatibleDataSchema, writer.uint32(90).fork()).join();
    }
    if (message.invalidDataPartition !== undefined) {
      Action_InvalidDataPartition.encode(message.invalidDataPartition, writer.uint32(98).fork()).join();
    }
    if (message.missingData !== undefined) {
      Action_MissingData.encode(message.missingData, writer.uint32(106).fork()).join();
    }
    if (message.missingResource !== undefined) {
      Action_MissingResource.encode(message.missingResource, writer.uint32(114).fork()).join();
    }
    if (message.unauthorizedResource !== undefined) {
      Action_UnauthorizedResource.encode(message.unauthorizedResource, writer.uint32(122).fork()).join();
    }
    if (message.failedSecurityPolicyApply !== undefined) {
      Action_FailedSecurityPolicyApply.encode(message.failedSecurityPolicyApply, writer.uint32(170).fork()).join();
    }
    if (message.invalidDataOrganization !== undefined) {
      Action_InvalidDataOrganization.encode(message.invalidDataOrganization, writer.uint32(178).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Action {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseAction();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 8) {
            break;
          }

          message.category = reader.int32() as any;
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.issue = reader.string();
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.detectTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.name = reader.string();
          continue;
        case 6:
          if (tag !== 50) {
            break;
          }

          message.lake = reader.string();
          continue;
        case 7:
          if (tag !== 58) {
            break;
          }

          message.zone = reader.string();
          continue;
        case 8:
          if (tag !== 66) {
            break;
          }

          message.asset = reader.string();
          continue;
        case 9:
          if (tag !== 74) {
            break;
          }

          message.dataLocations.push(reader.string());
          continue;
        case 10:
          if (tag !== 82) {
            break;
          }

          message.invalidDataFormat = Action_InvalidDataFormat.decode(reader, reader.uint32());
          continue;
        case 11:
          if (tag !== 90) {
            break;
          }

          message.incompatibleDataSchema = Action_IncompatibleDataSchema.decode(reader, reader.uint32());
          continue;
        case 12:
          if (tag !== 98) {
            break;
          }

          message.invalidDataPartition = Action_InvalidDataPartition.decode(reader, reader.uint32());
          continue;
        case 13:
          if (tag !== 106) {
            break;
          }

          message.missingData = Action_MissingData.decode(reader, reader.uint32());
          continue;
        case 14:
          if (tag !== 114) {
            break;
          }

          message.missingResource = Action_MissingResource.decode(reader, reader.uint32());
          continue;
        case 15:
          if (tag !== 122) {
            break;
          }

          message.unauthorizedResource = Action_UnauthorizedResource.decode(reader, reader.uint32());
          continue;
        case 21:
          if (tag !== 170) {
            break;
          }

          message.failedSecurityPolicyApply = Action_FailedSecurityPolicyApply.decode(reader, reader.uint32());
          continue;
        case 22:
          if (tag !== 178) {
            break;
          }

          message.invalidDataOrganization = Action_InvalidDataOrganization.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Action {
    return {
      category: isSet(object.category) ? action_CategoryFromJSON(object.category) : 0,
      issue: isSet(object.issue) ? globalThis.String(object.issue) : "",
      detectTime: isSet(object.detectTime) ? fromJsonTimestamp(object.detectTime) : undefined,
      name: isSet(object.name) ? globalThis.String(object.name) : "",
      lake: isSet(object.lake) ? globalThis.String(object.lake) : "",
      zone: isSet(object.zone) ? globalThis.String(object.zone) : "",
      asset: isSet(object.asset) ? globalThis.String(object.asset) : "",
      dataLocations: globalThis.Array.isArray(object?.dataLocations)
        ? object.dataLocations.map((e: any) => globalThis.String(e))
        : [],
      invalidDataFormat: isSet(object.invalidDataFormat)
        ? Action_InvalidDataFormat.fromJSON(object.invalidDataFormat)
        : undefined,
      incompatibleDataSchema: isSet(object.incompatibleDataSchema)
        ? Action_IncompatibleDataSchema.fromJSON(object.incompatibleDataSchema)
        : undefined,
      invalidDataPartition: isSet(object.invalidDataPartition)
        ? Action_InvalidDataPartition.fromJSON(object.invalidDataPartition)
        : undefined,
      missingData: isSet(object.missingData) ? Action_MissingData.fromJSON(object.missingData) : undefined,
      missingResource: isSet(object.missingResource)
        ? Action_MissingResource.fromJSON(object.missingResource)
        : undefined,
      unauthorizedResource: isSet(object.unauthorizedResource)
        ? Action_UnauthorizedResource.fromJSON(object.unauthorizedResource)
        : undefined,
      failedSecurityPolicyApply: isSet(object.failedSecurityPolicyApply)
        ? Action_FailedSecurityPolicyApply.fromJSON(object.failedSecurityPolicyApply)
        : undefined,
      invalidDataOrganization: isSet(object.invalidDataOrganization)
        ? Action_InvalidDataOrganization.fromJSON(object.invalidDataOrganization)
        : undefined,
    };
  },

  toJSON(message: Action): unknown {
    const obj: any = {};
    if (message.category !== 0) {
      obj.category = action_CategoryToJSON(message.category);
    }
    if (message.issue !== "") {
      obj.issue = message.issue;
    }
    if (message.detectTime !== undefined) {
      obj.detectTime = message.detectTime.toISOString();
    }
    if (message.name !== "") {
      obj.name = message.name;
    }
    if (message.lake !== "") {
      obj.lake = message.lake;
    }
    if (message.zone !== "") {
      obj.zone = message.zone;
    }
    if (message.asset !== "") {
      obj.asset = message.asset;
    }
    if (message.dataLocations?.length) {
      obj.dataLocations = message.dataLocations;
    }
    if (message.invalidDataFormat !== undefined) {
      obj.invalidDataFormat = Action_InvalidDataFormat.toJSON(message.invalidDataFormat);
    }
    if (message.incompatibleDataSchema !== undefined) {
      obj.incompatibleDataSchema = Action_IncompatibleDataSchema.toJSON(message.incompatibleDataSchema);
    }
    if (message.invalidDataPartition !== undefined) {
      obj.invalidDataPartition = Action_InvalidDataPartition.toJSON(message.invalidDataPartition);
    }
    if (message.missingData !== undefined) {
      obj.missingData = Action_MissingData.toJSON(message.missingData);
    }
    if (message.missingResource !== undefined) {
      obj.missingResource = Action_MissingResource.toJSON(message.missingResource);
    }
    if (message.unauthorizedResource !== undefined) {
      obj.unauthorizedResource = Action_UnauthorizedResource.toJSON(message.unauthorizedResource);
    }
    if (message.failedSecurityPolicyApply !== undefined) {
      obj.failedSecurityPolicyApply = Action_FailedSecurityPolicyApply.toJSON(message.failedSecurityPolicyApply);
    }
    if (message.invalidDataOrganization !== undefined) {
      obj.invalidDataOrganization = Action_InvalidDataOrganization.toJSON(message.invalidDataOrganization);
    }
    return obj;
  },

  create(base?: DeepPartial<Action>): Action {
    return Action.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<Action>): Action {
    const message = createBaseAction();
    message.category = object.category ?? 0;
    message.issue = object.issue ?? "";
    message.detectTime = object.detectTime ?? undefined;
    message.name = object.name ?? "";
    message.lake = object.lake ?? "";
    message.zone = object.zone ?? "";
    message.asset = object.asset ?? "";
    message.dataLocations = object.dataLocations?.map((e) => e) || [];
    message.invalidDataFormat = (object.invalidDataFormat !== undefined && object.invalidDataFormat !== null)
      ? Action_InvalidDataFormat.fromPartial(object.invalidDataFormat)
      : undefined;
    message.incompatibleDataSchema =
      (object.incompatibleDataSchema !== undefined && object.incompatibleDataSchema !== null)
        ? Action_IncompatibleDataSchema.fromPartial(object.incompatibleDataSchema)
        : undefined;
    message.invalidDataPartition = (object.invalidDataPartition !== undefined && object.invalidDataPartition !== null)
      ? Action_InvalidDataPartition.fromPartial(object.invalidDataPartition)
      : undefined;
    message.missingData = (object.missingData !== undefined && object.missingData !== null)
      ? Action_MissingData.fromPartial(object.missingData)
      : undefined;
    message.missingResource = (object.missingResource !== undefined && object.missingResource !== null)
      ? Action_MissingResource.fromPartial(object.missingResource)
      : undefined;
    message.unauthorizedResource = (object.unauthorizedResource !== undefined && object.unauthorizedResource !== null)
      ? Action_UnauthorizedResource.fromPartial(object.unauthorizedResource)
      : undefined;
    message.failedSecurityPolicyApply =
      (object.failedSecurityPolicyApply !== undefined && object.failedSecurityPolicyApply !== null)
        ? Action_FailedSecurityPolicyApply.fromPartial(object.failedSecurityPolicyApply)
        : undefined;
    message.invalidDataOrganization =
      (object.invalidDataOrganization !== undefined && object.invalidDataOrganization !== null)
        ? Action_InvalidDataOrganization.fromPartial(object.invalidDataOrganization)
        : undefined;
    return message;
  },
};

function createBaseAction_MissingResource(): Action_MissingResource {
  return {};
}

export const Action_MissingResource: MessageFns<Action_MissingResource> = {
  encode(_: Action_MissingResource, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Action_MissingResource {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseAction_MissingResource();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(_: any): Action_MissingResource {
    return {};
  },

  toJSON(_: Action_MissingResource): unknown {
    const obj: any = {};
    return obj;
  },

  create(base?: DeepPartial<Action_MissingResource>): Action_MissingResource {
    return Action_MissingResource.fromPartial(base ?? {});
  },
  fromPartial(_: DeepPartial<Action_MissingResource>): Action_MissingResource {
    const message = createBaseAction_MissingResource();
    return message;
  },
};

function createBaseAction_UnauthorizedResource(): Action_UnauthorizedResource {
  return {};
}

export const Action_UnauthorizedResource: MessageFns<Action_UnauthorizedResource> = {
  encode(_: Action_UnauthorizedResource, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Action_UnauthorizedResource {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseAction_UnauthorizedResource();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(_: any): Action_UnauthorizedResource {
    return {};
  },

  toJSON(_: Action_UnauthorizedResource): unknown {
    const obj: any = {};
    return obj;
  },

  create(base?: DeepPartial<Action_UnauthorizedResource>): Action_UnauthorizedResource {
    return Action_UnauthorizedResource.fromPartial(base ?? {});
  },
  fromPartial(_: DeepPartial<Action_UnauthorizedResource>): Action_UnauthorizedResource {
    const message = createBaseAction_UnauthorizedResource();
    return message;
  },
};

function createBaseAction_FailedSecurityPolicyApply(): Action_FailedSecurityPolicyApply {
  return { asset: "" };
}

export const Action_FailedSecurityPolicyApply: MessageFns<Action_FailedSecurityPolicyApply> = {
  encode(message: Action_FailedSecurityPolicyApply, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.asset !== "") {
      writer.uint32(10).string(message.asset);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Action_FailedSecurityPolicyApply {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseAction_FailedSecurityPolicyApply();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.asset = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Action_FailedSecurityPolicyApply {
    return { asset: isSet(object.asset) ? globalThis.String(object.asset) : "" };
  },

  toJSON(message: Action_FailedSecurityPolicyApply): unknown {
    const obj: any = {};
    if (message.asset !== "") {
      obj.asset = message.asset;
    }
    return obj;
  },

  create(base?: DeepPartial<Action_FailedSecurityPolicyApply>): Action_FailedSecurityPolicyApply {
    return Action_FailedSecurityPolicyApply.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<Action_FailedSecurityPolicyApply>): Action_FailedSecurityPolicyApply {
    const message = createBaseAction_FailedSecurityPolicyApply();
    message.asset = object.asset ?? "";
    return message;
  },
};

function createBaseAction_InvalidDataFormat(): Action_InvalidDataFormat {
  return { sampledDataLocations: [], expectedFormat: "", newFormat: "" };
}

export const Action_InvalidDataFormat: MessageFns<Action_InvalidDataFormat> = {
  encode(message: Action_InvalidDataFormat, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.sampledDataLocations) {
      writer.uint32(10).string(v!);
    }
    if (message.expectedFormat !== "") {
      writer.uint32(18).string(message.expectedFormat);
    }
    if (message.newFormat !== "") {
      writer.uint32(26).string(message.newFormat);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Action_InvalidDataFormat {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseAction_InvalidDataFormat();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.sampledDataLocations.push(reader.string());
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.expectedFormat = reader.string();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.newFormat = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Action_InvalidDataFormat {
    return {
      sampledDataLocations: globalThis.Array.isArray(object?.sampledDataLocations)
        ? object.sampledDataLocations.map((e: any) => globalThis.String(e))
        : [],
      expectedFormat: isSet(object.expectedFormat) ? globalThis.String(object.expectedFormat) : "",
      newFormat: isSet(object.newFormat) ? globalThis.String(object.newFormat) : "",
    };
  },

  toJSON(message: Action_InvalidDataFormat): unknown {
    const obj: any = {};
    if (message.sampledDataLocations?.length) {
      obj.sampledDataLocations = message.sampledDataLocations;
    }
    if (message.expectedFormat !== "") {
      obj.expectedFormat = message.expectedFormat;
    }
    if (message.newFormat !== "") {
      obj.newFormat = message.newFormat;
    }
    return obj;
  },

  create(base?: DeepPartial<Action_InvalidDataFormat>): Action_InvalidDataFormat {
    return Action_InvalidDataFormat.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<Action_InvalidDataFormat>): Action_InvalidDataFormat {
    const message = createBaseAction_InvalidDataFormat();
    message.sampledDataLocations = object.sampledDataLocations?.map((e) => e) || [];
    message.expectedFormat = object.expectedFormat ?? "";
    message.newFormat = object.newFormat ?? "";
    return message;
  },
};

function createBaseAction_IncompatibleDataSchema(): Action_IncompatibleDataSchema {
  return { table: "", existingSchema: "", newSchema: "", sampledDataLocations: [], schemaChange: 0 };
}

export const Action_IncompatibleDataSchema: MessageFns<Action_IncompatibleDataSchema> = {
  encode(message: Action_IncompatibleDataSchema, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.table !== "") {
      writer.uint32(10).string(message.table);
    }
    if (message.existingSchema !== "") {
      writer.uint32(18).string(message.existingSchema);
    }
    if (message.newSchema !== "") {
      writer.uint32(26).string(message.newSchema);
    }
    for (const v of message.sampledDataLocations) {
      writer.uint32(34).string(v!);
    }
    if (message.schemaChange !== 0) {
      writer.uint32(40).int32(message.schemaChange);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Action_IncompatibleDataSchema {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseAction_IncompatibleDataSchema();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.table = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.existingSchema = reader.string();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.newSchema = reader.string();
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.sampledDataLocations.push(reader.string());
          continue;
        case 5:
          if (tag !== 40) {
            break;
          }

          message.schemaChange = reader.int32() as any;
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Action_IncompatibleDataSchema {
    return {
      table: isSet(object.table) ? globalThis.String(object.table) : "",
      existingSchema: isSet(object.existingSchema) ? globalThis.String(object.existingSchema) : "",
      newSchema: isSet(object.newSchema) ? globalThis.String(object.newSchema) : "",
      sampledDataLocations: globalThis.Array.isArray(object?.sampledDataLocations)
        ? object.sampledDataLocations.map((e: any) => globalThis.String(e))
        : [],
      schemaChange: isSet(object.schemaChange)
        ? action_IncompatibleDataSchema_SchemaChangeFromJSON(object.schemaChange)
        : 0,
    };
  },

  toJSON(message: Action_IncompatibleDataSchema): unknown {
    const obj: any = {};
    if (message.table !== "") {
      obj.table = message.table;
    }
    if (message.existingSchema !== "") {
      obj.existingSchema = message.existingSchema;
    }
    if (message.newSchema !== "") {
      obj.newSchema = message.newSchema;
    }
    if (message.sampledDataLocations?.length) {
      obj.sampledDataLocations = message.sampledDataLocations;
    }
    if (message.schemaChange !== 0) {
      obj.schemaChange = action_IncompatibleDataSchema_SchemaChangeToJSON(message.schemaChange);
    }
    return obj;
  },

  create(base?: DeepPartial<Action_IncompatibleDataSchema>): Action_IncompatibleDataSchema {
    return Action_IncompatibleDataSchema.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<Action_IncompatibleDataSchema>): Action_IncompatibleDataSchema {
    const message = createBaseAction_IncompatibleDataSchema();
    message.table = object.table ?? "";
    message.existingSchema = object.existingSchema ?? "";
    message.newSchema = object.newSchema ?? "";
    message.sampledDataLocations = object.sampledDataLocations?.map((e) => e) || [];
    message.schemaChange = object.schemaChange ?? 0;
    return message;
  },
};

function createBaseAction_InvalidDataPartition(): Action_InvalidDataPartition {
  return { expectedStructure: 0 };
}

export const Action_InvalidDataPartition: MessageFns<Action_InvalidDataPartition> = {
  encode(message: Action_InvalidDataPartition, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.expectedStructure !== 0) {
      writer.uint32(8).int32(message.expectedStructure);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Action_InvalidDataPartition {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseAction_InvalidDataPartition();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 8) {
            break;
          }

          message.expectedStructure = reader.int32() as any;
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Action_InvalidDataPartition {
    return {
      expectedStructure: isSet(object.expectedStructure)
        ? action_InvalidDataPartition_PartitionStructureFromJSON(object.expectedStructure)
        : 0,
    };
  },

  toJSON(message: Action_InvalidDataPartition): unknown {
    const obj: any = {};
    if (message.expectedStructure !== 0) {
      obj.expectedStructure = action_InvalidDataPartition_PartitionStructureToJSON(message.expectedStructure);
    }
    return obj;
  },

  create(base?: DeepPartial<Action_InvalidDataPartition>): Action_InvalidDataPartition {
    return Action_InvalidDataPartition.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<Action_InvalidDataPartition>): Action_InvalidDataPartition {
    const message = createBaseAction_InvalidDataPartition();
    message.expectedStructure = object.expectedStructure ?? 0;
    return message;
  },
};

function createBaseAction_MissingData(): Action_MissingData {
  return {};
}

export const Action_MissingData: MessageFns<Action_MissingData> = {
  encode(_: Action_MissingData, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Action_MissingData {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseAction_MissingData();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(_: any): Action_MissingData {
    return {};
  },

  toJSON(_: Action_MissingData): unknown {
    const obj: any = {};
    return obj;
  },

  create(base?: DeepPartial<Action_MissingData>): Action_MissingData {
    return Action_MissingData.fromPartial(base ?? {});
  },
  fromPartial(_: DeepPartial<Action_MissingData>): Action_MissingData {
    const message = createBaseAction_MissingData();
    return message;
  },
};

function createBaseAction_InvalidDataOrganization(): Action_InvalidDataOrganization {
  return {};
}

export const Action_InvalidDataOrganization: MessageFns<Action_InvalidDataOrganization> = {
  encode(_: Action_InvalidDataOrganization, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Action_InvalidDataOrganization {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseAction_InvalidDataOrganization();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(_: any): Action_InvalidDataOrganization {
    return {};
  },

  toJSON(_: Action_InvalidDataOrganization): unknown {
    const obj: any = {};
    return obj;
  },

  create(base?: DeepPartial<Action_InvalidDataOrganization>): Action_InvalidDataOrganization {
    return Action_InvalidDataOrganization.fromPartial(base ?? {});
  },
  fromPartial(_: DeepPartial<Action_InvalidDataOrganization>): Action_InvalidDataOrganization {
    const message = createBaseAction_InvalidDataOrganization();
    return message;
  },
};

function createBaseAsset(): Asset {
  return {
    name: "",
    displayName: "",
    uid: "",
    createTime: undefined,
    updateTime: undefined,
    labels: {},
    description: "",
    state: 0,
    resourceSpec: undefined,
    resourceStatus: undefined,
    securityStatus: undefined,
    discoverySpec: undefined,
    discoveryStatus: undefined,
  };
}

export const Asset: MessageFns<Asset> = {
  encode(message: Asset, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    if (message.displayName !== "") {
      writer.uint32(18).string(message.displayName);
    }
    if (message.uid !== "") {
      writer.uint32(26).string(message.uid);
    }
    if (message.createTime !== undefined) {
      Timestamp.encode(toTimestamp(message.createTime), writer.uint32(34).fork()).join();
    }
    if (message.updateTime !== undefined) {
      Timestamp.encode(toTimestamp(message.updateTime), writer.uint32(42).fork()).join();
    }
    Object.entries(message.labels).forEach(([key, value]) => {
      Asset_LabelsEntry.encode({ key: key as any, value }, writer.uint32(50).fork()).join();
    });
    if (message.description !== "") {
      writer.uint32(58).string(message.description);
    }
    if (message.state !== 0) {
      writer.uint32(64).int32(message.state);
    }
    if (message.resourceSpec !== undefined) {
      Asset_ResourceSpec.encode(message.resourceSpec, writer.uint32(802).fork()).join();
    }
    if (message.resourceStatus !== undefined) {
      Asset_ResourceStatus.encode(message.resourceStatus, writer.uint32(810).fork()).join();
    }
    if (message.securityStatus !== undefined) {
      Asset_SecurityStatus.encode(message.securityStatus, writer.uint32(826).fork()).join();
    }
    if (message.discoverySpec !== undefined) {
      Asset_DiscoverySpec.encode(message.discoverySpec, writer.uint32(850).fork()).join();
    }
    if (message.discoveryStatus !== undefined) {
      Asset_DiscoveryStatus.encode(message.discoveryStatus, writer.uint32(858).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Asset {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseAsset();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.displayName = reader.string();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.uid = reader.string();
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.createTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.updateTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        case 6:
          if (tag !== 50) {
            break;
          }

          const entry6 = Asset_LabelsEntry.decode(reader, reader.uint32());
          if (entry6.value !== undefined) {
            message.labels[entry6.key] = entry6.value;
          }
          continue;
        case 7:
          if (tag !== 58) {
            break;
          }

          message.description = reader.string();
          continue;
        case 8:
          if (tag !== 64) {
            break;
          }

          message.state = reader.int32() as any;
          continue;
        case 100:
          if (tag !== 802) {
            break;
          }

          message.resourceSpec = Asset_ResourceSpec.decode(reader, reader.uint32());
          continue;
        case 101:
          if (tag !== 810) {
            break;
          }

          message.resourceStatus = Asset_ResourceStatus.decode(reader, reader.uint32());
          continue;
        case 103:
          if (tag !== 826) {
            break;
          }

          message.securityStatus = Asset_SecurityStatus.decode(reader, reader.uint32());
          continue;
        case 106:
          if (tag !== 850) {
            break;
          }

          message.discoverySpec = Asset_DiscoverySpec.decode(reader, reader.uint32());
          continue;
        case 107:
          if (tag !== 858) {
            break;
          }

          message.discoveryStatus = Asset_DiscoveryStatus.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Asset {
    return {
      name: isSet(object.name) ? globalThis.String(object.name) : "",
      displayName: isSet(object.displayName) ? globalThis.String(object.displayName) : "",
      uid: isSet(object.uid) ? globalThis.String(object.uid) : "",
      createTime: isSet(object.createTime) ? fromJsonTimestamp(object.createTime) : undefined,
      updateTime: isSet(object.updateTime) ? fromJsonTimestamp(object.updateTime) : undefined,
      labels: isObject(object.labels)
        ? Object.entries(object.labels).reduce<{ [key: string]: string }>((acc, [key, value]) => {
          acc[key] = String(value);
          return acc;
        }, {})
        : {},
      description: isSet(object.description) ? globalThis.String(object.description) : "",
      state: isSet(object.state) ? stateFromJSON(object.state) : 0,
      resourceSpec: isSet(object.resourceSpec) ? Asset_ResourceSpec.fromJSON(object.resourceSpec) : undefined,
      resourceStatus: isSet(object.resourceStatus) ? Asset_ResourceStatus.fromJSON(object.resourceStatus) : undefined,
      securityStatus: isSet(object.securityStatus) ? Asset_SecurityStatus.fromJSON(object.securityStatus) : undefined,
      discoverySpec: isSet(object.discoverySpec) ? Asset_DiscoverySpec.fromJSON(object.discoverySpec) : undefined,
      discoveryStatus: isSet(object.discoveryStatus)
        ? Asset_DiscoveryStatus.fromJSON(object.discoveryStatus)
        : undefined,
    };
  },

  toJSON(message: Asset): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    if (message.displayName !== "") {
      obj.displayName = message.displayName;
    }
    if (message.uid !== "") {
      obj.uid = message.uid;
    }
    if (message.createTime !== undefined) {
      obj.createTime = message.createTime.toISOString();
    }
    if (message.updateTime !== undefined) {
      obj.updateTime = message.updateTime.toISOString();
    }
    if (message.labels) {
      const entries = Object.entries(message.labels);
      if (entries.length > 0) {
        obj.labels = {};
        entries.forEach(([k, v]) => {
          obj.labels[k] = v;
        });
      }
    }
    if (message.description !== "") {
      obj.description = message.description;
    }
    if (message.state !== 0) {
      obj.state = stateToJSON(message.state);
    }
    if (message.resourceSpec !== undefined) {
      obj.resourceSpec = Asset_ResourceSpec.toJSON(message.resourceSpec);
    }
    if (message.resourceStatus !== undefined) {
      obj.resourceStatus = Asset_ResourceStatus.toJSON(message.resourceStatus);
    }
    if (message.securityStatus !== undefined) {
      obj.securityStatus = Asset_SecurityStatus.toJSON(message.securityStatus);
    }
    if (message.discoverySpec !== undefined) {
      obj.discoverySpec = Asset_DiscoverySpec.toJSON(message.discoverySpec);
    }
    if (message.discoveryStatus !== undefined) {
      obj.discoveryStatus = Asset_DiscoveryStatus.toJSON(message.discoveryStatus);
    }
    return obj;
  },

  create(base?: DeepPartial<Asset>): Asset {
    return Asset.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<Asset>): Asset {
    const message = createBaseAsset();
    message.name = object.name ?? "";
    message.displayName = object.displayName ?? "";
    message.uid = object.uid ?? "";
    message.createTime = object.createTime ?? undefined;
    message.updateTime = object.updateTime ?? undefined;
    message.labels = Object.entries(object.labels ?? {}).reduce<{ [key: string]: string }>((acc, [key, value]) => {
      if (value !== undefined) {
        acc[key] = globalThis.String(value);
      }
      return acc;
    }, {});
    message.description = object.description ?? "";
    message.state = object.state ?? 0;
    message.resourceSpec = (object.resourceSpec !== undefined && object.resourceSpec !== null)
      ? Asset_ResourceSpec.fromPartial(object.resourceSpec)
      : undefined;
    message.resourceStatus = (object.resourceStatus !== undefined && object.resourceStatus !== null)
      ? Asset_ResourceStatus.fromPartial(object.resourceStatus)
      : undefined;
    message.securityStatus = (object.securityStatus !== undefined && object.securityStatus !== null)
      ? Asset_SecurityStatus.fromPartial(object.securityStatus)
      : undefined;
    message.discoverySpec = (object.discoverySpec !== undefined && object.discoverySpec !== null)
      ? Asset_DiscoverySpec.fromPartial(object.discoverySpec)
      : undefined;
    message.discoveryStatus = (object.discoveryStatus !== undefined && object.discoveryStatus !== null)
      ? Asset_DiscoveryStatus.fromPartial(object.discoveryStatus)
      : undefined;
    return message;
  },
};

function createBaseAsset_SecurityStatus(): Asset_SecurityStatus {
  return { state: 0, message: "", updateTime: undefined };
}

export const Asset_SecurityStatus: MessageFns<Asset_SecurityStatus> = {
  encode(message: Asset_SecurityStatus, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.state !== 0) {
      writer.uint32(8).int32(message.state);
    }
    if (message.message !== "") {
      writer.uint32(18).string(message.message);
    }
    if (message.updateTime !== undefined) {
      Timestamp.encode(toTimestamp(message.updateTime), writer.uint32(26).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Asset_SecurityStatus {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseAsset_SecurityStatus();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 8) {
            break;
          }

          message.state = reader.int32() as any;
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.message = reader.string();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.updateTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Asset_SecurityStatus {
    return {
      state: isSet(object.state) ? asset_SecurityStatus_StateFromJSON(object.state) : 0,
      message: isSet(object.message) ? globalThis.String(object.message) : "",
      updateTime: isSet(object.updateTime) ? fromJsonTimestamp(object.updateTime) : undefined,
    };
  },

  toJSON(message: Asset_SecurityStatus): unknown {
    const obj: any = {};
    if (message.state !== 0) {
      obj.state = asset_SecurityStatus_StateToJSON(message.state);
    }
    if (message.message !== "") {
      obj.message = message.message;
    }
    if (message.updateTime !== undefined) {
      obj.updateTime = message.updateTime.toISOString();
    }
    return obj;
  },

  create(base?: DeepPartial<Asset_SecurityStatus>): Asset_SecurityStatus {
    return Asset_SecurityStatus.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<Asset_SecurityStatus>): Asset_SecurityStatus {
    const message = createBaseAsset_SecurityStatus();
    message.state = object.state ?? 0;
    message.message = object.message ?? "";
    message.updateTime = object.updateTime ?? undefined;
    return message;
  },
};

function createBaseAsset_DiscoverySpec(): Asset_DiscoverySpec {
  return {
    enabled: false,
    includePatterns: [],
    excludePatterns: [],
    csvOptions: undefined,
    jsonOptions: undefined,
    schedule: undefined,
  };
}

export const Asset_DiscoverySpec: MessageFns<Asset_DiscoverySpec> = {
  encode(message: Asset_DiscoverySpec, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.enabled !== false) {
      writer.uint32(8).bool(message.enabled);
    }
    for (const v of message.includePatterns) {
      writer.uint32(18).string(v!);
    }
    for (const v of message.excludePatterns) {
      writer.uint32(26).string(v!);
    }
    if (message.csvOptions !== undefined) {
      Asset_DiscoverySpec_CsvOptions.encode(message.csvOptions, writer.uint32(34).fork()).join();
    }
    if (message.jsonOptions !== undefined) {
      Asset_DiscoverySpec_JsonOptions.encode(message.jsonOptions, writer.uint32(42).fork()).join();
    }
    if (message.schedule !== undefined) {
      writer.uint32(82).string(message.schedule);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Asset_DiscoverySpec {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseAsset_DiscoverySpec();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 8) {
            break;
          }

          message.enabled = reader.bool();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.includePatterns.push(reader.string());
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.excludePatterns.push(reader.string());
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.csvOptions = Asset_DiscoverySpec_CsvOptions.decode(reader, reader.uint32());
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.jsonOptions = Asset_DiscoverySpec_JsonOptions.decode(reader, reader.uint32());
          continue;
        case 10:
          if (tag !== 82) {
            break;
          }

          message.schedule = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Asset_DiscoverySpec {
    return {
      enabled: isSet(object.enabled) ? globalThis.Boolean(object.enabled) : false,
      includePatterns: globalThis.Array.isArray(object?.includePatterns)
        ? object.includePatterns.map((e: any) => globalThis.String(e))
        : [],
      excludePatterns: globalThis.Array.isArray(object?.excludePatterns)
        ? object.excludePatterns.map((e: any) => globalThis.String(e))
        : [],
      csvOptions: isSet(object.csvOptions) ? Asset_DiscoverySpec_CsvOptions.fromJSON(object.csvOptions) : undefined,
      jsonOptions: isSet(object.jsonOptions) ? Asset_DiscoverySpec_JsonOptions.fromJSON(object.jsonOptions) : undefined,
      schedule: isSet(object.schedule) ? globalThis.String(object.schedule) : undefined,
    };
  },

  toJSON(message: Asset_DiscoverySpec): unknown {
    const obj: any = {};
    if (message.enabled !== false) {
      obj.enabled = message.enabled;
    }
    if (message.includePatterns?.length) {
      obj.includePatterns = message.includePatterns;
    }
    if (message.excludePatterns?.length) {
      obj.excludePatterns = message.excludePatterns;
    }
    if (message.csvOptions !== undefined) {
      obj.csvOptions = Asset_DiscoverySpec_CsvOptions.toJSON(message.csvOptions);
    }
    if (message.jsonOptions !== undefined) {
      obj.jsonOptions = Asset_DiscoverySpec_JsonOptions.toJSON(message.jsonOptions);
    }
    if (message.schedule !== undefined) {
      obj.schedule = message.schedule;
    }
    return obj;
  },

  create(base?: DeepPartial<Asset_DiscoverySpec>): Asset_DiscoverySpec {
    return Asset_DiscoverySpec.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<Asset_DiscoverySpec>): Asset_DiscoverySpec {
    const message = createBaseAsset_DiscoverySpec();
    message.enabled = object.enabled ?? false;
    message.includePatterns = object.includePatterns?.map((e) => e) || [];
    message.excludePatterns = object.excludePatterns?.map((e) => e) || [];
    message.csvOptions = (object.csvOptions !== undefined && object.csvOptions !== null)
      ? Asset_DiscoverySpec_CsvOptions.fromPartial(object.csvOptions)
      : undefined;
    message.jsonOptions = (object.jsonOptions !== undefined && object.jsonOptions !== null)
      ? Asset_DiscoverySpec_JsonOptions.fromPartial(object.jsonOptions)
      : undefined;
    message.schedule = object.schedule ?? undefined;
    return message;
  },
};

function createBaseAsset_DiscoverySpec_CsvOptions(): Asset_DiscoverySpec_CsvOptions {
  return { headerRows: 0, delimiter: "", encoding: "", disableTypeInference: false };
}

export const Asset_DiscoverySpec_CsvOptions: MessageFns<Asset_DiscoverySpec_CsvOptions> = {
  encode(message: Asset_DiscoverySpec_CsvOptions, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.headerRows !== 0) {
      writer.uint32(8).int32(message.headerRows);
    }
    if (message.delimiter !== "") {
      writer.uint32(18).string(message.delimiter);
    }
    if (message.encoding !== "") {
      writer.uint32(26).string(message.encoding);
    }
    if (message.disableTypeInference !== false) {
      writer.uint32(32).bool(message.disableTypeInference);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Asset_DiscoverySpec_CsvOptions {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseAsset_DiscoverySpec_CsvOptions();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 8) {
            break;
          }

          message.headerRows = reader.int32();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.delimiter = reader.string();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.encoding = reader.string();
          continue;
        case 4:
          if (tag !== 32) {
            break;
          }

          message.disableTypeInference = reader.bool();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Asset_DiscoverySpec_CsvOptions {
    return {
      headerRows: isSet(object.headerRows) ? globalThis.Number(object.headerRows) : 0,
      delimiter: isSet(object.delimiter) ? globalThis.String(object.delimiter) : "",
      encoding: isSet(object.encoding) ? globalThis.String(object.encoding) : "",
      disableTypeInference: isSet(object.disableTypeInference)
        ? globalThis.Boolean(object.disableTypeInference)
        : false,
    };
  },

  toJSON(message: Asset_DiscoverySpec_CsvOptions): unknown {
    const obj: any = {};
    if (message.headerRows !== 0) {
      obj.headerRows = Math.round(message.headerRows);
    }
    if (message.delimiter !== "") {
      obj.delimiter = message.delimiter;
    }
    if (message.encoding !== "") {
      obj.encoding = message.encoding;
    }
    if (message.disableTypeInference !== false) {
      obj.disableTypeInference = message.disableTypeInference;
    }
    return obj;
  },

  create(base?: DeepPartial<Asset_DiscoverySpec_CsvOptions>): Asset_DiscoverySpec_CsvOptions {
    return Asset_DiscoverySpec_CsvOptions.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<Asset_DiscoverySpec_CsvOptions>): Asset_DiscoverySpec_CsvOptions {
    const message = createBaseAsset_DiscoverySpec_CsvOptions();
    message.headerRows = object.headerRows ?? 0;
    message.delimiter = object.delimiter ?? "";
    message.encoding = object.encoding ?? "";
    message.disableTypeInference = object.disableTypeInference ?? false;
    return message;
  },
};

function createBaseAsset_DiscoverySpec_JsonOptions(): Asset_DiscoverySpec_JsonOptions {
  return { encoding: "", disableTypeInference: false };
}

export const Asset_DiscoverySpec_JsonOptions: MessageFns<Asset_DiscoverySpec_JsonOptions> = {
  encode(message: Asset_DiscoverySpec_JsonOptions, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.encoding !== "") {
      writer.uint32(10).string(message.encoding);
    }
    if (message.disableTypeInference !== false) {
      writer.uint32(16).bool(message.disableTypeInference);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Asset_DiscoverySpec_JsonOptions {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseAsset_DiscoverySpec_JsonOptions();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.encoding = reader.string();
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.disableTypeInference = reader.bool();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Asset_DiscoverySpec_JsonOptions {
    return {
      encoding: isSet(object.encoding) ? globalThis.String(object.encoding) : "",
      disableTypeInference: isSet(object.disableTypeInference)
        ? globalThis.Boolean(object.disableTypeInference)
        : false,
    };
  },

  toJSON(message: Asset_DiscoverySpec_JsonOptions): unknown {
    const obj: any = {};
    if (message.encoding !== "") {
      obj.encoding = message.encoding;
    }
    if (message.disableTypeInference !== false) {
      obj.disableTypeInference = message.disableTypeInference;
    }
    return obj;
  },

  create(base?: DeepPartial<Asset_DiscoverySpec_JsonOptions>): Asset_DiscoverySpec_JsonOptions {
    return Asset_DiscoverySpec_JsonOptions.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<Asset_DiscoverySpec_JsonOptions>): Asset_DiscoverySpec_JsonOptions {
    const message = createBaseAsset_DiscoverySpec_JsonOptions();
    message.encoding = object.encoding ?? "";
    message.disableTypeInference = object.disableTypeInference ?? false;
    return message;
  },
};

function createBaseAsset_ResourceSpec(): Asset_ResourceSpec {
  return { name: "", type: 0, readAccessMode: 0 };
}

export const Asset_ResourceSpec: MessageFns<Asset_ResourceSpec> = {
  encode(message: Asset_ResourceSpec, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    if (message.type !== 0) {
      writer.uint32(16).int32(message.type);
    }
    if (message.readAccessMode !== 0) {
      writer.uint32(40).int32(message.readAccessMode);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Asset_ResourceSpec {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseAsset_ResourceSpec();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.type = reader.int32() as any;
          continue;
        case 5:
          if (tag !== 40) {
            break;
          }

          message.readAccessMode = reader.int32() as any;
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Asset_ResourceSpec {
    return {
      name: isSet(object.name) ? globalThis.String(object.name) : "",
      type: isSet(object.type) ? asset_ResourceSpec_TypeFromJSON(object.type) : 0,
      readAccessMode: isSet(object.readAccessMode) ? asset_ResourceSpec_AccessModeFromJSON(object.readAccessMode) : 0,
    };
  },

  toJSON(message: Asset_ResourceSpec): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    if (message.type !== 0) {
      obj.type = asset_ResourceSpec_TypeToJSON(message.type);
    }
    if (message.readAccessMode !== 0) {
      obj.readAccessMode = asset_ResourceSpec_AccessModeToJSON(message.readAccessMode);
    }
    return obj;
  },

  create(base?: DeepPartial<Asset_ResourceSpec>): Asset_ResourceSpec {
    return Asset_ResourceSpec.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<Asset_ResourceSpec>): Asset_ResourceSpec {
    const message = createBaseAsset_ResourceSpec();
    message.name = object.name ?? "";
    message.type = object.type ?? 0;
    message.readAccessMode = object.readAccessMode ?? 0;
    return message;
  },
};

function createBaseAsset_ResourceStatus(): Asset_ResourceStatus {
  return { state: 0, message: "", updateTime: undefined, managedAccessIdentity: "" };
}

export const Asset_ResourceStatus: MessageFns<Asset_ResourceStatus> = {
  encode(message: Asset_ResourceStatus, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.state !== 0) {
      writer.uint32(8).int32(message.state);
    }
    if (message.message !== "") {
      writer.uint32(18).string(message.message);
    }
    if (message.updateTime !== undefined) {
      Timestamp.encode(toTimestamp(message.updateTime), writer.uint32(26).fork()).join();
    }
    if (message.managedAccessIdentity !== "") {
      writer.uint32(34).string(message.managedAccessIdentity);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Asset_ResourceStatus {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseAsset_ResourceStatus();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 8) {
            break;
          }

          message.state = reader.int32() as any;
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.message = reader.string();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.updateTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.managedAccessIdentity = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Asset_ResourceStatus {
    return {
      state: isSet(object.state) ? asset_ResourceStatus_StateFromJSON(object.state) : 0,
      message: isSet(object.message) ? globalThis.String(object.message) : "",
      updateTime: isSet(object.updateTime) ? fromJsonTimestamp(object.updateTime) : undefined,
      managedAccessIdentity: isSet(object.managedAccessIdentity) ? globalThis.String(object.managedAccessIdentity) : "",
    };
  },

  toJSON(message: Asset_ResourceStatus): unknown {
    const obj: any = {};
    if (message.state !== 0) {
      obj.state = asset_ResourceStatus_StateToJSON(message.state);
    }
    if (message.message !== "") {
      obj.message = message.message;
    }
    if (message.updateTime !== undefined) {
      obj.updateTime = message.updateTime.toISOString();
    }
    if (message.managedAccessIdentity !== "") {
      obj.managedAccessIdentity = message.managedAccessIdentity;
    }
    return obj;
  },

  create(base?: DeepPartial<Asset_ResourceStatus>): Asset_ResourceStatus {
    return Asset_ResourceStatus.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<Asset_ResourceStatus>): Asset_ResourceStatus {
    const message = createBaseAsset_ResourceStatus();
    message.state = object.state ?? 0;
    message.message = object.message ?? "";
    message.updateTime = object.updateTime ?? undefined;
    message.managedAccessIdentity = object.managedAccessIdentity ?? "";
    return message;
  },
};

function createBaseAsset_DiscoveryStatus(): Asset_DiscoveryStatus {
  return {
    state: 0,
    message: "",
    updateTime: undefined,
    lastRunTime: undefined,
    stats: undefined,
    lastRunDuration: undefined,
  };
}

export const Asset_DiscoveryStatus: MessageFns<Asset_DiscoveryStatus> = {
  encode(message: Asset_DiscoveryStatus, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.state !== 0) {
      writer.uint32(8).int32(message.state);
    }
    if (message.message !== "") {
      writer.uint32(18).string(message.message);
    }
    if (message.updateTime !== undefined) {
      Timestamp.encode(toTimestamp(message.updateTime), writer.uint32(26).fork()).join();
    }
    if (message.lastRunTime !== undefined) {
      Timestamp.encode(toTimestamp(message.lastRunTime), writer.uint32(34).fork()).join();
    }
    if (message.stats !== undefined) {
      Asset_DiscoveryStatus_Stats.encode(message.stats, writer.uint32(50).fork()).join();
    }
    if (message.lastRunDuration !== undefined) {
      Duration.encode(message.lastRunDuration, writer.uint32(58).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Asset_DiscoveryStatus {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseAsset_DiscoveryStatus();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 8) {
            break;
          }

          message.state = reader.int32() as any;
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.message = reader.string();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.updateTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.lastRunTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        case 6:
          if (tag !== 50) {
            break;
          }

          message.stats = Asset_DiscoveryStatus_Stats.decode(reader, reader.uint32());
          continue;
        case 7:
          if (tag !== 58) {
            break;
          }

          message.lastRunDuration = Duration.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Asset_DiscoveryStatus {
    return {
      state: isSet(object.state) ? asset_DiscoveryStatus_StateFromJSON(object.state) : 0,
      message: isSet(object.message) ? globalThis.String(object.message) : "",
      updateTime: isSet(object.updateTime) ? fromJsonTimestamp(object.updateTime) : undefined,
      lastRunTime: isSet(object.lastRunTime) ? fromJsonTimestamp(object.lastRunTime) : undefined,
      stats: isSet(object.stats) ? Asset_DiscoveryStatus_Stats.fromJSON(object.stats) : undefined,
      lastRunDuration: isSet(object.lastRunDuration) ? Duration.fromJSON(object.lastRunDuration) : undefined,
    };
  },

  toJSON(message: Asset_DiscoveryStatus): unknown {
    const obj: any = {};
    if (message.state !== 0) {
      obj.state = asset_DiscoveryStatus_StateToJSON(message.state);
    }
    if (message.message !== "") {
      obj.message = message.message;
    }
    if (message.updateTime !== undefined) {
      obj.updateTime = message.updateTime.toISOString();
    }
    if (message.lastRunTime !== undefined) {
      obj.lastRunTime = message.lastRunTime.toISOString();
    }
    if (message.stats !== undefined) {
      obj.stats = Asset_DiscoveryStatus_Stats.toJSON(message.stats);
    }
    if (message.lastRunDuration !== undefined) {
      obj.lastRunDuration = Duration.toJSON(message.lastRunDuration);
    }
    return obj;
  },

  create(base?: DeepPartial<Asset_DiscoveryStatus>): Asset_DiscoveryStatus {
    return Asset_DiscoveryStatus.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<Asset_DiscoveryStatus>): Asset_DiscoveryStatus {
    const message = createBaseAsset_DiscoveryStatus();
    message.state = object.state ?? 0;
    message.message = object.message ?? "";
    message.updateTime = object.updateTime ?? undefined;
    message.lastRunTime = object.lastRunTime ?? undefined;
    message.stats = (object.stats !== undefined && object.stats !== null)
      ? Asset_DiscoveryStatus_Stats.fromPartial(object.stats)
      : undefined;
    message.lastRunDuration = (object.lastRunDuration !== undefined && object.lastRunDuration !== null)
      ? Duration.fromPartial(object.lastRunDuration)
      : undefined;
    return message;
  },
};

function createBaseAsset_DiscoveryStatus_Stats(): Asset_DiscoveryStatus_Stats {
  return { dataItems: Long.ZERO, dataSize: Long.ZERO, tables: Long.ZERO, filesets: Long.ZERO };
}

export const Asset_DiscoveryStatus_Stats: MessageFns<Asset_DiscoveryStatus_Stats> = {
  encode(message: Asset_DiscoveryStatus_Stats, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (!message.dataItems.equals(Long.ZERO)) {
      writer.uint32(8).int64(message.dataItems.toString());
    }
    if (!message.dataSize.equals(Long.ZERO)) {
      writer.uint32(16).int64(message.dataSize.toString());
    }
    if (!message.tables.equals(Long.ZERO)) {
      writer.uint32(24).int64(message.tables.toString());
    }
    if (!message.filesets.equals(Long.ZERO)) {
      writer.uint32(32).int64(message.filesets.toString());
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Asset_DiscoveryStatus_Stats {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseAsset_DiscoveryStatus_Stats();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 8) {
            break;
          }

          message.dataItems = Long.fromString(reader.int64().toString());
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.dataSize = Long.fromString(reader.int64().toString());
          continue;
        case 3:
          if (tag !== 24) {
            break;
          }

          message.tables = Long.fromString(reader.int64().toString());
          continue;
        case 4:
          if (tag !== 32) {
            break;
          }

          message.filesets = Long.fromString(reader.int64().toString());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Asset_DiscoveryStatus_Stats {
    return {
      dataItems: isSet(object.dataItems) ? Long.fromValue(object.dataItems) : Long.ZERO,
      dataSize: isSet(object.dataSize) ? Long.fromValue(object.dataSize) : Long.ZERO,
      tables: isSet(object.tables) ? Long.fromValue(object.tables) : Long.ZERO,
      filesets: isSet(object.filesets) ? Long.fromValue(object.filesets) : Long.ZERO,
    };
  },

  toJSON(message: Asset_DiscoveryStatus_Stats): unknown {
    const obj: any = {};
    if (!message.dataItems.equals(Long.ZERO)) {
      obj.dataItems = (message.dataItems || Long.ZERO).toString();
    }
    if (!message.dataSize.equals(Long.ZERO)) {
      obj.dataSize = (message.dataSize || Long.ZERO).toString();
    }
    if (!message.tables.equals(Long.ZERO)) {
      obj.tables = (message.tables || Long.ZERO).toString();
    }
    if (!message.filesets.equals(Long.ZERO)) {
      obj.filesets = (message.filesets || Long.ZERO).toString();
    }
    return obj;
  },

  create(base?: DeepPartial<Asset_DiscoveryStatus_Stats>): Asset_DiscoveryStatus_Stats {
    return Asset_DiscoveryStatus_Stats.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<Asset_DiscoveryStatus_Stats>): Asset_DiscoveryStatus_Stats {
    const message = createBaseAsset_DiscoveryStatus_Stats();
    message.dataItems = (object.dataItems !== undefined && object.dataItems !== null)
      ? Long.fromValue(object.dataItems)
      : Long.ZERO;
    message.dataSize = (object.dataSize !== undefined && object.dataSize !== null)
      ? Long.fromValue(object.dataSize)
      : Long.ZERO;
    message.tables = (object.tables !== undefined && object.tables !== null)
      ? Long.fromValue(object.tables)
      : Long.ZERO;
    message.filesets = (object.filesets !== undefined && object.filesets !== null)
      ? Long.fromValue(object.filesets)
      : Long.ZERO;
    return message;
  },
};

function createBaseAsset_LabelsEntry(): Asset_LabelsEntry {
  return { key: "", value: "" };
}

export const Asset_LabelsEntry: MessageFns<Asset_LabelsEntry> = {
  encode(message: Asset_LabelsEntry, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.key !== "") {
      writer.uint32(10).string(message.key);
    }
    if (message.value !== "") {
      writer.uint32(18).string(message.value);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Asset_LabelsEntry {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseAsset_LabelsEntry();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.key = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.value = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Asset_LabelsEntry {
    return {
      key: isSet(object.key) ? globalThis.String(object.key) : "",
      value: isSet(object.value) ? globalThis.String(object.value) : "",
    };
  },

  toJSON(message: Asset_LabelsEntry): unknown {
    const obj: any = {};
    if (message.key !== "") {
      obj.key = message.key;
    }
    if (message.value !== "") {
      obj.value = message.value;
    }
    return obj;
  },

  create(base?: DeepPartial<Asset_LabelsEntry>): Asset_LabelsEntry {
    return Asset_LabelsEntry.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<Asset_LabelsEntry>): Asset_LabelsEntry {
    const message = createBaseAsset_LabelsEntry();
    message.key = object.key ?? "";
    message.value = object.value ?? "";
    return message;
  },
};

type Builtin = Date | Function | Uint8Array | string | number | boolean | undefined;

export type DeepPartial<T> = T extends Builtin ? T
  : T extends Long ? string | number | Long : T extends globalThis.Array<infer U> ? globalThis.Array<DeepPartial<U>>
  : T extends ReadonlyArray<infer U> ? ReadonlyArray<DeepPartial<U>>
  : T extends {} ? { [K in keyof T]?: DeepPartial<T[K]> }
  : Partial<T>;

function toTimestamp(date: Date): Timestamp {
  const seconds = numberToLong(Math.trunc(date.getTime() / 1_000));
  const nanos = (date.getTime() % 1_000) * 1_000_000;
  return { seconds, nanos };
}

function fromTimestamp(t: Timestamp): Date {
  let millis = (t.seconds.toNumber() || 0) * 1_000;
  millis += (t.nanos || 0) / 1_000_000;
  return new globalThis.Date(millis);
}

function fromJsonTimestamp(o: any): Date {
  if (o instanceof globalThis.Date) {
    return o;
  } else if (typeof o === "string") {
    return new globalThis.Date(o);
  } else {
    return fromTimestamp(Timestamp.fromJSON(o));
  }
}

function numberToLong(number: number) {
  return Long.fromNumber(number);
}

function isObject(value: any): boolean {
  return typeof value === "object" && value !== null;
}

function isSet(value: any): boolean {
  return value !== null && value !== undefined;
}

export interface MessageFns<T> {
  encode(message: T, writer?: BinaryWriter): BinaryWriter;
  decode(input: BinaryReader | Uint8Array, length?: number): T;
  fromJSON(object: any): T;
  toJSON(message: T): unknown;
  create(base?: DeepPartial<T>): T;
  fromPartial(object: DeepPartial<T>): T;
}
