// Code generated by protoc-gen-ts_proto. DO NOT EDIT.
// versions:
//   protoc-gen-ts_proto  v2.2.0
//   protoc               unknown
// source: google/cloud/datalabeling/v1beta1/evaluation_job.proto

/* eslint-disable */
import { BinaryReader, BinaryWriter } from "@bufbuild/protobuf/wire";
import Long from "long";
import { Timestamp } from "../../../protobuf/timestamp.js";
import { Status } from "../../../rpc/status.js";
import { InputConfig } from "./dataset.js";
import { EvaluationConfig } from "./evaluation.js";
import {
  BoundingPolyConfig,
  HumanAnnotationConfig,
  ImageClassificationConfig,
  TextClassificationConfig,
} from "./human_annotation_config.js";

export const protobufPackage = "google.cloud.datalabeling.v1beta1";

/**
 * Defines an evaluation job that runs periodically to generate
 * [Evaluations][google.cloud.datalabeling.v1beta1.Evaluation]. [Creating an evaluation
 * job](/ml-engine/docs/continuous-evaluation/create-job) is the starting point
 * for using continuous evaluation.
 */
export interface EvaluationJob {
  /**
   * Output only. After you create a job, Data Labeling Service assigns a name
   * to the job with the following format:
   *
   * "projects/<var>{project_id}</var>/evaluationJobs/<var>{evaluation_job_id}</var>"
   */
  name: string;
  /**
   * Required. Description of the job. The description can be up to 25,000
   * characters long.
   */
  description: string;
  /** Output only. Describes the current state of the job. */
  state: EvaluationJob_State;
  /**
   * Required. Describes the interval at which the job runs. This interval must
   * be at least 1 day, and it is rounded to the nearest day. For example, if
   * you specify a 50-hour interval, the job runs every 2 days.
   *
   * You can provide the schedule in
   * [crontab format](/scheduler/docs/configuring/cron-job-schedules) or in an
   * [English-like
   * format](/appengine/docs/standard/python/config/cronref#schedule_format).
   *
   * Regardless of what you specify, the job will run at 10:00 AM UTC. Only the
   * interval from this schedule is used, not the specific time of day.
   */
  schedule: string;
  /**
   * Required. The [AI Platform Prediction model
   * version](/ml-engine/docs/prediction-overview) to be evaluated. Prediction
   * input and output is sampled from this model version. When creating an
   * evaluation job, specify the model version in the following format:
   *
   * "projects/<var>{project_id}</var>/models/<var>{model_name}</var>/versions/<var>{version_name}</var>"
   *
   * There can only be one evaluation job per model version.
   */
  modelVersion: string;
  /** Required. Configuration details for the evaluation job. */
  evaluationJobConfig:
    | EvaluationJobConfig
    | undefined;
  /**
   * Required. Name of the [AnnotationSpecSet][google.cloud.datalabeling.v1beta1.AnnotationSpecSet] describing all the
   * labels that your machine learning model outputs. You must create this
   * resource before you create an evaluation job and provide its name in the
   * following format:
   *
   * "projects/<var>{project_id}</var>/annotationSpecSets/<var>{annotation_spec_set_id}</var>"
   */
  annotationSpecSet: string;
  /**
   * Required. Whether you want Data Labeling Service to provide ground truth
   * labels for prediction input. If you want the service to assign human
   * labelers to annotate your data, set this to `true`. If you want to provide
   * your own ground truth labels in the evaluation job's BigQuery table, set
   * this to `false`.
   */
  labelMissingGroundTruth: boolean;
  /**
   * Output only. Every time the evaluation job runs and an error occurs, the
   * failed attempt is appended to this array.
   */
  attempts: Attempt[];
  /** Output only. Timestamp of when this evaluation job was created. */
  createTime: Date | undefined;
}

/** State of the job. */
export enum EvaluationJob_State {
  STATE_UNSPECIFIED = 0,
  /**
   * SCHEDULED - The job is scheduled to run at the [configured interval][google.cloud.datalabeling.v1beta1.EvaluationJob.schedule]. You
   * can [pause][google.cloud.datalabeling.v1beta1.DataLabelingService.PauseEvaluationJob] or
   * [delete][google.cloud.datalabeling.v1beta1.DataLabelingService.DeleteEvaluationJob] the job.
   *
   * When the job is in this state, it samples prediction input and output
   * from your model version into your BigQuery table as predictions occur.
   */
  SCHEDULED = 1,
  /**
   * RUNNING - The job is currently running. When the job runs, Data Labeling Service
   * does several things:
   *
   * 1. If you have configured your job to use Data Labeling Service for
   *    ground truth labeling, the service creates a
   *    [Dataset][google.cloud.datalabeling.v1beta1.Dataset] and a labeling task for all data sampled
   *    since the last time the job ran. Human labelers provide ground truth
   *    labels for your data. Human labeling may take hours, or even days,
   *    depending on how much data has been sampled. The job remains in the
   *    `RUNNING` state during this time, and it can even be running multiple
   *    times in parallel if it gets triggered again (for example 24 hours
   *    later) before the earlier run has completed. When human labelers have
   *    finished labeling the data, the next step occurs.
   *    <br><br>
   *    If you have configured your job to provide your own ground truth
   *    labels, Data Labeling Service still creates a [Dataset][google.cloud.datalabeling.v1beta1.Dataset] for newly
   *    sampled data, but it expects that you have already added ground truth
   *    labels to the BigQuery table by this time. The next step occurs
   *    immediately.
   *
   * 2. Data Labeling Service creates an [Evaluation][google.cloud.datalabeling.v1beta1.Evaluation] by comparing your
   *    model version's predictions with the ground truth labels.
   *
   * If the job remains in this state for a long time, it continues to sample
   * prediction data into your BigQuery table and will run again at the next
   * interval, even if it causes the job to run multiple times in parallel.
   */
  RUNNING = 2,
  /**
   * PAUSED - The job is not sampling prediction input and output into your BigQuery
   * table and it will not run according to its schedule. You can
   * [resume][google.cloud.datalabeling.v1beta1.DataLabelingService.ResumeEvaluationJob] the job.
   */
  PAUSED = 3,
  /** STOPPED - The job has this state right before it is deleted. */
  STOPPED = 4,
  UNRECOGNIZED = -1,
}

export function evaluationJob_StateFromJSON(object: any): EvaluationJob_State {
  switch (object) {
    case 0:
    case "STATE_UNSPECIFIED":
      return EvaluationJob_State.STATE_UNSPECIFIED;
    case 1:
    case "SCHEDULED":
      return EvaluationJob_State.SCHEDULED;
    case 2:
    case "RUNNING":
      return EvaluationJob_State.RUNNING;
    case 3:
    case "PAUSED":
      return EvaluationJob_State.PAUSED;
    case 4:
    case "STOPPED":
      return EvaluationJob_State.STOPPED;
    case -1:
    case "UNRECOGNIZED":
    default:
      return EvaluationJob_State.UNRECOGNIZED;
  }
}

export function evaluationJob_StateToJSON(object: EvaluationJob_State): string {
  switch (object) {
    case EvaluationJob_State.STATE_UNSPECIFIED:
      return "STATE_UNSPECIFIED";
    case EvaluationJob_State.SCHEDULED:
      return "SCHEDULED";
    case EvaluationJob_State.RUNNING:
      return "RUNNING";
    case EvaluationJob_State.PAUSED:
      return "PAUSED";
    case EvaluationJob_State.STOPPED:
      return "STOPPED";
    case EvaluationJob_State.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/**
 * Configures specific details of how a continuous evaluation job works. Provide
 * this configuration when you create an EvaluationJob.
 */
export interface EvaluationJobConfig {
  /**
   * Specify this field if your model version performs image classification or
   * general classification.
   *
   * `annotationSpecSet` in this configuration must match
   * [EvaluationJob.annotationSpecSet][google.cloud.datalabeling.v1beta1.EvaluationJob.annotation_spec_set].
   * `allowMultiLabel` in this configuration must match
   * `classificationMetadata.isMultiLabel` in [input_config][google.cloud.datalabeling.v1beta1.EvaluationJobConfig.input_config].
   */
  imageClassificationConfig?:
    | ImageClassificationConfig
    | undefined;
  /**
   * Specify this field if your model version performs image object detection
   * (bounding box detection).
   *
   * `annotationSpecSet` in this configuration must match
   * [EvaluationJob.annotationSpecSet][google.cloud.datalabeling.v1beta1.EvaluationJob.annotation_spec_set].
   */
  boundingPolyConfig?:
    | BoundingPolyConfig
    | undefined;
  /**
   * Specify this field if your model version performs text classification.
   *
   * `annotationSpecSet` in this configuration must match
   * [EvaluationJob.annotationSpecSet][google.cloud.datalabeling.v1beta1.EvaluationJob.annotation_spec_set].
   * `allowMultiLabel` in this configuration must match
   * `classificationMetadata.isMultiLabel` in [input_config][google.cloud.datalabeling.v1beta1.EvaluationJobConfig.input_config].
   */
  textClassificationConfig?:
    | TextClassificationConfig
    | undefined;
  /**
   * Rquired. Details for the sampled prediction input. Within this
   * configuration, there are requirements for several fields:
   *
   * * `dataType` must be one of `IMAGE`, `TEXT`, or `GENERAL_DATA`.
   * * `annotationType` must be one of `IMAGE_CLASSIFICATION_ANNOTATION`,
   *   `TEXT_CLASSIFICATION_ANNOTATION`, `GENERAL_CLASSIFICATION_ANNOTATION`,
   *   or `IMAGE_BOUNDING_BOX_ANNOTATION` (image object detection).
   * * If your machine learning model performs classification, you must specify
   *   `classificationMetadata.isMultiLabel`.
   * * You must specify `bigquerySource` (not `gcsSource`).
   */
  inputConfig:
    | InputConfig
    | undefined;
  /**
   * Required. Details for calculating evaluation metrics and creating
   * [Evaulations][google.cloud.datalabeling.v1beta1.Evaluation]. If your model version performs image object
   * detection, you must specify the `boundingBoxEvaluationOptions` field within
   * this configuration. Otherwise, provide an empty object for this
   * configuration.
   */
  evaluationConfig:
    | EvaluationConfig
    | undefined;
  /**
   * Optional. Details for human annotation of your data. If you set
   * [labelMissingGroundTruth][google.cloud.datalabeling.v1beta1.EvaluationJob.label_missing_ground_truth] to
   * `true` for this evaluation job, then you must specify this field. If you
   * plan to provide your own ground truth labels, then omit this field.
   *
   * Note that you must create an [Instruction][google.cloud.datalabeling.v1beta1.Instruction] resource before you can
   * specify this field. Provide the name of the instruction resource in the
   * `instruction` field within this configuration.
   */
  humanAnnotationConfig:
    | HumanAnnotationConfig
    | undefined;
  /**
   * Required. Prediction keys that tell Data Labeling Service where to find the
   * data for evaluation in your BigQuery table. When the service samples
   * prediction input and output from your model version and saves it to
   * BigQuery, the data gets stored as JSON strings in the BigQuery table. These
   * keys tell Data Labeling Service how to parse the JSON.
   *
   * You can provide the following entries in this field:
   *
   * * `data_json_key`: the data key for prediction input. You must provide
   *   either this key or `reference_json_key`.
   * * `reference_json_key`: the data reference key for prediction input. You
   *   must provide either this key or `data_json_key`.
   * * `label_json_key`: the label key for prediction output. Required.
   * * `label_score_json_key`: the score key for prediction output. Required.
   * * `bounding_box_json_key`: the bounding box key for prediction output.
   *   Required if your model version perform image object detection.
   *
   * Learn [how to configure prediction
   * keys](/ml-engine/docs/continuous-evaluation/create-job#prediction-keys).
   */
  bigqueryImportKeys: { [key: string]: string };
  /**
   * Required. The maximum number of predictions to sample and save to BigQuery
   * during each [evaluation interval][google.cloud.datalabeling.v1beta1.EvaluationJob.schedule]. This limit
   * overrides `example_sample_percentage`: even if the service has not sampled
   * enough predictions to fulfill `example_sample_perecentage` during an
   * interval, it stops sampling predictions when it meets this limit.
   */
  exampleCount: number;
  /**
   * Required. Fraction of predictions to sample and save to BigQuery during
   * each [evaluation interval][google.cloud.datalabeling.v1beta1.EvaluationJob.schedule]. For example, 0.1 means
   * 10% of predictions served by your model version get saved to BigQuery.
   */
  exampleSamplePercentage: number;
  /**
   * Optional. Configuration details for evaluation job alerts. Specify this
   * field if you want to receive email alerts if the evaluation job finds that
   * your predictions have low mean average precision during a run.
   */
  evaluationJobAlertConfig: EvaluationJobAlertConfig | undefined;
}

export interface EvaluationJobConfig_BigqueryImportKeysEntry {
  key: string;
  value: string;
}

/**
 * Provides details for how an evaluation job sends email alerts based on the
 * results of a run.
 */
export interface EvaluationJobAlertConfig {
  /** Required. An email address to send alerts to. */
  email: string;
  /**
   * Required. A number between 0 and 1 that describes a minimum mean average
   * precision threshold. When the evaluation job runs, if it calculates that
   * your model version's predictions from the recent interval have
   * [meanAveragePrecision][google.cloud.datalabeling.v1beta1.PrCurve.mean_average_precision] below this
   * threshold, then it sends an alert to your specified email.
   */
  minAcceptableMeanAveragePrecision: number;
}

/** Records a failed evaluation job run. */
export interface Attempt {
  attemptTime:
    | Date
    | undefined;
  /** Details of errors that occurred. */
  partialFailures: Status[];
}

function createBaseEvaluationJob(): EvaluationJob {
  return {
    name: "",
    description: "",
    state: 0,
    schedule: "",
    modelVersion: "",
    evaluationJobConfig: undefined,
    annotationSpecSet: "",
    labelMissingGroundTruth: false,
    attempts: [],
    createTime: undefined,
  };
}

export const EvaluationJob: MessageFns<EvaluationJob> = {
  encode(message: EvaluationJob, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    if (message.description !== "") {
      writer.uint32(18).string(message.description);
    }
    if (message.state !== 0) {
      writer.uint32(24).int32(message.state);
    }
    if (message.schedule !== "") {
      writer.uint32(34).string(message.schedule);
    }
    if (message.modelVersion !== "") {
      writer.uint32(42).string(message.modelVersion);
    }
    if (message.evaluationJobConfig !== undefined) {
      EvaluationJobConfig.encode(message.evaluationJobConfig, writer.uint32(50).fork()).join();
    }
    if (message.annotationSpecSet !== "") {
      writer.uint32(58).string(message.annotationSpecSet);
    }
    if (message.labelMissingGroundTruth !== false) {
      writer.uint32(64).bool(message.labelMissingGroundTruth);
    }
    for (const v of message.attempts) {
      Attempt.encode(v!, writer.uint32(74).fork()).join();
    }
    if (message.createTime !== undefined) {
      Timestamp.encode(toTimestamp(message.createTime), writer.uint32(82).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): EvaluationJob {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseEvaluationJob();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.description = reader.string();
          continue;
        case 3:
          if (tag !== 24) {
            break;
          }

          message.state = reader.int32() as any;
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.schedule = reader.string();
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.modelVersion = reader.string();
          continue;
        case 6:
          if (tag !== 50) {
            break;
          }

          message.evaluationJobConfig = EvaluationJobConfig.decode(reader, reader.uint32());
          continue;
        case 7:
          if (tag !== 58) {
            break;
          }

          message.annotationSpecSet = reader.string();
          continue;
        case 8:
          if (tag !== 64) {
            break;
          }

          message.labelMissingGroundTruth = reader.bool();
          continue;
        case 9:
          if (tag !== 74) {
            break;
          }

          message.attempts.push(Attempt.decode(reader, reader.uint32()));
          continue;
        case 10:
          if (tag !== 82) {
            break;
          }

          message.createTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): EvaluationJob {
    return {
      name: isSet(object.name) ? globalThis.String(object.name) : "",
      description: isSet(object.description) ? globalThis.String(object.description) : "",
      state: isSet(object.state) ? evaluationJob_StateFromJSON(object.state) : 0,
      schedule: isSet(object.schedule) ? globalThis.String(object.schedule) : "",
      modelVersion: isSet(object.modelVersion) ? globalThis.String(object.modelVersion) : "",
      evaluationJobConfig: isSet(object.evaluationJobConfig)
        ? EvaluationJobConfig.fromJSON(object.evaluationJobConfig)
        : undefined,
      annotationSpecSet: isSet(object.annotationSpecSet) ? globalThis.String(object.annotationSpecSet) : "",
      labelMissingGroundTruth: isSet(object.labelMissingGroundTruth)
        ? globalThis.Boolean(object.labelMissingGroundTruth)
        : false,
      attempts: globalThis.Array.isArray(object?.attempts) ? object.attempts.map((e: any) => Attempt.fromJSON(e)) : [],
      createTime: isSet(object.createTime) ? fromJsonTimestamp(object.createTime) : undefined,
    };
  },

  toJSON(message: EvaluationJob): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    if (message.description !== "") {
      obj.description = message.description;
    }
    if (message.state !== 0) {
      obj.state = evaluationJob_StateToJSON(message.state);
    }
    if (message.schedule !== "") {
      obj.schedule = message.schedule;
    }
    if (message.modelVersion !== "") {
      obj.modelVersion = message.modelVersion;
    }
    if (message.evaluationJobConfig !== undefined) {
      obj.evaluationJobConfig = EvaluationJobConfig.toJSON(message.evaluationJobConfig);
    }
    if (message.annotationSpecSet !== "") {
      obj.annotationSpecSet = message.annotationSpecSet;
    }
    if (message.labelMissingGroundTruth !== false) {
      obj.labelMissingGroundTruth = message.labelMissingGroundTruth;
    }
    if (message.attempts?.length) {
      obj.attempts = message.attempts.map((e) => Attempt.toJSON(e));
    }
    if (message.createTime !== undefined) {
      obj.createTime = message.createTime.toISOString();
    }
    return obj;
  },

  create(base?: DeepPartial<EvaluationJob>): EvaluationJob {
    return EvaluationJob.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<EvaluationJob>): EvaluationJob {
    const message = createBaseEvaluationJob();
    message.name = object.name ?? "";
    message.description = object.description ?? "";
    message.state = object.state ?? 0;
    message.schedule = object.schedule ?? "";
    message.modelVersion = object.modelVersion ?? "";
    message.evaluationJobConfig = (object.evaluationJobConfig !== undefined && object.evaluationJobConfig !== null)
      ? EvaluationJobConfig.fromPartial(object.evaluationJobConfig)
      : undefined;
    message.annotationSpecSet = object.annotationSpecSet ?? "";
    message.labelMissingGroundTruth = object.labelMissingGroundTruth ?? false;
    message.attempts = object.attempts?.map((e) => Attempt.fromPartial(e)) || [];
    message.createTime = object.createTime ?? undefined;
    return message;
  },
};

function createBaseEvaluationJobConfig(): EvaluationJobConfig {
  return {
    imageClassificationConfig: undefined,
    boundingPolyConfig: undefined,
    textClassificationConfig: undefined,
    inputConfig: undefined,
    evaluationConfig: undefined,
    humanAnnotationConfig: undefined,
    bigqueryImportKeys: {},
    exampleCount: 0,
    exampleSamplePercentage: 0,
    evaluationJobAlertConfig: undefined,
  };
}

export const EvaluationJobConfig: MessageFns<EvaluationJobConfig> = {
  encode(message: EvaluationJobConfig, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.imageClassificationConfig !== undefined) {
      ImageClassificationConfig.encode(message.imageClassificationConfig, writer.uint32(34).fork()).join();
    }
    if (message.boundingPolyConfig !== undefined) {
      BoundingPolyConfig.encode(message.boundingPolyConfig, writer.uint32(42).fork()).join();
    }
    if (message.textClassificationConfig !== undefined) {
      TextClassificationConfig.encode(message.textClassificationConfig, writer.uint32(66).fork()).join();
    }
    if (message.inputConfig !== undefined) {
      InputConfig.encode(message.inputConfig, writer.uint32(10).fork()).join();
    }
    if (message.evaluationConfig !== undefined) {
      EvaluationConfig.encode(message.evaluationConfig, writer.uint32(18).fork()).join();
    }
    if (message.humanAnnotationConfig !== undefined) {
      HumanAnnotationConfig.encode(message.humanAnnotationConfig, writer.uint32(26).fork()).join();
    }
    Object.entries(message.bigqueryImportKeys).forEach(([key, value]) => {
      EvaluationJobConfig_BigqueryImportKeysEntry.encode({ key: key as any, value }, writer.uint32(74).fork()).join();
    });
    if (message.exampleCount !== 0) {
      writer.uint32(80).int32(message.exampleCount);
    }
    if (message.exampleSamplePercentage !== 0) {
      writer.uint32(89).double(message.exampleSamplePercentage);
    }
    if (message.evaluationJobAlertConfig !== undefined) {
      EvaluationJobAlertConfig.encode(message.evaluationJobAlertConfig, writer.uint32(106).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): EvaluationJobConfig {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseEvaluationJobConfig();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 4:
          if (tag !== 34) {
            break;
          }

          message.imageClassificationConfig = ImageClassificationConfig.decode(reader, reader.uint32());
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.boundingPolyConfig = BoundingPolyConfig.decode(reader, reader.uint32());
          continue;
        case 8:
          if (tag !== 66) {
            break;
          }

          message.textClassificationConfig = TextClassificationConfig.decode(reader, reader.uint32());
          continue;
        case 1:
          if (tag !== 10) {
            break;
          }

          message.inputConfig = InputConfig.decode(reader, reader.uint32());
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.evaluationConfig = EvaluationConfig.decode(reader, reader.uint32());
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.humanAnnotationConfig = HumanAnnotationConfig.decode(reader, reader.uint32());
          continue;
        case 9:
          if (tag !== 74) {
            break;
          }

          const entry9 = EvaluationJobConfig_BigqueryImportKeysEntry.decode(reader, reader.uint32());
          if (entry9.value !== undefined) {
            message.bigqueryImportKeys[entry9.key] = entry9.value;
          }
          continue;
        case 10:
          if (tag !== 80) {
            break;
          }

          message.exampleCount = reader.int32();
          continue;
        case 11:
          if (tag !== 89) {
            break;
          }

          message.exampleSamplePercentage = reader.double();
          continue;
        case 13:
          if (tag !== 106) {
            break;
          }

          message.evaluationJobAlertConfig = EvaluationJobAlertConfig.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): EvaluationJobConfig {
    return {
      imageClassificationConfig: isSet(object.imageClassificationConfig)
        ? ImageClassificationConfig.fromJSON(object.imageClassificationConfig)
        : undefined,
      boundingPolyConfig: isSet(object.boundingPolyConfig)
        ? BoundingPolyConfig.fromJSON(object.boundingPolyConfig)
        : undefined,
      textClassificationConfig: isSet(object.textClassificationConfig)
        ? TextClassificationConfig.fromJSON(object.textClassificationConfig)
        : undefined,
      inputConfig: isSet(object.inputConfig) ? InputConfig.fromJSON(object.inputConfig) : undefined,
      evaluationConfig: isSet(object.evaluationConfig) ? EvaluationConfig.fromJSON(object.evaluationConfig) : undefined,
      humanAnnotationConfig: isSet(object.humanAnnotationConfig)
        ? HumanAnnotationConfig.fromJSON(object.humanAnnotationConfig)
        : undefined,
      bigqueryImportKeys: isObject(object.bigqueryImportKeys)
        ? Object.entries(object.bigqueryImportKeys).reduce<{ [key: string]: string }>((acc, [key, value]) => {
          acc[key] = String(value);
          return acc;
        }, {})
        : {},
      exampleCount: isSet(object.exampleCount) ? globalThis.Number(object.exampleCount) : 0,
      exampleSamplePercentage: isSet(object.exampleSamplePercentage)
        ? globalThis.Number(object.exampleSamplePercentage)
        : 0,
      evaluationJobAlertConfig: isSet(object.evaluationJobAlertConfig)
        ? EvaluationJobAlertConfig.fromJSON(object.evaluationJobAlertConfig)
        : undefined,
    };
  },

  toJSON(message: EvaluationJobConfig): unknown {
    const obj: any = {};
    if (message.imageClassificationConfig !== undefined) {
      obj.imageClassificationConfig = ImageClassificationConfig.toJSON(message.imageClassificationConfig);
    }
    if (message.boundingPolyConfig !== undefined) {
      obj.boundingPolyConfig = BoundingPolyConfig.toJSON(message.boundingPolyConfig);
    }
    if (message.textClassificationConfig !== undefined) {
      obj.textClassificationConfig = TextClassificationConfig.toJSON(message.textClassificationConfig);
    }
    if (message.inputConfig !== undefined) {
      obj.inputConfig = InputConfig.toJSON(message.inputConfig);
    }
    if (message.evaluationConfig !== undefined) {
      obj.evaluationConfig = EvaluationConfig.toJSON(message.evaluationConfig);
    }
    if (message.humanAnnotationConfig !== undefined) {
      obj.humanAnnotationConfig = HumanAnnotationConfig.toJSON(message.humanAnnotationConfig);
    }
    if (message.bigqueryImportKeys) {
      const entries = Object.entries(message.bigqueryImportKeys);
      if (entries.length > 0) {
        obj.bigqueryImportKeys = {};
        entries.forEach(([k, v]) => {
          obj.bigqueryImportKeys[k] = v;
        });
      }
    }
    if (message.exampleCount !== 0) {
      obj.exampleCount = Math.round(message.exampleCount);
    }
    if (message.exampleSamplePercentage !== 0) {
      obj.exampleSamplePercentage = message.exampleSamplePercentage;
    }
    if (message.evaluationJobAlertConfig !== undefined) {
      obj.evaluationJobAlertConfig = EvaluationJobAlertConfig.toJSON(message.evaluationJobAlertConfig);
    }
    return obj;
  },

  create(base?: DeepPartial<EvaluationJobConfig>): EvaluationJobConfig {
    return EvaluationJobConfig.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<EvaluationJobConfig>): EvaluationJobConfig {
    const message = createBaseEvaluationJobConfig();
    message.imageClassificationConfig =
      (object.imageClassificationConfig !== undefined && object.imageClassificationConfig !== null)
        ? ImageClassificationConfig.fromPartial(object.imageClassificationConfig)
        : undefined;
    message.boundingPolyConfig = (object.boundingPolyConfig !== undefined && object.boundingPolyConfig !== null)
      ? BoundingPolyConfig.fromPartial(object.boundingPolyConfig)
      : undefined;
    message.textClassificationConfig =
      (object.textClassificationConfig !== undefined && object.textClassificationConfig !== null)
        ? TextClassificationConfig.fromPartial(object.textClassificationConfig)
        : undefined;
    message.inputConfig = (object.inputConfig !== undefined && object.inputConfig !== null)
      ? InputConfig.fromPartial(object.inputConfig)
      : undefined;
    message.evaluationConfig = (object.evaluationConfig !== undefined && object.evaluationConfig !== null)
      ? EvaluationConfig.fromPartial(object.evaluationConfig)
      : undefined;
    message.humanAnnotationConfig =
      (object.humanAnnotationConfig !== undefined && object.humanAnnotationConfig !== null)
        ? HumanAnnotationConfig.fromPartial(object.humanAnnotationConfig)
        : undefined;
    message.bigqueryImportKeys = Object.entries(object.bigqueryImportKeys ?? {}).reduce<{ [key: string]: string }>(
      (acc, [key, value]) => {
        if (value !== undefined) {
          acc[key] = globalThis.String(value);
        }
        return acc;
      },
      {},
    );
    message.exampleCount = object.exampleCount ?? 0;
    message.exampleSamplePercentage = object.exampleSamplePercentage ?? 0;
    message.evaluationJobAlertConfig =
      (object.evaluationJobAlertConfig !== undefined && object.evaluationJobAlertConfig !== null)
        ? EvaluationJobAlertConfig.fromPartial(object.evaluationJobAlertConfig)
        : undefined;
    return message;
  },
};

function createBaseEvaluationJobConfig_BigqueryImportKeysEntry(): EvaluationJobConfig_BigqueryImportKeysEntry {
  return { key: "", value: "" };
}

export const EvaluationJobConfig_BigqueryImportKeysEntry: MessageFns<EvaluationJobConfig_BigqueryImportKeysEntry> = {
  encode(
    message: EvaluationJobConfig_BigqueryImportKeysEntry,
    writer: BinaryWriter = new BinaryWriter(),
  ): BinaryWriter {
    if (message.key !== "") {
      writer.uint32(10).string(message.key);
    }
    if (message.value !== "") {
      writer.uint32(18).string(message.value);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): EvaluationJobConfig_BigqueryImportKeysEntry {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseEvaluationJobConfig_BigqueryImportKeysEntry();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.key = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.value = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): EvaluationJobConfig_BigqueryImportKeysEntry {
    return {
      key: isSet(object.key) ? globalThis.String(object.key) : "",
      value: isSet(object.value) ? globalThis.String(object.value) : "",
    };
  },

  toJSON(message: EvaluationJobConfig_BigqueryImportKeysEntry): unknown {
    const obj: any = {};
    if (message.key !== "") {
      obj.key = message.key;
    }
    if (message.value !== "") {
      obj.value = message.value;
    }
    return obj;
  },

  create(base?: DeepPartial<EvaluationJobConfig_BigqueryImportKeysEntry>): EvaluationJobConfig_BigqueryImportKeysEntry {
    return EvaluationJobConfig_BigqueryImportKeysEntry.fromPartial(base ?? {});
  },
  fromPartial(
    object: DeepPartial<EvaluationJobConfig_BigqueryImportKeysEntry>,
  ): EvaluationJobConfig_BigqueryImportKeysEntry {
    const message = createBaseEvaluationJobConfig_BigqueryImportKeysEntry();
    message.key = object.key ?? "";
    message.value = object.value ?? "";
    return message;
  },
};

function createBaseEvaluationJobAlertConfig(): EvaluationJobAlertConfig {
  return { email: "", minAcceptableMeanAveragePrecision: 0 };
}

export const EvaluationJobAlertConfig: MessageFns<EvaluationJobAlertConfig> = {
  encode(message: EvaluationJobAlertConfig, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.email !== "") {
      writer.uint32(10).string(message.email);
    }
    if (message.minAcceptableMeanAveragePrecision !== 0) {
      writer.uint32(17).double(message.minAcceptableMeanAveragePrecision);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): EvaluationJobAlertConfig {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseEvaluationJobAlertConfig();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.email = reader.string();
          continue;
        case 2:
          if (tag !== 17) {
            break;
          }

          message.minAcceptableMeanAveragePrecision = reader.double();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): EvaluationJobAlertConfig {
    return {
      email: isSet(object.email) ? globalThis.String(object.email) : "",
      minAcceptableMeanAveragePrecision: isSet(object.minAcceptableMeanAveragePrecision)
        ? globalThis.Number(object.minAcceptableMeanAveragePrecision)
        : 0,
    };
  },

  toJSON(message: EvaluationJobAlertConfig): unknown {
    const obj: any = {};
    if (message.email !== "") {
      obj.email = message.email;
    }
    if (message.minAcceptableMeanAveragePrecision !== 0) {
      obj.minAcceptableMeanAveragePrecision = message.minAcceptableMeanAveragePrecision;
    }
    return obj;
  },

  create(base?: DeepPartial<EvaluationJobAlertConfig>): EvaluationJobAlertConfig {
    return EvaluationJobAlertConfig.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<EvaluationJobAlertConfig>): EvaluationJobAlertConfig {
    const message = createBaseEvaluationJobAlertConfig();
    message.email = object.email ?? "";
    message.minAcceptableMeanAveragePrecision = object.minAcceptableMeanAveragePrecision ?? 0;
    return message;
  },
};

function createBaseAttempt(): Attempt {
  return { attemptTime: undefined, partialFailures: [] };
}

export const Attempt: MessageFns<Attempt> = {
  encode(message: Attempt, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.attemptTime !== undefined) {
      Timestamp.encode(toTimestamp(message.attemptTime), writer.uint32(10).fork()).join();
    }
    for (const v of message.partialFailures) {
      Status.encode(v!, writer.uint32(18).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Attempt {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseAttempt();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.attemptTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.partialFailures.push(Status.decode(reader, reader.uint32()));
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Attempt {
    return {
      attemptTime: isSet(object.attemptTime) ? fromJsonTimestamp(object.attemptTime) : undefined,
      partialFailures: globalThis.Array.isArray(object?.partialFailures)
        ? object.partialFailures.map((e: any) => Status.fromJSON(e))
        : [],
    };
  },

  toJSON(message: Attempt): unknown {
    const obj: any = {};
    if (message.attemptTime !== undefined) {
      obj.attemptTime = message.attemptTime.toISOString();
    }
    if (message.partialFailures?.length) {
      obj.partialFailures = message.partialFailures.map((e) => Status.toJSON(e));
    }
    return obj;
  },

  create(base?: DeepPartial<Attempt>): Attempt {
    return Attempt.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<Attempt>): Attempt {
    const message = createBaseAttempt();
    message.attemptTime = object.attemptTime ?? undefined;
    message.partialFailures = object.partialFailures?.map((e) => Status.fromPartial(e)) || [];
    return message;
  },
};

type Builtin = Date | Function | Uint8Array | string | number | boolean | undefined;

export type DeepPartial<T> = T extends Builtin ? T
  : T extends Long ? string | number | Long : T extends globalThis.Array<infer U> ? globalThis.Array<DeepPartial<U>>
  : T extends ReadonlyArray<infer U> ? ReadonlyArray<DeepPartial<U>>
  : T extends {} ? { [K in keyof T]?: DeepPartial<T[K]> }
  : Partial<T>;

function toTimestamp(date: Date): Timestamp {
  const seconds = numberToLong(Math.trunc(date.getTime() / 1_000));
  const nanos = (date.getTime() % 1_000) * 1_000_000;
  return { seconds, nanos };
}

function fromTimestamp(t: Timestamp): Date {
  let millis = (t.seconds.toNumber() || 0) * 1_000;
  millis += (t.nanos || 0) / 1_000_000;
  return new globalThis.Date(millis);
}

function fromJsonTimestamp(o: any): Date {
  if (o instanceof globalThis.Date) {
    return o;
  } else if (typeof o === "string") {
    return new globalThis.Date(o);
  } else {
    return fromTimestamp(Timestamp.fromJSON(o));
  }
}

function numberToLong(number: number) {
  return Long.fromNumber(number);
}

function isObject(value: any): boolean {
  return typeof value === "object" && value !== null;
}

function isSet(value: any): boolean {
  return value !== null && value !== undefined;
}

export interface MessageFns<T> {
  encode(message: T, writer?: BinaryWriter): BinaryWriter;
  decode(input: BinaryReader | Uint8Array, length?: number): T;
  fromJSON(object: any): T;
  toJSON(message: T): unknown;
  create(base?: DeepPartial<T>): T;
  fromPartial(object: DeepPartial<T>): T;
}
