// Code generated by protoc-gen-ts_proto. DO NOT EDIT.
// versions:
//   protoc-gen-ts_proto  v2.2.0
//   protoc               unknown
// source: google/cloud/metastore/v1/metastore.proto

/* eslint-disable */
import { BinaryReader, BinaryWriter } from "@bufbuild/protobuf/wire";
import Long from "long";
import { type CallContext, type CallOptions } from "nice-grpc-common";
import { Operation } from "../../../longrunning/operations.js";
import { FieldMask } from "../../../protobuf/field_mask.js";
import { Timestamp } from "../../../protobuf/timestamp.js";
import { Int32Value } from "../../../protobuf/wrappers.js";
import { DayOfWeek, dayOfWeekFromJSON, dayOfWeekToJSON } from "../../../type/dayofweek.js";

export const protobufPackage = "google.cloud.metastore.v1";

/** A managed metastore service that serves metadata queries. */
export interface Service {
  /**
   * Configuration information specific to running Hive metastore
   * software as the metastore service.
   */
  hiveMetastoreConfig?:
    | HiveMetastoreConfig
    | undefined;
  /**
   * Immutable. The relative resource name of the metastore service, in the
   * following format:
   *
   * `projects/{project_number}/locations/{location_id}/services/{service_id}`.
   */
  name: string;
  /** Output only. The time when the metastore service was created. */
  createTime:
    | Date
    | undefined;
  /** Output only. The time when the metastore service was last updated. */
  updateTime:
    | Date
    | undefined;
  /** User-defined labels for the metastore service. */
  labels: { [key: string]: string };
  /**
   * Immutable. The relative resource name of the VPC network on which the
   * instance can be accessed. It is specified in the following form:
   *
   * `projects/{project_number}/global/networks/{network_id}`.
   */
  network: string;
  /** Output only. The URI of the endpoint used to access the metastore service. */
  endpointUri: string;
  /** The TCP port at which the metastore service is reached. Default: 9083. */
  port: number;
  /** Output only. The current state of the metastore service. */
  state: Service_State;
  /**
   * Output only. Additional information about the current state of the
   * metastore service, if available.
   */
  stateMessage: string;
  /**
   * Output only. A Cloud Storage URI (starting with `gs://`) that specifies
   * where artifacts related to the metastore service are stored.
   */
  artifactGcsUri: string;
  /** The tier of the service. */
  tier: Service_Tier;
  /**
   * The one hour maintenance window of the metastore service. This specifies
   * when the service can be restarted for maintenance purposes in UTC time.
   * Maintenance window is not needed for services with the SPANNER
   * database type.
   */
  maintenanceWindow:
    | MaintenanceWindow
    | undefined;
  /**
   * Output only. The globally unique resource identifier of the metastore
   * service.
   */
  uid: string;
  /** Output only. The metadata management activities of the metastore service. */
  metadataManagementActivity:
    | MetadataManagementActivity
    | undefined;
  /**
   * Immutable. The release channel of the service.
   * If unspecified, defaults to `STABLE`.
   */
  releaseChannel: Service_ReleaseChannel;
  /**
   * Immutable. Information used to configure the Dataproc Metastore service to
   * encrypt customer data at rest. Cannot be updated.
   */
  encryptionConfig:
    | EncryptionConfig
    | undefined;
  /**
   * The configuration specifying the network settings for the
   * Dataproc Metastore service.
   */
  networkConfig:
    | NetworkConfig
    | undefined;
  /** Immutable. The database type that the Metastore service stores its data. */
  databaseType: Service_DatabaseType;
  /**
   * The configuration specifying telemetry settings for the Dataproc Metastore
   * service. If unspecified defaults to `JSON`.
   */
  telemetryConfig:
    | TelemetryConfig
    | undefined;
  /** Scaling configuration of the metastore service. */
  scalingConfig: ScalingConfig | undefined;
}

/** The current state of the metastore service. */
export enum Service_State {
  /** STATE_UNSPECIFIED - The state of the metastore service is unknown. */
  STATE_UNSPECIFIED = 0,
  /** CREATING - The metastore service is in the process of being created. */
  CREATING = 1,
  /** ACTIVE - The metastore service is running and ready to serve queries. */
  ACTIVE = 2,
  /**
   * SUSPENDING - The metastore service is entering suspension. Its query-serving
   * availability may cease unexpectedly.
   */
  SUSPENDING = 3,
  /** SUSPENDED - The metastore service is suspended and unable to serve queries. */
  SUSPENDED = 4,
  /**
   * UPDATING - The metastore service is being updated. It remains usable but cannot
   * accept additional update requests or be deleted at this time.
   */
  UPDATING = 5,
  /** DELETING - The metastore service is undergoing deletion. It cannot be used. */
  DELETING = 6,
  /**
   * ERROR - The metastore service has encountered an error and cannot be used. The
   * metastore service should be deleted.
   */
  ERROR = 7,
  UNRECOGNIZED = -1,
}

export function service_StateFromJSON(object: any): Service_State {
  switch (object) {
    case 0:
    case "STATE_UNSPECIFIED":
      return Service_State.STATE_UNSPECIFIED;
    case 1:
    case "CREATING":
      return Service_State.CREATING;
    case 2:
    case "ACTIVE":
      return Service_State.ACTIVE;
    case 3:
    case "SUSPENDING":
      return Service_State.SUSPENDING;
    case 4:
    case "SUSPENDED":
      return Service_State.SUSPENDED;
    case 5:
    case "UPDATING":
      return Service_State.UPDATING;
    case 6:
    case "DELETING":
      return Service_State.DELETING;
    case 7:
    case "ERROR":
      return Service_State.ERROR;
    case -1:
    case "UNRECOGNIZED":
    default:
      return Service_State.UNRECOGNIZED;
  }
}

export function service_StateToJSON(object: Service_State): string {
  switch (object) {
    case Service_State.STATE_UNSPECIFIED:
      return "STATE_UNSPECIFIED";
    case Service_State.CREATING:
      return "CREATING";
    case Service_State.ACTIVE:
      return "ACTIVE";
    case Service_State.SUSPENDING:
      return "SUSPENDING";
    case Service_State.SUSPENDED:
      return "SUSPENDED";
    case Service_State.UPDATING:
      return "UPDATING";
    case Service_State.DELETING:
      return "DELETING";
    case Service_State.ERROR:
      return "ERROR";
    case Service_State.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/** Available service tiers. */
export enum Service_Tier {
  /** TIER_UNSPECIFIED - The tier is not set. */
  TIER_UNSPECIFIED = 0,
  /**
   * DEVELOPER - The developer tier provides limited scalability and no fault tolerance.
   * Good for low-cost proof-of-concept.
   */
  DEVELOPER = 1,
  /**
   * ENTERPRISE - The enterprise tier provides multi-zone high availability, and sufficient
   * scalability for enterprise-level Dataproc Metastore workloads.
   */
  ENTERPRISE = 3,
  UNRECOGNIZED = -1,
}

export function service_TierFromJSON(object: any): Service_Tier {
  switch (object) {
    case 0:
    case "TIER_UNSPECIFIED":
      return Service_Tier.TIER_UNSPECIFIED;
    case 1:
    case "DEVELOPER":
      return Service_Tier.DEVELOPER;
    case 3:
    case "ENTERPRISE":
      return Service_Tier.ENTERPRISE;
    case -1:
    case "UNRECOGNIZED":
    default:
      return Service_Tier.UNRECOGNIZED;
  }
}

export function service_TierToJSON(object: Service_Tier): string {
  switch (object) {
    case Service_Tier.TIER_UNSPECIFIED:
      return "TIER_UNSPECIFIED";
    case Service_Tier.DEVELOPER:
      return "DEVELOPER";
    case Service_Tier.ENTERPRISE:
      return "ENTERPRISE";
    case Service_Tier.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/**
 * Release channels bundle features of varying levels of stability. Newer
 * features may be introduced initially into less stable release channels and
 * can be automatically promoted into more stable release channels.
 */
export enum Service_ReleaseChannel {
  /** RELEASE_CHANNEL_UNSPECIFIED - Release channel is not specified. */
  RELEASE_CHANNEL_UNSPECIFIED = 0,
  /**
   * CANARY - The `CANARY` release channel contains the newest features, which may be
   * unstable and subject to unresolved issues with no known workarounds.
   * Services using the `CANARY` release channel are not subject to any SLAs.
   */
  CANARY = 1,
  /**
   * STABLE - The `STABLE` release channel contains features that are considered stable
   * and have been validated for production use.
   */
  STABLE = 2,
  UNRECOGNIZED = -1,
}

export function service_ReleaseChannelFromJSON(object: any): Service_ReleaseChannel {
  switch (object) {
    case 0:
    case "RELEASE_CHANNEL_UNSPECIFIED":
      return Service_ReleaseChannel.RELEASE_CHANNEL_UNSPECIFIED;
    case 1:
    case "CANARY":
      return Service_ReleaseChannel.CANARY;
    case 2:
    case "STABLE":
      return Service_ReleaseChannel.STABLE;
    case -1:
    case "UNRECOGNIZED":
    default:
      return Service_ReleaseChannel.UNRECOGNIZED;
  }
}

export function service_ReleaseChannelToJSON(object: Service_ReleaseChannel): string {
  switch (object) {
    case Service_ReleaseChannel.RELEASE_CHANNEL_UNSPECIFIED:
      return "RELEASE_CHANNEL_UNSPECIFIED";
    case Service_ReleaseChannel.CANARY:
      return "CANARY";
    case Service_ReleaseChannel.STABLE:
      return "STABLE";
    case Service_ReleaseChannel.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/** The backend database type for the metastore service. */
export enum Service_DatabaseType {
  /** DATABASE_TYPE_UNSPECIFIED - The DATABASE_TYPE is not set. */
  DATABASE_TYPE_UNSPECIFIED = 0,
  /** MYSQL - MySQL is used to persist the metastore data. */
  MYSQL = 1,
  /** SPANNER - Spanner is used to persist the metastore data. */
  SPANNER = 2,
  UNRECOGNIZED = -1,
}

export function service_DatabaseTypeFromJSON(object: any): Service_DatabaseType {
  switch (object) {
    case 0:
    case "DATABASE_TYPE_UNSPECIFIED":
      return Service_DatabaseType.DATABASE_TYPE_UNSPECIFIED;
    case 1:
    case "MYSQL":
      return Service_DatabaseType.MYSQL;
    case 2:
    case "SPANNER":
      return Service_DatabaseType.SPANNER;
    case -1:
    case "UNRECOGNIZED":
    default:
      return Service_DatabaseType.UNRECOGNIZED;
  }
}

export function service_DatabaseTypeToJSON(object: Service_DatabaseType): string {
  switch (object) {
    case Service_DatabaseType.DATABASE_TYPE_UNSPECIFIED:
      return "DATABASE_TYPE_UNSPECIFIED";
    case Service_DatabaseType.MYSQL:
      return "MYSQL";
    case Service_DatabaseType.SPANNER:
      return "SPANNER";
    case Service_DatabaseType.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

export interface Service_LabelsEntry {
  key: string;
  value: string;
}

/**
 * Maintenance window. This specifies when Dataproc Metastore
 * may perform system maintenance operation to the service.
 */
export interface MaintenanceWindow {
  /** The hour of day (0-23) when the window starts. */
  hourOfDay:
    | number
    | undefined;
  /** The day of week, when the window starts. */
  dayOfWeek: DayOfWeek;
}

/**
 * Specifies configuration information specific to running Hive metastore
 * software as the metastore service.
 */
export interface HiveMetastoreConfig {
  /** Immutable. The Hive metastore schema version. */
  version: string;
  /**
   * A mapping of Hive metastore configuration key-value pairs to apply to the
   * Hive metastore (configured in `hive-site.xml`). The mappings
   * override system defaults (some keys cannot be overridden). These
   * overrides are also applied to auxiliary versions and can be further
   * customized in the auxiliary version's `AuxiliaryVersionConfig`.
   */
  configOverrides: { [key: string]: string };
  /**
   * Information used to configure the Hive metastore service as a service
   * principal in a Kerberos realm. To disable Kerberos, use the `UpdateService`
   * method and specify this field's path
   * (`hive_metastore_config.kerberos_config`) in the request's `update_mask`
   * while omitting this field from the request's `service`.
   */
  kerberosConfig:
    | KerberosConfig
    | undefined;
  /**
   * The protocol to use for the metastore service endpoint. If unspecified,
   * defaults to `THRIFT`.
   */
  endpointProtocol: HiveMetastoreConfig_EndpointProtocol;
  /**
   * A mapping of Hive metastore version to the auxiliary version
   * configuration. When specified, a secondary Hive metastore service is
   * created along with the primary service. All auxiliary versions must be less
   * than the service's primary version. The key is the auxiliary service name
   * and it must match the regular expression [a-z]([-a-z0-9]*[a-z0-9])?. This
   * means that the first character must be a lowercase letter, and all the
   * following characters must be hyphens, lowercase letters, or digits, except
   * the last character, which cannot be a hyphen.
   */
  auxiliaryVersions: { [key: string]: AuxiliaryVersionConfig };
}

/** Protocols available for serving the metastore service endpoint. */
export enum HiveMetastoreConfig_EndpointProtocol {
  /** ENDPOINT_PROTOCOL_UNSPECIFIED - The protocol is not set. */
  ENDPOINT_PROTOCOL_UNSPECIFIED = 0,
  /** THRIFT - Use the legacy Apache Thrift protocol for the metastore service endpoint. */
  THRIFT = 1,
  /** GRPC - Use the modernized gRPC protocol for the metastore service endpoint. */
  GRPC = 2,
  UNRECOGNIZED = -1,
}

export function hiveMetastoreConfig_EndpointProtocolFromJSON(object: any): HiveMetastoreConfig_EndpointProtocol {
  switch (object) {
    case 0:
    case "ENDPOINT_PROTOCOL_UNSPECIFIED":
      return HiveMetastoreConfig_EndpointProtocol.ENDPOINT_PROTOCOL_UNSPECIFIED;
    case 1:
    case "THRIFT":
      return HiveMetastoreConfig_EndpointProtocol.THRIFT;
    case 2:
    case "GRPC":
      return HiveMetastoreConfig_EndpointProtocol.GRPC;
    case -1:
    case "UNRECOGNIZED":
    default:
      return HiveMetastoreConfig_EndpointProtocol.UNRECOGNIZED;
  }
}

export function hiveMetastoreConfig_EndpointProtocolToJSON(object: HiveMetastoreConfig_EndpointProtocol): string {
  switch (object) {
    case HiveMetastoreConfig_EndpointProtocol.ENDPOINT_PROTOCOL_UNSPECIFIED:
      return "ENDPOINT_PROTOCOL_UNSPECIFIED";
    case HiveMetastoreConfig_EndpointProtocol.THRIFT:
      return "THRIFT";
    case HiveMetastoreConfig_EndpointProtocol.GRPC:
      return "GRPC";
    case HiveMetastoreConfig_EndpointProtocol.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

export interface HiveMetastoreConfig_ConfigOverridesEntry {
  key: string;
  value: string;
}

export interface HiveMetastoreConfig_AuxiliaryVersionsEntry {
  key: string;
  value: AuxiliaryVersionConfig | undefined;
}

/** Configuration information for a Kerberos principal. */
export interface KerberosConfig {
  /**
   * A Kerberos keytab file that can be used to authenticate a service principal
   * with a Kerberos Key Distribution Center (KDC).
   */
  keytab:
    | Secret
    | undefined;
  /**
   * A Kerberos principal that exists in the both the keytab the KDC
   * to authenticate as. A typical principal is of the form
   * `primary/instance@REALM`, but there is no exact format.
   */
  principal: string;
  /**
   * A Cloud Storage URI that specifies the path to a
   * krb5.conf file. It is of the form `gs://{bucket_name}/path/to/krb5.conf`,
   * although the file does not need to be named krb5.conf explicitly.
   */
  krb5ConfigGcsUri: string;
}

/** A securely stored value. */
export interface Secret {
  /**
   * The relative resource name of a Secret Manager secret version, in the
   * following form:
   *
   * `projects/{project_number}/secrets/{secret_id}/versions/{version_id}`.
   */
  cloudSecret?: string | undefined;
}

/** Encryption settings for the service. */
export interface EncryptionConfig {
  /**
   * The fully qualified customer provided Cloud KMS key name to use for
   * customer data encryption, in the following form:
   *
   * `projects/{project_number}/locations/{location_id}/keyRings/{key_ring_id}/cryptoKeys/{crypto_key_id}`.
   */
  kmsKey: string;
}

/** Configuration information for the auxiliary service versions. */
export interface AuxiliaryVersionConfig {
  /**
   * The Hive metastore version of the auxiliary service. It must be less
   * than the primary Hive metastore service's version.
   */
  version: string;
  /**
   * A mapping of Hive metastore configuration key-value pairs to apply to the
   * auxiliary Hive metastore (configured in `hive-site.xml`) in addition to
   * the primary version's overrides. If keys are present in both the auxiliary
   * version's overrides and the primary version's overrides, the value from
   * the auxiliary version's overrides takes precedence.
   */
  configOverrides: { [key: string]: string };
  /**
   * Output only. The network configuration contains the endpoint URI(s) of the
   * auxiliary Hive metastore service.
   */
  networkConfig: NetworkConfig | undefined;
}

export interface AuxiliaryVersionConfig_ConfigOverridesEntry {
  key: string;
  value: string;
}

/**
 * Network configuration for the Dataproc Metastore service.
 *
 * Next available ID: 4
 */
export interface NetworkConfig {
  /**
   * Immutable. The consumer-side network configuration for the Dataproc
   * Metastore instance.
   */
  consumers: NetworkConfig_Consumer[];
}

/**
 * Contains information of the customer's network configurations.
 *
 * Next available ID: 5
 */
export interface NetworkConfig_Consumer {
  /**
   * Immutable. The subnetwork of the customer project from which an IP
   * address is reserved and used as the Dataproc Metastore service's
   * endpoint. It is accessible to hosts in the subnet and to all
   * hosts in a subnet in the same region and same network. There must
   * be at least one IP address available in the subnet's primary range. The
   * subnet is specified in the following form:
   *
   * `projects/{project_number}/regions/{region_id}/subnetworks/{subnetwork_id}`
   */
  subnetwork?:
    | string
    | undefined;
  /**
   * Output only. The URI of the endpoint used to access the metastore
   * service.
   */
  endpointUri: string;
  /**
   * Output only. The location of the endpoint URI. Format:
   * `projects/{project}/locations/{location}`.
   */
  endpointLocation: string;
}

/** Telemetry Configuration for the Dataproc Metastore service. */
export interface TelemetryConfig {
  /** The output format of the Dataproc Metastore service's logs. */
  logFormat: TelemetryConfig_LogFormat;
}

export enum TelemetryConfig_LogFormat {
  /** LOG_FORMAT_UNSPECIFIED - The LOG_FORMAT is not set. */
  LOG_FORMAT_UNSPECIFIED = 0,
  /** LEGACY - Logging output uses the legacy `textPayload` format. */
  LEGACY = 1,
  /** JSON - Logging output uses the `jsonPayload` format. */
  JSON = 2,
  UNRECOGNIZED = -1,
}

export function telemetryConfig_LogFormatFromJSON(object: any): TelemetryConfig_LogFormat {
  switch (object) {
    case 0:
    case "LOG_FORMAT_UNSPECIFIED":
      return TelemetryConfig_LogFormat.LOG_FORMAT_UNSPECIFIED;
    case 1:
    case "LEGACY":
      return TelemetryConfig_LogFormat.LEGACY;
    case 2:
    case "JSON":
      return TelemetryConfig_LogFormat.JSON;
    case -1:
    case "UNRECOGNIZED":
    default:
      return TelemetryConfig_LogFormat.UNRECOGNIZED;
  }
}

export function telemetryConfig_LogFormatToJSON(object: TelemetryConfig_LogFormat): string {
  switch (object) {
    case TelemetryConfig_LogFormat.LOG_FORMAT_UNSPECIFIED:
      return "LOG_FORMAT_UNSPECIFIED";
    case TelemetryConfig_LogFormat.LEGACY:
      return "LEGACY";
    case TelemetryConfig_LogFormat.JSON:
      return "JSON";
    case TelemetryConfig_LogFormat.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/** The metadata management activities of the metastore service. */
export interface MetadataManagementActivity {
  /** Output only. The latest metadata exports of the metastore service. */
  metadataExports: MetadataExport[];
  /** Output only. The latest restores of the metastore service. */
  restores: Restore[];
}

/** A metastore resource that imports metadata. */
export interface MetadataImport {
  /** Immutable. A database dump from a pre-existing metastore's database. */
  databaseDump?:
    | MetadataImport_DatabaseDump
    | undefined;
  /**
   * Immutable. The relative resource name of the metadata import, of the form:
   *
   * `projects/{project_number}/locations/{location_id}/services/{service_id}/metadataImports/{metadata_import_id}`.
   */
  name: string;
  /** The description of the metadata import. */
  description: string;
  /** Output only. The time when the metadata import was started. */
  createTime:
    | Date
    | undefined;
  /** Output only. The time when the metadata import was last updated. */
  updateTime:
    | Date
    | undefined;
  /** Output only. The time when the metadata import finished. */
  endTime:
    | Date
    | undefined;
  /** Output only. The current state of the metadata import. */
  state: MetadataImport_State;
}

/** The current state of the metadata import. */
export enum MetadataImport_State {
  /** STATE_UNSPECIFIED - The state of the metadata import is unknown. */
  STATE_UNSPECIFIED = 0,
  /** RUNNING - The metadata import is running. */
  RUNNING = 1,
  /** SUCCEEDED - The metadata import completed successfully. */
  SUCCEEDED = 2,
  /** UPDATING - The metadata import is being updated. */
  UPDATING = 3,
  /**
   * FAILED - The metadata import failed, and attempted metadata changes were rolled
   * back.
   */
  FAILED = 4,
  UNRECOGNIZED = -1,
}

export function metadataImport_StateFromJSON(object: any): MetadataImport_State {
  switch (object) {
    case 0:
    case "STATE_UNSPECIFIED":
      return MetadataImport_State.STATE_UNSPECIFIED;
    case 1:
    case "RUNNING":
      return MetadataImport_State.RUNNING;
    case 2:
    case "SUCCEEDED":
      return MetadataImport_State.SUCCEEDED;
    case 3:
    case "UPDATING":
      return MetadataImport_State.UPDATING;
    case 4:
    case "FAILED":
      return MetadataImport_State.FAILED;
    case -1:
    case "UNRECOGNIZED":
    default:
      return MetadataImport_State.UNRECOGNIZED;
  }
}

export function metadataImport_StateToJSON(object: MetadataImport_State): string {
  switch (object) {
    case MetadataImport_State.STATE_UNSPECIFIED:
      return "STATE_UNSPECIFIED";
    case MetadataImport_State.RUNNING:
      return "RUNNING";
    case MetadataImport_State.SUCCEEDED:
      return "SUCCEEDED";
    case MetadataImport_State.UPDATING:
      return "UPDATING";
    case MetadataImport_State.FAILED:
      return "FAILED";
    case MetadataImport_State.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/**
 * A specification of the location of and metadata about a database dump from
 * a relational database management system.
 */
export interface MetadataImport_DatabaseDump {
  /**
   * The type of the database.
   *
   * @deprecated
   */
  databaseType: MetadataImport_DatabaseDump_DatabaseType;
  /**
   * A Cloud Storage object or folder URI that specifies the source from which
   * to import metadata. It must begin with `gs://`.
   */
  gcsUri: string;
  /**
   * The name of the source database.
   *
   * @deprecated
   */
  sourceDatabase: string;
  /**
   * Optional. The type of the database dump. If unspecified, defaults to
   * `MYSQL`.
   */
  type: DatabaseDumpSpec_Type;
}

/** The type of the database. */
export enum MetadataImport_DatabaseDump_DatabaseType {
  /** DATABASE_TYPE_UNSPECIFIED - The type of the source database is unknown. */
  DATABASE_TYPE_UNSPECIFIED = 0,
  /** MYSQL - The type of the source database is MySQL. */
  MYSQL = 1,
  UNRECOGNIZED = -1,
}

export function metadataImport_DatabaseDump_DatabaseTypeFromJSON(
  object: any,
): MetadataImport_DatabaseDump_DatabaseType {
  switch (object) {
    case 0:
    case "DATABASE_TYPE_UNSPECIFIED":
      return MetadataImport_DatabaseDump_DatabaseType.DATABASE_TYPE_UNSPECIFIED;
    case 1:
    case "MYSQL":
      return MetadataImport_DatabaseDump_DatabaseType.MYSQL;
    case -1:
    case "UNRECOGNIZED":
    default:
      return MetadataImport_DatabaseDump_DatabaseType.UNRECOGNIZED;
  }
}

export function metadataImport_DatabaseDump_DatabaseTypeToJSON(
  object: MetadataImport_DatabaseDump_DatabaseType,
): string {
  switch (object) {
    case MetadataImport_DatabaseDump_DatabaseType.DATABASE_TYPE_UNSPECIFIED:
      return "DATABASE_TYPE_UNSPECIFIED";
    case MetadataImport_DatabaseDump_DatabaseType.MYSQL:
      return "MYSQL";
    case MetadataImport_DatabaseDump_DatabaseType.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/** The details of a metadata export operation. */
export interface MetadataExport {
  /**
   * Output only. A Cloud Storage URI of a folder that metadata are exported
   * to, in the form of
   * `gs://<bucket_name>/<path_inside_bucket>/<export_folder>`, where
   * `<export_folder>` is automatically generated.
   */
  destinationGcsUri?:
    | string
    | undefined;
  /** Output only. The time when the export started. */
  startTime:
    | Date
    | undefined;
  /** Output only. The time when the export ended. */
  endTime:
    | Date
    | undefined;
  /** Output only. The current state of the export. */
  state: MetadataExport_State;
  /** Output only. The type of the database dump. */
  databaseDumpType: DatabaseDumpSpec_Type;
}

/** The current state of the metadata export. */
export enum MetadataExport_State {
  /** STATE_UNSPECIFIED - The state of the metadata export is unknown. */
  STATE_UNSPECIFIED = 0,
  /** RUNNING - The metadata export is running. */
  RUNNING = 1,
  /** SUCCEEDED - The metadata export completed successfully. */
  SUCCEEDED = 2,
  /** FAILED - The metadata export failed. */
  FAILED = 3,
  /** CANCELLED - The metadata export is cancelled. */
  CANCELLED = 4,
  UNRECOGNIZED = -1,
}

export function metadataExport_StateFromJSON(object: any): MetadataExport_State {
  switch (object) {
    case 0:
    case "STATE_UNSPECIFIED":
      return MetadataExport_State.STATE_UNSPECIFIED;
    case 1:
    case "RUNNING":
      return MetadataExport_State.RUNNING;
    case 2:
    case "SUCCEEDED":
      return MetadataExport_State.SUCCEEDED;
    case 3:
    case "FAILED":
      return MetadataExport_State.FAILED;
    case 4:
    case "CANCELLED":
      return MetadataExport_State.CANCELLED;
    case -1:
    case "UNRECOGNIZED":
    default:
      return MetadataExport_State.UNRECOGNIZED;
  }
}

export function metadataExport_StateToJSON(object: MetadataExport_State): string {
  switch (object) {
    case MetadataExport_State.STATE_UNSPECIFIED:
      return "STATE_UNSPECIFIED";
    case MetadataExport_State.RUNNING:
      return "RUNNING";
    case MetadataExport_State.SUCCEEDED:
      return "SUCCEEDED";
    case MetadataExport_State.FAILED:
      return "FAILED";
    case MetadataExport_State.CANCELLED:
      return "CANCELLED";
    case MetadataExport_State.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/** The details of a backup resource. */
export interface Backup {
  /**
   * Immutable. The relative resource name of the backup, in the following form:
   *
   * `projects/{project_number}/locations/{location_id}/services/{service_id}/backups/{backup_id}`
   */
  name: string;
  /** Output only. The time when the backup was started. */
  createTime:
    | Date
    | undefined;
  /** Output only. The time when the backup finished creating. */
  endTime:
    | Date
    | undefined;
  /** Output only. The current state of the backup. */
  state: Backup_State;
  /** Output only. The revision of the service at the time of backup. */
  serviceRevision:
    | Service
    | undefined;
  /** The description of the backup. */
  description: string;
  /** Output only. Services that are restoring from the backup. */
  restoringServices: string[];
}

/** The current state of the backup. */
export enum Backup_State {
  /** STATE_UNSPECIFIED - The state of the backup is unknown. */
  STATE_UNSPECIFIED = 0,
  /** CREATING - The backup is being created. */
  CREATING = 1,
  /** DELETING - The backup is being deleted. */
  DELETING = 2,
  /** ACTIVE - The backup is active and ready to use. */
  ACTIVE = 3,
  /** FAILED - The backup failed. */
  FAILED = 4,
  /** RESTORING - The backup is being restored. */
  RESTORING = 5,
  UNRECOGNIZED = -1,
}

export function backup_StateFromJSON(object: any): Backup_State {
  switch (object) {
    case 0:
    case "STATE_UNSPECIFIED":
      return Backup_State.STATE_UNSPECIFIED;
    case 1:
    case "CREATING":
      return Backup_State.CREATING;
    case 2:
    case "DELETING":
      return Backup_State.DELETING;
    case 3:
    case "ACTIVE":
      return Backup_State.ACTIVE;
    case 4:
    case "FAILED":
      return Backup_State.FAILED;
    case 5:
    case "RESTORING":
      return Backup_State.RESTORING;
    case -1:
    case "UNRECOGNIZED":
    default:
      return Backup_State.UNRECOGNIZED;
  }
}

export function backup_StateToJSON(object: Backup_State): string {
  switch (object) {
    case Backup_State.STATE_UNSPECIFIED:
      return "STATE_UNSPECIFIED";
    case Backup_State.CREATING:
      return "CREATING";
    case Backup_State.DELETING:
      return "DELETING";
    case Backup_State.ACTIVE:
      return "ACTIVE";
    case Backup_State.FAILED:
      return "FAILED";
    case Backup_State.RESTORING:
      return "RESTORING";
    case Backup_State.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/** The details of a metadata restore operation. */
export interface Restore {
  /** Output only. The time when the restore started. */
  startTime:
    | Date
    | undefined;
  /** Output only. The time when the restore ended. */
  endTime:
    | Date
    | undefined;
  /** Output only. The current state of the restore. */
  state: Restore_State;
  /**
   * Output only. The relative resource name of the metastore service backup to
   * restore from, in the following form:
   *
   * `projects/{project_id}/locations/{location_id}/services/{service_id}/backups/{backup_id}`.
   */
  backup: string;
  /** Output only. The type of restore. */
  type: Restore_RestoreType;
  /**
   * Output only. The restore details containing the revision of the service to
   * be restored to, in format of JSON.
   */
  details: string;
}

/** The current state of the restore. */
export enum Restore_State {
  /** STATE_UNSPECIFIED - The state of the metadata restore is unknown. */
  STATE_UNSPECIFIED = 0,
  /** RUNNING - The metadata restore is running. */
  RUNNING = 1,
  /** SUCCEEDED - The metadata restore completed successfully. */
  SUCCEEDED = 2,
  /** FAILED - The metadata restore failed. */
  FAILED = 3,
  /** CANCELLED - The metadata restore is cancelled. */
  CANCELLED = 4,
  UNRECOGNIZED = -1,
}

export function restore_StateFromJSON(object: any): Restore_State {
  switch (object) {
    case 0:
    case "STATE_UNSPECIFIED":
      return Restore_State.STATE_UNSPECIFIED;
    case 1:
    case "RUNNING":
      return Restore_State.RUNNING;
    case 2:
    case "SUCCEEDED":
      return Restore_State.SUCCEEDED;
    case 3:
    case "FAILED":
      return Restore_State.FAILED;
    case 4:
    case "CANCELLED":
      return Restore_State.CANCELLED;
    case -1:
    case "UNRECOGNIZED":
    default:
      return Restore_State.UNRECOGNIZED;
  }
}

export function restore_StateToJSON(object: Restore_State): string {
  switch (object) {
    case Restore_State.STATE_UNSPECIFIED:
      return "STATE_UNSPECIFIED";
    case Restore_State.RUNNING:
      return "RUNNING";
    case Restore_State.SUCCEEDED:
      return "SUCCEEDED";
    case Restore_State.FAILED:
      return "FAILED";
    case Restore_State.CANCELLED:
      return "CANCELLED";
    case Restore_State.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/** The type of restore. If unspecified, defaults to `METADATA_ONLY`. */
export enum Restore_RestoreType {
  /** RESTORE_TYPE_UNSPECIFIED - The restore type is unknown. */
  RESTORE_TYPE_UNSPECIFIED = 0,
  /** FULL - The service's metadata and configuration are restored. */
  FULL = 1,
  /** METADATA_ONLY - Only the service's metadata is restored. */
  METADATA_ONLY = 2,
  UNRECOGNIZED = -1,
}

export function restore_RestoreTypeFromJSON(object: any): Restore_RestoreType {
  switch (object) {
    case 0:
    case "RESTORE_TYPE_UNSPECIFIED":
      return Restore_RestoreType.RESTORE_TYPE_UNSPECIFIED;
    case 1:
    case "FULL":
      return Restore_RestoreType.FULL;
    case 2:
    case "METADATA_ONLY":
      return Restore_RestoreType.METADATA_ONLY;
    case -1:
    case "UNRECOGNIZED":
    default:
      return Restore_RestoreType.UNRECOGNIZED;
  }
}

export function restore_RestoreTypeToJSON(object: Restore_RestoreType): string {
  switch (object) {
    case Restore_RestoreType.RESTORE_TYPE_UNSPECIFIED:
      return "RESTORE_TYPE_UNSPECIFIED";
    case Restore_RestoreType.FULL:
      return "FULL";
    case Restore_RestoreType.METADATA_ONLY:
      return "METADATA_ONLY";
    case Restore_RestoreType.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/** Represents the scaling configuration of a metastore service. */
export interface ScalingConfig {
  /**
   * An enum of readable instance sizes, with each instance size mapping to a
   * float value (e.g. InstanceSize.EXTRA_SMALL = scaling_factor(0.1))
   */
  instanceSize?:
    | ScalingConfig_InstanceSize
    | undefined;
  /**
   * Scaling factor, increments of 0.1 for values less than 1.0, and
   * increments of 1.0 for values greater than 1.0.
   */
  scalingFactor?: number | undefined;
}

/** Metastore instance sizes. */
export enum ScalingConfig_InstanceSize {
  /** INSTANCE_SIZE_UNSPECIFIED - Unspecified instance size */
  INSTANCE_SIZE_UNSPECIFIED = 0,
  /** EXTRA_SMALL - Extra small instance size, maps to a scaling factor of 0.1. */
  EXTRA_SMALL = 1,
  /** SMALL - Small instance size, maps to a scaling factor of 0.5. */
  SMALL = 2,
  /** MEDIUM - Medium instance size, maps to a scaling factor of 1.0. */
  MEDIUM = 3,
  /** LARGE - Large instance size, maps to a scaling factor of 3.0. */
  LARGE = 4,
  /** EXTRA_LARGE - Extra large instance size, maps to a scaling factor of 6.0. */
  EXTRA_LARGE = 5,
  UNRECOGNIZED = -1,
}

export function scalingConfig_InstanceSizeFromJSON(object: any): ScalingConfig_InstanceSize {
  switch (object) {
    case 0:
    case "INSTANCE_SIZE_UNSPECIFIED":
      return ScalingConfig_InstanceSize.INSTANCE_SIZE_UNSPECIFIED;
    case 1:
    case "EXTRA_SMALL":
      return ScalingConfig_InstanceSize.EXTRA_SMALL;
    case 2:
    case "SMALL":
      return ScalingConfig_InstanceSize.SMALL;
    case 3:
    case "MEDIUM":
      return ScalingConfig_InstanceSize.MEDIUM;
    case 4:
    case "LARGE":
      return ScalingConfig_InstanceSize.LARGE;
    case 5:
    case "EXTRA_LARGE":
      return ScalingConfig_InstanceSize.EXTRA_LARGE;
    case -1:
    case "UNRECOGNIZED":
    default:
      return ScalingConfig_InstanceSize.UNRECOGNIZED;
  }
}

export function scalingConfig_InstanceSizeToJSON(object: ScalingConfig_InstanceSize): string {
  switch (object) {
    case ScalingConfig_InstanceSize.INSTANCE_SIZE_UNSPECIFIED:
      return "INSTANCE_SIZE_UNSPECIFIED";
    case ScalingConfig_InstanceSize.EXTRA_SMALL:
      return "EXTRA_SMALL";
    case ScalingConfig_InstanceSize.SMALL:
      return "SMALL";
    case ScalingConfig_InstanceSize.MEDIUM:
      return "MEDIUM";
    case ScalingConfig_InstanceSize.LARGE:
      return "LARGE";
    case ScalingConfig_InstanceSize.EXTRA_LARGE:
      return "EXTRA_LARGE";
    case ScalingConfig_InstanceSize.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/**
 * Request message for
 * [DataprocMetastore.ListServices][google.cloud.metastore.v1.DataprocMetastore.ListServices].
 */
export interface ListServicesRequest {
  /**
   * Required. The relative resource name of the location of metastore services
   * to list, in the following form:
   *
   * `projects/{project_number}/locations/{location_id}`.
   */
  parent: string;
  /**
   * Optional. The maximum number of services to return. The response may
   * contain less than the maximum number. If unspecified, no more than 500
   * services are returned. The maximum value is 1000; values above 1000 are
   * changed to 1000.
   */
  pageSize: number;
  /**
   * Optional. A page token, received from a previous
   * [DataprocMetastore.ListServices][google.cloud.metastore.v1.DataprocMetastore.ListServices]
   * call. Provide this token to retrieve the subsequent page.
   *
   * To retrieve the first page, supply an empty page token.
   *
   * When paginating, other parameters provided to
   * [DataprocMetastore.ListServices][google.cloud.metastore.v1.DataprocMetastore.ListServices]
   * must match the call that provided the page token.
   */
  pageToken: string;
  /** Optional. The filter to apply to list results. */
  filter: string;
  /**
   * Optional. Specify the ordering of results as described in [Sorting
   * Order](https://cloud.google.com/apis/design/design_patterns#sorting_order).
   * If not specified, the results will be sorted in the default order.
   */
  orderBy: string;
}

/**
 * Response message for
 * [DataprocMetastore.ListServices][google.cloud.metastore.v1.DataprocMetastore.ListServices].
 */
export interface ListServicesResponse {
  /** The services in the specified location. */
  services: Service[];
  /**
   * A token that can be sent as `page_token` to retrieve the next page. If this
   * field is omitted, there are no subsequent pages.
   */
  nextPageToken: string;
  /** Locations that could not be reached. */
  unreachable: string[];
}

/**
 * Request message for
 * [DataprocMetastore.GetService][google.cloud.metastore.v1.DataprocMetastore.GetService].
 */
export interface GetServiceRequest {
  /**
   * Required. The relative resource name of the metastore service to retrieve,
   * in the following form:
   *
   * `projects/{project_number}/locations/{location_id}/services/{service_id}`.
   */
  name: string;
}

/**
 * Request message for
 * [DataprocMetastore.CreateService][google.cloud.metastore.v1.DataprocMetastore.CreateService].
 */
export interface CreateServiceRequest {
  /**
   * Required. The relative resource name of the location in which to create a
   * metastore service, in the following form:
   *
   * `projects/{project_number}/locations/{location_id}`.
   */
  parent: string;
  /**
   * Required. The ID of the metastore service, which is used as the final
   * component of the metastore service's name.
   *
   * This value must be between 2 and 63 characters long inclusive, begin with a
   * letter, end with a letter or number, and consist of alpha-numeric
   * ASCII characters or hyphens.
   */
  serviceId: string;
  /**
   * Required. The Metastore service to create. The `name` field is
   * ignored. The ID of the created metastore service must be provided in
   * the request's `service_id` field.
   */
  service:
    | Service
    | undefined;
  /**
   * Optional. A request ID. Specify a unique request ID to allow the server to
   * ignore the request if it has completed. The server will ignore subsequent
   * requests that provide a duplicate request ID for at least 60 minutes after
   * the first request.
   *
   * For example, if an initial request times out, followed by another request
   * with the same request ID, the server ignores the second request to prevent
   * the creation of duplicate commitments.
   *
   * The request ID must be a valid
   * [UUID](https://en.wikipedia.org/wiki/Universally_unique_identifier#Format)
   * A zero UUID (00000000-0000-0000-0000-000000000000) is not supported.
   */
  requestId: string;
}

/**
 * Request message for
 * [DataprocMetastore.UpdateService][google.cloud.metastore.v1.DataprocMetastore.UpdateService].
 */
export interface UpdateServiceRequest {
  /**
   * Required. A field mask used to specify the fields to be overwritten in the
   * metastore service resource by the update.
   * Fields specified in the `update_mask` are relative to the resource (not
   * to the full request). A field is overwritten if it is in the mask.
   */
  updateMask:
    | string[]
    | undefined;
  /**
   * Required. The metastore service to update. The server only merges fields
   * in the service if they are specified in `update_mask`.
   *
   * The metastore service's `name` field is used to identify the metastore
   * service to be updated.
   */
  service:
    | Service
    | undefined;
  /**
   * Optional. A request ID. Specify a unique request ID to allow the server to
   * ignore the request if it has completed. The server will ignore subsequent
   * requests that provide a duplicate request ID for at least 60 minutes after
   * the first request.
   *
   * For example, if an initial request times out, followed by another request
   * with the same request ID, the server ignores the second request to prevent
   * the creation of duplicate commitments.
   *
   * The request ID must be a valid
   * [UUID](https://en.wikipedia.org/wiki/Universally_unique_identifier#Format)
   * A zero UUID (00000000-0000-0000-0000-000000000000) is not supported.
   */
  requestId: string;
}

/**
 * Request message for
 * [DataprocMetastore.DeleteService][google.cloud.metastore.v1.DataprocMetastore.DeleteService].
 */
export interface DeleteServiceRequest {
  /**
   * Required. The relative resource name of the metastore service to delete, in
   * the following form:
   *
   * `projects/{project_number}/locations/{location_id}/services/{service_id}`.
   */
  name: string;
  /**
   * Optional. A request ID. Specify a unique request ID to allow the server to
   * ignore the request if it has completed. The server will ignore subsequent
   * requests that provide a duplicate request ID for at least 60 minutes after
   * the first request.
   *
   * For example, if an initial request times out, followed by another request
   * with the same request ID, the server ignores the second request to prevent
   * the creation of duplicate commitments.
   *
   * The request ID must be a valid
   * [UUID](https://en.wikipedia.org/wiki/Universally_unique_identifier#Format)
   * A zero UUID (00000000-0000-0000-0000-000000000000) is not supported.
   */
  requestId: string;
}

/**
 * Request message for
 * [DataprocMetastore.ListMetadataImports][google.cloud.metastore.v1.DataprocMetastore.ListMetadataImports].
 */
export interface ListMetadataImportsRequest {
  /**
   * Required. The relative resource name of the service whose metadata imports
   * to list, in the following form:
   *
   * `projects/{project_number}/locations/{location_id}/services/{service_id}/metadataImports`.
   */
  parent: string;
  /**
   * Optional. The maximum number of imports to return. The response may contain
   * less than the maximum number. If unspecified, no more than 500 imports are
   * returned. The maximum value is 1000; values above 1000 are changed to 1000.
   */
  pageSize: number;
  /**
   * Optional. A page token, received from a previous
   * [DataprocMetastore.ListServices][google.cloud.metastore.v1.DataprocMetastore.ListServices]
   * call. Provide this token to retrieve the subsequent page.
   *
   * To retrieve the first page, supply an empty page token.
   *
   * When paginating, other parameters provided to
   * [DataprocMetastore.ListServices][google.cloud.metastore.v1.DataprocMetastore.ListServices]
   * must match the call that provided the page token.
   */
  pageToken: string;
  /** Optional. The filter to apply to list results. */
  filter: string;
  /**
   * Optional. Specify the ordering of results as described in [Sorting
   * Order](https://cloud.google.com/apis/design/design_patterns#sorting_order).
   * If not specified, the results will be sorted in the default order.
   */
  orderBy: string;
}

/**
 * Response message for
 * [DataprocMetastore.ListMetadataImports][google.cloud.metastore.v1.DataprocMetastore.ListMetadataImports].
 */
export interface ListMetadataImportsResponse {
  /** The imports in the specified service. */
  metadataImports: MetadataImport[];
  /**
   * A token that can be sent as `page_token` to retrieve the next page. If this
   * field is omitted, there are no subsequent pages.
   */
  nextPageToken: string;
  /** Locations that could not be reached. */
  unreachable: string[];
}

/**
 * Request message for
 * [DataprocMetastore.GetMetadataImport][google.cloud.metastore.v1.DataprocMetastore.GetMetadataImport].
 */
export interface GetMetadataImportRequest {
  /**
   * Required. The relative resource name of the metadata import to retrieve, in
   * the following form:
   *
   * `projects/{project_number}/locations/{location_id}/services/{service_id}/metadataImports/{import_id}`.
   */
  name: string;
}

/**
 * Request message for
 * [DataprocMetastore.CreateMetadataImport][google.cloud.metastore.v1.DataprocMetastore.CreateMetadataImport].
 */
export interface CreateMetadataImportRequest {
  /**
   * Required. The relative resource name of the service in which to create a
   * metastore import, in the following form:
   *
   * `projects/{project_number}/locations/{location_id}/services/{service_id}`.
   */
  parent: string;
  /**
   * Required. The ID of the metadata import, which is used as the final
   * component of the metadata import's name.
   *
   * This value must be between 1 and 64 characters long, begin with a letter,
   * end with a letter or number, and consist of alpha-numeric ASCII characters
   * or hyphens.
   */
  metadataImportId: string;
  /**
   * Required. The metadata import to create. The `name` field is ignored. The
   * ID of the created metadata import must be provided in the request's
   * `metadata_import_id` field.
   */
  metadataImport:
    | MetadataImport
    | undefined;
  /**
   * Optional. A request ID. Specify a unique request ID to allow the server to
   * ignore the request if it has completed. The server will ignore subsequent
   * requests that provide a duplicate request ID for at least 60 minutes after
   * the first request.
   *
   * For example, if an initial request times out, followed by another request
   * with the same request ID, the server ignores the second request to prevent
   * the creation of duplicate commitments.
   *
   * The request ID must be a valid
   * [UUID](https://en.wikipedia.org/wiki/Universally_unique_identifier#Format)
   * A zero UUID (00000000-0000-0000-0000-000000000000) is not supported.
   */
  requestId: string;
}

/**
 * Request message for
 * [DataprocMetastore.UpdateMetadataImport][google.cloud.metastore.v1.DataprocMetastore.UpdateMetadataImport].
 */
export interface UpdateMetadataImportRequest {
  /**
   * Required. A field mask used to specify the fields to be overwritten in the
   * metadata import resource by the update.
   * Fields specified in the `update_mask` are relative to the resource (not
   * to the full request). A field is overwritten if it is in the mask.
   */
  updateMask:
    | string[]
    | undefined;
  /**
   * Required. The metadata import to update. The server only merges fields
   * in the import if they are specified in `update_mask`.
   *
   * The metadata import's `name` field is used to identify the metastore
   * import to be updated.
   */
  metadataImport:
    | MetadataImport
    | undefined;
  /**
   * Optional. A request ID. Specify a unique request ID to allow the server to
   * ignore the request if it has completed. The server will ignore subsequent
   * requests that provide a duplicate request ID for at least 60 minutes after
   * the first request.
   *
   * For example, if an initial request times out, followed by another request
   * with the same request ID, the server ignores the second request to prevent
   * the creation of duplicate commitments.
   *
   * The request ID must be a valid
   * [UUID](https://en.wikipedia.org/wiki/Universally_unique_identifier#Format)
   * A zero UUID (00000000-0000-0000-0000-000000000000) is not supported.
   */
  requestId: string;
}

/**
 * Request message for
 * [DataprocMetastore.ListBackups][google.cloud.metastore.v1.DataprocMetastore.ListBackups].
 */
export interface ListBackupsRequest {
  /**
   * Required. The relative resource name of the service whose backups to
   * list, in the following form:
   *
   * `projects/{project_number}/locations/{location_id}/services/{service_id}/backups`.
   */
  parent: string;
  /**
   * Optional. The maximum number of backups to return. The response may contain
   * less than the maximum number. If unspecified, no more than 500 backups are
   * returned. The maximum value is 1000; values above 1000 are changed to 1000.
   */
  pageSize: number;
  /**
   * Optional. A page token, received from a previous
   * [DataprocMetastore.ListBackups][google.cloud.metastore.v1.DataprocMetastore.ListBackups]
   * call. Provide this token to retrieve the subsequent page.
   *
   * To retrieve the first page, supply an empty page token.
   *
   * When paginating, other parameters provided to
   * [DataprocMetastore.ListBackups][google.cloud.metastore.v1.DataprocMetastore.ListBackups]
   * must match the call that provided the page token.
   */
  pageToken: string;
  /** Optional. The filter to apply to list results. */
  filter: string;
  /**
   * Optional. Specify the ordering of results as described in [Sorting
   * Order](https://cloud.google.com/apis/design/design_patterns#sorting_order).
   * If not specified, the results will be sorted in the default order.
   */
  orderBy: string;
}

/**
 * Response message for
 * [DataprocMetastore.ListBackups][google.cloud.metastore.v1.DataprocMetastore.ListBackups].
 */
export interface ListBackupsResponse {
  /** The backups of the specified service. */
  backups: Backup[];
  /**
   * A token that can be sent as `page_token` to retrieve the next page. If this
   * field is omitted, there are no subsequent pages.
   */
  nextPageToken: string;
  /** Locations that could not be reached. */
  unreachable: string[];
}

/**
 * Request message for
 * [DataprocMetastore.GetBackup][google.cloud.metastore.v1.DataprocMetastore.GetBackup].
 */
export interface GetBackupRequest {
  /**
   * Required. The relative resource name of the backup to retrieve, in the
   * following form:
   *
   * `projects/{project_number}/locations/{location_id}/services/{service_id}/backups/{backup_id}`.
   */
  name: string;
}

/**
 * Request message for
 * [DataprocMetastore.CreateBackup][google.cloud.metastore.v1.DataprocMetastore.CreateBackup].
 */
export interface CreateBackupRequest {
  /**
   * Required. The relative resource name of the service in which to create a
   * backup of the following form:
   *
   * `projects/{project_number}/locations/{location_id}/services/{service_id}`.
   */
  parent: string;
  /**
   * Required. The ID of the backup, which is used as the final component of the
   * backup's name.
   *
   * This value must be between 1 and 64 characters long, begin with a letter,
   * end with a letter or number, and consist of alpha-numeric ASCII characters
   * or hyphens.
   */
  backupId: string;
  /**
   * Required. The backup to create. The `name` field is ignored. The ID of the
   * created backup must be provided in the request's `backup_id` field.
   */
  backup:
    | Backup
    | undefined;
  /**
   * Optional. A request ID. Specify a unique request ID to allow the server to
   * ignore the request if it has completed. The server will ignore subsequent
   * requests that provide a duplicate request ID for at least 60 minutes after
   * the first request.
   *
   * For example, if an initial request times out, followed by another request
   * with the same request ID, the server ignores the second request to prevent
   * the creation of duplicate commitments.
   *
   * The request ID must be a valid
   * [UUID](https://en.wikipedia.org/wiki/Universally_unique_identifier#Format)
   * A zero UUID (00000000-0000-0000-0000-000000000000) is not supported.
   */
  requestId: string;
}

/**
 * Request message for
 * [DataprocMetastore.DeleteBackup][google.cloud.metastore.v1.DataprocMetastore.DeleteBackup].
 */
export interface DeleteBackupRequest {
  /**
   * Required. The relative resource name of the backup to delete, in the
   * following form:
   *
   * `projects/{project_number}/locations/{location_id}/services/{service_id}/backups/{backup_id}`.
   */
  name: string;
  /**
   * Optional. A request ID. Specify a unique request ID to allow the server to
   * ignore the request if it has completed. The server will ignore subsequent
   * requests that provide a duplicate request ID for at least 60 minutes after
   * the first request.
   *
   * For example, if an initial request times out, followed by another request
   * with the same request ID, the server ignores the second request to prevent
   * the creation of duplicate commitments.
   *
   * The request ID must be a valid
   * [UUID](https://en.wikipedia.org/wiki/Universally_unique_identifier#Format)
   * A zero UUID (00000000-0000-0000-0000-000000000000) is not supported.
   */
  requestId: string;
}

/**
 * Request message for
 * [DataprocMetastore.ExportMetadata][google.cloud.metastore.v1.DataprocMetastore.ExportMetadata].
 */
export interface ExportMetadataRequest {
  /**
   * A Cloud Storage URI of a folder, in the format
   * `gs://<bucket_name>/<path_inside_bucket>`. A sub-folder
   * `<export_folder>` containing exported files will be created below it.
   */
  destinationGcsFolder?:
    | string
    | undefined;
  /**
   * Required. The relative resource name of the metastore service to run
   * export, in the following form:
   *
   * `projects/{project_id}/locations/{location_id}/services/{service_id}`.
   */
  service: string;
  /**
   * Optional. A request ID. Specify a unique request ID to allow the server to
   * ignore the request if it has completed. The server will ignore subsequent
   * requests that provide a duplicate request ID for at least 60 minutes after
   * the first request.
   *
   * For example, if an initial request times out, followed by another request
   * with the same request ID, the server ignores the second request to prevent
   * the creation of duplicate commitments.
   *
   * The request ID must be a valid
   * [UUID](https://en.wikipedia.org/wiki/Universally_unique_identifier#Format).
   * A zero UUID (00000000-0000-0000-0000-000000000000) is not supported.
   */
  requestId: string;
  /**
   * Optional. The type of the database dump. If unspecified, defaults to
   * `MYSQL`.
   */
  databaseDumpType: DatabaseDumpSpec_Type;
}

/** Request message for [DataprocMetastore.Restore][]. */
export interface RestoreServiceRequest {
  /**
   * Required. The relative resource name of the metastore service to run
   * restore, in the following form:
   *
   * `projects/{project_id}/locations/{location_id}/services/{service_id}`.
   */
  service: string;
  /**
   * Required. The relative resource name of the metastore service backup to
   * restore from, in the following form:
   *
   * `projects/{project_id}/locations/{location_id}/services/{service_id}/backups/{backup_id}`.
   */
  backup: string;
  /** Optional. The type of restore. If unspecified, defaults to `METADATA_ONLY`. */
  restoreType: Restore_RestoreType;
  /**
   * Optional. A request ID. Specify a unique request ID to allow the server to
   * ignore the request if it has completed. The server will ignore subsequent
   * requests that provide a duplicate request ID for at least 60 minutes after
   * the first request.
   *
   * For example, if an initial request times out, followed by another request
   * with the same request ID, the server ignores the second request to prevent
   * the creation of duplicate commitments.
   *
   * The request ID must be a valid
   * [UUID](https://en.wikipedia.org/wiki/Universally_unique_identifier#Format).
   * A zero UUID (00000000-0000-0000-0000-000000000000) is not supported.
   */
  requestId: string;
}

/** Represents the metadata of a long-running operation. */
export interface OperationMetadata {
  /** Output only. The time the operation was created. */
  createTime:
    | Date
    | undefined;
  /** Output only. The time the operation finished running. */
  endTime:
    | Date
    | undefined;
  /** Output only. Server-defined resource path for the target of the operation. */
  target: string;
  /** Output only. Name of the verb executed by the operation. */
  verb: string;
  /** Output only. Human-readable status of the operation, if any. */
  statusMessage: string;
  /**
   * Output only. Identifies whether the caller has requested cancellation
   * of the operation. Operations that have successfully been cancelled
   * have [Operation.error][] value with a
   * [google.rpc.Status.code][google.rpc.Status.code] of 1, corresponding to
   * `Code.CANCELLED`.
   */
  requestedCancellation: boolean;
  /** Output only. API version used to start the operation. */
  apiVersion: string;
}

/** Metadata about the service in a location. */
export interface LocationMetadata {
  /**
   * The versions of Hive Metastore that can be used when creating a new
   * metastore service in this location. The server guarantees that exactly one
   * `HiveMetastoreVersion` in the list will set `is_default`.
   */
  supportedHiveMetastoreVersions: LocationMetadata_HiveMetastoreVersion[];
}

/** A specification of a supported version of the Hive Metastore software. */
export interface LocationMetadata_HiveMetastoreVersion {
  /** The semantic version of the Hive Metastore software. */
  version: string;
  /**
   * Whether `version` will be chosen by the server if a metastore service is
   * created with a `HiveMetastoreConfig` that omits the `version`.
   */
  isDefault: boolean;
}

/** The specification of database dump to import from or export to. */
export interface DatabaseDumpSpec {
}

/** The type of the database dump. */
export enum DatabaseDumpSpec_Type {
  /** TYPE_UNSPECIFIED - The type of the database dump is unknown. */
  TYPE_UNSPECIFIED = 0,
  /** MYSQL - Database dump is a MySQL dump file. */
  MYSQL = 1,
  /** AVRO - Database dump contains Avro files. */
  AVRO = 2,
  UNRECOGNIZED = -1,
}

export function databaseDumpSpec_TypeFromJSON(object: any): DatabaseDumpSpec_Type {
  switch (object) {
    case 0:
    case "TYPE_UNSPECIFIED":
      return DatabaseDumpSpec_Type.TYPE_UNSPECIFIED;
    case 1:
    case "MYSQL":
      return DatabaseDumpSpec_Type.MYSQL;
    case 2:
    case "AVRO":
      return DatabaseDumpSpec_Type.AVRO;
    case -1:
    case "UNRECOGNIZED":
    default:
      return DatabaseDumpSpec_Type.UNRECOGNIZED;
  }
}

export function databaseDumpSpec_TypeToJSON(object: DatabaseDumpSpec_Type): string {
  switch (object) {
    case DatabaseDumpSpec_Type.TYPE_UNSPECIFIED:
      return "TYPE_UNSPECIFIED";
    case DatabaseDumpSpec_Type.MYSQL:
      return "MYSQL";
    case DatabaseDumpSpec_Type.AVRO:
      return "AVRO";
    case DatabaseDumpSpec_Type.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/**
 * Request message for
 * [DataprocMetastore.QueryMetadata][google.cloud.metastore.v1.DataprocMetastore.QueryMetadata].
 */
export interface QueryMetadataRequest {
  /**
   * Required. The relative resource name of the metastore service to query
   * metadata, in the following format:
   *
   * `projects/{project_id}/locations/{location_id}/services/{service_id}`.
   */
  service: string;
  /**
   * Required. A read-only SQL query to execute against the metadata database.
   * The query cannot change or mutate the data.
   */
  query: string;
}

/**
 * Response message for
 * [DataprocMetastore.QueryMetadata][google.cloud.metastore.v1.DataprocMetastore.QueryMetadata].
 */
export interface QueryMetadataResponse {
  /**
   * The manifest URI  is link to a JSON instance in Cloud Storage.
   * This instance manifests immediately along with QueryMetadataResponse. The
   * content of the URI is not retriable until the long-running operation query
   * against the metadata finishes.
   */
  resultManifestUri: string;
}

/**
 * Error details in public error message for
 * [DataprocMetastore.QueryMetadata][google.cloud.metastore.v1.DataprocMetastore.QueryMetadata].
 */
export interface ErrorDetails {
  /**
   * Additional structured details about this error.
   *
   * Keys define the failure items.
   * Value describes the exception or details of the item.
   */
  details: { [key: string]: string };
}

export interface ErrorDetails_DetailsEntry {
  key: string;
  value: string;
}

/**
 * Request message for
 * [DataprocMetastore.MoveTableToDatabase][google.cloud.metastore.v1.DataprocMetastore.MoveTableToDatabase].
 */
export interface MoveTableToDatabaseRequest {
  /**
   * Required. The relative resource name of the metastore service to mutate
   * metadata, in the following format:
   *
   * `projects/{project_id}/locations/{location_id}/services/{service_id}`.
   */
  service: string;
  /** Required. The name of the table to be moved. */
  tableName: string;
  /** Required. The name of the database where the table resides. */
  dbName: string;
  /** Required. The name of the database where the table should be moved. */
  destinationDbName: string;
}

/**
 * Response message for
 * [DataprocMetastore.MoveTableToDatabase][google.cloud.metastore.v1.DataprocMetastore.MoveTableToDatabase].
 */
export interface MoveTableToDatabaseResponse {
}

/**
 * Request message for
 * [DataprocMetastore.AlterMetadataResourceLocation][google.cloud.metastore.v1.DataprocMetastore.AlterMetadataResourceLocation].
 */
export interface AlterMetadataResourceLocationRequest {
  /**
   * Required. The relative resource name of the metastore service to mutate
   * metadata, in the following format:
   *
   * `projects/{project_id}/locations/{location_id}/services/{service_id}`.
   */
  service: string;
  /**
   * Required. The relative metadata resource name in the following format.
   *
   * `databases/{database_id}`
   * or
   * `databases/{database_id}/tables/{table_id}`
   * or
   * `databases/{database_id}/tables/{table_id}/partitions/{partition_id}`
   */
  resourceName: string;
  /** Required. The new location URI for the metadata resource. */
  locationUri: string;
}

/**
 * Response message for
 * [DataprocMetastore.AlterMetadataResourceLocation][google.cloud.metastore.v1.DataprocMetastore.AlterMetadataResourceLocation].
 */
export interface AlterMetadataResourceLocationResponse {
}

function createBaseService(): Service {
  return {
    hiveMetastoreConfig: undefined,
    name: "",
    createTime: undefined,
    updateTime: undefined,
    labels: {},
    network: "",
    endpointUri: "",
    port: 0,
    state: 0,
    stateMessage: "",
    artifactGcsUri: "",
    tier: 0,
    maintenanceWindow: undefined,
    uid: "",
    metadataManagementActivity: undefined,
    releaseChannel: 0,
    encryptionConfig: undefined,
    networkConfig: undefined,
    databaseType: 0,
    telemetryConfig: undefined,
    scalingConfig: undefined,
  };
}

export const Service: MessageFns<Service> = {
  encode(message: Service, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.hiveMetastoreConfig !== undefined) {
      HiveMetastoreConfig.encode(message.hiveMetastoreConfig, writer.uint32(42).fork()).join();
    }
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    if (message.createTime !== undefined) {
      Timestamp.encode(toTimestamp(message.createTime), writer.uint32(18).fork()).join();
    }
    if (message.updateTime !== undefined) {
      Timestamp.encode(toTimestamp(message.updateTime), writer.uint32(26).fork()).join();
    }
    Object.entries(message.labels).forEach(([key, value]) => {
      Service_LabelsEntry.encode({ key: key as any, value }, writer.uint32(34).fork()).join();
    });
    if (message.network !== "") {
      writer.uint32(58).string(message.network);
    }
    if (message.endpointUri !== "") {
      writer.uint32(66).string(message.endpointUri);
    }
    if (message.port !== 0) {
      writer.uint32(72).int32(message.port);
    }
    if (message.state !== 0) {
      writer.uint32(80).int32(message.state);
    }
    if (message.stateMessage !== "") {
      writer.uint32(90).string(message.stateMessage);
    }
    if (message.artifactGcsUri !== "") {
      writer.uint32(98).string(message.artifactGcsUri);
    }
    if (message.tier !== 0) {
      writer.uint32(104).int32(message.tier);
    }
    if (message.maintenanceWindow !== undefined) {
      MaintenanceWindow.encode(message.maintenanceWindow, writer.uint32(122).fork()).join();
    }
    if (message.uid !== "") {
      writer.uint32(130).string(message.uid);
    }
    if (message.metadataManagementActivity !== undefined) {
      MetadataManagementActivity.encode(message.metadataManagementActivity, writer.uint32(138).fork()).join();
    }
    if (message.releaseChannel !== 0) {
      writer.uint32(152).int32(message.releaseChannel);
    }
    if (message.encryptionConfig !== undefined) {
      EncryptionConfig.encode(message.encryptionConfig, writer.uint32(162).fork()).join();
    }
    if (message.networkConfig !== undefined) {
      NetworkConfig.encode(message.networkConfig, writer.uint32(170).fork()).join();
    }
    if (message.databaseType !== 0) {
      writer.uint32(176).int32(message.databaseType);
    }
    if (message.telemetryConfig !== undefined) {
      TelemetryConfig.encode(message.telemetryConfig, writer.uint32(186).fork()).join();
    }
    if (message.scalingConfig !== undefined) {
      ScalingConfig.encode(message.scalingConfig, writer.uint32(194).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Service {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseService();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 5:
          if (tag !== 42) {
            break;
          }

          message.hiveMetastoreConfig = HiveMetastoreConfig.decode(reader, reader.uint32());
          continue;
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.createTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.updateTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          const entry4 = Service_LabelsEntry.decode(reader, reader.uint32());
          if (entry4.value !== undefined) {
            message.labels[entry4.key] = entry4.value;
          }
          continue;
        case 7:
          if (tag !== 58) {
            break;
          }

          message.network = reader.string();
          continue;
        case 8:
          if (tag !== 66) {
            break;
          }

          message.endpointUri = reader.string();
          continue;
        case 9:
          if (tag !== 72) {
            break;
          }

          message.port = reader.int32();
          continue;
        case 10:
          if (tag !== 80) {
            break;
          }

          message.state = reader.int32() as any;
          continue;
        case 11:
          if (tag !== 90) {
            break;
          }

          message.stateMessage = reader.string();
          continue;
        case 12:
          if (tag !== 98) {
            break;
          }

          message.artifactGcsUri = reader.string();
          continue;
        case 13:
          if (tag !== 104) {
            break;
          }

          message.tier = reader.int32() as any;
          continue;
        case 15:
          if (tag !== 122) {
            break;
          }

          message.maintenanceWindow = MaintenanceWindow.decode(reader, reader.uint32());
          continue;
        case 16:
          if (tag !== 130) {
            break;
          }

          message.uid = reader.string();
          continue;
        case 17:
          if (tag !== 138) {
            break;
          }

          message.metadataManagementActivity = MetadataManagementActivity.decode(reader, reader.uint32());
          continue;
        case 19:
          if (tag !== 152) {
            break;
          }

          message.releaseChannel = reader.int32() as any;
          continue;
        case 20:
          if (tag !== 162) {
            break;
          }

          message.encryptionConfig = EncryptionConfig.decode(reader, reader.uint32());
          continue;
        case 21:
          if (tag !== 170) {
            break;
          }

          message.networkConfig = NetworkConfig.decode(reader, reader.uint32());
          continue;
        case 22:
          if (tag !== 176) {
            break;
          }

          message.databaseType = reader.int32() as any;
          continue;
        case 23:
          if (tag !== 186) {
            break;
          }

          message.telemetryConfig = TelemetryConfig.decode(reader, reader.uint32());
          continue;
        case 24:
          if (tag !== 194) {
            break;
          }

          message.scalingConfig = ScalingConfig.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Service {
    return {
      hiveMetastoreConfig: isSet(object.hiveMetastoreConfig)
        ? HiveMetastoreConfig.fromJSON(object.hiveMetastoreConfig)
        : undefined,
      name: isSet(object.name) ? globalThis.String(object.name) : "",
      createTime: isSet(object.createTime) ? fromJsonTimestamp(object.createTime) : undefined,
      updateTime: isSet(object.updateTime) ? fromJsonTimestamp(object.updateTime) : undefined,
      labels: isObject(object.labels)
        ? Object.entries(object.labels).reduce<{ [key: string]: string }>((acc, [key, value]) => {
          acc[key] = String(value);
          return acc;
        }, {})
        : {},
      network: isSet(object.network) ? globalThis.String(object.network) : "",
      endpointUri: isSet(object.endpointUri) ? globalThis.String(object.endpointUri) : "",
      port: isSet(object.port) ? globalThis.Number(object.port) : 0,
      state: isSet(object.state) ? service_StateFromJSON(object.state) : 0,
      stateMessage: isSet(object.stateMessage) ? globalThis.String(object.stateMessage) : "",
      artifactGcsUri: isSet(object.artifactGcsUri) ? globalThis.String(object.artifactGcsUri) : "",
      tier: isSet(object.tier) ? service_TierFromJSON(object.tier) : 0,
      maintenanceWindow: isSet(object.maintenanceWindow)
        ? MaintenanceWindow.fromJSON(object.maintenanceWindow)
        : undefined,
      uid: isSet(object.uid) ? globalThis.String(object.uid) : "",
      metadataManagementActivity: isSet(object.metadataManagementActivity)
        ? MetadataManagementActivity.fromJSON(object.metadataManagementActivity)
        : undefined,
      releaseChannel: isSet(object.releaseChannel) ? service_ReleaseChannelFromJSON(object.releaseChannel) : 0,
      encryptionConfig: isSet(object.encryptionConfig) ? EncryptionConfig.fromJSON(object.encryptionConfig) : undefined,
      networkConfig: isSet(object.networkConfig) ? NetworkConfig.fromJSON(object.networkConfig) : undefined,
      databaseType: isSet(object.databaseType) ? service_DatabaseTypeFromJSON(object.databaseType) : 0,
      telemetryConfig: isSet(object.telemetryConfig) ? TelemetryConfig.fromJSON(object.telemetryConfig) : undefined,
      scalingConfig: isSet(object.scalingConfig) ? ScalingConfig.fromJSON(object.scalingConfig) : undefined,
    };
  },

  toJSON(message: Service): unknown {
    const obj: any = {};
    if (message.hiveMetastoreConfig !== undefined) {
      obj.hiveMetastoreConfig = HiveMetastoreConfig.toJSON(message.hiveMetastoreConfig);
    }
    if (message.name !== "") {
      obj.name = message.name;
    }
    if (message.createTime !== undefined) {
      obj.createTime = message.createTime.toISOString();
    }
    if (message.updateTime !== undefined) {
      obj.updateTime = message.updateTime.toISOString();
    }
    if (message.labels) {
      const entries = Object.entries(message.labels);
      if (entries.length > 0) {
        obj.labels = {};
        entries.forEach(([k, v]) => {
          obj.labels[k] = v;
        });
      }
    }
    if (message.network !== "") {
      obj.network = message.network;
    }
    if (message.endpointUri !== "") {
      obj.endpointUri = message.endpointUri;
    }
    if (message.port !== 0) {
      obj.port = Math.round(message.port);
    }
    if (message.state !== 0) {
      obj.state = service_StateToJSON(message.state);
    }
    if (message.stateMessage !== "") {
      obj.stateMessage = message.stateMessage;
    }
    if (message.artifactGcsUri !== "") {
      obj.artifactGcsUri = message.artifactGcsUri;
    }
    if (message.tier !== 0) {
      obj.tier = service_TierToJSON(message.tier);
    }
    if (message.maintenanceWindow !== undefined) {
      obj.maintenanceWindow = MaintenanceWindow.toJSON(message.maintenanceWindow);
    }
    if (message.uid !== "") {
      obj.uid = message.uid;
    }
    if (message.metadataManagementActivity !== undefined) {
      obj.metadataManagementActivity = MetadataManagementActivity.toJSON(message.metadataManagementActivity);
    }
    if (message.releaseChannel !== 0) {
      obj.releaseChannel = service_ReleaseChannelToJSON(message.releaseChannel);
    }
    if (message.encryptionConfig !== undefined) {
      obj.encryptionConfig = EncryptionConfig.toJSON(message.encryptionConfig);
    }
    if (message.networkConfig !== undefined) {
      obj.networkConfig = NetworkConfig.toJSON(message.networkConfig);
    }
    if (message.databaseType !== 0) {
      obj.databaseType = service_DatabaseTypeToJSON(message.databaseType);
    }
    if (message.telemetryConfig !== undefined) {
      obj.telemetryConfig = TelemetryConfig.toJSON(message.telemetryConfig);
    }
    if (message.scalingConfig !== undefined) {
      obj.scalingConfig = ScalingConfig.toJSON(message.scalingConfig);
    }
    return obj;
  },

  create(base?: DeepPartial<Service>): Service {
    return Service.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<Service>): Service {
    const message = createBaseService();
    message.hiveMetastoreConfig = (object.hiveMetastoreConfig !== undefined && object.hiveMetastoreConfig !== null)
      ? HiveMetastoreConfig.fromPartial(object.hiveMetastoreConfig)
      : undefined;
    message.name = object.name ?? "";
    message.createTime = object.createTime ?? undefined;
    message.updateTime = object.updateTime ?? undefined;
    message.labels = Object.entries(object.labels ?? {}).reduce<{ [key: string]: string }>((acc, [key, value]) => {
      if (value !== undefined) {
        acc[key] = globalThis.String(value);
      }
      return acc;
    }, {});
    message.network = object.network ?? "";
    message.endpointUri = object.endpointUri ?? "";
    message.port = object.port ?? 0;
    message.state = object.state ?? 0;
    message.stateMessage = object.stateMessage ?? "";
    message.artifactGcsUri = object.artifactGcsUri ?? "";
    message.tier = object.tier ?? 0;
    message.maintenanceWindow = (object.maintenanceWindow !== undefined && object.maintenanceWindow !== null)
      ? MaintenanceWindow.fromPartial(object.maintenanceWindow)
      : undefined;
    message.uid = object.uid ?? "";
    message.metadataManagementActivity =
      (object.metadataManagementActivity !== undefined && object.metadataManagementActivity !== null)
        ? MetadataManagementActivity.fromPartial(object.metadataManagementActivity)
        : undefined;
    message.releaseChannel = object.releaseChannel ?? 0;
    message.encryptionConfig = (object.encryptionConfig !== undefined && object.encryptionConfig !== null)
      ? EncryptionConfig.fromPartial(object.encryptionConfig)
      : undefined;
    message.networkConfig = (object.networkConfig !== undefined && object.networkConfig !== null)
      ? NetworkConfig.fromPartial(object.networkConfig)
      : undefined;
    message.databaseType = object.databaseType ?? 0;
    message.telemetryConfig = (object.telemetryConfig !== undefined && object.telemetryConfig !== null)
      ? TelemetryConfig.fromPartial(object.telemetryConfig)
      : undefined;
    message.scalingConfig = (object.scalingConfig !== undefined && object.scalingConfig !== null)
      ? ScalingConfig.fromPartial(object.scalingConfig)
      : undefined;
    return message;
  },
};

function createBaseService_LabelsEntry(): Service_LabelsEntry {
  return { key: "", value: "" };
}

export const Service_LabelsEntry: MessageFns<Service_LabelsEntry> = {
  encode(message: Service_LabelsEntry, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.key !== "") {
      writer.uint32(10).string(message.key);
    }
    if (message.value !== "") {
      writer.uint32(18).string(message.value);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Service_LabelsEntry {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseService_LabelsEntry();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.key = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.value = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Service_LabelsEntry {
    return {
      key: isSet(object.key) ? globalThis.String(object.key) : "",
      value: isSet(object.value) ? globalThis.String(object.value) : "",
    };
  },

  toJSON(message: Service_LabelsEntry): unknown {
    const obj: any = {};
    if (message.key !== "") {
      obj.key = message.key;
    }
    if (message.value !== "") {
      obj.value = message.value;
    }
    return obj;
  },

  create(base?: DeepPartial<Service_LabelsEntry>): Service_LabelsEntry {
    return Service_LabelsEntry.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<Service_LabelsEntry>): Service_LabelsEntry {
    const message = createBaseService_LabelsEntry();
    message.key = object.key ?? "";
    message.value = object.value ?? "";
    return message;
  },
};

function createBaseMaintenanceWindow(): MaintenanceWindow {
  return { hourOfDay: undefined, dayOfWeek: 0 };
}

export const MaintenanceWindow: MessageFns<MaintenanceWindow> = {
  encode(message: MaintenanceWindow, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.hourOfDay !== undefined) {
      Int32Value.encode({ value: message.hourOfDay! }, writer.uint32(10).fork()).join();
    }
    if (message.dayOfWeek !== 0) {
      writer.uint32(16).int32(message.dayOfWeek);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): MaintenanceWindow {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseMaintenanceWindow();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.hourOfDay = Int32Value.decode(reader, reader.uint32()).value;
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.dayOfWeek = reader.int32() as any;
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): MaintenanceWindow {
    return {
      hourOfDay: isSet(object.hourOfDay) ? Number(object.hourOfDay) : undefined,
      dayOfWeek: isSet(object.dayOfWeek) ? dayOfWeekFromJSON(object.dayOfWeek) : 0,
    };
  },

  toJSON(message: MaintenanceWindow): unknown {
    const obj: any = {};
    if (message.hourOfDay !== undefined) {
      obj.hourOfDay = message.hourOfDay;
    }
    if (message.dayOfWeek !== 0) {
      obj.dayOfWeek = dayOfWeekToJSON(message.dayOfWeek);
    }
    return obj;
  },

  create(base?: DeepPartial<MaintenanceWindow>): MaintenanceWindow {
    return MaintenanceWindow.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<MaintenanceWindow>): MaintenanceWindow {
    const message = createBaseMaintenanceWindow();
    message.hourOfDay = object.hourOfDay ?? undefined;
    message.dayOfWeek = object.dayOfWeek ?? 0;
    return message;
  },
};

function createBaseHiveMetastoreConfig(): HiveMetastoreConfig {
  return { version: "", configOverrides: {}, kerberosConfig: undefined, endpointProtocol: 0, auxiliaryVersions: {} };
}

export const HiveMetastoreConfig: MessageFns<HiveMetastoreConfig> = {
  encode(message: HiveMetastoreConfig, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.version !== "") {
      writer.uint32(10).string(message.version);
    }
    Object.entries(message.configOverrides).forEach(([key, value]) => {
      HiveMetastoreConfig_ConfigOverridesEntry.encode({ key: key as any, value }, writer.uint32(18).fork()).join();
    });
    if (message.kerberosConfig !== undefined) {
      KerberosConfig.encode(message.kerberosConfig, writer.uint32(26).fork()).join();
    }
    if (message.endpointProtocol !== 0) {
      writer.uint32(32).int32(message.endpointProtocol);
    }
    Object.entries(message.auxiliaryVersions).forEach(([key, value]) => {
      HiveMetastoreConfig_AuxiliaryVersionsEntry.encode({ key: key as any, value }, writer.uint32(42).fork()).join();
    });
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): HiveMetastoreConfig {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseHiveMetastoreConfig();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.version = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          const entry2 = HiveMetastoreConfig_ConfigOverridesEntry.decode(reader, reader.uint32());
          if (entry2.value !== undefined) {
            message.configOverrides[entry2.key] = entry2.value;
          }
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.kerberosConfig = KerberosConfig.decode(reader, reader.uint32());
          continue;
        case 4:
          if (tag !== 32) {
            break;
          }

          message.endpointProtocol = reader.int32() as any;
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          const entry5 = HiveMetastoreConfig_AuxiliaryVersionsEntry.decode(reader, reader.uint32());
          if (entry5.value !== undefined) {
            message.auxiliaryVersions[entry5.key] = entry5.value;
          }
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): HiveMetastoreConfig {
    return {
      version: isSet(object.version) ? globalThis.String(object.version) : "",
      configOverrides: isObject(object.configOverrides)
        ? Object.entries(object.configOverrides).reduce<{ [key: string]: string }>((acc, [key, value]) => {
          acc[key] = String(value);
          return acc;
        }, {})
        : {},
      kerberosConfig: isSet(object.kerberosConfig) ? KerberosConfig.fromJSON(object.kerberosConfig) : undefined,
      endpointProtocol: isSet(object.endpointProtocol)
        ? hiveMetastoreConfig_EndpointProtocolFromJSON(object.endpointProtocol)
        : 0,
      auxiliaryVersions: isObject(object.auxiliaryVersions)
        ? Object.entries(object.auxiliaryVersions).reduce<{ [key: string]: AuxiliaryVersionConfig }>(
          (acc, [key, value]) => {
            acc[key] = AuxiliaryVersionConfig.fromJSON(value);
            return acc;
          },
          {},
        )
        : {},
    };
  },

  toJSON(message: HiveMetastoreConfig): unknown {
    const obj: any = {};
    if (message.version !== "") {
      obj.version = message.version;
    }
    if (message.configOverrides) {
      const entries = Object.entries(message.configOverrides);
      if (entries.length > 0) {
        obj.configOverrides = {};
        entries.forEach(([k, v]) => {
          obj.configOverrides[k] = v;
        });
      }
    }
    if (message.kerberosConfig !== undefined) {
      obj.kerberosConfig = KerberosConfig.toJSON(message.kerberosConfig);
    }
    if (message.endpointProtocol !== 0) {
      obj.endpointProtocol = hiveMetastoreConfig_EndpointProtocolToJSON(message.endpointProtocol);
    }
    if (message.auxiliaryVersions) {
      const entries = Object.entries(message.auxiliaryVersions);
      if (entries.length > 0) {
        obj.auxiliaryVersions = {};
        entries.forEach(([k, v]) => {
          obj.auxiliaryVersions[k] = AuxiliaryVersionConfig.toJSON(v);
        });
      }
    }
    return obj;
  },

  create(base?: DeepPartial<HiveMetastoreConfig>): HiveMetastoreConfig {
    return HiveMetastoreConfig.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<HiveMetastoreConfig>): HiveMetastoreConfig {
    const message = createBaseHiveMetastoreConfig();
    message.version = object.version ?? "";
    message.configOverrides = Object.entries(object.configOverrides ?? {}).reduce<{ [key: string]: string }>(
      (acc, [key, value]) => {
        if (value !== undefined) {
          acc[key] = globalThis.String(value);
        }
        return acc;
      },
      {},
    );
    message.kerberosConfig = (object.kerberosConfig !== undefined && object.kerberosConfig !== null)
      ? KerberosConfig.fromPartial(object.kerberosConfig)
      : undefined;
    message.endpointProtocol = object.endpointProtocol ?? 0;
    message.auxiliaryVersions = Object.entries(object.auxiliaryVersions ?? {}).reduce<
      { [key: string]: AuxiliaryVersionConfig }
    >((acc, [key, value]) => {
      if (value !== undefined) {
        acc[key] = AuxiliaryVersionConfig.fromPartial(value);
      }
      return acc;
    }, {});
    return message;
  },
};

function createBaseHiveMetastoreConfig_ConfigOverridesEntry(): HiveMetastoreConfig_ConfigOverridesEntry {
  return { key: "", value: "" };
}

export const HiveMetastoreConfig_ConfigOverridesEntry: MessageFns<HiveMetastoreConfig_ConfigOverridesEntry> = {
  encode(message: HiveMetastoreConfig_ConfigOverridesEntry, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.key !== "") {
      writer.uint32(10).string(message.key);
    }
    if (message.value !== "") {
      writer.uint32(18).string(message.value);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): HiveMetastoreConfig_ConfigOverridesEntry {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseHiveMetastoreConfig_ConfigOverridesEntry();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.key = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.value = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): HiveMetastoreConfig_ConfigOverridesEntry {
    return {
      key: isSet(object.key) ? globalThis.String(object.key) : "",
      value: isSet(object.value) ? globalThis.String(object.value) : "",
    };
  },

  toJSON(message: HiveMetastoreConfig_ConfigOverridesEntry): unknown {
    const obj: any = {};
    if (message.key !== "") {
      obj.key = message.key;
    }
    if (message.value !== "") {
      obj.value = message.value;
    }
    return obj;
  },

  create(base?: DeepPartial<HiveMetastoreConfig_ConfigOverridesEntry>): HiveMetastoreConfig_ConfigOverridesEntry {
    return HiveMetastoreConfig_ConfigOverridesEntry.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<HiveMetastoreConfig_ConfigOverridesEntry>): HiveMetastoreConfig_ConfigOverridesEntry {
    const message = createBaseHiveMetastoreConfig_ConfigOverridesEntry();
    message.key = object.key ?? "";
    message.value = object.value ?? "";
    return message;
  },
};

function createBaseHiveMetastoreConfig_AuxiliaryVersionsEntry(): HiveMetastoreConfig_AuxiliaryVersionsEntry {
  return { key: "", value: undefined };
}

export const HiveMetastoreConfig_AuxiliaryVersionsEntry: MessageFns<HiveMetastoreConfig_AuxiliaryVersionsEntry> = {
  encode(message: HiveMetastoreConfig_AuxiliaryVersionsEntry, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.key !== "") {
      writer.uint32(10).string(message.key);
    }
    if (message.value !== undefined) {
      AuxiliaryVersionConfig.encode(message.value, writer.uint32(18).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): HiveMetastoreConfig_AuxiliaryVersionsEntry {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseHiveMetastoreConfig_AuxiliaryVersionsEntry();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.key = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.value = AuxiliaryVersionConfig.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): HiveMetastoreConfig_AuxiliaryVersionsEntry {
    return {
      key: isSet(object.key) ? globalThis.String(object.key) : "",
      value: isSet(object.value) ? AuxiliaryVersionConfig.fromJSON(object.value) : undefined,
    };
  },

  toJSON(message: HiveMetastoreConfig_AuxiliaryVersionsEntry): unknown {
    const obj: any = {};
    if (message.key !== "") {
      obj.key = message.key;
    }
    if (message.value !== undefined) {
      obj.value = AuxiliaryVersionConfig.toJSON(message.value);
    }
    return obj;
  },

  create(base?: DeepPartial<HiveMetastoreConfig_AuxiliaryVersionsEntry>): HiveMetastoreConfig_AuxiliaryVersionsEntry {
    return HiveMetastoreConfig_AuxiliaryVersionsEntry.fromPartial(base ?? {});
  },
  fromPartial(
    object: DeepPartial<HiveMetastoreConfig_AuxiliaryVersionsEntry>,
  ): HiveMetastoreConfig_AuxiliaryVersionsEntry {
    const message = createBaseHiveMetastoreConfig_AuxiliaryVersionsEntry();
    message.key = object.key ?? "";
    message.value = (object.value !== undefined && object.value !== null)
      ? AuxiliaryVersionConfig.fromPartial(object.value)
      : undefined;
    return message;
  },
};

function createBaseKerberosConfig(): KerberosConfig {
  return { keytab: undefined, principal: "", krb5ConfigGcsUri: "" };
}

export const KerberosConfig: MessageFns<KerberosConfig> = {
  encode(message: KerberosConfig, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.keytab !== undefined) {
      Secret.encode(message.keytab, writer.uint32(10).fork()).join();
    }
    if (message.principal !== "") {
      writer.uint32(18).string(message.principal);
    }
    if (message.krb5ConfigGcsUri !== "") {
      writer.uint32(26).string(message.krb5ConfigGcsUri);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): KerberosConfig {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseKerberosConfig();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.keytab = Secret.decode(reader, reader.uint32());
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.principal = reader.string();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.krb5ConfigGcsUri = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): KerberosConfig {
    return {
      keytab: isSet(object.keytab) ? Secret.fromJSON(object.keytab) : undefined,
      principal: isSet(object.principal) ? globalThis.String(object.principal) : "",
      krb5ConfigGcsUri: isSet(object.krb5ConfigGcsUri) ? globalThis.String(object.krb5ConfigGcsUri) : "",
    };
  },

  toJSON(message: KerberosConfig): unknown {
    const obj: any = {};
    if (message.keytab !== undefined) {
      obj.keytab = Secret.toJSON(message.keytab);
    }
    if (message.principal !== "") {
      obj.principal = message.principal;
    }
    if (message.krb5ConfigGcsUri !== "") {
      obj.krb5ConfigGcsUri = message.krb5ConfigGcsUri;
    }
    return obj;
  },

  create(base?: DeepPartial<KerberosConfig>): KerberosConfig {
    return KerberosConfig.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<KerberosConfig>): KerberosConfig {
    const message = createBaseKerberosConfig();
    message.keytab = (object.keytab !== undefined && object.keytab !== null)
      ? Secret.fromPartial(object.keytab)
      : undefined;
    message.principal = object.principal ?? "";
    message.krb5ConfigGcsUri = object.krb5ConfigGcsUri ?? "";
    return message;
  },
};

function createBaseSecret(): Secret {
  return { cloudSecret: undefined };
}

export const Secret: MessageFns<Secret> = {
  encode(message: Secret, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.cloudSecret !== undefined) {
      writer.uint32(18).string(message.cloudSecret);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Secret {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseSecret();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 2:
          if (tag !== 18) {
            break;
          }

          message.cloudSecret = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Secret {
    return { cloudSecret: isSet(object.cloudSecret) ? globalThis.String(object.cloudSecret) : undefined };
  },

  toJSON(message: Secret): unknown {
    const obj: any = {};
    if (message.cloudSecret !== undefined) {
      obj.cloudSecret = message.cloudSecret;
    }
    return obj;
  },

  create(base?: DeepPartial<Secret>): Secret {
    return Secret.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<Secret>): Secret {
    const message = createBaseSecret();
    message.cloudSecret = object.cloudSecret ?? undefined;
    return message;
  },
};

function createBaseEncryptionConfig(): EncryptionConfig {
  return { kmsKey: "" };
}

export const EncryptionConfig: MessageFns<EncryptionConfig> = {
  encode(message: EncryptionConfig, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.kmsKey !== "") {
      writer.uint32(10).string(message.kmsKey);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): EncryptionConfig {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseEncryptionConfig();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.kmsKey = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): EncryptionConfig {
    return { kmsKey: isSet(object.kmsKey) ? globalThis.String(object.kmsKey) : "" };
  },

  toJSON(message: EncryptionConfig): unknown {
    const obj: any = {};
    if (message.kmsKey !== "") {
      obj.kmsKey = message.kmsKey;
    }
    return obj;
  },

  create(base?: DeepPartial<EncryptionConfig>): EncryptionConfig {
    return EncryptionConfig.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<EncryptionConfig>): EncryptionConfig {
    const message = createBaseEncryptionConfig();
    message.kmsKey = object.kmsKey ?? "";
    return message;
  },
};

function createBaseAuxiliaryVersionConfig(): AuxiliaryVersionConfig {
  return { version: "", configOverrides: {}, networkConfig: undefined };
}

export const AuxiliaryVersionConfig: MessageFns<AuxiliaryVersionConfig> = {
  encode(message: AuxiliaryVersionConfig, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.version !== "") {
      writer.uint32(10).string(message.version);
    }
    Object.entries(message.configOverrides).forEach(([key, value]) => {
      AuxiliaryVersionConfig_ConfigOverridesEntry.encode({ key: key as any, value }, writer.uint32(18).fork()).join();
    });
    if (message.networkConfig !== undefined) {
      NetworkConfig.encode(message.networkConfig, writer.uint32(26).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): AuxiliaryVersionConfig {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseAuxiliaryVersionConfig();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.version = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          const entry2 = AuxiliaryVersionConfig_ConfigOverridesEntry.decode(reader, reader.uint32());
          if (entry2.value !== undefined) {
            message.configOverrides[entry2.key] = entry2.value;
          }
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.networkConfig = NetworkConfig.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): AuxiliaryVersionConfig {
    return {
      version: isSet(object.version) ? globalThis.String(object.version) : "",
      configOverrides: isObject(object.configOverrides)
        ? Object.entries(object.configOverrides).reduce<{ [key: string]: string }>((acc, [key, value]) => {
          acc[key] = String(value);
          return acc;
        }, {})
        : {},
      networkConfig: isSet(object.networkConfig) ? NetworkConfig.fromJSON(object.networkConfig) : undefined,
    };
  },

  toJSON(message: AuxiliaryVersionConfig): unknown {
    const obj: any = {};
    if (message.version !== "") {
      obj.version = message.version;
    }
    if (message.configOverrides) {
      const entries = Object.entries(message.configOverrides);
      if (entries.length > 0) {
        obj.configOverrides = {};
        entries.forEach(([k, v]) => {
          obj.configOverrides[k] = v;
        });
      }
    }
    if (message.networkConfig !== undefined) {
      obj.networkConfig = NetworkConfig.toJSON(message.networkConfig);
    }
    return obj;
  },

  create(base?: DeepPartial<AuxiliaryVersionConfig>): AuxiliaryVersionConfig {
    return AuxiliaryVersionConfig.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<AuxiliaryVersionConfig>): AuxiliaryVersionConfig {
    const message = createBaseAuxiliaryVersionConfig();
    message.version = object.version ?? "";
    message.configOverrides = Object.entries(object.configOverrides ?? {}).reduce<{ [key: string]: string }>(
      (acc, [key, value]) => {
        if (value !== undefined) {
          acc[key] = globalThis.String(value);
        }
        return acc;
      },
      {},
    );
    message.networkConfig = (object.networkConfig !== undefined && object.networkConfig !== null)
      ? NetworkConfig.fromPartial(object.networkConfig)
      : undefined;
    return message;
  },
};

function createBaseAuxiliaryVersionConfig_ConfigOverridesEntry(): AuxiliaryVersionConfig_ConfigOverridesEntry {
  return { key: "", value: "" };
}

export const AuxiliaryVersionConfig_ConfigOverridesEntry: MessageFns<AuxiliaryVersionConfig_ConfigOverridesEntry> = {
  encode(
    message: AuxiliaryVersionConfig_ConfigOverridesEntry,
    writer: BinaryWriter = new BinaryWriter(),
  ): BinaryWriter {
    if (message.key !== "") {
      writer.uint32(10).string(message.key);
    }
    if (message.value !== "") {
      writer.uint32(18).string(message.value);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): AuxiliaryVersionConfig_ConfigOverridesEntry {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseAuxiliaryVersionConfig_ConfigOverridesEntry();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.key = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.value = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): AuxiliaryVersionConfig_ConfigOverridesEntry {
    return {
      key: isSet(object.key) ? globalThis.String(object.key) : "",
      value: isSet(object.value) ? globalThis.String(object.value) : "",
    };
  },

  toJSON(message: AuxiliaryVersionConfig_ConfigOverridesEntry): unknown {
    const obj: any = {};
    if (message.key !== "") {
      obj.key = message.key;
    }
    if (message.value !== "") {
      obj.value = message.value;
    }
    return obj;
  },

  create(base?: DeepPartial<AuxiliaryVersionConfig_ConfigOverridesEntry>): AuxiliaryVersionConfig_ConfigOverridesEntry {
    return AuxiliaryVersionConfig_ConfigOverridesEntry.fromPartial(base ?? {});
  },
  fromPartial(
    object: DeepPartial<AuxiliaryVersionConfig_ConfigOverridesEntry>,
  ): AuxiliaryVersionConfig_ConfigOverridesEntry {
    const message = createBaseAuxiliaryVersionConfig_ConfigOverridesEntry();
    message.key = object.key ?? "";
    message.value = object.value ?? "";
    return message;
  },
};

function createBaseNetworkConfig(): NetworkConfig {
  return { consumers: [] };
}

export const NetworkConfig: MessageFns<NetworkConfig> = {
  encode(message: NetworkConfig, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.consumers) {
      NetworkConfig_Consumer.encode(v!, writer.uint32(10).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): NetworkConfig {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseNetworkConfig();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.consumers.push(NetworkConfig_Consumer.decode(reader, reader.uint32()));
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): NetworkConfig {
    return {
      consumers: globalThis.Array.isArray(object?.consumers)
        ? object.consumers.map((e: any) => NetworkConfig_Consumer.fromJSON(e))
        : [],
    };
  },

  toJSON(message: NetworkConfig): unknown {
    const obj: any = {};
    if (message.consumers?.length) {
      obj.consumers = message.consumers.map((e) => NetworkConfig_Consumer.toJSON(e));
    }
    return obj;
  },

  create(base?: DeepPartial<NetworkConfig>): NetworkConfig {
    return NetworkConfig.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<NetworkConfig>): NetworkConfig {
    const message = createBaseNetworkConfig();
    message.consumers = object.consumers?.map((e) => NetworkConfig_Consumer.fromPartial(e)) || [];
    return message;
  },
};

function createBaseNetworkConfig_Consumer(): NetworkConfig_Consumer {
  return { subnetwork: undefined, endpointUri: "", endpointLocation: "" };
}

export const NetworkConfig_Consumer: MessageFns<NetworkConfig_Consumer> = {
  encode(message: NetworkConfig_Consumer, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.subnetwork !== undefined) {
      writer.uint32(10).string(message.subnetwork);
    }
    if (message.endpointUri !== "") {
      writer.uint32(26).string(message.endpointUri);
    }
    if (message.endpointLocation !== "") {
      writer.uint32(34).string(message.endpointLocation);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): NetworkConfig_Consumer {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseNetworkConfig_Consumer();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.subnetwork = reader.string();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.endpointUri = reader.string();
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.endpointLocation = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): NetworkConfig_Consumer {
    return {
      subnetwork: isSet(object.subnetwork) ? globalThis.String(object.subnetwork) : undefined,
      endpointUri: isSet(object.endpointUri) ? globalThis.String(object.endpointUri) : "",
      endpointLocation: isSet(object.endpointLocation) ? globalThis.String(object.endpointLocation) : "",
    };
  },

  toJSON(message: NetworkConfig_Consumer): unknown {
    const obj: any = {};
    if (message.subnetwork !== undefined) {
      obj.subnetwork = message.subnetwork;
    }
    if (message.endpointUri !== "") {
      obj.endpointUri = message.endpointUri;
    }
    if (message.endpointLocation !== "") {
      obj.endpointLocation = message.endpointLocation;
    }
    return obj;
  },

  create(base?: DeepPartial<NetworkConfig_Consumer>): NetworkConfig_Consumer {
    return NetworkConfig_Consumer.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<NetworkConfig_Consumer>): NetworkConfig_Consumer {
    const message = createBaseNetworkConfig_Consumer();
    message.subnetwork = object.subnetwork ?? undefined;
    message.endpointUri = object.endpointUri ?? "";
    message.endpointLocation = object.endpointLocation ?? "";
    return message;
  },
};

function createBaseTelemetryConfig(): TelemetryConfig {
  return { logFormat: 0 };
}

export const TelemetryConfig: MessageFns<TelemetryConfig> = {
  encode(message: TelemetryConfig, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.logFormat !== 0) {
      writer.uint32(8).int32(message.logFormat);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): TelemetryConfig {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseTelemetryConfig();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 8) {
            break;
          }

          message.logFormat = reader.int32() as any;
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): TelemetryConfig {
    return { logFormat: isSet(object.logFormat) ? telemetryConfig_LogFormatFromJSON(object.logFormat) : 0 };
  },

  toJSON(message: TelemetryConfig): unknown {
    const obj: any = {};
    if (message.logFormat !== 0) {
      obj.logFormat = telemetryConfig_LogFormatToJSON(message.logFormat);
    }
    return obj;
  },

  create(base?: DeepPartial<TelemetryConfig>): TelemetryConfig {
    return TelemetryConfig.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<TelemetryConfig>): TelemetryConfig {
    const message = createBaseTelemetryConfig();
    message.logFormat = object.logFormat ?? 0;
    return message;
  },
};

function createBaseMetadataManagementActivity(): MetadataManagementActivity {
  return { metadataExports: [], restores: [] };
}

export const MetadataManagementActivity: MessageFns<MetadataManagementActivity> = {
  encode(message: MetadataManagementActivity, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.metadataExports) {
      MetadataExport.encode(v!, writer.uint32(10).fork()).join();
    }
    for (const v of message.restores) {
      Restore.encode(v!, writer.uint32(18).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): MetadataManagementActivity {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseMetadataManagementActivity();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.metadataExports.push(MetadataExport.decode(reader, reader.uint32()));
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.restores.push(Restore.decode(reader, reader.uint32()));
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): MetadataManagementActivity {
    return {
      metadataExports: globalThis.Array.isArray(object?.metadataExports)
        ? object.metadataExports.map((e: any) => MetadataExport.fromJSON(e))
        : [],
      restores: globalThis.Array.isArray(object?.restores) ? object.restores.map((e: any) => Restore.fromJSON(e)) : [],
    };
  },

  toJSON(message: MetadataManagementActivity): unknown {
    const obj: any = {};
    if (message.metadataExports?.length) {
      obj.metadataExports = message.metadataExports.map((e) => MetadataExport.toJSON(e));
    }
    if (message.restores?.length) {
      obj.restores = message.restores.map((e) => Restore.toJSON(e));
    }
    return obj;
  },

  create(base?: DeepPartial<MetadataManagementActivity>): MetadataManagementActivity {
    return MetadataManagementActivity.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<MetadataManagementActivity>): MetadataManagementActivity {
    const message = createBaseMetadataManagementActivity();
    message.metadataExports = object.metadataExports?.map((e) => MetadataExport.fromPartial(e)) || [];
    message.restores = object.restores?.map((e) => Restore.fromPartial(e)) || [];
    return message;
  },
};

function createBaseMetadataImport(): MetadataImport {
  return {
    databaseDump: undefined,
    name: "",
    description: "",
    createTime: undefined,
    updateTime: undefined,
    endTime: undefined,
    state: 0,
  };
}

export const MetadataImport: MessageFns<MetadataImport> = {
  encode(message: MetadataImport, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.databaseDump !== undefined) {
      MetadataImport_DatabaseDump.encode(message.databaseDump, writer.uint32(50).fork()).join();
    }
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    if (message.description !== "") {
      writer.uint32(18).string(message.description);
    }
    if (message.createTime !== undefined) {
      Timestamp.encode(toTimestamp(message.createTime), writer.uint32(26).fork()).join();
    }
    if (message.updateTime !== undefined) {
      Timestamp.encode(toTimestamp(message.updateTime), writer.uint32(34).fork()).join();
    }
    if (message.endTime !== undefined) {
      Timestamp.encode(toTimestamp(message.endTime), writer.uint32(58).fork()).join();
    }
    if (message.state !== 0) {
      writer.uint32(40).int32(message.state);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): MetadataImport {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseMetadataImport();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 6:
          if (tag !== 50) {
            break;
          }

          message.databaseDump = MetadataImport_DatabaseDump.decode(reader, reader.uint32());
          continue;
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.description = reader.string();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.createTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.updateTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        case 7:
          if (tag !== 58) {
            break;
          }

          message.endTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        case 5:
          if (tag !== 40) {
            break;
          }

          message.state = reader.int32() as any;
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): MetadataImport {
    return {
      databaseDump: isSet(object.databaseDump) ? MetadataImport_DatabaseDump.fromJSON(object.databaseDump) : undefined,
      name: isSet(object.name) ? globalThis.String(object.name) : "",
      description: isSet(object.description) ? globalThis.String(object.description) : "",
      createTime: isSet(object.createTime) ? fromJsonTimestamp(object.createTime) : undefined,
      updateTime: isSet(object.updateTime) ? fromJsonTimestamp(object.updateTime) : undefined,
      endTime: isSet(object.endTime) ? fromJsonTimestamp(object.endTime) : undefined,
      state: isSet(object.state) ? metadataImport_StateFromJSON(object.state) : 0,
    };
  },

  toJSON(message: MetadataImport): unknown {
    const obj: any = {};
    if (message.databaseDump !== undefined) {
      obj.databaseDump = MetadataImport_DatabaseDump.toJSON(message.databaseDump);
    }
    if (message.name !== "") {
      obj.name = message.name;
    }
    if (message.description !== "") {
      obj.description = message.description;
    }
    if (message.createTime !== undefined) {
      obj.createTime = message.createTime.toISOString();
    }
    if (message.updateTime !== undefined) {
      obj.updateTime = message.updateTime.toISOString();
    }
    if (message.endTime !== undefined) {
      obj.endTime = message.endTime.toISOString();
    }
    if (message.state !== 0) {
      obj.state = metadataImport_StateToJSON(message.state);
    }
    return obj;
  },

  create(base?: DeepPartial<MetadataImport>): MetadataImport {
    return MetadataImport.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<MetadataImport>): MetadataImport {
    const message = createBaseMetadataImport();
    message.databaseDump = (object.databaseDump !== undefined && object.databaseDump !== null)
      ? MetadataImport_DatabaseDump.fromPartial(object.databaseDump)
      : undefined;
    message.name = object.name ?? "";
    message.description = object.description ?? "";
    message.createTime = object.createTime ?? undefined;
    message.updateTime = object.updateTime ?? undefined;
    message.endTime = object.endTime ?? undefined;
    message.state = object.state ?? 0;
    return message;
  },
};

function createBaseMetadataImport_DatabaseDump(): MetadataImport_DatabaseDump {
  return { databaseType: 0, gcsUri: "", sourceDatabase: "", type: 0 };
}

export const MetadataImport_DatabaseDump: MessageFns<MetadataImport_DatabaseDump> = {
  encode(message: MetadataImport_DatabaseDump, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.databaseType !== 0) {
      writer.uint32(8).int32(message.databaseType);
    }
    if (message.gcsUri !== "") {
      writer.uint32(18).string(message.gcsUri);
    }
    if (message.sourceDatabase !== "") {
      writer.uint32(26).string(message.sourceDatabase);
    }
    if (message.type !== 0) {
      writer.uint32(32).int32(message.type);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): MetadataImport_DatabaseDump {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseMetadataImport_DatabaseDump();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 8) {
            break;
          }

          message.databaseType = reader.int32() as any;
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.gcsUri = reader.string();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.sourceDatabase = reader.string();
          continue;
        case 4:
          if (tag !== 32) {
            break;
          }

          message.type = reader.int32() as any;
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): MetadataImport_DatabaseDump {
    return {
      databaseType: isSet(object.databaseType)
        ? metadataImport_DatabaseDump_DatabaseTypeFromJSON(object.databaseType)
        : 0,
      gcsUri: isSet(object.gcsUri) ? globalThis.String(object.gcsUri) : "",
      sourceDatabase: isSet(object.sourceDatabase) ? globalThis.String(object.sourceDatabase) : "",
      type: isSet(object.type) ? databaseDumpSpec_TypeFromJSON(object.type) : 0,
    };
  },

  toJSON(message: MetadataImport_DatabaseDump): unknown {
    const obj: any = {};
    if (message.databaseType !== 0) {
      obj.databaseType = metadataImport_DatabaseDump_DatabaseTypeToJSON(message.databaseType);
    }
    if (message.gcsUri !== "") {
      obj.gcsUri = message.gcsUri;
    }
    if (message.sourceDatabase !== "") {
      obj.sourceDatabase = message.sourceDatabase;
    }
    if (message.type !== 0) {
      obj.type = databaseDumpSpec_TypeToJSON(message.type);
    }
    return obj;
  },

  create(base?: DeepPartial<MetadataImport_DatabaseDump>): MetadataImport_DatabaseDump {
    return MetadataImport_DatabaseDump.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<MetadataImport_DatabaseDump>): MetadataImport_DatabaseDump {
    const message = createBaseMetadataImport_DatabaseDump();
    message.databaseType = object.databaseType ?? 0;
    message.gcsUri = object.gcsUri ?? "";
    message.sourceDatabase = object.sourceDatabase ?? "";
    message.type = object.type ?? 0;
    return message;
  },
};

function createBaseMetadataExport(): MetadataExport {
  return { destinationGcsUri: undefined, startTime: undefined, endTime: undefined, state: 0, databaseDumpType: 0 };
}

export const MetadataExport: MessageFns<MetadataExport> = {
  encode(message: MetadataExport, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.destinationGcsUri !== undefined) {
      writer.uint32(34).string(message.destinationGcsUri);
    }
    if (message.startTime !== undefined) {
      Timestamp.encode(toTimestamp(message.startTime), writer.uint32(10).fork()).join();
    }
    if (message.endTime !== undefined) {
      Timestamp.encode(toTimestamp(message.endTime), writer.uint32(18).fork()).join();
    }
    if (message.state !== 0) {
      writer.uint32(24).int32(message.state);
    }
    if (message.databaseDumpType !== 0) {
      writer.uint32(40).int32(message.databaseDumpType);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): MetadataExport {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseMetadataExport();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 4:
          if (tag !== 34) {
            break;
          }

          message.destinationGcsUri = reader.string();
          continue;
        case 1:
          if (tag !== 10) {
            break;
          }

          message.startTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.endTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        case 3:
          if (tag !== 24) {
            break;
          }

          message.state = reader.int32() as any;
          continue;
        case 5:
          if (tag !== 40) {
            break;
          }

          message.databaseDumpType = reader.int32() as any;
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): MetadataExport {
    return {
      destinationGcsUri: isSet(object.destinationGcsUri) ? globalThis.String(object.destinationGcsUri) : undefined,
      startTime: isSet(object.startTime) ? fromJsonTimestamp(object.startTime) : undefined,
      endTime: isSet(object.endTime) ? fromJsonTimestamp(object.endTime) : undefined,
      state: isSet(object.state) ? metadataExport_StateFromJSON(object.state) : 0,
      databaseDumpType: isSet(object.databaseDumpType) ? databaseDumpSpec_TypeFromJSON(object.databaseDumpType) : 0,
    };
  },

  toJSON(message: MetadataExport): unknown {
    const obj: any = {};
    if (message.destinationGcsUri !== undefined) {
      obj.destinationGcsUri = message.destinationGcsUri;
    }
    if (message.startTime !== undefined) {
      obj.startTime = message.startTime.toISOString();
    }
    if (message.endTime !== undefined) {
      obj.endTime = message.endTime.toISOString();
    }
    if (message.state !== 0) {
      obj.state = metadataExport_StateToJSON(message.state);
    }
    if (message.databaseDumpType !== 0) {
      obj.databaseDumpType = databaseDumpSpec_TypeToJSON(message.databaseDumpType);
    }
    return obj;
  },

  create(base?: DeepPartial<MetadataExport>): MetadataExport {
    return MetadataExport.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<MetadataExport>): MetadataExport {
    const message = createBaseMetadataExport();
    message.destinationGcsUri = object.destinationGcsUri ?? undefined;
    message.startTime = object.startTime ?? undefined;
    message.endTime = object.endTime ?? undefined;
    message.state = object.state ?? 0;
    message.databaseDumpType = object.databaseDumpType ?? 0;
    return message;
  },
};

function createBaseBackup(): Backup {
  return {
    name: "",
    createTime: undefined,
    endTime: undefined,
    state: 0,
    serviceRevision: undefined,
    description: "",
    restoringServices: [],
  };
}

export const Backup: MessageFns<Backup> = {
  encode(message: Backup, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    if (message.createTime !== undefined) {
      Timestamp.encode(toTimestamp(message.createTime), writer.uint32(18).fork()).join();
    }
    if (message.endTime !== undefined) {
      Timestamp.encode(toTimestamp(message.endTime), writer.uint32(26).fork()).join();
    }
    if (message.state !== 0) {
      writer.uint32(32).int32(message.state);
    }
    if (message.serviceRevision !== undefined) {
      Service.encode(message.serviceRevision, writer.uint32(42).fork()).join();
    }
    if (message.description !== "") {
      writer.uint32(50).string(message.description);
    }
    for (const v of message.restoringServices) {
      writer.uint32(58).string(v!);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Backup {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseBackup();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.createTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.endTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        case 4:
          if (tag !== 32) {
            break;
          }

          message.state = reader.int32() as any;
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.serviceRevision = Service.decode(reader, reader.uint32());
          continue;
        case 6:
          if (tag !== 50) {
            break;
          }

          message.description = reader.string();
          continue;
        case 7:
          if (tag !== 58) {
            break;
          }

          message.restoringServices.push(reader.string());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Backup {
    return {
      name: isSet(object.name) ? globalThis.String(object.name) : "",
      createTime: isSet(object.createTime) ? fromJsonTimestamp(object.createTime) : undefined,
      endTime: isSet(object.endTime) ? fromJsonTimestamp(object.endTime) : undefined,
      state: isSet(object.state) ? backup_StateFromJSON(object.state) : 0,
      serviceRevision: isSet(object.serviceRevision) ? Service.fromJSON(object.serviceRevision) : undefined,
      description: isSet(object.description) ? globalThis.String(object.description) : "",
      restoringServices: globalThis.Array.isArray(object?.restoringServices)
        ? object.restoringServices.map((e: any) => globalThis.String(e))
        : [],
    };
  },

  toJSON(message: Backup): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    if (message.createTime !== undefined) {
      obj.createTime = message.createTime.toISOString();
    }
    if (message.endTime !== undefined) {
      obj.endTime = message.endTime.toISOString();
    }
    if (message.state !== 0) {
      obj.state = backup_StateToJSON(message.state);
    }
    if (message.serviceRevision !== undefined) {
      obj.serviceRevision = Service.toJSON(message.serviceRevision);
    }
    if (message.description !== "") {
      obj.description = message.description;
    }
    if (message.restoringServices?.length) {
      obj.restoringServices = message.restoringServices;
    }
    return obj;
  },

  create(base?: DeepPartial<Backup>): Backup {
    return Backup.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<Backup>): Backup {
    const message = createBaseBackup();
    message.name = object.name ?? "";
    message.createTime = object.createTime ?? undefined;
    message.endTime = object.endTime ?? undefined;
    message.state = object.state ?? 0;
    message.serviceRevision = (object.serviceRevision !== undefined && object.serviceRevision !== null)
      ? Service.fromPartial(object.serviceRevision)
      : undefined;
    message.description = object.description ?? "";
    message.restoringServices = object.restoringServices?.map((e) => e) || [];
    return message;
  },
};

function createBaseRestore(): Restore {
  return { startTime: undefined, endTime: undefined, state: 0, backup: "", type: 0, details: "" };
}

export const Restore: MessageFns<Restore> = {
  encode(message: Restore, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.startTime !== undefined) {
      Timestamp.encode(toTimestamp(message.startTime), writer.uint32(10).fork()).join();
    }
    if (message.endTime !== undefined) {
      Timestamp.encode(toTimestamp(message.endTime), writer.uint32(18).fork()).join();
    }
    if (message.state !== 0) {
      writer.uint32(24).int32(message.state);
    }
    if (message.backup !== "") {
      writer.uint32(34).string(message.backup);
    }
    if (message.type !== 0) {
      writer.uint32(40).int32(message.type);
    }
    if (message.details !== "") {
      writer.uint32(50).string(message.details);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Restore {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseRestore();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.startTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.endTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        case 3:
          if (tag !== 24) {
            break;
          }

          message.state = reader.int32() as any;
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.backup = reader.string();
          continue;
        case 5:
          if (tag !== 40) {
            break;
          }

          message.type = reader.int32() as any;
          continue;
        case 6:
          if (tag !== 50) {
            break;
          }

          message.details = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Restore {
    return {
      startTime: isSet(object.startTime) ? fromJsonTimestamp(object.startTime) : undefined,
      endTime: isSet(object.endTime) ? fromJsonTimestamp(object.endTime) : undefined,
      state: isSet(object.state) ? restore_StateFromJSON(object.state) : 0,
      backup: isSet(object.backup) ? globalThis.String(object.backup) : "",
      type: isSet(object.type) ? restore_RestoreTypeFromJSON(object.type) : 0,
      details: isSet(object.details) ? globalThis.String(object.details) : "",
    };
  },

  toJSON(message: Restore): unknown {
    const obj: any = {};
    if (message.startTime !== undefined) {
      obj.startTime = message.startTime.toISOString();
    }
    if (message.endTime !== undefined) {
      obj.endTime = message.endTime.toISOString();
    }
    if (message.state !== 0) {
      obj.state = restore_StateToJSON(message.state);
    }
    if (message.backup !== "") {
      obj.backup = message.backup;
    }
    if (message.type !== 0) {
      obj.type = restore_RestoreTypeToJSON(message.type);
    }
    if (message.details !== "") {
      obj.details = message.details;
    }
    return obj;
  },

  create(base?: DeepPartial<Restore>): Restore {
    return Restore.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<Restore>): Restore {
    const message = createBaseRestore();
    message.startTime = object.startTime ?? undefined;
    message.endTime = object.endTime ?? undefined;
    message.state = object.state ?? 0;
    message.backup = object.backup ?? "";
    message.type = object.type ?? 0;
    message.details = object.details ?? "";
    return message;
  },
};

function createBaseScalingConfig(): ScalingConfig {
  return { instanceSize: undefined, scalingFactor: undefined };
}

export const ScalingConfig: MessageFns<ScalingConfig> = {
  encode(message: ScalingConfig, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.instanceSize !== undefined) {
      writer.uint32(8).int32(message.instanceSize);
    }
    if (message.scalingFactor !== undefined) {
      writer.uint32(21).float(message.scalingFactor);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ScalingConfig {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseScalingConfig();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 8) {
            break;
          }

          message.instanceSize = reader.int32() as any;
          continue;
        case 2:
          if (tag !== 21) {
            break;
          }

          message.scalingFactor = reader.float();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ScalingConfig {
    return {
      instanceSize: isSet(object.instanceSize) ? scalingConfig_InstanceSizeFromJSON(object.instanceSize) : undefined,
      scalingFactor: isSet(object.scalingFactor) ? globalThis.Number(object.scalingFactor) : undefined,
    };
  },

  toJSON(message: ScalingConfig): unknown {
    const obj: any = {};
    if (message.instanceSize !== undefined) {
      obj.instanceSize = scalingConfig_InstanceSizeToJSON(message.instanceSize);
    }
    if (message.scalingFactor !== undefined) {
      obj.scalingFactor = message.scalingFactor;
    }
    return obj;
  },

  create(base?: DeepPartial<ScalingConfig>): ScalingConfig {
    return ScalingConfig.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ScalingConfig>): ScalingConfig {
    const message = createBaseScalingConfig();
    message.instanceSize = object.instanceSize ?? undefined;
    message.scalingFactor = object.scalingFactor ?? undefined;
    return message;
  },
};

function createBaseListServicesRequest(): ListServicesRequest {
  return { parent: "", pageSize: 0, pageToken: "", filter: "", orderBy: "" };
}

export const ListServicesRequest: MessageFns<ListServicesRequest> = {
  encode(message: ListServicesRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.parent !== "") {
      writer.uint32(10).string(message.parent);
    }
    if (message.pageSize !== 0) {
      writer.uint32(16).int32(message.pageSize);
    }
    if (message.pageToken !== "") {
      writer.uint32(26).string(message.pageToken);
    }
    if (message.filter !== "") {
      writer.uint32(34).string(message.filter);
    }
    if (message.orderBy !== "") {
      writer.uint32(42).string(message.orderBy);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ListServicesRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseListServicesRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.parent = reader.string();
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.pageSize = reader.int32();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.pageToken = reader.string();
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.filter = reader.string();
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.orderBy = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ListServicesRequest {
    return {
      parent: isSet(object.parent) ? globalThis.String(object.parent) : "",
      pageSize: isSet(object.pageSize) ? globalThis.Number(object.pageSize) : 0,
      pageToken: isSet(object.pageToken) ? globalThis.String(object.pageToken) : "",
      filter: isSet(object.filter) ? globalThis.String(object.filter) : "",
      orderBy: isSet(object.orderBy) ? globalThis.String(object.orderBy) : "",
    };
  },

  toJSON(message: ListServicesRequest): unknown {
    const obj: any = {};
    if (message.parent !== "") {
      obj.parent = message.parent;
    }
    if (message.pageSize !== 0) {
      obj.pageSize = Math.round(message.pageSize);
    }
    if (message.pageToken !== "") {
      obj.pageToken = message.pageToken;
    }
    if (message.filter !== "") {
      obj.filter = message.filter;
    }
    if (message.orderBy !== "") {
      obj.orderBy = message.orderBy;
    }
    return obj;
  },

  create(base?: DeepPartial<ListServicesRequest>): ListServicesRequest {
    return ListServicesRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ListServicesRequest>): ListServicesRequest {
    const message = createBaseListServicesRequest();
    message.parent = object.parent ?? "";
    message.pageSize = object.pageSize ?? 0;
    message.pageToken = object.pageToken ?? "";
    message.filter = object.filter ?? "";
    message.orderBy = object.orderBy ?? "";
    return message;
  },
};

function createBaseListServicesResponse(): ListServicesResponse {
  return { services: [], nextPageToken: "", unreachable: [] };
}

export const ListServicesResponse: MessageFns<ListServicesResponse> = {
  encode(message: ListServicesResponse, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.services) {
      Service.encode(v!, writer.uint32(10).fork()).join();
    }
    if (message.nextPageToken !== "") {
      writer.uint32(18).string(message.nextPageToken);
    }
    for (const v of message.unreachable) {
      writer.uint32(26).string(v!);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ListServicesResponse {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseListServicesResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.services.push(Service.decode(reader, reader.uint32()));
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.nextPageToken = reader.string();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.unreachable.push(reader.string());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ListServicesResponse {
    return {
      services: globalThis.Array.isArray(object?.services) ? object.services.map((e: any) => Service.fromJSON(e)) : [],
      nextPageToken: isSet(object.nextPageToken) ? globalThis.String(object.nextPageToken) : "",
      unreachable: globalThis.Array.isArray(object?.unreachable)
        ? object.unreachable.map((e: any) => globalThis.String(e))
        : [],
    };
  },

  toJSON(message: ListServicesResponse): unknown {
    const obj: any = {};
    if (message.services?.length) {
      obj.services = message.services.map((e) => Service.toJSON(e));
    }
    if (message.nextPageToken !== "") {
      obj.nextPageToken = message.nextPageToken;
    }
    if (message.unreachable?.length) {
      obj.unreachable = message.unreachable;
    }
    return obj;
  },

  create(base?: DeepPartial<ListServicesResponse>): ListServicesResponse {
    return ListServicesResponse.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ListServicesResponse>): ListServicesResponse {
    const message = createBaseListServicesResponse();
    message.services = object.services?.map((e) => Service.fromPartial(e)) || [];
    message.nextPageToken = object.nextPageToken ?? "";
    message.unreachable = object.unreachable?.map((e) => e) || [];
    return message;
  },
};

function createBaseGetServiceRequest(): GetServiceRequest {
  return { name: "" };
}

export const GetServiceRequest: MessageFns<GetServiceRequest> = {
  encode(message: GetServiceRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): GetServiceRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseGetServiceRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): GetServiceRequest {
    return { name: isSet(object.name) ? globalThis.String(object.name) : "" };
  },

  toJSON(message: GetServiceRequest): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    return obj;
  },

  create(base?: DeepPartial<GetServiceRequest>): GetServiceRequest {
    return GetServiceRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<GetServiceRequest>): GetServiceRequest {
    const message = createBaseGetServiceRequest();
    message.name = object.name ?? "";
    return message;
  },
};

function createBaseCreateServiceRequest(): CreateServiceRequest {
  return { parent: "", serviceId: "", service: undefined, requestId: "" };
}

export const CreateServiceRequest: MessageFns<CreateServiceRequest> = {
  encode(message: CreateServiceRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.parent !== "") {
      writer.uint32(10).string(message.parent);
    }
    if (message.serviceId !== "") {
      writer.uint32(18).string(message.serviceId);
    }
    if (message.service !== undefined) {
      Service.encode(message.service, writer.uint32(26).fork()).join();
    }
    if (message.requestId !== "") {
      writer.uint32(34).string(message.requestId);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): CreateServiceRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseCreateServiceRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.parent = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.serviceId = reader.string();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.service = Service.decode(reader, reader.uint32());
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.requestId = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): CreateServiceRequest {
    return {
      parent: isSet(object.parent) ? globalThis.String(object.parent) : "",
      serviceId: isSet(object.serviceId) ? globalThis.String(object.serviceId) : "",
      service: isSet(object.service) ? Service.fromJSON(object.service) : undefined,
      requestId: isSet(object.requestId) ? globalThis.String(object.requestId) : "",
    };
  },

  toJSON(message: CreateServiceRequest): unknown {
    const obj: any = {};
    if (message.parent !== "") {
      obj.parent = message.parent;
    }
    if (message.serviceId !== "") {
      obj.serviceId = message.serviceId;
    }
    if (message.service !== undefined) {
      obj.service = Service.toJSON(message.service);
    }
    if (message.requestId !== "") {
      obj.requestId = message.requestId;
    }
    return obj;
  },

  create(base?: DeepPartial<CreateServiceRequest>): CreateServiceRequest {
    return CreateServiceRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<CreateServiceRequest>): CreateServiceRequest {
    const message = createBaseCreateServiceRequest();
    message.parent = object.parent ?? "";
    message.serviceId = object.serviceId ?? "";
    message.service = (object.service !== undefined && object.service !== null)
      ? Service.fromPartial(object.service)
      : undefined;
    message.requestId = object.requestId ?? "";
    return message;
  },
};

function createBaseUpdateServiceRequest(): UpdateServiceRequest {
  return { updateMask: undefined, service: undefined, requestId: "" };
}

export const UpdateServiceRequest: MessageFns<UpdateServiceRequest> = {
  encode(message: UpdateServiceRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.updateMask !== undefined) {
      FieldMask.encode(FieldMask.wrap(message.updateMask), writer.uint32(10).fork()).join();
    }
    if (message.service !== undefined) {
      Service.encode(message.service, writer.uint32(18).fork()).join();
    }
    if (message.requestId !== "") {
      writer.uint32(26).string(message.requestId);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): UpdateServiceRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseUpdateServiceRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.updateMask = FieldMask.unwrap(FieldMask.decode(reader, reader.uint32()));
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.service = Service.decode(reader, reader.uint32());
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.requestId = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): UpdateServiceRequest {
    return {
      updateMask: isSet(object.updateMask) ? FieldMask.unwrap(FieldMask.fromJSON(object.updateMask)) : undefined,
      service: isSet(object.service) ? Service.fromJSON(object.service) : undefined,
      requestId: isSet(object.requestId) ? globalThis.String(object.requestId) : "",
    };
  },

  toJSON(message: UpdateServiceRequest): unknown {
    const obj: any = {};
    if (message.updateMask !== undefined) {
      obj.updateMask = FieldMask.toJSON(FieldMask.wrap(message.updateMask));
    }
    if (message.service !== undefined) {
      obj.service = Service.toJSON(message.service);
    }
    if (message.requestId !== "") {
      obj.requestId = message.requestId;
    }
    return obj;
  },

  create(base?: DeepPartial<UpdateServiceRequest>): UpdateServiceRequest {
    return UpdateServiceRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<UpdateServiceRequest>): UpdateServiceRequest {
    const message = createBaseUpdateServiceRequest();
    message.updateMask = object.updateMask ?? undefined;
    message.service = (object.service !== undefined && object.service !== null)
      ? Service.fromPartial(object.service)
      : undefined;
    message.requestId = object.requestId ?? "";
    return message;
  },
};

function createBaseDeleteServiceRequest(): DeleteServiceRequest {
  return { name: "", requestId: "" };
}

export const DeleteServiceRequest: MessageFns<DeleteServiceRequest> = {
  encode(message: DeleteServiceRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    if (message.requestId !== "") {
      writer.uint32(18).string(message.requestId);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): DeleteServiceRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDeleteServiceRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.requestId = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): DeleteServiceRequest {
    return {
      name: isSet(object.name) ? globalThis.String(object.name) : "",
      requestId: isSet(object.requestId) ? globalThis.String(object.requestId) : "",
    };
  },

  toJSON(message: DeleteServiceRequest): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    if (message.requestId !== "") {
      obj.requestId = message.requestId;
    }
    return obj;
  },

  create(base?: DeepPartial<DeleteServiceRequest>): DeleteServiceRequest {
    return DeleteServiceRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<DeleteServiceRequest>): DeleteServiceRequest {
    const message = createBaseDeleteServiceRequest();
    message.name = object.name ?? "";
    message.requestId = object.requestId ?? "";
    return message;
  },
};

function createBaseListMetadataImportsRequest(): ListMetadataImportsRequest {
  return { parent: "", pageSize: 0, pageToken: "", filter: "", orderBy: "" };
}

export const ListMetadataImportsRequest: MessageFns<ListMetadataImportsRequest> = {
  encode(message: ListMetadataImportsRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.parent !== "") {
      writer.uint32(10).string(message.parent);
    }
    if (message.pageSize !== 0) {
      writer.uint32(16).int32(message.pageSize);
    }
    if (message.pageToken !== "") {
      writer.uint32(26).string(message.pageToken);
    }
    if (message.filter !== "") {
      writer.uint32(34).string(message.filter);
    }
    if (message.orderBy !== "") {
      writer.uint32(42).string(message.orderBy);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ListMetadataImportsRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseListMetadataImportsRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.parent = reader.string();
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.pageSize = reader.int32();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.pageToken = reader.string();
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.filter = reader.string();
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.orderBy = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ListMetadataImportsRequest {
    return {
      parent: isSet(object.parent) ? globalThis.String(object.parent) : "",
      pageSize: isSet(object.pageSize) ? globalThis.Number(object.pageSize) : 0,
      pageToken: isSet(object.pageToken) ? globalThis.String(object.pageToken) : "",
      filter: isSet(object.filter) ? globalThis.String(object.filter) : "",
      orderBy: isSet(object.orderBy) ? globalThis.String(object.orderBy) : "",
    };
  },

  toJSON(message: ListMetadataImportsRequest): unknown {
    const obj: any = {};
    if (message.parent !== "") {
      obj.parent = message.parent;
    }
    if (message.pageSize !== 0) {
      obj.pageSize = Math.round(message.pageSize);
    }
    if (message.pageToken !== "") {
      obj.pageToken = message.pageToken;
    }
    if (message.filter !== "") {
      obj.filter = message.filter;
    }
    if (message.orderBy !== "") {
      obj.orderBy = message.orderBy;
    }
    return obj;
  },

  create(base?: DeepPartial<ListMetadataImportsRequest>): ListMetadataImportsRequest {
    return ListMetadataImportsRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ListMetadataImportsRequest>): ListMetadataImportsRequest {
    const message = createBaseListMetadataImportsRequest();
    message.parent = object.parent ?? "";
    message.pageSize = object.pageSize ?? 0;
    message.pageToken = object.pageToken ?? "";
    message.filter = object.filter ?? "";
    message.orderBy = object.orderBy ?? "";
    return message;
  },
};

function createBaseListMetadataImportsResponse(): ListMetadataImportsResponse {
  return { metadataImports: [], nextPageToken: "", unreachable: [] };
}

export const ListMetadataImportsResponse: MessageFns<ListMetadataImportsResponse> = {
  encode(message: ListMetadataImportsResponse, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.metadataImports) {
      MetadataImport.encode(v!, writer.uint32(10).fork()).join();
    }
    if (message.nextPageToken !== "") {
      writer.uint32(18).string(message.nextPageToken);
    }
    for (const v of message.unreachable) {
      writer.uint32(26).string(v!);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ListMetadataImportsResponse {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseListMetadataImportsResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.metadataImports.push(MetadataImport.decode(reader, reader.uint32()));
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.nextPageToken = reader.string();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.unreachable.push(reader.string());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ListMetadataImportsResponse {
    return {
      metadataImports: globalThis.Array.isArray(object?.metadataImports)
        ? object.metadataImports.map((e: any) => MetadataImport.fromJSON(e))
        : [],
      nextPageToken: isSet(object.nextPageToken) ? globalThis.String(object.nextPageToken) : "",
      unreachable: globalThis.Array.isArray(object?.unreachable)
        ? object.unreachable.map((e: any) => globalThis.String(e))
        : [],
    };
  },

  toJSON(message: ListMetadataImportsResponse): unknown {
    const obj: any = {};
    if (message.metadataImports?.length) {
      obj.metadataImports = message.metadataImports.map((e) => MetadataImport.toJSON(e));
    }
    if (message.nextPageToken !== "") {
      obj.nextPageToken = message.nextPageToken;
    }
    if (message.unreachable?.length) {
      obj.unreachable = message.unreachable;
    }
    return obj;
  },

  create(base?: DeepPartial<ListMetadataImportsResponse>): ListMetadataImportsResponse {
    return ListMetadataImportsResponse.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ListMetadataImportsResponse>): ListMetadataImportsResponse {
    const message = createBaseListMetadataImportsResponse();
    message.metadataImports = object.metadataImports?.map((e) => MetadataImport.fromPartial(e)) || [];
    message.nextPageToken = object.nextPageToken ?? "";
    message.unreachable = object.unreachable?.map((e) => e) || [];
    return message;
  },
};

function createBaseGetMetadataImportRequest(): GetMetadataImportRequest {
  return { name: "" };
}

export const GetMetadataImportRequest: MessageFns<GetMetadataImportRequest> = {
  encode(message: GetMetadataImportRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): GetMetadataImportRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseGetMetadataImportRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): GetMetadataImportRequest {
    return { name: isSet(object.name) ? globalThis.String(object.name) : "" };
  },

  toJSON(message: GetMetadataImportRequest): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    return obj;
  },

  create(base?: DeepPartial<GetMetadataImportRequest>): GetMetadataImportRequest {
    return GetMetadataImportRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<GetMetadataImportRequest>): GetMetadataImportRequest {
    const message = createBaseGetMetadataImportRequest();
    message.name = object.name ?? "";
    return message;
  },
};

function createBaseCreateMetadataImportRequest(): CreateMetadataImportRequest {
  return { parent: "", metadataImportId: "", metadataImport: undefined, requestId: "" };
}

export const CreateMetadataImportRequest: MessageFns<CreateMetadataImportRequest> = {
  encode(message: CreateMetadataImportRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.parent !== "") {
      writer.uint32(10).string(message.parent);
    }
    if (message.metadataImportId !== "") {
      writer.uint32(18).string(message.metadataImportId);
    }
    if (message.metadataImport !== undefined) {
      MetadataImport.encode(message.metadataImport, writer.uint32(26).fork()).join();
    }
    if (message.requestId !== "") {
      writer.uint32(34).string(message.requestId);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): CreateMetadataImportRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseCreateMetadataImportRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.parent = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.metadataImportId = reader.string();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.metadataImport = MetadataImport.decode(reader, reader.uint32());
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.requestId = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): CreateMetadataImportRequest {
    return {
      parent: isSet(object.parent) ? globalThis.String(object.parent) : "",
      metadataImportId: isSet(object.metadataImportId) ? globalThis.String(object.metadataImportId) : "",
      metadataImport: isSet(object.metadataImport) ? MetadataImport.fromJSON(object.metadataImport) : undefined,
      requestId: isSet(object.requestId) ? globalThis.String(object.requestId) : "",
    };
  },

  toJSON(message: CreateMetadataImportRequest): unknown {
    const obj: any = {};
    if (message.parent !== "") {
      obj.parent = message.parent;
    }
    if (message.metadataImportId !== "") {
      obj.metadataImportId = message.metadataImportId;
    }
    if (message.metadataImport !== undefined) {
      obj.metadataImport = MetadataImport.toJSON(message.metadataImport);
    }
    if (message.requestId !== "") {
      obj.requestId = message.requestId;
    }
    return obj;
  },

  create(base?: DeepPartial<CreateMetadataImportRequest>): CreateMetadataImportRequest {
    return CreateMetadataImportRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<CreateMetadataImportRequest>): CreateMetadataImportRequest {
    const message = createBaseCreateMetadataImportRequest();
    message.parent = object.parent ?? "";
    message.metadataImportId = object.metadataImportId ?? "";
    message.metadataImport = (object.metadataImport !== undefined && object.metadataImport !== null)
      ? MetadataImport.fromPartial(object.metadataImport)
      : undefined;
    message.requestId = object.requestId ?? "";
    return message;
  },
};

function createBaseUpdateMetadataImportRequest(): UpdateMetadataImportRequest {
  return { updateMask: undefined, metadataImport: undefined, requestId: "" };
}

export const UpdateMetadataImportRequest: MessageFns<UpdateMetadataImportRequest> = {
  encode(message: UpdateMetadataImportRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.updateMask !== undefined) {
      FieldMask.encode(FieldMask.wrap(message.updateMask), writer.uint32(10).fork()).join();
    }
    if (message.metadataImport !== undefined) {
      MetadataImport.encode(message.metadataImport, writer.uint32(18).fork()).join();
    }
    if (message.requestId !== "") {
      writer.uint32(26).string(message.requestId);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): UpdateMetadataImportRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseUpdateMetadataImportRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.updateMask = FieldMask.unwrap(FieldMask.decode(reader, reader.uint32()));
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.metadataImport = MetadataImport.decode(reader, reader.uint32());
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.requestId = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): UpdateMetadataImportRequest {
    return {
      updateMask: isSet(object.updateMask) ? FieldMask.unwrap(FieldMask.fromJSON(object.updateMask)) : undefined,
      metadataImport: isSet(object.metadataImport) ? MetadataImport.fromJSON(object.metadataImport) : undefined,
      requestId: isSet(object.requestId) ? globalThis.String(object.requestId) : "",
    };
  },

  toJSON(message: UpdateMetadataImportRequest): unknown {
    const obj: any = {};
    if (message.updateMask !== undefined) {
      obj.updateMask = FieldMask.toJSON(FieldMask.wrap(message.updateMask));
    }
    if (message.metadataImport !== undefined) {
      obj.metadataImport = MetadataImport.toJSON(message.metadataImport);
    }
    if (message.requestId !== "") {
      obj.requestId = message.requestId;
    }
    return obj;
  },

  create(base?: DeepPartial<UpdateMetadataImportRequest>): UpdateMetadataImportRequest {
    return UpdateMetadataImportRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<UpdateMetadataImportRequest>): UpdateMetadataImportRequest {
    const message = createBaseUpdateMetadataImportRequest();
    message.updateMask = object.updateMask ?? undefined;
    message.metadataImport = (object.metadataImport !== undefined && object.metadataImport !== null)
      ? MetadataImport.fromPartial(object.metadataImport)
      : undefined;
    message.requestId = object.requestId ?? "";
    return message;
  },
};

function createBaseListBackupsRequest(): ListBackupsRequest {
  return { parent: "", pageSize: 0, pageToken: "", filter: "", orderBy: "" };
}

export const ListBackupsRequest: MessageFns<ListBackupsRequest> = {
  encode(message: ListBackupsRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.parent !== "") {
      writer.uint32(10).string(message.parent);
    }
    if (message.pageSize !== 0) {
      writer.uint32(16).int32(message.pageSize);
    }
    if (message.pageToken !== "") {
      writer.uint32(26).string(message.pageToken);
    }
    if (message.filter !== "") {
      writer.uint32(34).string(message.filter);
    }
    if (message.orderBy !== "") {
      writer.uint32(42).string(message.orderBy);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ListBackupsRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseListBackupsRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.parent = reader.string();
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.pageSize = reader.int32();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.pageToken = reader.string();
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.filter = reader.string();
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.orderBy = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ListBackupsRequest {
    return {
      parent: isSet(object.parent) ? globalThis.String(object.parent) : "",
      pageSize: isSet(object.pageSize) ? globalThis.Number(object.pageSize) : 0,
      pageToken: isSet(object.pageToken) ? globalThis.String(object.pageToken) : "",
      filter: isSet(object.filter) ? globalThis.String(object.filter) : "",
      orderBy: isSet(object.orderBy) ? globalThis.String(object.orderBy) : "",
    };
  },

  toJSON(message: ListBackupsRequest): unknown {
    const obj: any = {};
    if (message.parent !== "") {
      obj.parent = message.parent;
    }
    if (message.pageSize !== 0) {
      obj.pageSize = Math.round(message.pageSize);
    }
    if (message.pageToken !== "") {
      obj.pageToken = message.pageToken;
    }
    if (message.filter !== "") {
      obj.filter = message.filter;
    }
    if (message.orderBy !== "") {
      obj.orderBy = message.orderBy;
    }
    return obj;
  },

  create(base?: DeepPartial<ListBackupsRequest>): ListBackupsRequest {
    return ListBackupsRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ListBackupsRequest>): ListBackupsRequest {
    const message = createBaseListBackupsRequest();
    message.parent = object.parent ?? "";
    message.pageSize = object.pageSize ?? 0;
    message.pageToken = object.pageToken ?? "";
    message.filter = object.filter ?? "";
    message.orderBy = object.orderBy ?? "";
    return message;
  },
};

function createBaseListBackupsResponse(): ListBackupsResponse {
  return { backups: [], nextPageToken: "", unreachable: [] };
}

export const ListBackupsResponse: MessageFns<ListBackupsResponse> = {
  encode(message: ListBackupsResponse, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.backups) {
      Backup.encode(v!, writer.uint32(10).fork()).join();
    }
    if (message.nextPageToken !== "") {
      writer.uint32(18).string(message.nextPageToken);
    }
    for (const v of message.unreachable) {
      writer.uint32(26).string(v!);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ListBackupsResponse {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseListBackupsResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.backups.push(Backup.decode(reader, reader.uint32()));
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.nextPageToken = reader.string();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.unreachable.push(reader.string());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ListBackupsResponse {
    return {
      backups: globalThis.Array.isArray(object?.backups) ? object.backups.map((e: any) => Backup.fromJSON(e)) : [],
      nextPageToken: isSet(object.nextPageToken) ? globalThis.String(object.nextPageToken) : "",
      unreachable: globalThis.Array.isArray(object?.unreachable)
        ? object.unreachable.map((e: any) => globalThis.String(e))
        : [],
    };
  },

  toJSON(message: ListBackupsResponse): unknown {
    const obj: any = {};
    if (message.backups?.length) {
      obj.backups = message.backups.map((e) => Backup.toJSON(e));
    }
    if (message.nextPageToken !== "") {
      obj.nextPageToken = message.nextPageToken;
    }
    if (message.unreachable?.length) {
      obj.unreachable = message.unreachable;
    }
    return obj;
  },

  create(base?: DeepPartial<ListBackupsResponse>): ListBackupsResponse {
    return ListBackupsResponse.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ListBackupsResponse>): ListBackupsResponse {
    const message = createBaseListBackupsResponse();
    message.backups = object.backups?.map((e) => Backup.fromPartial(e)) || [];
    message.nextPageToken = object.nextPageToken ?? "";
    message.unreachable = object.unreachable?.map((e) => e) || [];
    return message;
  },
};

function createBaseGetBackupRequest(): GetBackupRequest {
  return { name: "" };
}

export const GetBackupRequest: MessageFns<GetBackupRequest> = {
  encode(message: GetBackupRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): GetBackupRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseGetBackupRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): GetBackupRequest {
    return { name: isSet(object.name) ? globalThis.String(object.name) : "" };
  },

  toJSON(message: GetBackupRequest): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    return obj;
  },

  create(base?: DeepPartial<GetBackupRequest>): GetBackupRequest {
    return GetBackupRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<GetBackupRequest>): GetBackupRequest {
    const message = createBaseGetBackupRequest();
    message.name = object.name ?? "";
    return message;
  },
};

function createBaseCreateBackupRequest(): CreateBackupRequest {
  return { parent: "", backupId: "", backup: undefined, requestId: "" };
}

export const CreateBackupRequest: MessageFns<CreateBackupRequest> = {
  encode(message: CreateBackupRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.parent !== "") {
      writer.uint32(10).string(message.parent);
    }
    if (message.backupId !== "") {
      writer.uint32(18).string(message.backupId);
    }
    if (message.backup !== undefined) {
      Backup.encode(message.backup, writer.uint32(26).fork()).join();
    }
    if (message.requestId !== "") {
      writer.uint32(34).string(message.requestId);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): CreateBackupRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseCreateBackupRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.parent = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.backupId = reader.string();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.backup = Backup.decode(reader, reader.uint32());
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.requestId = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): CreateBackupRequest {
    return {
      parent: isSet(object.parent) ? globalThis.String(object.parent) : "",
      backupId: isSet(object.backupId) ? globalThis.String(object.backupId) : "",
      backup: isSet(object.backup) ? Backup.fromJSON(object.backup) : undefined,
      requestId: isSet(object.requestId) ? globalThis.String(object.requestId) : "",
    };
  },

  toJSON(message: CreateBackupRequest): unknown {
    const obj: any = {};
    if (message.parent !== "") {
      obj.parent = message.parent;
    }
    if (message.backupId !== "") {
      obj.backupId = message.backupId;
    }
    if (message.backup !== undefined) {
      obj.backup = Backup.toJSON(message.backup);
    }
    if (message.requestId !== "") {
      obj.requestId = message.requestId;
    }
    return obj;
  },

  create(base?: DeepPartial<CreateBackupRequest>): CreateBackupRequest {
    return CreateBackupRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<CreateBackupRequest>): CreateBackupRequest {
    const message = createBaseCreateBackupRequest();
    message.parent = object.parent ?? "";
    message.backupId = object.backupId ?? "";
    message.backup = (object.backup !== undefined && object.backup !== null)
      ? Backup.fromPartial(object.backup)
      : undefined;
    message.requestId = object.requestId ?? "";
    return message;
  },
};

function createBaseDeleteBackupRequest(): DeleteBackupRequest {
  return { name: "", requestId: "" };
}

export const DeleteBackupRequest: MessageFns<DeleteBackupRequest> = {
  encode(message: DeleteBackupRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    if (message.requestId !== "") {
      writer.uint32(18).string(message.requestId);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): DeleteBackupRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDeleteBackupRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.requestId = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): DeleteBackupRequest {
    return {
      name: isSet(object.name) ? globalThis.String(object.name) : "",
      requestId: isSet(object.requestId) ? globalThis.String(object.requestId) : "",
    };
  },

  toJSON(message: DeleteBackupRequest): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    if (message.requestId !== "") {
      obj.requestId = message.requestId;
    }
    return obj;
  },

  create(base?: DeepPartial<DeleteBackupRequest>): DeleteBackupRequest {
    return DeleteBackupRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<DeleteBackupRequest>): DeleteBackupRequest {
    const message = createBaseDeleteBackupRequest();
    message.name = object.name ?? "";
    message.requestId = object.requestId ?? "";
    return message;
  },
};

function createBaseExportMetadataRequest(): ExportMetadataRequest {
  return { destinationGcsFolder: undefined, service: "", requestId: "", databaseDumpType: 0 };
}

export const ExportMetadataRequest: MessageFns<ExportMetadataRequest> = {
  encode(message: ExportMetadataRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.destinationGcsFolder !== undefined) {
      writer.uint32(18).string(message.destinationGcsFolder);
    }
    if (message.service !== "") {
      writer.uint32(10).string(message.service);
    }
    if (message.requestId !== "") {
      writer.uint32(26).string(message.requestId);
    }
    if (message.databaseDumpType !== 0) {
      writer.uint32(32).int32(message.databaseDumpType);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ExportMetadataRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseExportMetadataRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 2:
          if (tag !== 18) {
            break;
          }

          message.destinationGcsFolder = reader.string();
          continue;
        case 1:
          if (tag !== 10) {
            break;
          }

          message.service = reader.string();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.requestId = reader.string();
          continue;
        case 4:
          if (tag !== 32) {
            break;
          }

          message.databaseDumpType = reader.int32() as any;
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ExportMetadataRequest {
    return {
      destinationGcsFolder: isSet(object.destinationGcsFolder)
        ? globalThis.String(object.destinationGcsFolder)
        : undefined,
      service: isSet(object.service) ? globalThis.String(object.service) : "",
      requestId: isSet(object.requestId) ? globalThis.String(object.requestId) : "",
      databaseDumpType: isSet(object.databaseDumpType) ? databaseDumpSpec_TypeFromJSON(object.databaseDumpType) : 0,
    };
  },

  toJSON(message: ExportMetadataRequest): unknown {
    const obj: any = {};
    if (message.destinationGcsFolder !== undefined) {
      obj.destinationGcsFolder = message.destinationGcsFolder;
    }
    if (message.service !== "") {
      obj.service = message.service;
    }
    if (message.requestId !== "") {
      obj.requestId = message.requestId;
    }
    if (message.databaseDumpType !== 0) {
      obj.databaseDumpType = databaseDumpSpec_TypeToJSON(message.databaseDumpType);
    }
    return obj;
  },

  create(base?: DeepPartial<ExportMetadataRequest>): ExportMetadataRequest {
    return ExportMetadataRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ExportMetadataRequest>): ExportMetadataRequest {
    const message = createBaseExportMetadataRequest();
    message.destinationGcsFolder = object.destinationGcsFolder ?? undefined;
    message.service = object.service ?? "";
    message.requestId = object.requestId ?? "";
    message.databaseDumpType = object.databaseDumpType ?? 0;
    return message;
  },
};

function createBaseRestoreServiceRequest(): RestoreServiceRequest {
  return { service: "", backup: "", restoreType: 0, requestId: "" };
}

export const RestoreServiceRequest: MessageFns<RestoreServiceRequest> = {
  encode(message: RestoreServiceRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.service !== "") {
      writer.uint32(10).string(message.service);
    }
    if (message.backup !== "") {
      writer.uint32(18).string(message.backup);
    }
    if (message.restoreType !== 0) {
      writer.uint32(24).int32(message.restoreType);
    }
    if (message.requestId !== "") {
      writer.uint32(34).string(message.requestId);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): RestoreServiceRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseRestoreServiceRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.service = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.backup = reader.string();
          continue;
        case 3:
          if (tag !== 24) {
            break;
          }

          message.restoreType = reader.int32() as any;
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.requestId = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): RestoreServiceRequest {
    return {
      service: isSet(object.service) ? globalThis.String(object.service) : "",
      backup: isSet(object.backup) ? globalThis.String(object.backup) : "",
      restoreType: isSet(object.restoreType) ? restore_RestoreTypeFromJSON(object.restoreType) : 0,
      requestId: isSet(object.requestId) ? globalThis.String(object.requestId) : "",
    };
  },

  toJSON(message: RestoreServiceRequest): unknown {
    const obj: any = {};
    if (message.service !== "") {
      obj.service = message.service;
    }
    if (message.backup !== "") {
      obj.backup = message.backup;
    }
    if (message.restoreType !== 0) {
      obj.restoreType = restore_RestoreTypeToJSON(message.restoreType);
    }
    if (message.requestId !== "") {
      obj.requestId = message.requestId;
    }
    return obj;
  },

  create(base?: DeepPartial<RestoreServiceRequest>): RestoreServiceRequest {
    return RestoreServiceRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<RestoreServiceRequest>): RestoreServiceRequest {
    const message = createBaseRestoreServiceRequest();
    message.service = object.service ?? "";
    message.backup = object.backup ?? "";
    message.restoreType = object.restoreType ?? 0;
    message.requestId = object.requestId ?? "";
    return message;
  },
};

function createBaseOperationMetadata(): OperationMetadata {
  return {
    createTime: undefined,
    endTime: undefined,
    target: "",
    verb: "",
    statusMessage: "",
    requestedCancellation: false,
    apiVersion: "",
  };
}

export const OperationMetadata: MessageFns<OperationMetadata> = {
  encode(message: OperationMetadata, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.createTime !== undefined) {
      Timestamp.encode(toTimestamp(message.createTime), writer.uint32(10).fork()).join();
    }
    if (message.endTime !== undefined) {
      Timestamp.encode(toTimestamp(message.endTime), writer.uint32(18).fork()).join();
    }
    if (message.target !== "") {
      writer.uint32(26).string(message.target);
    }
    if (message.verb !== "") {
      writer.uint32(34).string(message.verb);
    }
    if (message.statusMessage !== "") {
      writer.uint32(42).string(message.statusMessage);
    }
    if (message.requestedCancellation !== false) {
      writer.uint32(48).bool(message.requestedCancellation);
    }
    if (message.apiVersion !== "") {
      writer.uint32(58).string(message.apiVersion);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): OperationMetadata {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseOperationMetadata();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.createTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.endTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.target = reader.string();
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.verb = reader.string();
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.statusMessage = reader.string();
          continue;
        case 6:
          if (tag !== 48) {
            break;
          }

          message.requestedCancellation = reader.bool();
          continue;
        case 7:
          if (tag !== 58) {
            break;
          }

          message.apiVersion = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): OperationMetadata {
    return {
      createTime: isSet(object.createTime) ? fromJsonTimestamp(object.createTime) : undefined,
      endTime: isSet(object.endTime) ? fromJsonTimestamp(object.endTime) : undefined,
      target: isSet(object.target) ? globalThis.String(object.target) : "",
      verb: isSet(object.verb) ? globalThis.String(object.verb) : "",
      statusMessage: isSet(object.statusMessage) ? globalThis.String(object.statusMessage) : "",
      requestedCancellation: isSet(object.requestedCancellation)
        ? globalThis.Boolean(object.requestedCancellation)
        : false,
      apiVersion: isSet(object.apiVersion) ? globalThis.String(object.apiVersion) : "",
    };
  },

  toJSON(message: OperationMetadata): unknown {
    const obj: any = {};
    if (message.createTime !== undefined) {
      obj.createTime = message.createTime.toISOString();
    }
    if (message.endTime !== undefined) {
      obj.endTime = message.endTime.toISOString();
    }
    if (message.target !== "") {
      obj.target = message.target;
    }
    if (message.verb !== "") {
      obj.verb = message.verb;
    }
    if (message.statusMessage !== "") {
      obj.statusMessage = message.statusMessage;
    }
    if (message.requestedCancellation !== false) {
      obj.requestedCancellation = message.requestedCancellation;
    }
    if (message.apiVersion !== "") {
      obj.apiVersion = message.apiVersion;
    }
    return obj;
  },

  create(base?: DeepPartial<OperationMetadata>): OperationMetadata {
    return OperationMetadata.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<OperationMetadata>): OperationMetadata {
    const message = createBaseOperationMetadata();
    message.createTime = object.createTime ?? undefined;
    message.endTime = object.endTime ?? undefined;
    message.target = object.target ?? "";
    message.verb = object.verb ?? "";
    message.statusMessage = object.statusMessage ?? "";
    message.requestedCancellation = object.requestedCancellation ?? false;
    message.apiVersion = object.apiVersion ?? "";
    return message;
  },
};

function createBaseLocationMetadata(): LocationMetadata {
  return { supportedHiveMetastoreVersions: [] };
}

export const LocationMetadata: MessageFns<LocationMetadata> = {
  encode(message: LocationMetadata, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.supportedHiveMetastoreVersions) {
      LocationMetadata_HiveMetastoreVersion.encode(v!, writer.uint32(10).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): LocationMetadata {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseLocationMetadata();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.supportedHiveMetastoreVersions.push(
            LocationMetadata_HiveMetastoreVersion.decode(reader, reader.uint32()),
          );
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): LocationMetadata {
    return {
      supportedHiveMetastoreVersions: globalThis.Array.isArray(object?.supportedHiveMetastoreVersions)
        ? object.supportedHiveMetastoreVersions.map((e: any) => LocationMetadata_HiveMetastoreVersion.fromJSON(e))
        : [],
    };
  },

  toJSON(message: LocationMetadata): unknown {
    const obj: any = {};
    if (message.supportedHiveMetastoreVersions?.length) {
      obj.supportedHiveMetastoreVersions = message.supportedHiveMetastoreVersions.map((e) =>
        LocationMetadata_HiveMetastoreVersion.toJSON(e)
      );
    }
    return obj;
  },

  create(base?: DeepPartial<LocationMetadata>): LocationMetadata {
    return LocationMetadata.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<LocationMetadata>): LocationMetadata {
    const message = createBaseLocationMetadata();
    message.supportedHiveMetastoreVersions =
      object.supportedHiveMetastoreVersions?.map((e) => LocationMetadata_HiveMetastoreVersion.fromPartial(e)) || [];
    return message;
  },
};

function createBaseLocationMetadata_HiveMetastoreVersion(): LocationMetadata_HiveMetastoreVersion {
  return { version: "", isDefault: false };
}

export const LocationMetadata_HiveMetastoreVersion: MessageFns<LocationMetadata_HiveMetastoreVersion> = {
  encode(message: LocationMetadata_HiveMetastoreVersion, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.version !== "") {
      writer.uint32(10).string(message.version);
    }
    if (message.isDefault !== false) {
      writer.uint32(16).bool(message.isDefault);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): LocationMetadata_HiveMetastoreVersion {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseLocationMetadata_HiveMetastoreVersion();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.version = reader.string();
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.isDefault = reader.bool();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): LocationMetadata_HiveMetastoreVersion {
    return {
      version: isSet(object.version) ? globalThis.String(object.version) : "",
      isDefault: isSet(object.isDefault) ? globalThis.Boolean(object.isDefault) : false,
    };
  },

  toJSON(message: LocationMetadata_HiveMetastoreVersion): unknown {
    const obj: any = {};
    if (message.version !== "") {
      obj.version = message.version;
    }
    if (message.isDefault !== false) {
      obj.isDefault = message.isDefault;
    }
    return obj;
  },

  create(base?: DeepPartial<LocationMetadata_HiveMetastoreVersion>): LocationMetadata_HiveMetastoreVersion {
    return LocationMetadata_HiveMetastoreVersion.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<LocationMetadata_HiveMetastoreVersion>): LocationMetadata_HiveMetastoreVersion {
    const message = createBaseLocationMetadata_HiveMetastoreVersion();
    message.version = object.version ?? "";
    message.isDefault = object.isDefault ?? false;
    return message;
  },
};

function createBaseDatabaseDumpSpec(): DatabaseDumpSpec {
  return {};
}

export const DatabaseDumpSpec: MessageFns<DatabaseDumpSpec> = {
  encode(_: DatabaseDumpSpec, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): DatabaseDumpSpec {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDatabaseDumpSpec();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(_: any): DatabaseDumpSpec {
    return {};
  },

  toJSON(_: DatabaseDumpSpec): unknown {
    const obj: any = {};
    return obj;
  },

  create(base?: DeepPartial<DatabaseDumpSpec>): DatabaseDumpSpec {
    return DatabaseDumpSpec.fromPartial(base ?? {});
  },
  fromPartial(_: DeepPartial<DatabaseDumpSpec>): DatabaseDumpSpec {
    const message = createBaseDatabaseDumpSpec();
    return message;
  },
};

function createBaseQueryMetadataRequest(): QueryMetadataRequest {
  return { service: "", query: "" };
}

export const QueryMetadataRequest: MessageFns<QueryMetadataRequest> = {
  encode(message: QueryMetadataRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.service !== "") {
      writer.uint32(10).string(message.service);
    }
    if (message.query !== "") {
      writer.uint32(18).string(message.query);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): QueryMetadataRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseQueryMetadataRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.service = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.query = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): QueryMetadataRequest {
    return {
      service: isSet(object.service) ? globalThis.String(object.service) : "",
      query: isSet(object.query) ? globalThis.String(object.query) : "",
    };
  },

  toJSON(message: QueryMetadataRequest): unknown {
    const obj: any = {};
    if (message.service !== "") {
      obj.service = message.service;
    }
    if (message.query !== "") {
      obj.query = message.query;
    }
    return obj;
  },

  create(base?: DeepPartial<QueryMetadataRequest>): QueryMetadataRequest {
    return QueryMetadataRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<QueryMetadataRequest>): QueryMetadataRequest {
    const message = createBaseQueryMetadataRequest();
    message.service = object.service ?? "";
    message.query = object.query ?? "";
    return message;
  },
};

function createBaseQueryMetadataResponse(): QueryMetadataResponse {
  return { resultManifestUri: "" };
}

export const QueryMetadataResponse: MessageFns<QueryMetadataResponse> = {
  encode(message: QueryMetadataResponse, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.resultManifestUri !== "") {
      writer.uint32(10).string(message.resultManifestUri);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): QueryMetadataResponse {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseQueryMetadataResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.resultManifestUri = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): QueryMetadataResponse {
    return { resultManifestUri: isSet(object.resultManifestUri) ? globalThis.String(object.resultManifestUri) : "" };
  },

  toJSON(message: QueryMetadataResponse): unknown {
    const obj: any = {};
    if (message.resultManifestUri !== "") {
      obj.resultManifestUri = message.resultManifestUri;
    }
    return obj;
  },

  create(base?: DeepPartial<QueryMetadataResponse>): QueryMetadataResponse {
    return QueryMetadataResponse.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<QueryMetadataResponse>): QueryMetadataResponse {
    const message = createBaseQueryMetadataResponse();
    message.resultManifestUri = object.resultManifestUri ?? "";
    return message;
  },
};

function createBaseErrorDetails(): ErrorDetails {
  return { details: {} };
}

export const ErrorDetails: MessageFns<ErrorDetails> = {
  encode(message: ErrorDetails, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    Object.entries(message.details).forEach(([key, value]) => {
      ErrorDetails_DetailsEntry.encode({ key: key as any, value }, writer.uint32(10).fork()).join();
    });
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ErrorDetails {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseErrorDetails();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          const entry1 = ErrorDetails_DetailsEntry.decode(reader, reader.uint32());
          if (entry1.value !== undefined) {
            message.details[entry1.key] = entry1.value;
          }
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ErrorDetails {
    return {
      details: isObject(object.details)
        ? Object.entries(object.details).reduce<{ [key: string]: string }>((acc, [key, value]) => {
          acc[key] = String(value);
          return acc;
        }, {})
        : {},
    };
  },

  toJSON(message: ErrorDetails): unknown {
    const obj: any = {};
    if (message.details) {
      const entries = Object.entries(message.details);
      if (entries.length > 0) {
        obj.details = {};
        entries.forEach(([k, v]) => {
          obj.details[k] = v;
        });
      }
    }
    return obj;
  },

  create(base?: DeepPartial<ErrorDetails>): ErrorDetails {
    return ErrorDetails.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ErrorDetails>): ErrorDetails {
    const message = createBaseErrorDetails();
    message.details = Object.entries(object.details ?? {}).reduce<{ [key: string]: string }>((acc, [key, value]) => {
      if (value !== undefined) {
        acc[key] = globalThis.String(value);
      }
      return acc;
    }, {});
    return message;
  },
};

function createBaseErrorDetails_DetailsEntry(): ErrorDetails_DetailsEntry {
  return { key: "", value: "" };
}

export const ErrorDetails_DetailsEntry: MessageFns<ErrorDetails_DetailsEntry> = {
  encode(message: ErrorDetails_DetailsEntry, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.key !== "") {
      writer.uint32(10).string(message.key);
    }
    if (message.value !== "") {
      writer.uint32(18).string(message.value);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ErrorDetails_DetailsEntry {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseErrorDetails_DetailsEntry();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.key = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.value = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ErrorDetails_DetailsEntry {
    return {
      key: isSet(object.key) ? globalThis.String(object.key) : "",
      value: isSet(object.value) ? globalThis.String(object.value) : "",
    };
  },

  toJSON(message: ErrorDetails_DetailsEntry): unknown {
    const obj: any = {};
    if (message.key !== "") {
      obj.key = message.key;
    }
    if (message.value !== "") {
      obj.value = message.value;
    }
    return obj;
  },

  create(base?: DeepPartial<ErrorDetails_DetailsEntry>): ErrorDetails_DetailsEntry {
    return ErrorDetails_DetailsEntry.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ErrorDetails_DetailsEntry>): ErrorDetails_DetailsEntry {
    const message = createBaseErrorDetails_DetailsEntry();
    message.key = object.key ?? "";
    message.value = object.value ?? "";
    return message;
  },
};

function createBaseMoveTableToDatabaseRequest(): MoveTableToDatabaseRequest {
  return { service: "", tableName: "", dbName: "", destinationDbName: "" };
}

export const MoveTableToDatabaseRequest: MessageFns<MoveTableToDatabaseRequest> = {
  encode(message: MoveTableToDatabaseRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.service !== "") {
      writer.uint32(10).string(message.service);
    }
    if (message.tableName !== "") {
      writer.uint32(18).string(message.tableName);
    }
    if (message.dbName !== "") {
      writer.uint32(26).string(message.dbName);
    }
    if (message.destinationDbName !== "") {
      writer.uint32(34).string(message.destinationDbName);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): MoveTableToDatabaseRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseMoveTableToDatabaseRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.service = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.tableName = reader.string();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.dbName = reader.string();
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.destinationDbName = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): MoveTableToDatabaseRequest {
    return {
      service: isSet(object.service) ? globalThis.String(object.service) : "",
      tableName: isSet(object.tableName) ? globalThis.String(object.tableName) : "",
      dbName: isSet(object.dbName) ? globalThis.String(object.dbName) : "",
      destinationDbName: isSet(object.destinationDbName) ? globalThis.String(object.destinationDbName) : "",
    };
  },

  toJSON(message: MoveTableToDatabaseRequest): unknown {
    const obj: any = {};
    if (message.service !== "") {
      obj.service = message.service;
    }
    if (message.tableName !== "") {
      obj.tableName = message.tableName;
    }
    if (message.dbName !== "") {
      obj.dbName = message.dbName;
    }
    if (message.destinationDbName !== "") {
      obj.destinationDbName = message.destinationDbName;
    }
    return obj;
  },

  create(base?: DeepPartial<MoveTableToDatabaseRequest>): MoveTableToDatabaseRequest {
    return MoveTableToDatabaseRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<MoveTableToDatabaseRequest>): MoveTableToDatabaseRequest {
    const message = createBaseMoveTableToDatabaseRequest();
    message.service = object.service ?? "";
    message.tableName = object.tableName ?? "";
    message.dbName = object.dbName ?? "";
    message.destinationDbName = object.destinationDbName ?? "";
    return message;
  },
};

function createBaseMoveTableToDatabaseResponse(): MoveTableToDatabaseResponse {
  return {};
}

export const MoveTableToDatabaseResponse: MessageFns<MoveTableToDatabaseResponse> = {
  encode(_: MoveTableToDatabaseResponse, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): MoveTableToDatabaseResponse {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseMoveTableToDatabaseResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(_: any): MoveTableToDatabaseResponse {
    return {};
  },

  toJSON(_: MoveTableToDatabaseResponse): unknown {
    const obj: any = {};
    return obj;
  },

  create(base?: DeepPartial<MoveTableToDatabaseResponse>): MoveTableToDatabaseResponse {
    return MoveTableToDatabaseResponse.fromPartial(base ?? {});
  },
  fromPartial(_: DeepPartial<MoveTableToDatabaseResponse>): MoveTableToDatabaseResponse {
    const message = createBaseMoveTableToDatabaseResponse();
    return message;
  },
};

function createBaseAlterMetadataResourceLocationRequest(): AlterMetadataResourceLocationRequest {
  return { service: "", resourceName: "", locationUri: "" };
}

export const AlterMetadataResourceLocationRequest: MessageFns<AlterMetadataResourceLocationRequest> = {
  encode(message: AlterMetadataResourceLocationRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.service !== "") {
      writer.uint32(10).string(message.service);
    }
    if (message.resourceName !== "") {
      writer.uint32(18).string(message.resourceName);
    }
    if (message.locationUri !== "") {
      writer.uint32(26).string(message.locationUri);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): AlterMetadataResourceLocationRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseAlterMetadataResourceLocationRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.service = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.resourceName = reader.string();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.locationUri = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): AlterMetadataResourceLocationRequest {
    return {
      service: isSet(object.service) ? globalThis.String(object.service) : "",
      resourceName: isSet(object.resourceName) ? globalThis.String(object.resourceName) : "",
      locationUri: isSet(object.locationUri) ? globalThis.String(object.locationUri) : "",
    };
  },

  toJSON(message: AlterMetadataResourceLocationRequest): unknown {
    const obj: any = {};
    if (message.service !== "") {
      obj.service = message.service;
    }
    if (message.resourceName !== "") {
      obj.resourceName = message.resourceName;
    }
    if (message.locationUri !== "") {
      obj.locationUri = message.locationUri;
    }
    return obj;
  },

  create(base?: DeepPartial<AlterMetadataResourceLocationRequest>): AlterMetadataResourceLocationRequest {
    return AlterMetadataResourceLocationRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<AlterMetadataResourceLocationRequest>): AlterMetadataResourceLocationRequest {
    const message = createBaseAlterMetadataResourceLocationRequest();
    message.service = object.service ?? "";
    message.resourceName = object.resourceName ?? "";
    message.locationUri = object.locationUri ?? "";
    return message;
  },
};

function createBaseAlterMetadataResourceLocationResponse(): AlterMetadataResourceLocationResponse {
  return {};
}

export const AlterMetadataResourceLocationResponse: MessageFns<AlterMetadataResourceLocationResponse> = {
  encode(_: AlterMetadataResourceLocationResponse, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): AlterMetadataResourceLocationResponse {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseAlterMetadataResourceLocationResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(_: any): AlterMetadataResourceLocationResponse {
    return {};
  },

  toJSON(_: AlterMetadataResourceLocationResponse): unknown {
    const obj: any = {};
    return obj;
  },

  create(base?: DeepPartial<AlterMetadataResourceLocationResponse>): AlterMetadataResourceLocationResponse {
    return AlterMetadataResourceLocationResponse.fromPartial(base ?? {});
  },
  fromPartial(_: DeepPartial<AlterMetadataResourceLocationResponse>): AlterMetadataResourceLocationResponse {
    const message = createBaseAlterMetadataResourceLocationResponse();
    return message;
  },
};

/**
 * Configures and manages metastore services.
 * Metastore services are fully managed, highly available, autoscaled,
 * autohealing, OSS-native deployments of technical metadata management
 * software. Each metastore service exposes a network endpoint through which
 * metadata queries are served. Metadata queries can originate from a variety
 * of sources, including Apache Hive, Apache Presto, and Apache Spark.
 *
 * The Dataproc Metastore API defines the following resource model:
 *
 * * The service works with a collection of Google Cloud projects, named:
 * `/projects/*`
 * * Each project has a collection of available locations, named: `/locations/*`
 *   (a location must refer to a Google Cloud `region`)
 * * Each location has a collection of services, named: `/services/*`
 * * Dataproc Metastore services are resources with names of the form:
 *
 *   `/projects/{project_number}/locations/{location_id}/services/{service_id}`.
 */
export type DataprocMetastoreDefinition = typeof DataprocMetastoreDefinition;
export const DataprocMetastoreDefinition = {
  name: "DataprocMetastore",
  fullName: "google.cloud.metastore.v1.DataprocMetastore",
  methods: {
    /** Lists services in a project and location. */
    listServices: {
      name: "ListServices",
      requestType: ListServicesRequest,
      requestStream: false,
      responseType: ListServicesResponse,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [Buffer.from([6, 112, 97, 114, 101, 110, 116])],
          578365826: [
            Buffer.from([
              46,
              18,
              44,
              47,
              118,
              49,
              47,
              123,
              112,
              97,
              114,
              101,
              110,
              116,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              125,
              47,
              115,
              101,
              114,
              118,
              105,
              99,
              101,
              115,
            ]),
          ],
        },
      },
    },
    /** Gets the details of a single service. */
    getService: {
      name: "GetService",
      requestType: GetServiceRequest,
      requestStream: false,
      responseType: Service,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [Buffer.from([4, 110, 97, 109, 101])],
          578365826: [
            Buffer.from([
              46,
              18,
              44,
              47,
              118,
              49,
              47,
              123,
              110,
              97,
              109,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              115,
              101,
              114,
              118,
              105,
              99,
              101,
              115,
              47,
              42,
              125,
            ]),
          ],
        },
      },
    },
    /** Creates a metastore service in a project and location. */
    createService: {
      name: "CreateService",
      requestType: CreateServiceRequest,
      requestStream: false,
      responseType: Operation,
      responseStream: false,
      options: {
        _unknownFields: {
          8394: [
            Buffer.from([
              54,
              10,
              7,
              83,
              101,
              114,
              118,
              105,
              99,
              101,
              18,
              43,
              103,
              111,
              111,
              103,
              108,
              101,
              46,
              99,
              108,
              111,
              117,
              100,
              46,
              109,
              101,
              116,
              97,
              115,
              116,
              111,
              114,
              101,
              46,
              118,
              49,
              46,
              79,
              112,
              101,
              114,
              97,
              116,
              105,
              111,
              110,
              77,
              101,
              116,
              97,
              100,
              97,
              116,
              97,
            ]),
          ],
          8410: [
            Buffer.from([
              25,
              112,
              97,
              114,
              101,
              110,
              116,
              44,
              115,
              101,
              114,
              118,
              105,
              99,
              101,
              44,
              115,
              101,
              114,
              118,
              105,
              99,
              101,
              95,
              105,
              100,
            ]),
          ],
          578365826: [
            Buffer.from([
              55,
              58,
              7,
              115,
              101,
              114,
              118,
              105,
              99,
              101,
              34,
              44,
              47,
              118,
              49,
              47,
              123,
              112,
              97,
              114,
              101,
              110,
              116,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              125,
              47,
              115,
              101,
              114,
              118,
              105,
              99,
              101,
              115,
            ]),
          ],
        },
      },
    },
    /** Updates the parameters of a single service. */
    updateService: {
      name: "UpdateService",
      requestType: UpdateServiceRequest,
      requestStream: false,
      responseType: Operation,
      responseStream: false,
      options: {
        _unknownFields: {
          8394: [
            Buffer.from([
              54,
              10,
              7,
              83,
              101,
              114,
              118,
              105,
              99,
              101,
              18,
              43,
              103,
              111,
              111,
              103,
              108,
              101,
              46,
              99,
              108,
              111,
              117,
              100,
              46,
              109,
              101,
              116,
              97,
              115,
              116,
              111,
              114,
              101,
              46,
              118,
              49,
              46,
              79,
              112,
              101,
              114,
              97,
              116,
              105,
              111,
              110,
              77,
              101,
              116,
              97,
              100,
              97,
              116,
              97,
            ]),
          ],
          8410: [
            Buffer.from([19, 115, 101, 114, 118, 105, 99, 101, 44, 117, 112, 100, 97, 116, 101, 95, 109, 97, 115, 107]),
          ],
          578365826: [
            Buffer.from([
              63,
              58,
              7,
              115,
              101,
              114,
              118,
              105,
              99,
              101,
              50,
              52,
              47,
              118,
              49,
              47,
              123,
              115,
              101,
              114,
              118,
              105,
              99,
              101,
              46,
              110,
              97,
              109,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              115,
              101,
              114,
              118,
              105,
              99,
              101,
              115,
              47,
              42,
              125,
            ]),
          ],
        },
      },
    },
    /** Deletes a single service. */
    deleteService: {
      name: "DeleteService",
      requestType: DeleteServiceRequest,
      requestStream: false,
      responseType: Operation,
      responseStream: false,
      options: {
        _unknownFields: {
          8394: [
            Buffer.from([
              68,
              10,
              21,
              103,
              111,
              111,
              103,
              108,
              101,
              46,
              112,
              114,
              111,
              116,
              111,
              98,
              117,
              102,
              46,
              69,
              109,
              112,
              116,
              121,
              18,
              43,
              103,
              111,
              111,
              103,
              108,
              101,
              46,
              99,
              108,
              111,
              117,
              100,
              46,
              109,
              101,
              116,
              97,
              115,
              116,
              111,
              114,
              101,
              46,
              118,
              49,
              46,
              79,
              112,
              101,
              114,
              97,
              116,
              105,
              111,
              110,
              77,
              101,
              116,
              97,
              100,
              97,
              116,
              97,
            ]),
          ],
          8410: [Buffer.from([4, 110, 97, 109, 101])],
          578365826: [
            Buffer.from([
              46,
              42,
              44,
              47,
              118,
              49,
              47,
              123,
              110,
              97,
              109,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              115,
              101,
              114,
              118,
              105,
              99,
              101,
              115,
              47,
              42,
              125,
            ]),
          ],
        },
      },
    },
    /** Lists imports in a service. */
    listMetadataImports: {
      name: "ListMetadataImports",
      requestType: ListMetadataImportsRequest,
      requestStream: false,
      responseType: ListMetadataImportsResponse,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [Buffer.from([6, 112, 97, 114, 101, 110, 116])],
          578365826: [
            Buffer.from([
              64,
              18,
              62,
              47,
              118,
              49,
              47,
              123,
              112,
              97,
              114,
              101,
              110,
              116,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              115,
              101,
              114,
              118,
              105,
              99,
              101,
              115,
              47,
              42,
              125,
              47,
              109,
              101,
              116,
              97,
              100,
              97,
              116,
              97,
              73,
              109,
              112,
              111,
              114,
              116,
              115,
            ]),
          ],
        },
      },
    },
    /** Gets details of a single import. */
    getMetadataImport: {
      name: "GetMetadataImport",
      requestType: GetMetadataImportRequest,
      requestStream: false,
      responseType: MetadataImport,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [Buffer.from([4, 110, 97, 109, 101])],
          578365826: [
            Buffer.from([
              64,
              18,
              62,
              47,
              118,
              49,
              47,
              123,
              110,
              97,
              109,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              115,
              101,
              114,
              118,
              105,
              99,
              101,
              115,
              47,
              42,
              47,
              109,
              101,
              116,
              97,
              100,
              97,
              116,
              97,
              73,
              109,
              112,
              111,
              114,
              116,
              115,
              47,
              42,
              125,
            ]),
          ],
        },
      },
    },
    /** Creates a new MetadataImport in a given project and location. */
    createMetadataImport: {
      name: "CreateMetadataImport",
      requestType: CreateMetadataImportRequest,
      requestStream: false,
      responseType: Operation,
      responseStream: false,
      options: {
        _unknownFields: {
          8394: [
            Buffer.from([
              61,
              10,
              14,
              77,
              101,
              116,
              97,
              100,
              97,
              116,
              97,
              73,
              109,
              112,
              111,
              114,
              116,
              18,
              43,
              103,
              111,
              111,
              103,
              108,
              101,
              46,
              99,
              108,
              111,
              117,
              100,
              46,
              109,
              101,
              116,
              97,
              115,
              116,
              111,
              114,
              101,
              46,
              118,
              49,
              46,
              79,
              112,
              101,
              114,
              97,
              116,
              105,
              111,
              110,
              77,
              101,
              116,
              97,
              100,
              97,
              116,
              97,
            ]),
          ],
          8410: [
            Buffer.from([
              41,
              112,
              97,
              114,
              101,
              110,
              116,
              44,
              109,
              101,
              116,
              97,
              100,
              97,
              116,
              97,
              95,
              105,
              109,
              112,
              111,
              114,
              116,
              44,
              109,
              101,
              116,
              97,
              100,
              97,
              116,
              97,
              95,
              105,
              109,
              112,
              111,
              114,
              116,
              95,
              105,
              100,
            ]),
          ],
          578365826: [
            Buffer.from([
              81,
              58,
              15,
              109,
              101,
              116,
              97,
              100,
              97,
              116,
              97,
              95,
              105,
              109,
              112,
              111,
              114,
              116,
              34,
              62,
              47,
              118,
              49,
              47,
              123,
              112,
              97,
              114,
              101,
              110,
              116,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              115,
              101,
              114,
              118,
              105,
              99,
              101,
              115,
              47,
              42,
              125,
              47,
              109,
              101,
              116,
              97,
              100,
              97,
              116,
              97,
              73,
              109,
              112,
              111,
              114,
              116,
              115,
            ]),
          ],
        },
      },
    },
    /**
     * Updates a single import.
     * Only the description field of MetadataImport is supported to be updated.
     */
    updateMetadataImport: {
      name: "UpdateMetadataImport",
      requestType: UpdateMetadataImportRequest,
      requestStream: false,
      responseType: Operation,
      responseStream: false,
      options: {
        _unknownFields: {
          8394: [
            Buffer.from([
              61,
              10,
              14,
              77,
              101,
              116,
              97,
              100,
              97,
              116,
              97,
              73,
              109,
              112,
              111,
              114,
              116,
              18,
              43,
              103,
              111,
              111,
              103,
              108,
              101,
              46,
              99,
              108,
              111,
              117,
              100,
              46,
              109,
              101,
              116,
              97,
              115,
              116,
              111,
              114,
              101,
              46,
              118,
              49,
              46,
              79,
              112,
              101,
              114,
              97,
              116,
              105,
              111,
              110,
              77,
              101,
              116,
              97,
              100,
              97,
              116,
              97,
            ]),
          ],
          8410: [
            Buffer.from([
              27,
              109,
              101,
              116,
              97,
              100,
              97,
              116,
              97,
              95,
              105,
              109,
              112,
              111,
              114,
              116,
              44,
              117,
              112,
              100,
              97,
              116,
              101,
              95,
              109,
              97,
              115,
              107,
            ]),
          ],
          578365826: [
            Buffer.from([
              97,
              58,
              15,
              109,
              101,
              116,
              97,
              100,
              97,
              116,
              97,
              95,
              105,
              109,
              112,
              111,
              114,
              116,
              50,
              78,
              47,
              118,
              49,
              47,
              123,
              109,
              101,
              116,
              97,
              100,
              97,
              116,
              97,
              95,
              105,
              109,
              112,
              111,
              114,
              116,
              46,
              110,
              97,
              109,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              115,
              101,
              114,
              118,
              105,
              99,
              101,
              115,
              47,
              42,
              47,
              109,
              101,
              116,
              97,
              100,
              97,
              116,
              97,
              73,
              109,
              112,
              111,
              114,
              116,
              115,
              47,
              42,
              125,
            ]),
          ],
        },
      },
    },
    /** Exports metadata from a service. */
    exportMetadata: {
      name: "ExportMetadata",
      requestType: ExportMetadataRequest,
      requestStream: false,
      responseType: Operation,
      responseStream: false,
      options: {
        _unknownFields: {
          8394: [
            Buffer.from([
              61,
              10,
              14,
              77,
              101,
              116,
              97,
              100,
              97,
              116,
              97,
              69,
              120,
              112,
              111,
              114,
              116,
              18,
              43,
              103,
              111,
              111,
              103,
              108,
              101,
              46,
              99,
              108,
              111,
              117,
              100,
              46,
              109,
              101,
              116,
              97,
              115,
              116,
              111,
              114,
              101,
              46,
              118,
              49,
              46,
              79,
              112,
              101,
              114,
              97,
              116,
              105,
              111,
              110,
              77,
              101,
              116,
              97,
              100,
              97,
              116,
              97,
            ]),
          ],
          578365826: [
            Buffer.from([
              67,
              58,
              1,
              42,
              34,
              62,
              47,
              118,
              49,
              47,
              123,
              115,
              101,
              114,
              118,
              105,
              99,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              115,
              101,
              114,
              118,
              105,
              99,
              101,
              115,
              47,
              42,
              125,
              58,
              101,
              120,
              112,
              111,
              114,
              116,
              77,
              101,
              116,
              97,
              100,
              97,
              116,
              97,
            ]),
          ],
        },
      },
    },
    /** Restores a service from a backup. */
    restoreService: {
      name: "RestoreService",
      requestType: RestoreServiceRequest,
      requestStream: false,
      responseType: Operation,
      responseStream: false,
      options: {
        _unknownFields: {
          8394: [
            Buffer.from([
              54,
              10,
              7,
              82,
              101,
              115,
              116,
              111,
              114,
              101,
              18,
              43,
              103,
              111,
              111,
              103,
              108,
              101,
              46,
              99,
              108,
              111,
              117,
              100,
              46,
              109,
              101,
              116,
              97,
              115,
              116,
              111,
              114,
              101,
              46,
              118,
              49,
              46,
              79,
              112,
              101,
              114,
              97,
              116,
              105,
              111,
              110,
              77,
              101,
              116,
              97,
              100,
              97,
              116,
              97,
            ]),
          ],
          8410: [Buffer.from([14, 115, 101, 114, 118, 105, 99, 101, 44, 98, 97, 99, 107, 117, 112])],
          578365826: [
            Buffer.from([
              60,
              58,
              1,
              42,
              34,
              55,
              47,
              118,
              49,
              47,
              123,
              115,
              101,
              114,
              118,
              105,
              99,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              115,
              101,
              114,
              118,
              105,
              99,
              101,
              115,
              47,
              42,
              125,
              58,
              114,
              101,
              115,
              116,
              111,
              114,
              101,
            ]),
          ],
        },
      },
    },
    /** Lists backups in a service. */
    listBackups: {
      name: "ListBackups",
      requestType: ListBackupsRequest,
      requestStream: false,
      responseType: ListBackupsResponse,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [Buffer.from([6, 112, 97, 114, 101, 110, 116])],
          578365826: [
            Buffer.from([
              56,
              18,
              54,
              47,
              118,
              49,
              47,
              123,
              112,
              97,
              114,
              101,
              110,
              116,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              115,
              101,
              114,
              118,
              105,
              99,
              101,
              115,
              47,
              42,
              125,
              47,
              98,
              97,
              99,
              107,
              117,
              112,
              115,
            ]),
          ],
        },
      },
    },
    /** Gets details of a single backup. */
    getBackup: {
      name: "GetBackup",
      requestType: GetBackupRequest,
      requestStream: false,
      responseType: Backup,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [Buffer.from([4, 110, 97, 109, 101])],
          578365826: [
            Buffer.from([
              56,
              18,
              54,
              47,
              118,
              49,
              47,
              123,
              110,
              97,
              109,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              115,
              101,
              114,
              118,
              105,
              99,
              101,
              115,
              47,
              42,
              47,
              98,
              97,
              99,
              107,
              117,
              112,
              115,
              47,
              42,
              125,
            ]),
          ],
        },
      },
    },
    /** Creates a new backup in a given project and location. */
    createBackup: {
      name: "CreateBackup",
      requestType: CreateBackupRequest,
      requestStream: false,
      responseType: Operation,
      responseStream: false,
      options: {
        _unknownFields: {
          8394: [
            Buffer.from([
              53,
              10,
              6,
              66,
              97,
              99,
              107,
              117,
              112,
              18,
              43,
              103,
              111,
              111,
              103,
              108,
              101,
              46,
              99,
              108,
              111,
              117,
              100,
              46,
              109,
              101,
              116,
              97,
              115,
              116,
              111,
              114,
              101,
              46,
              118,
              49,
              46,
              79,
              112,
              101,
              114,
              97,
              116,
              105,
              111,
              110,
              77,
              101,
              116,
              97,
              100,
              97,
              116,
              97,
            ]),
          ],
          8410: [
            Buffer.from([
              23,
              112,
              97,
              114,
              101,
              110,
              116,
              44,
              98,
              97,
              99,
              107,
              117,
              112,
              44,
              98,
              97,
              99,
              107,
              117,
              112,
              95,
              105,
              100,
            ]),
          ],
          578365826: [
            Buffer.from([
              64,
              58,
              6,
              98,
              97,
              99,
              107,
              117,
              112,
              34,
              54,
              47,
              118,
              49,
              47,
              123,
              112,
              97,
              114,
              101,
              110,
              116,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              115,
              101,
              114,
              118,
              105,
              99,
              101,
              115,
              47,
              42,
              125,
              47,
              98,
              97,
              99,
              107,
              117,
              112,
              115,
            ]),
          ],
        },
      },
    },
    /** Deletes a single backup. */
    deleteBackup: {
      name: "DeleteBackup",
      requestType: DeleteBackupRequest,
      requestStream: false,
      responseType: Operation,
      responseStream: false,
      options: {
        _unknownFields: {
          8394: [
            Buffer.from([
              68,
              10,
              21,
              103,
              111,
              111,
              103,
              108,
              101,
              46,
              112,
              114,
              111,
              116,
              111,
              98,
              117,
              102,
              46,
              69,
              109,
              112,
              116,
              121,
              18,
              43,
              103,
              111,
              111,
              103,
              108,
              101,
              46,
              99,
              108,
              111,
              117,
              100,
              46,
              109,
              101,
              116,
              97,
              115,
              116,
              111,
              114,
              101,
              46,
              118,
              49,
              46,
              79,
              112,
              101,
              114,
              97,
              116,
              105,
              111,
              110,
              77,
              101,
              116,
              97,
              100,
              97,
              116,
              97,
            ]),
          ],
          8410: [Buffer.from([4, 110, 97, 109, 101])],
          578365826: [
            Buffer.from([
              56,
              42,
              54,
              47,
              118,
              49,
              47,
              123,
              110,
              97,
              109,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              115,
              101,
              114,
              118,
              105,
              99,
              101,
              115,
              47,
              42,
              47,
              98,
              97,
              99,
              107,
              117,
              112,
              115,
              47,
              42,
              125,
            ]),
          ],
        },
      },
    },
    /** Query DPMS metadata. */
    queryMetadata: {
      name: "QueryMetadata",
      requestType: QueryMetadataRequest,
      requestStream: false,
      responseType: Operation,
      responseStream: false,
      options: {
        _unknownFields: {
          8394: [
            Buffer.from([
              68,
              10,
              21,
              81,
              117,
              101,
              114,
              121,
              77,
              101,
              116,
              97,
              100,
              97,
              116,
              97,
              82,
              101,
              115,
              112,
              111,
              110,
              115,
              101,
              18,
              43,
              103,
              111,
              111,
              103,
              108,
              101,
              46,
              99,
              108,
              111,
              117,
              100,
              46,
              109,
              101,
              116,
              97,
              115,
              116,
              111,
              114,
              101,
              46,
              118,
              49,
              46,
              79,
              112,
              101,
              114,
              97,
              116,
              105,
              111,
              110,
              77,
              101,
              116,
              97,
              100,
              97,
              116,
              97,
            ]),
          ],
          578365826: [
            Buffer.from([
              66,
              58,
              1,
              42,
              34,
              61,
              47,
              118,
              49,
              47,
              123,
              115,
              101,
              114,
              118,
              105,
              99,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              115,
              101,
              114,
              118,
              105,
              99,
              101,
              115,
              47,
              42,
              125,
              58,
              113,
              117,
              101,
              114,
              121,
              77,
              101,
              116,
              97,
              100,
              97,
              116,
              97,
            ]),
          ],
        },
      },
    },
    /** Move a table to another database. */
    moveTableToDatabase: {
      name: "MoveTableToDatabase",
      requestType: MoveTableToDatabaseRequest,
      requestStream: false,
      responseType: Operation,
      responseStream: false,
      options: {
        _unknownFields: {
          8394: [
            Buffer.from([
              74,
              10,
              27,
              77,
              111,
              118,
              101,
              84,
              97,
              98,
              108,
              101,
              84,
              111,
              68,
              97,
              116,
              97,
              98,
              97,
              115,
              101,
              82,
              101,
              115,
              112,
              111,
              110,
              115,
              101,
              18,
              43,
              103,
              111,
              111,
              103,
              108,
              101,
              46,
              99,
              108,
              111,
              117,
              100,
              46,
              109,
              101,
              116,
              97,
              115,
              116,
              111,
              114,
              101,
              46,
              118,
              49,
              46,
              79,
              112,
              101,
              114,
              97,
              116,
              105,
              111,
              110,
              77,
              101,
              116,
              97,
              100,
              97,
              116,
              97,
            ]),
          ],
          578365826: [
            Buffer.from([
              72,
              58,
              1,
              42,
              34,
              67,
              47,
              118,
              49,
              47,
              123,
              115,
              101,
              114,
              118,
              105,
              99,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              115,
              101,
              114,
              118,
              105,
              99,
              101,
              115,
              47,
              42,
              125,
              58,
              109,
              111,
              118,
              101,
              84,
              97,
              98,
              108,
              101,
              84,
              111,
              68,
              97,
              116,
              97,
              98,
              97,
              115,
              101,
            ]),
          ],
        },
      },
    },
    /**
     * Alter metadata resource location. The metadata resource can be a database,
     * table, or partition. This functionality only updates the parent directory
     * for the respective metadata resource and does not transfer any existing
     * data to the new location.
     */
    alterMetadataResourceLocation: {
      name: "AlterMetadataResourceLocation",
      requestType: AlterMetadataResourceLocationRequest,
      requestStream: false,
      responseType: Operation,
      responseStream: false,
      options: {
        _unknownFields: {
          8394: [
            Buffer.from([
              84,
              10,
              37,
              65,
              108,
              116,
              101,
              114,
              77,
              101,
              116,
              97,
              100,
              97,
              116,
              97,
              82,
              101,
              115,
              111,
              117,
              114,
              99,
              101,
              76,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              82,
              101,
              115,
              112,
              111,
              110,
              115,
              101,
              18,
              43,
              103,
              111,
              111,
              103,
              108,
              101,
              46,
              99,
              108,
              111,
              117,
              100,
              46,
              109,
              101,
              116,
              97,
              115,
              116,
              111,
              114,
              101,
              46,
              118,
              49,
              46,
              79,
              112,
              101,
              114,
              97,
              116,
              105,
              111,
              110,
              77,
              101,
              116,
              97,
              100,
              97,
              116,
              97,
            ]),
          ],
          578365826: [
            Buffer.from([
              66,
              58,
              1,
              42,
              34,
              61,
              47,
              118,
              49,
              47,
              123,
              115,
              101,
              114,
              118,
              105,
              99,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              115,
              101,
              114,
              118,
              105,
              99,
              101,
              115,
              47,
              42,
              125,
              58,
              97,
              108,
              116,
              101,
              114,
              76,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
            ]),
          ],
        },
      },
    },
  },
} as const;

export interface DataprocMetastoreServiceImplementation<CallContextExt = {}> {
  /** Lists services in a project and location. */
  listServices(
    request: ListServicesRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<ListServicesResponse>>;
  /** Gets the details of a single service. */
  getService(request: GetServiceRequest, context: CallContext & CallContextExt): Promise<DeepPartial<Service>>;
  /** Creates a metastore service in a project and location. */
  createService(request: CreateServiceRequest, context: CallContext & CallContextExt): Promise<DeepPartial<Operation>>;
  /** Updates the parameters of a single service. */
  updateService(request: UpdateServiceRequest, context: CallContext & CallContextExt): Promise<DeepPartial<Operation>>;
  /** Deletes a single service. */
  deleteService(request: DeleteServiceRequest, context: CallContext & CallContextExt): Promise<DeepPartial<Operation>>;
  /** Lists imports in a service. */
  listMetadataImports(
    request: ListMetadataImportsRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<ListMetadataImportsResponse>>;
  /** Gets details of a single import. */
  getMetadataImport(
    request: GetMetadataImportRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<MetadataImport>>;
  /** Creates a new MetadataImport in a given project and location. */
  createMetadataImport(
    request: CreateMetadataImportRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<Operation>>;
  /**
   * Updates a single import.
   * Only the description field of MetadataImport is supported to be updated.
   */
  updateMetadataImport(
    request: UpdateMetadataImportRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<Operation>>;
  /** Exports metadata from a service. */
  exportMetadata(
    request: ExportMetadataRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<Operation>>;
  /** Restores a service from a backup. */
  restoreService(
    request: RestoreServiceRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<Operation>>;
  /** Lists backups in a service. */
  listBackups(
    request: ListBackupsRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<ListBackupsResponse>>;
  /** Gets details of a single backup. */
  getBackup(request: GetBackupRequest, context: CallContext & CallContextExt): Promise<DeepPartial<Backup>>;
  /** Creates a new backup in a given project and location. */
  createBackup(request: CreateBackupRequest, context: CallContext & CallContextExt): Promise<DeepPartial<Operation>>;
  /** Deletes a single backup. */
  deleteBackup(request: DeleteBackupRequest, context: CallContext & CallContextExt): Promise<DeepPartial<Operation>>;
  /** Query DPMS metadata. */
  queryMetadata(request: QueryMetadataRequest, context: CallContext & CallContextExt): Promise<DeepPartial<Operation>>;
  /** Move a table to another database. */
  moveTableToDatabase(
    request: MoveTableToDatabaseRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<Operation>>;
  /**
   * Alter metadata resource location. The metadata resource can be a database,
   * table, or partition. This functionality only updates the parent directory
   * for the respective metadata resource and does not transfer any existing
   * data to the new location.
   */
  alterMetadataResourceLocation(
    request: AlterMetadataResourceLocationRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<Operation>>;
}

export interface DataprocMetastoreClient<CallOptionsExt = {}> {
  /** Lists services in a project and location. */
  listServices(
    request: DeepPartial<ListServicesRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<ListServicesResponse>;
  /** Gets the details of a single service. */
  getService(request: DeepPartial<GetServiceRequest>, options?: CallOptions & CallOptionsExt): Promise<Service>;
  /** Creates a metastore service in a project and location. */
  createService(request: DeepPartial<CreateServiceRequest>, options?: CallOptions & CallOptionsExt): Promise<Operation>;
  /** Updates the parameters of a single service. */
  updateService(request: DeepPartial<UpdateServiceRequest>, options?: CallOptions & CallOptionsExt): Promise<Operation>;
  /** Deletes a single service. */
  deleteService(request: DeepPartial<DeleteServiceRequest>, options?: CallOptions & CallOptionsExt): Promise<Operation>;
  /** Lists imports in a service. */
  listMetadataImports(
    request: DeepPartial<ListMetadataImportsRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<ListMetadataImportsResponse>;
  /** Gets details of a single import. */
  getMetadataImport(
    request: DeepPartial<GetMetadataImportRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<MetadataImport>;
  /** Creates a new MetadataImport in a given project and location. */
  createMetadataImport(
    request: DeepPartial<CreateMetadataImportRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<Operation>;
  /**
   * Updates a single import.
   * Only the description field of MetadataImport is supported to be updated.
   */
  updateMetadataImport(
    request: DeepPartial<UpdateMetadataImportRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<Operation>;
  /** Exports metadata from a service. */
  exportMetadata(
    request: DeepPartial<ExportMetadataRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<Operation>;
  /** Restores a service from a backup. */
  restoreService(
    request: DeepPartial<RestoreServiceRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<Operation>;
  /** Lists backups in a service. */
  listBackups(
    request: DeepPartial<ListBackupsRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<ListBackupsResponse>;
  /** Gets details of a single backup. */
  getBackup(request: DeepPartial<GetBackupRequest>, options?: CallOptions & CallOptionsExt): Promise<Backup>;
  /** Creates a new backup in a given project and location. */
  createBackup(request: DeepPartial<CreateBackupRequest>, options?: CallOptions & CallOptionsExt): Promise<Operation>;
  /** Deletes a single backup. */
  deleteBackup(request: DeepPartial<DeleteBackupRequest>, options?: CallOptions & CallOptionsExt): Promise<Operation>;
  /** Query DPMS metadata. */
  queryMetadata(request: DeepPartial<QueryMetadataRequest>, options?: CallOptions & CallOptionsExt): Promise<Operation>;
  /** Move a table to another database. */
  moveTableToDatabase(
    request: DeepPartial<MoveTableToDatabaseRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<Operation>;
  /**
   * Alter metadata resource location. The metadata resource can be a database,
   * table, or partition. This functionality only updates the parent directory
   * for the respective metadata resource and does not transfer any existing
   * data to the new location.
   */
  alterMetadataResourceLocation(
    request: DeepPartial<AlterMetadataResourceLocationRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<Operation>;
}

type Builtin = Date | Function | Uint8Array | string | number | boolean | undefined;

export type DeepPartial<T> = T extends Builtin ? T
  : T extends Long ? string | number | Long : T extends globalThis.Array<infer U> ? globalThis.Array<DeepPartial<U>>
  : T extends ReadonlyArray<infer U> ? ReadonlyArray<DeepPartial<U>>
  : T extends {} ? { [K in keyof T]?: DeepPartial<T[K]> }
  : Partial<T>;

function toTimestamp(date: Date): Timestamp {
  const seconds = numberToLong(Math.trunc(date.getTime() / 1_000));
  const nanos = (date.getTime() % 1_000) * 1_000_000;
  return { seconds, nanos };
}

function fromTimestamp(t: Timestamp): Date {
  let millis = (t.seconds.toNumber() || 0) * 1_000;
  millis += (t.nanos || 0) / 1_000_000;
  return new globalThis.Date(millis);
}

function fromJsonTimestamp(o: any): Date {
  if (o instanceof globalThis.Date) {
    return o;
  } else if (typeof o === "string") {
    return new globalThis.Date(o);
  } else {
    return fromTimestamp(Timestamp.fromJSON(o));
  }
}

function numberToLong(number: number) {
  return Long.fromNumber(number);
}

function isObject(value: any): boolean {
  return typeof value === "object" && value !== null;
}

function isSet(value: any): boolean {
  return value !== null && value !== undefined;
}

export interface MessageFns<T> {
  encode(message: T, writer?: BinaryWriter): BinaryWriter;
  decode(input: BinaryReader | Uint8Array, length?: number): T;
  fromJSON(object: any): T;
  toJSON(message: T): unknown;
  create(base?: DeepPartial<T>): T;
  fromPartial(object: DeepPartial<T>): T;
}
