// Code generated by protoc-gen-ts_proto. DO NOT EDIT.
// versions:
//   protoc-gen-ts_proto  v2.2.0
//   protoc               unknown
// source: google/cloud/sql/v1/cloud_sql_instances.proto

/* eslint-disable */
import { BinaryReader, BinaryWriter } from "@bufbuild/protobuf/wire";
import Long from "long";
import { type CallContext, type CallOptions } from "nice-grpc-common";
import { Duration } from "../../../protobuf/duration.js";
import { Timestamp } from "../../../protobuf/timestamp.js";
import { BoolValue, Int64Value } from "../../../protobuf/wrappers.js";
import {
  AcquireSsrsLeaseContext,
  ApiWarning,
  DemoteMasterConfiguration,
  DiskEncryptionConfiguration,
  DiskEncryptionStatus,
  ExportContext,
  ImportContext,
  InstanceReference,
  IpMapping,
  MySqlReplicaConfiguration,
  MySqlSyncConfig,
  Operation,
  PerformDiskShrinkContext,
  Settings,
  SqlBackendType,
  sqlBackendTypeFromJSON,
  sqlBackendTypeToJSON,
  SqlDatabaseVersion,
  sqlDatabaseVersionFromJSON,
  sqlDatabaseVersionToJSON,
  SslCert,
} from "./cloud_sql_resources.js";

export const protobufPackage = "google.cloud.sql.v1";

/** External Sync parallel level. */
export enum ExternalSyncParallelLevel {
  /** EXTERNAL_SYNC_PARALLEL_LEVEL_UNSPECIFIED - Unknown sync parallel level. Will be defaulted to OPTIMAL. */
  EXTERNAL_SYNC_PARALLEL_LEVEL_UNSPECIFIED = 0,
  /** MIN - Minimal parallel level. */
  MIN = 1,
  /** OPTIMAL - Optimal parallel level. */
  OPTIMAL = 2,
  /** MAX - Maximum parallel level. */
  MAX = 3,
  UNRECOGNIZED = -1,
}

export function externalSyncParallelLevelFromJSON(object: any): ExternalSyncParallelLevel {
  switch (object) {
    case 0:
    case "EXTERNAL_SYNC_PARALLEL_LEVEL_UNSPECIFIED":
      return ExternalSyncParallelLevel.EXTERNAL_SYNC_PARALLEL_LEVEL_UNSPECIFIED;
    case 1:
    case "MIN":
      return ExternalSyncParallelLevel.MIN;
    case 2:
    case "OPTIMAL":
      return ExternalSyncParallelLevel.OPTIMAL;
    case 3:
    case "MAX":
      return ExternalSyncParallelLevel.MAX;
    case -1:
    case "UNRECOGNIZED":
    default:
      return ExternalSyncParallelLevel.UNRECOGNIZED;
  }
}

export function externalSyncParallelLevelToJSON(object: ExternalSyncParallelLevel): string {
  switch (object) {
    case ExternalSyncParallelLevel.EXTERNAL_SYNC_PARALLEL_LEVEL_UNSPECIFIED:
      return "EXTERNAL_SYNC_PARALLEL_LEVEL_UNSPECIFIED";
    case ExternalSyncParallelLevel.MIN:
      return "MIN";
    case ExternalSyncParallelLevel.OPTIMAL:
      return "OPTIMAL";
    case ExternalSyncParallelLevel.MAX:
      return "MAX";
    case ExternalSyncParallelLevel.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

export enum SqlInstanceType {
  /** SQL_INSTANCE_TYPE_UNSPECIFIED - This is an unknown Cloud SQL instance type. */
  SQL_INSTANCE_TYPE_UNSPECIFIED = 0,
  /**
   * CLOUD_SQL_INSTANCE - A regular Cloud SQL instance that is not replicating from a primary
   * instance.
   */
  CLOUD_SQL_INSTANCE = 1,
  /**
   * ON_PREMISES_INSTANCE - An instance running on the customer's premises that is not managed by
   * Cloud SQL.
   */
  ON_PREMISES_INSTANCE = 2,
  /** READ_REPLICA_INSTANCE - A Cloud SQL instance acting as a read-replica. */
  READ_REPLICA_INSTANCE = 3,
  UNRECOGNIZED = -1,
}

export function sqlInstanceTypeFromJSON(object: any): SqlInstanceType {
  switch (object) {
    case 0:
    case "SQL_INSTANCE_TYPE_UNSPECIFIED":
      return SqlInstanceType.SQL_INSTANCE_TYPE_UNSPECIFIED;
    case 1:
    case "CLOUD_SQL_INSTANCE":
      return SqlInstanceType.CLOUD_SQL_INSTANCE;
    case 2:
    case "ON_PREMISES_INSTANCE":
      return SqlInstanceType.ON_PREMISES_INSTANCE;
    case 3:
    case "READ_REPLICA_INSTANCE":
      return SqlInstanceType.READ_REPLICA_INSTANCE;
    case -1:
    case "UNRECOGNIZED":
    default:
      return SqlInstanceType.UNRECOGNIZED;
  }
}

export function sqlInstanceTypeToJSON(object: SqlInstanceType): string {
  switch (object) {
    case SqlInstanceType.SQL_INSTANCE_TYPE_UNSPECIFIED:
      return "SQL_INSTANCE_TYPE_UNSPECIFIED";
    case SqlInstanceType.CLOUD_SQL_INSTANCE:
      return "CLOUD_SQL_INSTANCE";
    case SqlInstanceType.ON_PREMISES_INSTANCE:
      return "ON_PREMISES_INSTANCE";
    case SqlInstanceType.READ_REPLICA_INSTANCE:
      return "READ_REPLICA_INSTANCE";
    case SqlInstanceType.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/** The suspension reason of the database instance if the state is SUSPENDED. */
export enum SqlSuspensionReason {
  /** SQL_SUSPENSION_REASON_UNSPECIFIED - This is an unknown suspension reason. */
  SQL_SUSPENSION_REASON_UNSPECIFIED = 0,
  /**
   * BILLING_ISSUE - The instance is suspended due to billing issues (for example:, GCP account
   * issue)
   */
  BILLING_ISSUE = 2,
  /**
   * LEGAL_ISSUE - The instance is suspended due to illegal content (for example:, child
   * pornography, copyrighted material, etc.).
   */
  LEGAL_ISSUE = 3,
  /**
   * OPERATIONAL_ISSUE - The instance is causing operational issues (for example:, causing the
   * database to crash).
   */
  OPERATIONAL_ISSUE = 4,
  /** KMS_KEY_ISSUE - The KMS key used by the instance is either revoked or denied access to */
  KMS_KEY_ISSUE = 5,
  UNRECOGNIZED = -1,
}

export function sqlSuspensionReasonFromJSON(object: any): SqlSuspensionReason {
  switch (object) {
    case 0:
    case "SQL_SUSPENSION_REASON_UNSPECIFIED":
      return SqlSuspensionReason.SQL_SUSPENSION_REASON_UNSPECIFIED;
    case 2:
    case "BILLING_ISSUE":
      return SqlSuspensionReason.BILLING_ISSUE;
    case 3:
    case "LEGAL_ISSUE":
      return SqlSuspensionReason.LEGAL_ISSUE;
    case 4:
    case "OPERATIONAL_ISSUE":
      return SqlSuspensionReason.OPERATIONAL_ISSUE;
    case 5:
    case "KMS_KEY_ISSUE":
      return SqlSuspensionReason.KMS_KEY_ISSUE;
    case -1:
    case "UNRECOGNIZED":
    default:
      return SqlSuspensionReason.UNRECOGNIZED;
  }
}

export function sqlSuspensionReasonToJSON(object: SqlSuspensionReason): string {
  switch (object) {
    case SqlSuspensionReason.SQL_SUSPENSION_REASON_UNSPECIFIED:
      return "SQL_SUSPENSION_REASON_UNSPECIFIED";
    case SqlSuspensionReason.BILLING_ISSUE:
      return "BILLING_ISSUE";
    case SqlSuspensionReason.LEGAL_ISSUE:
      return "LEGAL_ISSUE";
    case SqlSuspensionReason.OPERATIONAL_ISSUE:
      return "OPERATIONAL_ISSUE";
    case SqlSuspensionReason.KMS_KEY_ISSUE:
      return "KMS_KEY_ISSUE";
    case SqlSuspensionReason.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/** Instance add server CA request. */
export interface SqlInstancesAddServerCaRequest {
  /** Cloud SQL instance ID. This does not include the project ID. */
  instance: string;
  /** Project ID of the project that contains the instance. */
  project: string;
}

/** Instance clone request. */
export interface SqlInstancesCloneRequest {
  /**
   * The ID of the Cloud SQL instance to be cloned (source). This does not
   * include the project ID.
   */
  instance: string;
  /** Project ID of the source as well as the clone Cloud SQL instance. */
  project: string;
  body: InstancesCloneRequest | undefined;
}

/** Instance delete request. */
export interface SqlInstancesDeleteRequest {
  /** Cloud SQL instance ID. This does not include the project ID. */
  instance: string;
  /** Project ID of the project that contains the instance to be deleted. */
  project: string;
}

/** Instance demote master request. */
export interface SqlInstancesDemoteMasterRequest {
  /** Cloud SQL instance name. */
  instance: string;
  /** ID of the project that contains the instance. */
  project: string;
  body: InstancesDemoteMasterRequest | undefined;
}

/** Instance demote request. */
export interface SqlInstancesDemoteRequest {
  /** Required. Cloud SQL instance name. */
  instance: string;
  /** Required. ID of the project that contains the instance. */
  project: string;
  /** Required. The request body. */
  body: InstancesDemoteRequest | undefined;
}

/** Instance export request. */
export interface SqlInstancesExportRequest {
  /** Cloud SQL instance ID. This does not include the project ID. */
  instance: string;
  /** Project ID of the project that contains the instance to be exported. */
  project: string;
  body: InstancesExportRequest | undefined;
}

/** Instance failover request. */
export interface SqlInstancesFailoverRequest {
  /** Cloud SQL instance ID. This does not include the project ID. */
  instance: string;
  /** ID of the project that contains the read replica. */
  project: string;
  body: InstancesFailoverRequest | undefined;
}

/** Instance get request. */
export interface SqlInstancesGetRequest {
  /** Database instance ID. This does not include the project ID. */
  instance: string;
  /** Project ID of the project that contains the instance. */
  project: string;
}

/** Instance import request. */
export interface SqlInstancesImportRequest {
  /** Cloud SQL instance ID. This does not include the project ID. */
  instance: string;
  /** Project ID of the project that contains the instance. */
  project: string;
  body: InstancesImportRequest | undefined;
}

/** Instance insert request. */
export interface SqlInstancesInsertRequest {
  /**
   * Project ID of the project to which the newly created Cloud SQL instances
   * should belong.
   */
  project: string;
  body: DatabaseInstance | undefined;
}

/** Instance list request. */
export interface SqlInstancesListRequest {
  /**
   * A filter expression that filters resources listed in the response.
   * The expression is in the form of field:value. For example,
   * 'instanceType:CLOUD_SQL_INSTANCE'. Fields can be nested as needed as per
   * their JSON representation, such as 'settings.userLabels.auto_start:true'.
   *
   * Multiple filter queries are space-separated. For example.
   * 'state:RUNNABLE instanceType:CLOUD_SQL_INSTANCE'. By default, each
   * expression is an AND expression. However, you can include AND and OR
   * expressions explicitly.
   */
  filter: string;
  /**
   * The maximum number of instances to return. The service may return fewer
   * than this value.
   * If unspecified, at most 500 instances are returned.
   * The maximum value is 1000; values above 1000 are coerced to 1000.
   */
  maxResults: number;
  /**
   * A previously-returned page token representing part of the larger set of
   * results to view.
   */
  pageToken: string;
  /** Project ID of the project for which to list Cloud SQL instances. */
  project: string;
}

/** Instance list server CAs request. */
export interface SqlInstancesListServerCasRequest {
  /** Cloud SQL instance ID. This does not include the project ID. */
  instance: string;
  /** Project ID of the project that contains the instance. */
  project: string;
}

/** Instance patch request. */
export interface SqlInstancesPatchRequest {
  /** Cloud SQL instance ID. This does not include the project ID. */
  instance: string;
  /** Project ID of the project that contains the instance. */
  project: string;
  body: DatabaseInstance | undefined;
}

/** Instance promote replica request. */
export interface SqlInstancesPromoteReplicaRequest {
  /** Cloud SQL read replica instance name. */
  instance: string;
  /** ID of the project that contains the read replica. */
  project: string;
  /**
   * Set to true to invoke a replica failover to the designated DR
   * replica. As part of replica failover, the promote operation attempts
   * to add the original primary instance as a replica of the promoted
   * DR replica when the original primary instance comes back online.
   * If set to false or not specified, then the original primary
   * instance becomes an independent Cloud SQL primary instance.
   * Only applicable to MySQL.
   */
  failover: boolean;
}

/** Instance switchover request. */
export interface SqlInstancesSwitchoverRequest {
  /** Cloud SQL read replica instance name. */
  instance: string;
  /** ID of the project that contains the replica. */
  project: string;
  /**
   * Optional. (MySQL only) Cloud SQL instance operations timeout, which is a
   * sum of all database operations. Default value is 10 minutes and can be
   * modified to a maximum value of 24 hours.
   */
  dbTimeout: Duration | undefined;
}

/** Instance reset SSL config request. */
export interface SqlInstancesResetSslConfigRequest {
  /** Cloud SQL instance ID. This does not include the project ID. */
  instance: string;
  /** Project ID of the project that contains the instance. */
  project: string;
}

/** Instance restart request. */
export interface SqlInstancesRestartRequest {
  /** Cloud SQL instance ID. This does not include the project ID. */
  instance: string;
  /** Project ID of the project that contains the instance to be restarted. */
  project: string;
}

/** Instance restore backup request. */
export interface SqlInstancesRestoreBackupRequest {
  /** Cloud SQL instance ID. This does not include the project ID. */
  instance: string;
  /** Project ID of the project that contains the instance. */
  project: string;
  body: InstancesRestoreBackupRequest | undefined;
}

/** Instance rotate server CA request. */
export interface SqlInstancesRotateServerCaRequest {
  /** Cloud SQL instance ID. This does not include the project ID. */
  instance: string;
  /** Project ID of the project that contains the instance. */
  project: string;
  body: InstancesRotateServerCaRequest | undefined;
}

/** Instance start replica request. */
export interface SqlInstancesStartReplicaRequest {
  /** Cloud SQL read replica instance name. */
  instance: string;
  /** ID of the project that contains the read replica. */
  project: string;
}

/** Instance stop replica request. */
export interface SqlInstancesStopReplicaRequest {
  /** Cloud SQL read replica instance name. */
  instance: string;
  /** ID of the project that contains the read replica. */
  project: string;
}

/** Instance truncate log request. */
export interface SqlInstancesTruncateLogRequest {
  /** Cloud SQL instance ID. This does not include the project ID. */
  instance: string;
  /** Project ID of the Cloud SQL project. */
  project: string;
  body: InstancesTruncateLogRequest | undefined;
}

/** Instance perform disk shrink request. */
export interface SqlInstancesPerformDiskShrinkRequest {
  /** Cloud SQL instance ID. This does not include the project ID. */
  instance: string;
  /** Project ID of the project that contains the instance. */
  project: string;
  /** Perform disk shrink context. */
  body: PerformDiskShrinkContext | undefined;
}

/** Instance update request. */
export interface SqlInstancesUpdateRequest {
  /** Cloud SQL instance ID. This does not include the project ID. */
  instance: string;
  /** Project ID of the project that contains the instance. */
  project: string;
  body: DatabaseInstance | undefined;
}

/** Instance reschedule maintenance request. */
export interface SqlInstancesRescheduleMaintenanceRequest {
  /** Cloud SQL instance ID. This does not include the project ID. */
  instance: string;
  /** ID of the project that contains the instance. */
  project: string;
  body: SqlInstancesRescheduleMaintenanceRequestBody | undefined;
}

/** Instance reencrypt request. */
export interface SqlInstancesReencryptRequest {
  /** Cloud SQL instance ID. This does not include the project ID. */
  instance: string;
  /** ID of the project that contains the instance. */
  project: string;
  /** Reencrypt body that users request */
  body: InstancesReencryptRequest | undefined;
}

/** Database Instance reencrypt request. */
export interface InstancesReencryptRequest {
  /** Configuration specific to backup re-encryption */
  backupReencryptionConfig?: BackupReencryptionConfig | undefined;
}

/** Backup Reencryption Config */
export interface BackupReencryptionConfig {
  /** Backup re-encryption limit */
  backupLimit?:
    | number
    | undefined;
  /** Type of backups users want to re-encrypt. */
  backupType?: BackupReencryptionConfig_BackupType | undefined;
}

/** Backup type for re-encryption */
export enum BackupReencryptionConfig_BackupType {
  /** BACKUP_TYPE_UNSPECIFIED - Unknown backup type, will be defaulted to AUTOMATIC backup type */
  BACKUP_TYPE_UNSPECIFIED = 0,
  /** AUTOMATED - Reencrypt automatic backups */
  AUTOMATED = 1,
  /** ON_DEMAND - Reencrypt on-demand backups */
  ON_DEMAND = 2,
  UNRECOGNIZED = -1,
}

export function backupReencryptionConfig_BackupTypeFromJSON(object: any): BackupReencryptionConfig_BackupType {
  switch (object) {
    case 0:
    case "BACKUP_TYPE_UNSPECIFIED":
      return BackupReencryptionConfig_BackupType.BACKUP_TYPE_UNSPECIFIED;
    case 1:
    case "AUTOMATED":
      return BackupReencryptionConfig_BackupType.AUTOMATED;
    case 2:
    case "ON_DEMAND":
      return BackupReencryptionConfig_BackupType.ON_DEMAND;
    case -1:
    case "UNRECOGNIZED":
    default:
      return BackupReencryptionConfig_BackupType.UNRECOGNIZED;
  }
}

export function backupReencryptionConfig_BackupTypeToJSON(object: BackupReencryptionConfig_BackupType): string {
  switch (object) {
    case BackupReencryptionConfig_BackupType.BACKUP_TYPE_UNSPECIFIED:
      return "BACKUP_TYPE_UNSPECIFIED";
    case BackupReencryptionConfig_BackupType.AUTOMATED:
      return "AUTOMATED";
    case BackupReencryptionConfig_BackupType.ON_DEMAND:
      return "ON_DEMAND";
    case BackupReencryptionConfig_BackupType.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/** Instance get disk shrink config request. */
export interface SqlInstancesGetDiskShrinkConfigRequest {
  /** Cloud SQL instance ID. This does not include the project ID. */
  instance: string;
  /** Project ID of the project that contains the instance. */
  project: string;
}

/** Instance verify external sync settings request. */
export interface SqlInstancesVerifyExternalSyncSettingsRequest {
  /** Cloud SQL instance ID. This does not include the project ID. */
  instance: string;
  /** Project ID of the project that contains the instance. */
  project: string;
  /** Flag to enable verifying connection only */
  verifyConnectionOnly: boolean;
  /** External sync mode */
  syncMode: SqlInstancesVerifyExternalSyncSettingsRequest_ExternalSyncMode;
  /** Optional. Flag to verify settings required by replication setup only */
  verifyReplicationOnly: boolean;
  /** Optional. MySQL-specific settings for start external sync. */
  mysqlSyncConfig?:
    | MySqlSyncConfig
    | undefined;
  /**
   * Optional. MigrationType configures the migration to use physical files or
   * logical dump files. If not set, then the logical dump file configuration is
   * used. Valid values are `LOGICAL` or `PHYSICAL`. Only applicable to MySQL.
   */
  migrationType: SqlInstancesVerifyExternalSyncSettingsRequest_MigrationType;
  /**
   * Optional. Parallel level for initial data sync. Only applicable for
   * PostgreSQL.
   */
  syncParallelLevel: ExternalSyncParallelLevel;
}

export enum SqlInstancesVerifyExternalSyncSettingsRequest_ExternalSyncMode {
  /** EXTERNAL_SYNC_MODE_UNSPECIFIED - Unknown external sync mode, will be defaulted to ONLINE mode */
  EXTERNAL_SYNC_MODE_UNSPECIFIED = 0,
  /**
   * ONLINE - Online external sync will set up replication after initial data external
   * sync
   */
  ONLINE = 1,
  /**
   * OFFLINE - Offline external sync only dumps and loads a one-time snapshot of
   * the primary instance's data
   */
  OFFLINE = 2,
  UNRECOGNIZED = -1,
}

export function sqlInstancesVerifyExternalSyncSettingsRequest_ExternalSyncModeFromJSON(
  object: any,
): SqlInstancesVerifyExternalSyncSettingsRequest_ExternalSyncMode {
  switch (object) {
    case 0:
    case "EXTERNAL_SYNC_MODE_UNSPECIFIED":
      return SqlInstancesVerifyExternalSyncSettingsRequest_ExternalSyncMode.EXTERNAL_SYNC_MODE_UNSPECIFIED;
    case 1:
    case "ONLINE":
      return SqlInstancesVerifyExternalSyncSettingsRequest_ExternalSyncMode.ONLINE;
    case 2:
    case "OFFLINE":
      return SqlInstancesVerifyExternalSyncSettingsRequest_ExternalSyncMode.OFFLINE;
    case -1:
    case "UNRECOGNIZED":
    default:
      return SqlInstancesVerifyExternalSyncSettingsRequest_ExternalSyncMode.UNRECOGNIZED;
  }
}

export function sqlInstancesVerifyExternalSyncSettingsRequest_ExternalSyncModeToJSON(
  object: SqlInstancesVerifyExternalSyncSettingsRequest_ExternalSyncMode,
): string {
  switch (object) {
    case SqlInstancesVerifyExternalSyncSettingsRequest_ExternalSyncMode.EXTERNAL_SYNC_MODE_UNSPECIFIED:
      return "EXTERNAL_SYNC_MODE_UNSPECIFIED";
    case SqlInstancesVerifyExternalSyncSettingsRequest_ExternalSyncMode.ONLINE:
      return "ONLINE";
    case SqlInstancesVerifyExternalSyncSettingsRequest_ExternalSyncMode.OFFLINE:
      return "OFFLINE";
    case SqlInstancesVerifyExternalSyncSettingsRequest_ExternalSyncMode.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/**
 * MigrationType determines whether the migration is a physical file-based
 * migration or a logical dump file-based migration.
 */
export enum SqlInstancesVerifyExternalSyncSettingsRequest_MigrationType {
  /** MIGRATION_TYPE_UNSPECIFIED - Default value is a logical dump file-based migration */
  MIGRATION_TYPE_UNSPECIFIED = 0,
  /** LOGICAL - Logical dump file-based migration */
  LOGICAL = 1,
  /** PHYSICAL - Physical file-based migration */
  PHYSICAL = 2,
  UNRECOGNIZED = -1,
}

export function sqlInstancesVerifyExternalSyncSettingsRequest_MigrationTypeFromJSON(
  object: any,
): SqlInstancesVerifyExternalSyncSettingsRequest_MigrationType {
  switch (object) {
    case 0:
    case "MIGRATION_TYPE_UNSPECIFIED":
      return SqlInstancesVerifyExternalSyncSettingsRequest_MigrationType.MIGRATION_TYPE_UNSPECIFIED;
    case 1:
    case "LOGICAL":
      return SqlInstancesVerifyExternalSyncSettingsRequest_MigrationType.LOGICAL;
    case 2:
    case "PHYSICAL":
      return SqlInstancesVerifyExternalSyncSettingsRequest_MigrationType.PHYSICAL;
    case -1:
    case "UNRECOGNIZED":
    default:
      return SqlInstancesVerifyExternalSyncSettingsRequest_MigrationType.UNRECOGNIZED;
  }
}

export function sqlInstancesVerifyExternalSyncSettingsRequest_MigrationTypeToJSON(
  object: SqlInstancesVerifyExternalSyncSettingsRequest_MigrationType,
): string {
  switch (object) {
    case SqlInstancesVerifyExternalSyncSettingsRequest_MigrationType.MIGRATION_TYPE_UNSPECIFIED:
      return "MIGRATION_TYPE_UNSPECIFIED";
    case SqlInstancesVerifyExternalSyncSettingsRequest_MigrationType.LOGICAL:
      return "LOGICAL";
    case SqlInstancesVerifyExternalSyncSettingsRequest_MigrationType.PHYSICAL:
      return "PHYSICAL";
    case SqlInstancesVerifyExternalSyncSettingsRequest_MigrationType.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/** Instance start external sync request. */
export interface SqlInstancesStartExternalSyncRequest {
  /** Cloud SQL instance ID. This does not include the project ID. */
  instance: string;
  /** ID of the project that contains the instance. */
  project: string;
  /** External sync mode. */
  syncMode: SqlInstancesVerifyExternalSyncSettingsRequest_ExternalSyncMode;
  /** Whether to skip the verification step (VESS). */
  skipVerification: boolean;
  /** MySQL-specific settings for start external sync. */
  mysqlSyncConfig?:
    | MySqlSyncConfig
    | undefined;
  /**
   * Optional. Parallel level for initial data sync. Currently only applicable
   * for MySQL.
   */
  syncParallelLevel: ExternalSyncParallelLevel;
  /**
   * Optional. MigrationType configures the migration to use physical files or
   * logical dump files. If not set, then the logical dump file configuration is
   * used. Valid values are `LOGICAL` or `PHYSICAL`. Only applicable to MySQL.
   */
  migrationType: SqlInstancesVerifyExternalSyncSettingsRequest_MigrationType;
}

/** Instance reset replica size request. */
export interface SqlInstancesResetReplicaSizeRequest {
  /** Cloud SQL read replica instance name. */
  instance: string;
  /** ID of the project that contains the read replica. */
  project: string;
}

/** Instance create ephemeral certificate request. */
export interface SqlInstancesCreateEphemeralCertRequest {
  /** Cloud SQL instance ID. This does not include the project ID. */
  instance: string;
  /** Project ID of the Cloud SQL project. */
  project: string;
  body: SslCertsCreateEphemeralRequest | undefined;
}

/** Database instance clone request. */
export interface InstancesCloneRequest {
  /** Contains details about the clone operation. */
  cloneContext: CloneContext | undefined;
}

/** Database demote primary instance request. */
export interface InstancesDemoteMasterRequest {
  /** Contains details about the demoteMaster operation. */
  demoteMasterContext: DemoteMasterContext | undefined;
}

/**
 * This request is used to demote an existing standalone instance to be a
 * Cloud SQL read replica for an external database server.
 */
export interface InstancesDemoteRequest {
  /** Required. Contains details about the demote operation. */
  demoteContext: DemoteContext | undefined;
}

/** Database instance export request. */
export interface InstancesExportRequest {
  /** Contains details about the export operation. */
  exportContext: ExportContext | undefined;
}

/** Instance failover request. */
export interface InstancesFailoverRequest {
  /** Failover Context. */
  failoverContext: FailoverContext | undefined;
}

/** SslCerts create ephemeral certificate request. */
export interface SslCertsCreateEphemeralRequest {
  /** PEM encoded public key to include in the signed certificate. */
  publicKey: string;
  /** Access token to include in the signed certificate. */
  accessToken: string;
}

/** Database instance import request. */
export interface InstancesImportRequest {
  /** Contains details about the import operation. */
  importContext: ImportContext | undefined;
}

/** Database instances list response. */
export interface InstancesListResponse {
  /** This is always `sql#instancesList`. */
  kind: string;
  /** List of warnings that occurred while handling the request. */
  warnings: ApiWarning[];
  /** List of database instance resources. */
  items: DatabaseInstance[];
  /**
   * The continuation token, used to page through large result sets. Provide
   * this value in a subsequent request to return the next page of results.
   */
  nextPageToken: string;
}

/** Instances ListServerCas response. */
export interface InstancesListServerCasResponse {
  /** List of server CA certificates for the instance. */
  certs: SslCert[];
  activeVersion: string;
  /** This is always `sql#instancesListServerCas`. */
  kind: string;
}

/** Database instance restore backup request. */
export interface InstancesRestoreBackupRequest {
  /** Parameters required to perform the restore backup operation. */
  restoreBackupContext: RestoreBackupContext | undefined;
}

/** Rotate server CA request. */
export interface InstancesRotateServerCaRequest {
  /** Contains details about the rotate server CA operation. */
  rotateServerCaContext: RotateServerCaContext | undefined;
}

/** Instance truncate log request. */
export interface InstancesTruncateLogRequest {
  /** Contains details about the truncate log operation. */
  truncateLogContext: TruncateLogContext | undefined;
}

/** Request to acquire a lease for SSRS. */
export interface InstancesAcquireSsrsLeaseRequest {
  /** Contains details about the acquire SSRS lease operation. */
  acquireSsrsLeaseContext: AcquireSsrsLeaseContext | undefined;
}

/** Instance verify external sync settings response. */
export interface SqlInstancesVerifyExternalSyncSettingsResponse {
  /** This is always `sql#migrationSettingErrorList`. */
  kind: string;
  /** List of migration violations. */
  errors: SqlExternalSyncSettingError[];
  /** List of migration warnings. */
  warnings: SqlExternalSyncSettingError[];
}

/** Instance get disk shrink config response. */
export interface SqlInstancesGetDiskShrinkConfigResponse {
  /** This is always `sql#getDiskShrinkConfig`. */
  kind: string;
  /** The minimum size to which a disk can be shrunk in GigaBytes. */
  minimalTargetSizeGb: Long;
  /** Additional message to customers. */
  message: string;
}

/** Instance get latest recovery time request. */
export interface SqlInstancesGetLatestRecoveryTimeRequest {
  /** Cloud SQL instance ID. This does not include the project ID. */
  instance: string;
  /** Project ID of the project that contains the instance. */
  project: string;
}

/** Instance get latest recovery time response. */
export interface SqlInstancesGetLatestRecoveryTimeResponse {
  /** This is always `sql#getLatestRecoveryTime`. */
  kind: string;
  /** Timestamp, identifies the latest recovery time of the source instance. */
  latestRecoveryTime: Date | undefined;
}

/** Database instance clone context. */
export interface CloneContext {
  /** This is always `sql#cloneContext`. */
  kind: string;
  /** Reserved for future use. */
  pitrTimestampMs: Long;
  /** Name of the Cloud SQL instance to be created as a clone. */
  destinationInstanceName: string;
  /**
   * Binary log coordinates, if specified, identify the position up to which the
   * source instance is cloned. If not specified, the source instance is
   * cloned up to the most recent binary log coordinates.
   */
  binLogCoordinates:
    | BinLogCoordinates
    | undefined;
  /**
   * Timestamp, if specified, identifies the time to which the source instance
   * is cloned.
   */
  pointInTime:
    | Date
    | undefined;
  /**
   * The name of the allocated ip range for the private ip Cloud SQL instance.
   * For example: "google-managed-services-default". If set, the cloned instance
   * ip will be created in the allocated range. The range name must comply with
   * [RFC 1035](https://tools.ietf.org/html/rfc1035). Specifically, the name
   * must be 1-63 characters long and match the regular expression
   * [a-z]([-a-z0-9]*[a-z0-9])?.
   * Reserved for future use.
   */
  allocatedIpRange: string;
  /**
   * (SQL Server only) Clone only the specified databases from the source
   * instance. Clone all databases if empty.
   */
  databaseNames: string[];
  /**
   * Optional. Copy clone and point-in-time recovery clone of an instance to the
   * specified zone. If no zone is specified, clone to the same primary zone as
   * the source instance. This field applies to all DB types.
   */
  preferredZone?: string | undefined;
}

/** Binary log coordinates. */
export interface BinLogCoordinates {
  /** Name of the binary log file for a Cloud SQL instance. */
  binLogFileName: string;
  /** Position (offset) within the binary log file. */
  binLogPosition: Long;
  /** This is always `sql#binLogCoordinates`. */
  kind: string;
}

/** A Cloud SQL instance resource. */
export interface DatabaseInstance {
  /** This is always `sql#instance`. */
  kind: string;
  /** The current serving state of the Cloud SQL instance. */
  state: DatabaseInstance_SqlInstanceState;
  /**
   * The database engine type and version. The `databaseVersion` field cannot
   * be changed after instance creation.
   */
  databaseVersion: SqlDatabaseVersion;
  /** The user settings. */
  settings:
    | Settings
    | undefined;
  /**
   * This field is deprecated and will be removed from a future version of the
   * API. Use the `settings.settingsVersion` field instead.
   */
  etag: string;
  /** The name and status of the failover replica. */
  failoverReplica:
    | DatabaseInstance_SqlFailoverReplica
    | undefined;
  /**
   * The name of the instance which will act as primary in the replication
   * setup.
   */
  masterInstanceName: string;
  /** The replicas of the instance. */
  replicaNames: string[];
  /**
   * The maximum disk size of the instance in bytes.
   *
   * @deprecated
   */
  maxDiskSize:
    | Long
    | undefined;
  /**
   * The current disk usage of the instance in bytes. This property has been
   * deprecated. Use the
   * "cloudsql.googleapis.com/database/disk/bytes_used" metric in Cloud
   * Monitoring API instead. Please see [this
   * announcement](https://groups.google.com/d/msg/google-cloud-sql-announce/I_7-F9EBhT0/BtvFtdFeAgAJ)
   * for details.
   *
   * @deprecated
   */
  currentDiskSize:
    | Long
    | undefined;
  /** The assigned IP addresses for the instance. */
  ipAddresses: IpMapping[];
  /** SSL configuration. */
  serverCaCert:
    | SslCert
    | undefined;
  /** The instance type. */
  instanceType: SqlInstanceType;
  /**
   * The project ID of the project containing the Cloud SQL instance. The Google
   * apps domain is prefixed if applicable.
   */
  project: string;
  /**
   * The IPv6 address assigned to the instance.
   * (Deprecated) This property was applicable only
   * to First Generation instances.
   *
   * @deprecated
   */
  ipv6Address: string;
  /**
   * The service account email address assigned to the instance.\This
   * property is read-only.
   */
  serviceAccountEmailAddress: string;
  /** Configuration specific to on-premises instances. */
  onPremisesConfiguration:
    | OnPremisesConfiguration
    | undefined;
  /** Configuration specific to failover replicas and read replicas. */
  replicaConfiguration:
    | ReplicaConfiguration
    | undefined;
  /**
   * The backend type.
   * `SECOND_GEN`: Cloud SQL database instance.
   * `EXTERNAL`: A database server that is not managed by Google.
   *
   * This property is read-only; use the `tier` property in the `settings`
   * object to determine the database type.
   */
  backendType: SqlBackendType;
  /** The URI of this resource. */
  selfLink: string;
  /** If the instance state is SUSPENDED, the reason for the suspension. */
  suspensionReason: SqlSuspensionReason[];
  /** Connection name of the Cloud SQL instance used in connection strings. */
  connectionName: string;
  /** Name of the Cloud SQL instance. This does not include the project ID. */
  name: string;
  /**
   * The geographical region of the Cloud SQL instance.
   *
   * It can be one of the
   * [regions](https://cloud.google.com/sql/docs/mysql/locations#location-r)
   * where Cloud SQL operates:
   *
   * For example,  `asia-east1`, `europe-west1`, and  `us-central1`.
   * The default value is `us-central1`.
   */
  region: string;
  /**
   * The Compute Engine zone that the instance is currently serving from. This
   * value could be different from the zone that was specified when the instance
   * was created if the instance has failed over to its secondary zone. WARNING:
   * Changing this might restart the instance.
   */
  gceZone: string;
  /**
   * The Compute Engine zone that the failover instance is currently serving
   * from for a regional instance. This value could be different
   * from the zone that was specified when the instance
   * was created if the instance has failed over to its secondary/failover zone.
   */
  secondaryGceZone: string;
  /** Disk encryption configuration specific to an instance. */
  diskEncryptionConfiguration:
    | DiskEncryptionConfiguration
    | undefined;
  /** Disk encryption status specific to an instance. */
  diskEncryptionStatus:
    | DiskEncryptionStatus
    | undefined;
  /**
   * Initial root password. Use only on creation. You must set root passwords
   * before you can connect to PostgreSQL instances.
   */
  rootPassword: string;
  /** The start time of any upcoming scheduled maintenance for this instance. */
  scheduledMaintenance:
    | DatabaseInstance_SqlScheduledMaintenance
    | undefined;
  /**
   * This status indicates whether the instance satisfies PZS.
   *
   * The status is reserved for future use.
   */
  satisfiesPzs:
    | boolean
    | undefined;
  /**
   * Output only. Stores the current database version running on the instance
   * including minor version such as `MYSQL_8_0_18`.
   */
  databaseInstalledVersion: string;
  /**
   * This field represents the report generated by the proactive database
   * wellness job for OutOfDisk issues.
   * *  Writers:
   *   *  the proactive database wellness job for OOD.
   * *  Readers:
   *   *  the proactive database wellness job
   */
  outOfDiskReport?:
    | DatabaseInstance_SqlOutOfDiskReport
    | undefined;
  /**
   * Output only. The time when the instance was created in
   * [RFC 3339](https://tools.ietf.org/html/rfc3339) format, for example
   * `2012-11-15T16:19:00.094Z`.
   */
  createTime:
    | Date
    | undefined;
  /** Output only. List all maintenance versions applicable on the instance */
  availableMaintenanceVersions: string[];
  /** The current software version on the instance. */
  maintenanceVersion: string;
  /** Output only. All database versions that are available for upgrade. */
  upgradableDatabaseVersions: AvailableDatabaseVersion[];
  sqlNetworkArchitecture?:
    | DatabaseInstance_SqlNetworkArchitecture
    | undefined;
  /** Output only. The link to service attachment of PSC instance. */
  pscServiceAttachmentLink?:
    | string
    | undefined;
  /** Output only. The dns name of the instance. */
  dnsName?:
    | string
    | undefined;
  /**
   * Output only. DEPRECATED: please use write_endpoint instead.
   *
   * @deprecated
   */
  primaryDnsName?:
    | string
    | undefined;
  /** Output only. The dns name of the primary instance in a replication group. */
  writeEndpoint?:
    | string
    | undefined;
  /**
   * Optional. A primary instance and disaster recovery (DR) replica pair.
   * A DR replica is a cross-region replica that you designate
   * for failover in the event that the primary instance
   * experiences regional failure. Only applicable to MySQL.
   */
  replicationCluster:
    | ReplicationCluster
    | undefined;
  /** Gemini instance configuration. */
  geminiConfig?:
    | GeminiInstanceConfig
    | undefined;
  /**
   * Output only. This status indicates whether the instance satisfies PZI.
   *
   * The status is reserved for future use.
   */
  satisfiesPzi:
    | boolean
    | undefined;
  /**
   * Input only. Whether Cloud SQL is enabled to switch storing point-in-time
   * recovery log files from a data disk to Cloud Storage.
   */
  switchTransactionLogsToCloudStorageEnabled?: boolean | undefined;
}

/** The current serving state of the database instance. */
export enum DatabaseInstance_SqlInstanceState {
  /** SQL_INSTANCE_STATE_UNSPECIFIED - The state of the instance is unknown. */
  SQL_INSTANCE_STATE_UNSPECIFIED = 0,
  /** RUNNABLE - The instance is running, or has been stopped by owner. */
  RUNNABLE = 1,
  /** SUSPENDED - The instance is not available, for example due to problems with billing. */
  SUSPENDED = 2,
  /** PENDING_DELETE - The instance is being deleted. */
  PENDING_DELETE = 3,
  /** PENDING_CREATE - The instance is being created. */
  PENDING_CREATE = 4,
  /** MAINTENANCE - The instance is down for maintenance. */
  MAINTENANCE = 5,
  /**
   * FAILED - The creation of the instance failed or a fatal error occurred during
   * maintenance.
   */
  FAILED = 6,
  /**
   * ONLINE_MAINTENANCE - Deprecated
   *
   * @deprecated
   */
  ONLINE_MAINTENANCE = 7,
  UNRECOGNIZED = -1,
}

export function databaseInstance_SqlInstanceStateFromJSON(object: any): DatabaseInstance_SqlInstanceState {
  switch (object) {
    case 0:
    case "SQL_INSTANCE_STATE_UNSPECIFIED":
      return DatabaseInstance_SqlInstanceState.SQL_INSTANCE_STATE_UNSPECIFIED;
    case 1:
    case "RUNNABLE":
      return DatabaseInstance_SqlInstanceState.RUNNABLE;
    case 2:
    case "SUSPENDED":
      return DatabaseInstance_SqlInstanceState.SUSPENDED;
    case 3:
    case "PENDING_DELETE":
      return DatabaseInstance_SqlInstanceState.PENDING_DELETE;
    case 4:
    case "PENDING_CREATE":
      return DatabaseInstance_SqlInstanceState.PENDING_CREATE;
    case 5:
    case "MAINTENANCE":
      return DatabaseInstance_SqlInstanceState.MAINTENANCE;
    case 6:
    case "FAILED":
      return DatabaseInstance_SqlInstanceState.FAILED;
    case 7:
    case "ONLINE_MAINTENANCE":
      return DatabaseInstance_SqlInstanceState.ONLINE_MAINTENANCE;
    case -1:
    case "UNRECOGNIZED":
    default:
      return DatabaseInstance_SqlInstanceState.UNRECOGNIZED;
  }
}

export function databaseInstance_SqlInstanceStateToJSON(object: DatabaseInstance_SqlInstanceState): string {
  switch (object) {
    case DatabaseInstance_SqlInstanceState.SQL_INSTANCE_STATE_UNSPECIFIED:
      return "SQL_INSTANCE_STATE_UNSPECIFIED";
    case DatabaseInstance_SqlInstanceState.RUNNABLE:
      return "RUNNABLE";
    case DatabaseInstance_SqlInstanceState.SUSPENDED:
      return "SUSPENDED";
    case DatabaseInstance_SqlInstanceState.PENDING_DELETE:
      return "PENDING_DELETE";
    case DatabaseInstance_SqlInstanceState.PENDING_CREATE:
      return "PENDING_CREATE";
    case DatabaseInstance_SqlInstanceState.MAINTENANCE:
      return "MAINTENANCE";
    case DatabaseInstance_SqlInstanceState.FAILED:
      return "FAILED";
    case DatabaseInstance_SqlInstanceState.ONLINE_MAINTENANCE:
      return "ONLINE_MAINTENANCE";
    case DatabaseInstance_SqlInstanceState.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/** The SQL network architecture for the instance. */
export enum DatabaseInstance_SqlNetworkArchitecture {
  SQL_NETWORK_ARCHITECTURE_UNSPECIFIED = 0,
  /** NEW_NETWORK_ARCHITECTURE - The instance uses the new network architecture. */
  NEW_NETWORK_ARCHITECTURE = 1,
  /** OLD_NETWORK_ARCHITECTURE - The instance uses the old network architecture. */
  OLD_NETWORK_ARCHITECTURE = 2,
  UNRECOGNIZED = -1,
}

export function databaseInstance_SqlNetworkArchitectureFromJSON(object: any): DatabaseInstance_SqlNetworkArchitecture {
  switch (object) {
    case 0:
    case "SQL_NETWORK_ARCHITECTURE_UNSPECIFIED":
      return DatabaseInstance_SqlNetworkArchitecture.SQL_NETWORK_ARCHITECTURE_UNSPECIFIED;
    case 1:
    case "NEW_NETWORK_ARCHITECTURE":
      return DatabaseInstance_SqlNetworkArchitecture.NEW_NETWORK_ARCHITECTURE;
    case 2:
    case "OLD_NETWORK_ARCHITECTURE":
      return DatabaseInstance_SqlNetworkArchitecture.OLD_NETWORK_ARCHITECTURE;
    case -1:
    case "UNRECOGNIZED":
    default:
      return DatabaseInstance_SqlNetworkArchitecture.UNRECOGNIZED;
  }
}

export function databaseInstance_SqlNetworkArchitectureToJSON(object: DatabaseInstance_SqlNetworkArchitecture): string {
  switch (object) {
    case DatabaseInstance_SqlNetworkArchitecture.SQL_NETWORK_ARCHITECTURE_UNSPECIFIED:
      return "SQL_NETWORK_ARCHITECTURE_UNSPECIFIED";
    case DatabaseInstance_SqlNetworkArchitecture.NEW_NETWORK_ARCHITECTURE:
      return "NEW_NETWORK_ARCHITECTURE";
    case DatabaseInstance_SqlNetworkArchitecture.OLD_NETWORK_ARCHITECTURE:
      return "OLD_NETWORK_ARCHITECTURE";
    case DatabaseInstance_SqlNetworkArchitecture.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

export interface DatabaseInstance_SqlFailoverReplica {
  /**
   * The name of the failover replica. If specified at instance creation, a
   * failover replica is created for the instance. The name
   * doesn't include the project ID.
   */
  name: string;
  /**
   * The availability status of the failover replica. A false status indicates
   * that the failover replica is out of sync. The primary instance can only
   * failover to the failover replica when the status is true.
   */
  available: boolean | undefined;
}

/** Any scheduled maintenance for this instance. */
export interface DatabaseInstance_SqlScheduledMaintenance {
  /** The start time of any upcoming scheduled maintenance for this instance. */
  startTime:
    | Date
    | undefined;
  /** @deprecated */
  canDefer: boolean;
  /** If the scheduled maintenance can be rescheduled. */
  canReschedule: boolean;
  /** Maintenance cannot be rescheduled to start beyond this deadline. */
  scheduleDeadlineTime?: Date | undefined;
}

/** This message wraps up the information written by out-of-disk detection job. */
export interface DatabaseInstance_SqlOutOfDiskReport {
  /**
   * This field represents the state generated by the proactive database
   * wellness job for OutOfDisk issues.
   * *  Writers:
   *   *  the proactive database wellness job for OOD.
   * *  Readers:
   *   *  the proactive database wellness job
   */
  sqlOutOfDiskState?:
    | DatabaseInstance_SqlOutOfDiskReport_SqlOutOfDiskState
    | undefined;
  /**
   * The minimum recommended increase size in GigaBytes
   * This field is consumed by the frontend
   * *  Writers:
   *   *  the proactive database wellness job for OOD.
   * *  Readers:
   */
  sqlMinRecommendedIncreaseSizeGb?: number | undefined;
}

/** This enum lists all possible states regarding out-of-disk issues. */
export enum DatabaseInstance_SqlOutOfDiskReport_SqlOutOfDiskState {
  /** SQL_OUT_OF_DISK_STATE_UNSPECIFIED - Unspecified state */
  SQL_OUT_OF_DISK_STATE_UNSPECIFIED = 0,
  /** NORMAL - The instance has plenty space on data disk */
  NORMAL = 1,
  /**
   * SOFT_SHUTDOWN - Data disk is almost used up. It is shutdown to prevent data
   * corruption.
   */
  SOFT_SHUTDOWN = 2,
  UNRECOGNIZED = -1,
}

export function databaseInstance_SqlOutOfDiskReport_SqlOutOfDiskStateFromJSON(
  object: any,
): DatabaseInstance_SqlOutOfDiskReport_SqlOutOfDiskState {
  switch (object) {
    case 0:
    case "SQL_OUT_OF_DISK_STATE_UNSPECIFIED":
      return DatabaseInstance_SqlOutOfDiskReport_SqlOutOfDiskState.SQL_OUT_OF_DISK_STATE_UNSPECIFIED;
    case 1:
    case "NORMAL":
      return DatabaseInstance_SqlOutOfDiskReport_SqlOutOfDiskState.NORMAL;
    case 2:
    case "SOFT_SHUTDOWN":
      return DatabaseInstance_SqlOutOfDiskReport_SqlOutOfDiskState.SOFT_SHUTDOWN;
    case -1:
    case "UNRECOGNIZED":
    default:
      return DatabaseInstance_SqlOutOfDiskReport_SqlOutOfDiskState.UNRECOGNIZED;
  }
}

export function databaseInstance_SqlOutOfDiskReport_SqlOutOfDiskStateToJSON(
  object: DatabaseInstance_SqlOutOfDiskReport_SqlOutOfDiskState,
): string {
  switch (object) {
    case DatabaseInstance_SqlOutOfDiskReport_SqlOutOfDiskState.SQL_OUT_OF_DISK_STATE_UNSPECIFIED:
      return "SQL_OUT_OF_DISK_STATE_UNSPECIFIED";
    case DatabaseInstance_SqlOutOfDiskReport_SqlOutOfDiskState.NORMAL:
      return "NORMAL";
    case DatabaseInstance_SqlOutOfDiskReport_SqlOutOfDiskState.SOFT_SHUTDOWN:
      return "SOFT_SHUTDOWN";
    case DatabaseInstance_SqlOutOfDiskReport_SqlOutOfDiskState.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/** Gemini instance configuration. */
export interface GeminiInstanceConfig {
  /** Output only. Whether Gemini is enabled. */
  entitled?:
    | boolean
    | undefined;
  /** Output only. Whether the vacuum management is enabled. */
  googleVacuumMgmtEnabled?:
    | boolean
    | undefined;
  /** Output only. Whether canceling the out-of-memory (OOM) session is enabled. */
  oomSessionCancelEnabled?:
    | boolean
    | undefined;
  /** Output only. Whether the active query is enabled. */
  activeQueryEnabled?:
    | boolean
    | undefined;
  /** Output only. Whether the index advisor is enabled. */
  indexAdvisorEnabled?:
    | boolean
    | undefined;
  /** Output only. Whether the flag recommender is enabled. */
  flagRecommenderEnabled?: boolean | undefined;
}

/**
 * A primary instance and disaster recovery (DR) replica pair.
 * A DR replica is a cross-region replica that you designate for failover in
 * the event that the primary instance experiences regional failure.
 * Only applicable to MySQL.
 */
export interface ReplicationCluster {
  /**
   * Output only. If set, it indicates this instance has a private service
   * access (PSA) dns endpoint that is pointing to the primary instance of the
   * cluster. If this instance is the primary, the dns should be pointing to
   * this instance. After Switchover or Replica failover, this DNS endpoint
   * points to the promoted instance. This is a read-only field, returned to the
   * user as information. This field can exist even if a standalone instance
   * does not yet have a replica, or had a DR replica that was deleted.
   */
  psaWriteEndpoint: string;
  /**
   * Optional. If the instance is a primary instance, then this field identifies
   * the disaster recovery (DR) replica. A DR replica is an optional
   * configuration for Enterprise Plus edition instances. If the instance is a
   * read replica, then the field is not set. Set this field to a replica name
   * to designate a DR replica for a primary instance. Remove the replica name
   * to remove the DR replica designation.
   */
  failoverDrReplicaName: string;
  /**
   * Output only. Read-only field that indicates whether the replica is a DR
   * replica. This field is not set if the instance is a primary instance.
   */
  drReplica: boolean;
}

/** An available database version. It can be a major or a minor version. */
export interface AvailableDatabaseVersion {
  /** The version's major version name. */
  majorVersion?:
    | string
    | undefined;
  /**
   * The database version name. For MySQL 8.0, this string provides the database
   * major and minor version.
   */
  name?:
    | string
    | undefined;
  /** The database version's display name. */
  displayName?: string | undefined;
}

/** Reschedule options for maintenance windows. */
export interface SqlInstancesRescheduleMaintenanceRequestBody {
  /** Required. The type of the reschedule the user wants. */
  reschedule: SqlInstancesRescheduleMaintenanceRequestBody_Reschedule | undefined;
}

export enum SqlInstancesRescheduleMaintenanceRequestBody_RescheduleType {
  RESCHEDULE_TYPE_UNSPECIFIED = 0,
  /** IMMEDIATE - Reschedules maintenance to happen now (within 5 minutes). */
  IMMEDIATE = 1,
  /**
   * NEXT_AVAILABLE_WINDOW - Reschedules maintenance to occur within one week from the originally
   * scheduled day and time.
   */
  NEXT_AVAILABLE_WINDOW = 2,
  /** SPECIFIC_TIME - Reschedules maintenance to a specific time and day. */
  SPECIFIC_TIME = 3,
  UNRECOGNIZED = -1,
}

export function sqlInstancesRescheduleMaintenanceRequestBody_RescheduleTypeFromJSON(
  object: any,
): SqlInstancesRescheduleMaintenanceRequestBody_RescheduleType {
  switch (object) {
    case 0:
    case "RESCHEDULE_TYPE_UNSPECIFIED":
      return SqlInstancesRescheduleMaintenanceRequestBody_RescheduleType.RESCHEDULE_TYPE_UNSPECIFIED;
    case 1:
    case "IMMEDIATE":
      return SqlInstancesRescheduleMaintenanceRequestBody_RescheduleType.IMMEDIATE;
    case 2:
    case "NEXT_AVAILABLE_WINDOW":
      return SqlInstancesRescheduleMaintenanceRequestBody_RescheduleType.NEXT_AVAILABLE_WINDOW;
    case 3:
    case "SPECIFIC_TIME":
      return SqlInstancesRescheduleMaintenanceRequestBody_RescheduleType.SPECIFIC_TIME;
    case -1:
    case "UNRECOGNIZED":
    default:
      return SqlInstancesRescheduleMaintenanceRequestBody_RescheduleType.UNRECOGNIZED;
  }
}

export function sqlInstancesRescheduleMaintenanceRequestBody_RescheduleTypeToJSON(
  object: SqlInstancesRescheduleMaintenanceRequestBody_RescheduleType,
): string {
  switch (object) {
    case SqlInstancesRescheduleMaintenanceRequestBody_RescheduleType.RESCHEDULE_TYPE_UNSPECIFIED:
      return "RESCHEDULE_TYPE_UNSPECIFIED";
    case SqlInstancesRescheduleMaintenanceRequestBody_RescheduleType.IMMEDIATE:
      return "IMMEDIATE";
    case SqlInstancesRescheduleMaintenanceRequestBody_RescheduleType.NEXT_AVAILABLE_WINDOW:
      return "NEXT_AVAILABLE_WINDOW";
    case SqlInstancesRescheduleMaintenanceRequestBody_RescheduleType.SPECIFIC_TIME:
      return "SPECIFIC_TIME";
    case SqlInstancesRescheduleMaintenanceRequestBody_RescheduleType.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

export interface SqlInstancesRescheduleMaintenanceRequestBody_Reschedule {
  /** Required. The type of the reschedule. */
  rescheduleType: SqlInstancesRescheduleMaintenanceRequestBody_RescheduleType;
  /**
   * Optional. Timestamp when the maintenance shall be rescheduled to if
   * reschedule_type=SPECIFIC_TIME, in
   * [RFC 3339](https://tools.ietf.org/html/rfc3339) format, for example
   * `2012-11-15T16:19:00.094Z`.
   */
  scheduleTime: Date | undefined;
}

/** Database instance demote primary instance context. */
export interface DemoteMasterContext {
  /** This is always `sql#demoteMasterContext`. */
  kind: string;
  /**
   * Verify the GTID consistency for demote operation. Default value:
   * `True`. Setting this flag to `false` enables you to bypass the GTID
   * consistency check between on-premises primary instance and Cloud SQL
   * instance during the demotion operation but also exposes you to the risk of
   * future replication failures. Change the value only if you know the reason
   * for the GTID divergence and are confident that doing so will not cause any
   * replication issues.
   */
  verifyGtidConsistency:
    | boolean
    | undefined;
  /**
   * The name of the instance which will act as on-premises primary instance
   * in the replication setup.
   */
  masterInstanceName: string;
  /**
   * Configuration specific to read-replicas replicating from the on-premises
   * primary instance.
   */
  replicaConfiguration:
    | DemoteMasterConfiguration
    | undefined;
  /** Flag to skip replication setup on the instance. */
  skipReplicationSetup: boolean;
}

/**
 * This context is used to demote an existing standalone instance to be
 * a Cloud SQL read replica for an external database server.
 */
export interface DemoteContext {
  /** This is always `sql#demoteContext`. */
  kind: string;
  /**
   * Required. The name of the instance which acts as the on-premises primary
   * instance in the replication setup.
   */
  sourceRepresentativeInstanceName: string;
}

/** Database instance failover context. */
export interface FailoverContext {
  /**
   * The current settings version of this instance. Request will be rejected if
   * this version doesn't match the current settings version.
   */
  settingsVersion: Long;
  /** This is always `sql#failoverContext`. */
  kind: string;
}

/**
 * Database instance restore from backup context.
 * Backup context contains source instance id and project id.
 */
export interface RestoreBackupContext {
  /** This is always `sql#restoreBackupContext`. */
  kind: string;
  /** The ID of the backup run to restore from. */
  backupRunId: Long;
  /** The ID of the instance that the backup was taken from. */
  instanceId: string;
  /** The full project ID of the source instance. */
  project: string;
}

/** Instance rotate server CA context. */
export interface RotateServerCaContext {
  /** This is always `sql#rotateServerCaContext`. */
  kind: string;
  /**
   * The fingerprint of the next version to be rotated to. If left unspecified,
   * will be rotated to the most recently added server CA version.
   */
  nextVersion: string;
}

/** Database Instance truncate log context. */
export interface TruncateLogContext {
  /** This is always `sql#truncateLogContext`. */
  kind: string;
  /**
   * The type of log to truncate. Valid values are `MYSQL_GENERAL_TABLE` and
   * `MYSQL_SLOW_TABLE`.
   */
  logType: string;
}

/** External primary instance migration setting error/warning. */
export interface SqlExternalSyncSettingError {
  /**
   * Can be `sql#externalSyncSettingError` or
   * `sql#externalSyncSettingWarning`.
   */
  kind: string;
  /** Identifies the specific error that occurred. */
  type: SqlExternalSyncSettingError_SqlExternalSyncSettingErrorType;
  /** Additional information about the error encountered. */
  detail: string;
}

export enum SqlExternalSyncSettingError_SqlExternalSyncSettingErrorType {
  SQL_EXTERNAL_SYNC_SETTING_ERROR_TYPE_UNSPECIFIED = 0,
  CONNECTION_FAILURE = 1,
  BINLOG_NOT_ENABLED = 2,
  INCOMPATIBLE_DATABASE_VERSION = 3,
  REPLICA_ALREADY_SETUP = 4,
  /** INSUFFICIENT_PRIVILEGE - The replication user is missing privileges that are required. */
  INSUFFICIENT_PRIVILEGE = 5,
  /** UNSUPPORTED_MIGRATION_TYPE - Unsupported migration type. */
  UNSUPPORTED_MIGRATION_TYPE = 6,
  /** NO_PGLOGICAL_INSTALLED - No pglogical extension installed on databases, applicable for postgres. */
  NO_PGLOGICAL_INSTALLED = 7,
  /** PGLOGICAL_NODE_ALREADY_EXISTS - pglogical node already exists on databases, applicable for postgres. */
  PGLOGICAL_NODE_ALREADY_EXISTS = 8,
  /** INVALID_WAL_LEVEL - The value of parameter wal_level is not set to logical. */
  INVALID_WAL_LEVEL = 9,
  /**
   * INVALID_SHARED_PRELOAD_LIBRARY - The value of parameter shared_preload_libraries does not include
   * pglogical.
   */
  INVALID_SHARED_PRELOAD_LIBRARY = 10,
  /** INSUFFICIENT_MAX_REPLICATION_SLOTS - The value of parameter max_replication_slots is not sufficient. */
  INSUFFICIENT_MAX_REPLICATION_SLOTS = 11,
  /** INSUFFICIENT_MAX_WAL_SENDERS - The value of parameter max_wal_senders is not sufficient. */
  INSUFFICIENT_MAX_WAL_SENDERS = 12,
  /** INSUFFICIENT_MAX_WORKER_PROCESSES - The value of parameter max_worker_processes is not sufficient. */
  INSUFFICIENT_MAX_WORKER_PROCESSES = 13,
  /**
   * UNSUPPORTED_EXTENSIONS - Extensions installed are either not supported or having unsupported
   * versions.
   */
  UNSUPPORTED_EXTENSIONS = 14,
  /** INVALID_RDS_LOGICAL_REPLICATION - The value of parameter rds.logical_replication is not set to 1. */
  INVALID_RDS_LOGICAL_REPLICATION = 15,
  /** INVALID_LOGGING_SETUP - The primary instance logging setup doesn't allow EM sync. */
  INVALID_LOGGING_SETUP = 16,
  /** INVALID_DB_PARAM - The primary instance database parameter setup doesn't allow EM sync. */
  INVALID_DB_PARAM = 17,
  /** UNSUPPORTED_GTID_MODE - The gtid_mode is not supported, applicable for MySQL. */
  UNSUPPORTED_GTID_MODE = 18,
  /** SQLSERVER_AGENT_NOT_RUNNING - SQL Server Agent is not running. */
  SQLSERVER_AGENT_NOT_RUNNING = 19,
  /**
   * UNSUPPORTED_TABLE_DEFINITION - The table definition is not support due to missing primary key or replica
   * identity, applicable for postgres.
   */
  UNSUPPORTED_TABLE_DEFINITION = 20,
  /** UNSUPPORTED_DEFINER - The customer has a definer that will break EM setup. */
  UNSUPPORTED_DEFINER = 21,
  /** SQLSERVER_SERVERNAME_MISMATCH - SQL Server @@SERVERNAME does not match actual host name. */
  SQLSERVER_SERVERNAME_MISMATCH = 22,
  /** PRIMARY_ALREADY_SETUP - The primary instance has been setup and will fail the setup. */
  PRIMARY_ALREADY_SETUP = 23,
  /** UNSUPPORTED_BINLOG_FORMAT - The primary instance has unsupported binary log format. */
  UNSUPPORTED_BINLOG_FORMAT = 24,
  /** BINLOG_RETENTION_SETTING - The primary instance's binary log retention setting. */
  BINLOG_RETENTION_SETTING = 25,
  /** UNSUPPORTED_STORAGE_ENGINE - The primary instance has tables with unsupported storage engine. */
  UNSUPPORTED_STORAGE_ENGINE = 26,
  /**
   * LIMITED_SUPPORT_TABLES - Source has tables with limited support
   * eg: PostgreSQL tables without primary keys.
   */
  LIMITED_SUPPORT_TABLES = 27,
  /** EXISTING_DATA_IN_REPLICA - The replica instance contains existing data. */
  EXISTING_DATA_IN_REPLICA = 28,
  /** MISSING_OPTIONAL_PRIVILEGES - The replication user is missing privileges that are optional. */
  MISSING_OPTIONAL_PRIVILEGES = 29,
  /**
   * RISKY_BACKUP_ADMIN_PRIVILEGE - Additional BACKUP_ADMIN privilege is granted to the replication user
   * which may lock source MySQL 8 instance for DDLs during initial sync.
   */
  RISKY_BACKUP_ADMIN_PRIVILEGE = 30,
  /** INSUFFICIENT_GCS_PERMISSIONS - The Cloud Storage bucket is missing necessary permissions. */
  INSUFFICIENT_GCS_PERMISSIONS = 31,
  /**
   * INVALID_FILE_INFO - The Cloud Storage bucket has an error in the file or contains invalid
   * file information.
   */
  INVALID_FILE_INFO = 32,
  /** UNSUPPORTED_DATABASE_SETTINGS - The source instance has unsupported database settings for migration. */
  UNSUPPORTED_DATABASE_SETTINGS = 33,
  /**
   * MYSQL_PARALLEL_IMPORT_INSUFFICIENT_PRIVILEGE - The replication user is missing parallel import specific privileges.
   * (e.g. LOCK TABLES) for MySQL.
   */
  MYSQL_PARALLEL_IMPORT_INSUFFICIENT_PRIVILEGE = 34,
  /** LOCAL_INFILE_OFF - The global variable local_infile is off on external server replica. */
  LOCAL_INFILE_OFF = 35,
  /**
   * TURN_ON_PITR_AFTER_PROMOTE - This code instructs customers to turn on point-in-time recovery manually
   * for the instance after promoting the Cloud SQL for PostgreSQL instance.
   */
  TURN_ON_PITR_AFTER_PROMOTE = 36,
  /** INCOMPATIBLE_DATABASE_MINOR_VERSION - The minor version of replica database is incompatible with the source. */
  INCOMPATIBLE_DATABASE_MINOR_VERSION = 37,
  /**
   * SOURCE_MAX_SUBSCRIPTIONS - This warning message indicates that Cloud SQL uses the maximum number of
   * subscriptions to migrate data from the source to the destination.
   */
  SOURCE_MAX_SUBSCRIPTIONS = 38,
  /** UNABLE_TO_VERIFY_DEFINERS - Unable to verify definers on the source for MySQL. */
  UNABLE_TO_VERIFY_DEFINERS = 39,
  /**
   * SUBSCRIPTION_CALCULATION_STATUS - If a time out occurs while the subscription counts are calculated, then
   * this value is set to 1. Otherwise, this value is set to 2.
   */
  SUBSCRIPTION_CALCULATION_STATUS = 40,
  /**
   * PG_SUBSCRIPTION_COUNT - Count of subscriptions needed to sync source data for PostgreSQL
   * database.
   */
  PG_SUBSCRIPTION_COUNT = 41,
  /** PG_SYNC_PARALLEL_LEVEL - Final parallel level that is used to do migration. */
  PG_SYNC_PARALLEL_LEVEL = 42,
  /**
   * INSUFFICIENT_DISK_SIZE - The disk size of the replica instance is smaller than the data size of
   * the source instance.
   */
  INSUFFICIENT_DISK_SIZE = 43,
  /**
   * INSUFFICIENT_MACHINE_TIER - The data size of the source instance is greater than 1 TB, the number of
   * cores of the replica instance is less than 8, and the memory of the
   * replica is less than 32 GB.
   */
  INSUFFICIENT_MACHINE_TIER = 44,
  /**
   * UNSUPPORTED_EXTENSIONS_NOT_MIGRATED - The warning message indicates the unsupported extensions will not be
   * migrated to the destination.
   */
  UNSUPPORTED_EXTENSIONS_NOT_MIGRATED = 45,
  /**
   * EXTENSIONS_NOT_MIGRATED - The warning message indicates the pg_cron extension and settings will not
   * be migrated to the destination.
   */
  EXTENSIONS_NOT_MIGRATED = 46,
  /**
   * PG_CRON_FLAG_ENABLED_IN_REPLICA - The error message indicates that pg_cron flags are enabled on the
   * destination which is not supported during the migration.
   */
  PG_CRON_FLAG_ENABLED_IN_REPLICA = 47,
  /**
   * EXTENSIONS_NOT_ENABLED_IN_REPLICA - This error message indicates that the specified extensions are not
   * enabled on destination instance. For example, before you can migrate
   * data to the destination instance, you must enable the PGAudit extension
   * on the instance.
   */
  EXTENSIONS_NOT_ENABLED_IN_REPLICA = 48,
  /**
   * UNSUPPORTED_COLUMNS - The source database has generated columns that can't be migrated. Please
   * change them to regular columns before migration.
   */
  UNSUPPORTED_COLUMNS = 49,
  UNRECOGNIZED = -1,
}

export function sqlExternalSyncSettingError_SqlExternalSyncSettingErrorTypeFromJSON(
  object: any,
): SqlExternalSyncSettingError_SqlExternalSyncSettingErrorType {
  switch (object) {
    case 0:
    case "SQL_EXTERNAL_SYNC_SETTING_ERROR_TYPE_UNSPECIFIED":
      return SqlExternalSyncSettingError_SqlExternalSyncSettingErrorType
        .SQL_EXTERNAL_SYNC_SETTING_ERROR_TYPE_UNSPECIFIED;
    case 1:
    case "CONNECTION_FAILURE":
      return SqlExternalSyncSettingError_SqlExternalSyncSettingErrorType.CONNECTION_FAILURE;
    case 2:
    case "BINLOG_NOT_ENABLED":
      return SqlExternalSyncSettingError_SqlExternalSyncSettingErrorType.BINLOG_NOT_ENABLED;
    case 3:
    case "INCOMPATIBLE_DATABASE_VERSION":
      return SqlExternalSyncSettingError_SqlExternalSyncSettingErrorType.INCOMPATIBLE_DATABASE_VERSION;
    case 4:
    case "REPLICA_ALREADY_SETUP":
      return SqlExternalSyncSettingError_SqlExternalSyncSettingErrorType.REPLICA_ALREADY_SETUP;
    case 5:
    case "INSUFFICIENT_PRIVILEGE":
      return SqlExternalSyncSettingError_SqlExternalSyncSettingErrorType.INSUFFICIENT_PRIVILEGE;
    case 6:
    case "UNSUPPORTED_MIGRATION_TYPE":
      return SqlExternalSyncSettingError_SqlExternalSyncSettingErrorType.UNSUPPORTED_MIGRATION_TYPE;
    case 7:
    case "NO_PGLOGICAL_INSTALLED":
      return SqlExternalSyncSettingError_SqlExternalSyncSettingErrorType.NO_PGLOGICAL_INSTALLED;
    case 8:
    case "PGLOGICAL_NODE_ALREADY_EXISTS":
      return SqlExternalSyncSettingError_SqlExternalSyncSettingErrorType.PGLOGICAL_NODE_ALREADY_EXISTS;
    case 9:
    case "INVALID_WAL_LEVEL":
      return SqlExternalSyncSettingError_SqlExternalSyncSettingErrorType.INVALID_WAL_LEVEL;
    case 10:
    case "INVALID_SHARED_PRELOAD_LIBRARY":
      return SqlExternalSyncSettingError_SqlExternalSyncSettingErrorType.INVALID_SHARED_PRELOAD_LIBRARY;
    case 11:
    case "INSUFFICIENT_MAX_REPLICATION_SLOTS":
      return SqlExternalSyncSettingError_SqlExternalSyncSettingErrorType.INSUFFICIENT_MAX_REPLICATION_SLOTS;
    case 12:
    case "INSUFFICIENT_MAX_WAL_SENDERS":
      return SqlExternalSyncSettingError_SqlExternalSyncSettingErrorType.INSUFFICIENT_MAX_WAL_SENDERS;
    case 13:
    case "INSUFFICIENT_MAX_WORKER_PROCESSES":
      return SqlExternalSyncSettingError_SqlExternalSyncSettingErrorType.INSUFFICIENT_MAX_WORKER_PROCESSES;
    case 14:
    case "UNSUPPORTED_EXTENSIONS":
      return SqlExternalSyncSettingError_SqlExternalSyncSettingErrorType.UNSUPPORTED_EXTENSIONS;
    case 15:
    case "INVALID_RDS_LOGICAL_REPLICATION":
      return SqlExternalSyncSettingError_SqlExternalSyncSettingErrorType.INVALID_RDS_LOGICAL_REPLICATION;
    case 16:
    case "INVALID_LOGGING_SETUP":
      return SqlExternalSyncSettingError_SqlExternalSyncSettingErrorType.INVALID_LOGGING_SETUP;
    case 17:
    case "INVALID_DB_PARAM":
      return SqlExternalSyncSettingError_SqlExternalSyncSettingErrorType.INVALID_DB_PARAM;
    case 18:
    case "UNSUPPORTED_GTID_MODE":
      return SqlExternalSyncSettingError_SqlExternalSyncSettingErrorType.UNSUPPORTED_GTID_MODE;
    case 19:
    case "SQLSERVER_AGENT_NOT_RUNNING":
      return SqlExternalSyncSettingError_SqlExternalSyncSettingErrorType.SQLSERVER_AGENT_NOT_RUNNING;
    case 20:
    case "UNSUPPORTED_TABLE_DEFINITION":
      return SqlExternalSyncSettingError_SqlExternalSyncSettingErrorType.UNSUPPORTED_TABLE_DEFINITION;
    case 21:
    case "UNSUPPORTED_DEFINER":
      return SqlExternalSyncSettingError_SqlExternalSyncSettingErrorType.UNSUPPORTED_DEFINER;
    case 22:
    case "SQLSERVER_SERVERNAME_MISMATCH":
      return SqlExternalSyncSettingError_SqlExternalSyncSettingErrorType.SQLSERVER_SERVERNAME_MISMATCH;
    case 23:
    case "PRIMARY_ALREADY_SETUP":
      return SqlExternalSyncSettingError_SqlExternalSyncSettingErrorType.PRIMARY_ALREADY_SETUP;
    case 24:
    case "UNSUPPORTED_BINLOG_FORMAT":
      return SqlExternalSyncSettingError_SqlExternalSyncSettingErrorType.UNSUPPORTED_BINLOG_FORMAT;
    case 25:
    case "BINLOG_RETENTION_SETTING":
      return SqlExternalSyncSettingError_SqlExternalSyncSettingErrorType.BINLOG_RETENTION_SETTING;
    case 26:
    case "UNSUPPORTED_STORAGE_ENGINE":
      return SqlExternalSyncSettingError_SqlExternalSyncSettingErrorType.UNSUPPORTED_STORAGE_ENGINE;
    case 27:
    case "LIMITED_SUPPORT_TABLES":
      return SqlExternalSyncSettingError_SqlExternalSyncSettingErrorType.LIMITED_SUPPORT_TABLES;
    case 28:
    case "EXISTING_DATA_IN_REPLICA":
      return SqlExternalSyncSettingError_SqlExternalSyncSettingErrorType.EXISTING_DATA_IN_REPLICA;
    case 29:
    case "MISSING_OPTIONAL_PRIVILEGES":
      return SqlExternalSyncSettingError_SqlExternalSyncSettingErrorType.MISSING_OPTIONAL_PRIVILEGES;
    case 30:
    case "RISKY_BACKUP_ADMIN_PRIVILEGE":
      return SqlExternalSyncSettingError_SqlExternalSyncSettingErrorType.RISKY_BACKUP_ADMIN_PRIVILEGE;
    case 31:
    case "INSUFFICIENT_GCS_PERMISSIONS":
      return SqlExternalSyncSettingError_SqlExternalSyncSettingErrorType.INSUFFICIENT_GCS_PERMISSIONS;
    case 32:
    case "INVALID_FILE_INFO":
      return SqlExternalSyncSettingError_SqlExternalSyncSettingErrorType.INVALID_FILE_INFO;
    case 33:
    case "UNSUPPORTED_DATABASE_SETTINGS":
      return SqlExternalSyncSettingError_SqlExternalSyncSettingErrorType.UNSUPPORTED_DATABASE_SETTINGS;
    case 34:
    case "MYSQL_PARALLEL_IMPORT_INSUFFICIENT_PRIVILEGE":
      return SqlExternalSyncSettingError_SqlExternalSyncSettingErrorType.MYSQL_PARALLEL_IMPORT_INSUFFICIENT_PRIVILEGE;
    case 35:
    case "LOCAL_INFILE_OFF":
      return SqlExternalSyncSettingError_SqlExternalSyncSettingErrorType.LOCAL_INFILE_OFF;
    case 36:
    case "TURN_ON_PITR_AFTER_PROMOTE":
      return SqlExternalSyncSettingError_SqlExternalSyncSettingErrorType.TURN_ON_PITR_AFTER_PROMOTE;
    case 37:
    case "INCOMPATIBLE_DATABASE_MINOR_VERSION":
      return SqlExternalSyncSettingError_SqlExternalSyncSettingErrorType.INCOMPATIBLE_DATABASE_MINOR_VERSION;
    case 38:
    case "SOURCE_MAX_SUBSCRIPTIONS":
      return SqlExternalSyncSettingError_SqlExternalSyncSettingErrorType.SOURCE_MAX_SUBSCRIPTIONS;
    case 39:
    case "UNABLE_TO_VERIFY_DEFINERS":
      return SqlExternalSyncSettingError_SqlExternalSyncSettingErrorType.UNABLE_TO_VERIFY_DEFINERS;
    case 40:
    case "SUBSCRIPTION_CALCULATION_STATUS":
      return SqlExternalSyncSettingError_SqlExternalSyncSettingErrorType.SUBSCRIPTION_CALCULATION_STATUS;
    case 41:
    case "PG_SUBSCRIPTION_COUNT":
      return SqlExternalSyncSettingError_SqlExternalSyncSettingErrorType.PG_SUBSCRIPTION_COUNT;
    case 42:
    case "PG_SYNC_PARALLEL_LEVEL":
      return SqlExternalSyncSettingError_SqlExternalSyncSettingErrorType.PG_SYNC_PARALLEL_LEVEL;
    case 43:
    case "INSUFFICIENT_DISK_SIZE":
      return SqlExternalSyncSettingError_SqlExternalSyncSettingErrorType.INSUFFICIENT_DISK_SIZE;
    case 44:
    case "INSUFFICIENT_MACHINE_TIER":
      return SqlExternalSyncSettingError_SqlExternalSyncSettingErrorType.INSUFFICIENT_MACHINE_TIER;
    case 45:
    case "UNSUPPORTED_EXTENSIONS_NOT_MIGRATED":
      return SqlExternalSyncSettingError_SqlExternalSyncSettingErrorType.UNSUPPORTED_EXTENSIONS_NOT_MIGRATED;
    case 46:
    case "EXTENSIONS_NOT_MIGRATED":
      return SqlExternalSyncSettingError_SqlExternalSyncSettingErrorType.EXTENSIONS_NOT_MIGRATED;
    case 47:
    case "PG_CRON_FLAG_ENABLED_IN_REPLICA":
      return SqlExternalSyncSettingError_SqlExternalSyncSettingErrorType.PG_CRON_FLAG_ENABLED_IN_REPLICA;
    case 48:
    case "EXTENSIONS_NOT_ENABLED_IN_REPLICA":
      return SqlExternalSyncSettingError_SqlExternalSyncSettingErrorType.EXTENSIONS_NOT_ENABLED_IN_REPLICA;
    case 49:
    case "UNSUPPORTED_COLUMNS":
      return SqlExternalSyncSettingError_SqlExternalSyncSettingErrorType.UNSUPPORTED_COLUMNS;
    case -1:
    case "UNRECOGNIZED":
    default:
      return SqlExternalSyncSettingError_SqlExternalSyncSettingErrorType.UNRECOGNIZED;
  }
}

export function sqlExternalSyncSettingError_SqlExternalSyncSettingErrorTypeToJSON(
  object: SqlExternalSyncSettingError_SqlExternalSyncSettingErrorType,
): string {
  switch (object) {
    case SqlExternalSyncSettingError_SqlExternalSyncSettingErrorType.SQL_EXTERNAL_SYNC_SETTING_ERROR_TYPE_UNSPECIFIED:
      return "SQL_EXTERNAL_SYNC_SETTING_ERROR_TYPE_UNSPECIFIED";
    case SqlExternalSyncSettingError_SqlExternalSyncSettingErrorType.CONNECTION_FAILURE:
      return "CONNECTION_FAILURE";
    case SqlExternalSyncSettingError_SqlExternalSyncSettingErrorType.BINLOG_NOT_ENABLED:
      return "BINLOG_NOT_ENABLED";
    case SqlExternalSyncSettingError_SqlExternalSyncSettingErrorType.INCOMPATIBLE_DATABASE_VERSION:
      return "INCOMPATIBLE_DATABASE_VERSION";
    case SqlExternalSyncSettingError_SqlExternalSyncSettingErrorType.REPLICA_ALREADY_SETUP:
      return "REPLICA_ALREADY_SETUP";
    case SqlExternalSyncSettingError_SqlExternalSyncSettingErrorType.INSUFFICIENT_PRIVILEGE:
      return "INSUFFICIENT_PRIVILEGE";
    case SqlExternalSyncSettingError_SqlExternalSyncSettingErrorType.UNSUPPORTED_MIGRATION_TYPE:
      return "UNSUPPORTED_MIGRATION_TYPE";
    case SqlExternalSyncSettingError_SqlExternalSyncSettingErrorType.NO_PGLOGICAL_INSTALLED:
      return "NO_PGLOGICAL_INSTALLED";
    case SqlExternalSyncSettingError_SqlExternalSyncSettingErrorType.PGLOGICAL_NODE_ALREADY_EXISTS:
      return "PGLOGICAL_NODE_ALREADY_EXISTS";
    case SqlExternalSyncSettingError_SqlExternalSyncSettingErrorType.INVALID_WAL_LEVEL:
      return "INVALID_WAL_LEVEL";
    case SqlExternalSyncSettingError_SqlExternalSyncSettingErrorType.INVALID_SHARED_PRELOAD_LIBRARY:
      return "INVALID_SHARED_PRELOAD_LIBRARY";
    case SqlExternalSyncSettingError_SqlExternalSyncSettingErrorType.INSUFFICIENT_MAX_REPLICATION_SLOTS:
      return "INSUFFICIENT_MAX_REPLICATION_SLOTS";
    case SqlExternalSyncSettingError_SqlExternalSyncSettingErrorType.INSUFFICIENT_MAX_WAL_SENDERS:
      return "INSUFFICIENT_MAX_WAL_SENDERS";
    case SqlExternalSyncSettingError_SqlExternalSyncSettingErrorType.INSUFFICIENT_MAX_WORKER_PROCESSES:
      return "INSUFFICIENT_MAX_WORKER_PROCESSES";
    case SqlExternalSyncSettingError_SqlExternalSyncSettingErrorType.UNSUPPORTED_EXTENSIONS:
      return "UNSUPPORTED_EXTENSIONS";
    case SqlExternalSyncSettingError_SqlExternalSyncSettingErrorType.INVALID_RDS_LOGICAL_REPLICATION:
      return "INVALID_RDS_LOGICAL_REPLICATION";
    case SqlExternalSyncSettingError_SqlExternalSyncSettingErrorType.INVALID_LOGGING_SETUP:
      return "INVALID_LOGGING_SETUP";
    case SqlExternalSyncSettingError_SqlExternalSyncSettingErrorType.INVALID_DB_PARAM:
      return "INVALID_DB_PARAM";
    case SqlExternalSyncSettingError_SqlExternalSyncSettingErrorType.UNSUPPORTED_GTID_MODE:
      return "UNSUPPORTED_GTID_MODE";
    case SqlExternalSyncSettingError_SqlExternalSyncSettingErrorType.SQLSERVER_AGENT_NOT_RUNNING:
      return "SQLSERVER_AGENT_NOT_RUNNING";
    case SqlExternalSyncSettingError_SqlExternalSyncSettingErrorType.UNSUPPORTED_TABLE_DEFINITION:
      return "UNSUPPORTED_TABLE_DEFINITION";
    case SqlExternalSyncSettingError_SqlExternalSyncSettingErrorType.UNSUPPORTED_DEFINER:
      return "UNSUPPORTED_DEFINER";
    case SqlExternalSyncSettingError_SqlExternalSyncSettingErrorType.SQLSERVER_SERVERNAME_MISMATCH:
      return "SQLSERVER_SERVERNAME_MISMATCH";
    case SqlExternalSyncSettingError_SqlExternalSyncSettingErrorType.PRIMARY_ALREADY_SETUP:
      return "PRIMARY_ALREADY_SETUP";
    case SqlExternalSyncSettingError_SqlExternalSyncSettingErrorType.UNSUPPORTED_BINLOG_FORMAT:
      return "UNSUPPORTED_BINLOG_FORMAT";
    case SqlExternalSyncSettingError_SqlExternalSyncSettingErrorType.BINLOG_RETENTION_SETTING:
      return "BINLOG_RETENTION_SETTING";
    case SqlExternalSyncSettingError_SqlExternalSyncSettingErrorType.UNSUPPORTED_STORAGE_ENGINE:
      return "UNSUPPORTED_STORAGE_ENGINE";
    case SqlExternalSyncSettingError_SqlExternalSyncSettingErrorType.LIMITED_SUPPORT_TABLES:
      return "LIMITED_SUPPORT_TABLES";
    case SqlExternalSyncSettingError_SqlExternalSyncSettingErrorType.EXISTING_DATA_IN_REPLICA:
      return "EXISTING_DATA_IN_REPLICA";
    case SqlExternalSyncSettingError_SqlExternalSyncSettingErrorType.MISSING_OPTIONAL_PRIVILEGES:
      return "MISSING_OPTIONAL_PRIVILEGES";
    case SqlExternalSyncSettingError_SqlExternalSyncSettingErrorType.RISKY_BACKUP_ADMIN_PRIVILEGE:
      return "RISKY_BACKUP_ADMIN_PRIVILEGE";
    case SqlExternalSyncSettingError_SqlExternalSyncSettingErrorType.INSUFFICIENT_GCS_PERMISSIONS:
      return "INSUFFICIENT_GCS_PERMISSIONS";
    case SqlExternalSyncSettingError_SqlExternalSyncSettingErrorType.INVALID_FILE_INFO:
      return "INVALID_FILE_INFO";
    case SqlExternalSyncSettingError_SqlExternalSyncSettingErrorType.UNSUPPORTED_DATABASE_SETTINGS:
      return "UNSUPPORTED_DATABASE_SETTINGS";
    case SqlExternalSyncSettingError_SqlExternalSyncSettingErrorType.MYSQL_PARALLEL_IMPORT_INSUFFICIENT_PRIVILEGE:
      return "MYSQL_PARALLEL_IMPORT_INSUFFICIENT_PRIVILEGE";
    case SqlExternalSyncSettingError_SqlExternalSyncSettingErrorType.LOCAL_INFILE_OFF:
      return "LOCAL_INFILE_OFF";
    case SqlExternalSyncSettingError_SqlExternalSyncSettingErrorType.TURN_ON_PITR_AFTER_PROMOTE:
      return "TURN_ON_PITR_AFTER_PROMOTE";
    case SqlExternalSyncSettingError_SqlExternalSyncSettingErrorType.INCOMPATIBLE_DATABASE_MINOR_VERSION:
      return "INCOMPATIBLE_DATABASE_MINOR_VERSION";
    case SqlExternalSyncSettingError_SqlExternalSyncSettingErrorType.SOURCE_MAX_SUBSCRIPTIONS:
      return "SOURCE_MAX_SUBSCRIPTIONS";
    case SqlExternalSyncSettingError_SqlExternalSyncSettingErrorType.UNABLE_TO_VERIFY_DEFINERS:
      return "UNABLE_TO_VERIFY_DEFINERS";
    case SqlExternalSyncSettingError_SqlExternalSyncSettingErrorType.SUBSCRIPTION_CALCULATION_STATUS:
      return "SUBSCRIPTION_CALCULATION_STATUS";
    case SqlExternalSyncSettingError_SqlExternalSyncSettingErrorType.PG_SUBSCRIPTION_COUNT:
      return "PG_SUBSCRIPTION_COUNT";
    case SqlExternalSyncSettingError_SqlExternalSyncSettingErrorType.PG_SYNC_PARALLEL_LEVEL:
      return "PG_SYNC_PARALLEL_LEVEL";
    case SqlExternalSyncSettingError_SqlExternalSyncSettingErrorType.INSUFFICIENT_DISK_SIZE:
      return "INSUFFICIENT_DISK_SIZE";
    case SqlExternalSyncSettingError_SqlExternalSyncSettingErrorType.INSUFFICIENT_MACHINE_TIER:
      return "INSUFFICIENT_MACHINE_TIER";
    case SqlExternalSyncSettingError_SqlExternalSyncSettingErrorType.UNSUPPORTED_EXTENSIONS_NOT_MIGRATED:
      return "UNSUPPORTED_EXTENSIONS_NOT_MIGRATED";
    case SqlExternalSyncSettingError_SqlExternalSyncSettingErrorType.EXTENSIONS_NOT_MIGRATED:
      return "EXTENSIONS_NOT_MIGRATED";
    case SqlExternalSyncSettingError_SqlExternalSyncSettingErrorType.PG_CRON_FLAG_ENABLED_IN_REPLICA:
      return "PG_CRON_FLAG_ENABLED_IN_REPLICA";
    case SqlExternalSyncSettingError_SqlExternalSyncSettingErrorType.EXTENSIONS_NOT_ENABLED_IN_REPLICA:
      return "EXTENSIONS_NOT_ENABLED_IN_REPLICA";
    case SqlExternalSyncSettingError_SqlExternalSyncSettingErrorType.UNSUPPORTED_COLUMNS:
      return "UNSUPPORTED_COLUMNS";
    case SqlExternalSyncSettingError_SqlExternalSyncSettingErrorType.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/** On-premises instance configuration. */
export interface OnPremisesConfiguration {
  /** The host and port of the on-premises instance in host:port format */
  hostPort: string;
  /** This is always `sql#onPremisesConfiguration`. */
  kind: string;
  /** The username for connecting to on-premises instance. */
  username: string;
  /** The password for connecting to on-premises instance. */
  password: string;
  /** PEM representation of the trusted CA's x509 certificate. */
  caCertificate: string;
  /** PEM representation of the replica's x509 certificate. */
  clientCertificate: string;
  /**
   * PEM representation of the replica's private key. The corresponsing public
   * key is encoded in the client's certificate.
   */
  clientKey: string;
  /** The dump file to create the Cloud SQL replica. */
  dumpFilePath: string;
  /** The reference to Cloud SQL instance if the source is Cloud SQL. */
  sourceInstance: InstanceReference | undefined;
}

/** Read-replica configuration for connecting to the primary instance. */
export interface ReplicaConfiguration {
  /** This is always `sql#replicaConfiguration`. */
  kind: string;
  /**
   * MySQL specific configuration when replicating from a MySQL on-premises
   * primary instance. Replication configuration information such as the
   * username, password, certificates, and keys are not stored in the instance
   * metadata. The configuration information is used only to set up the
   * replication connection and is stored by MySQL in a file named
   * `master.info` in the data directory.
   */
  mysqlReplicaConfiguration:
    | MySqlReplicaConfiguration
    | undefined;
  /**
   * Specifies if the replica is the failover target. If the field is set to
   * `true`, the replica will be designated as a failover replica. In case the
   * primary instance fails, the replica instance will be promoted as the new
   * primary instance. Only one replica can be specified as failover target, and
   * the replica has to be in different zone with the primary instance.
   */
  failoverTarget:
    | boolean
    | undefined;
  /**
   * Optional. Specifies if a SQL Server replica is a cascadable replica. A
   * cascadable replica is a SQL Server cross region replica that supports
   * replica(s) under it.
   */
  cascadableReplica: boolean | undefined;
}

/** Request to acquire a lease for SSRS. */
export interface SqlInstancesAcquireSsrsLeaseRequest {
  /**
   * Required. Cloud SQL instance ID. This doesn't include the project ID. It's
   * composed of lowercase letters, numbers, and hyphens, and it must start with
   * a letter. The total length must be 98 characters or less (Example:
   * instance-id).
   */
  instance: string;
  /**
   * Required. Project ID of the project that contains the instance (Example:
   * project-id).
   */
  project: string;
  /** Required. The request body. */
  body: InstancesAcquireSsrsLeaseRequest | undefined;
}

/** Response for the acquire SSRS lease request. */
export interface SqlInstancesAcquireSsrsLeaseResponse {
  /** The unique identifier for this operation. */
  operationId: string;
}

/** Request to release a lease for SSRS. */
export interface SqlInstancesReleaseSsrsLeaseRequest {
  /**
   * Required. The Cloud SQL instance ID. This doesn't include the project ID.
   * The instance ID contains lowercase letters, numbers, and hyphens, and it
   * must start with a letter. This ID can have a maximum length of 98
   * characters.
   */
  instance: string;
  /** Required. The project ID that contains the instance. */
  project: string;
}

/** Response for the release SSRS lease request. */
export interface SqlInstancesReleaseSsrsLeaseResponse {
  /** The unique identifier for this operation. */
  operationId: string;
}

function createBaseSqlInstancesAddServerCaRequest(): SqlInstancesAddServerCaRequest {
  return { instance: "", project: "" };
}

export const SqlInstancesAddServerCaRequest: MessageFns<SqlInstancesAddServerCaRequest> = {
  encode(message: SqlInstancesAddServerCaRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.instance !== "") {
      writer.uint32(10).string(message.instance);
    }
    if (message.project !== "") {
      writer.uint32(18).string(message.project);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): SqlInstancesAddServerCaRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseSqlInstancesAddServerCaRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.instance = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.project = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): SqlInstancesAddServerCaRequest {
    return {
      instance: isSet(object.instance) ? globalThis.String(object.instance) : "",
      project: isSet(object.project) ? globalThis.String(object.project) : "",
    };
  },

  toJSON(message: SqlInstancesAddServerCaRequest): unknown {
    const obj: any = {};
    if (message.instance !== "") {
      obj.instance = message.instance;
    }
    if (message.project !== "") {
      obj.project = message.project;
    }
    return obj;
  },

  create(base?: DeepPartial<SqlInstancesAddServerCaRequest>): SqlInstancesAddServerCaRequest {
    return SqlInstancesAddServerCaRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<SqlInstancesAddServerCaRequest>): SqlInstancesAddServerCaRequest {
    const message = createBaseSqlInstancesAddServerCaRequest();
    message.instance = object.instance ?? "";
    message.project = object.project ?? "";
    return message;
  },
};

function createBaseSqlInstancesCloneRequest(): SqlInstancesCloneRequest {
  return { instance: "", project: "", body: undefined };
}

export const SqlInstancesCloneRequest: MessageFns<SqlInstancesCloneRequest> = {
  encode(message: SqlInstancesCloneRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.instance !== "") {
      writer.uint32(10).string(message.instance);
    }
    if (message.project !== "") {
      writer.uint32(18).string(message.project);
    }
    if (message.body !== undefined) {
      InstancesCloneRequest.encode(message.body, writer.uint32(802).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): SqlInstancesCloneRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseSqlInstancesCloneRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.instance = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.project = reader.string();
          continue;
        case 100:
          if (tag !== 802) {
            break;
          }

          message.body = InstancesCloneRequest.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): SqlInstancesCloneRequest {
    return {
      instance: isSet(object.instance) ? globalThis.String(object.instance) : "",
      project: isSet(object.project) ? globalThis.String(object.project) : "",
      body: isSet(object.body) ? InstancesCloneRequest.fromJSON(object.body) : undefined,
    };
  },

  toJSON(message: SqlInstancesCloneRequest): unknown {
    const obj: any = {};
    if (message.instance !== "") {
      obj.instance = message.instance;
    }
    if (message.project !== "") {
      obj.project = message.project;
    }
    if (message.body !== undefined) {
      obj.body = InstancesCloneRequest.toJSON(message.body);
    }
    return obj;
  },

  create(base?: DeepPartial<SqlInstancesCloneRequest>): SqlInstancesCloneRequest {
    return SqlInstancesCloneRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<SqlInstancesCloneRequest>): SqlInstancesCloneRequest {
    const message = createBaseSqlInstancesCloneRequest();
    message.instance = object.instance ?? "";
    message.project = object.project ?? "";
    message.body = (object.body !== undefined && object.body !== null)
      ? InstancesCloneRequest.fromPartial(object.body)
      : undefined;
    return message;
  },
};

function createBaseSqlInstancesDeleteRequest(): SqlInstancesDeleteRequest {
  return { instance: "", project: "" };
}

export const SqlInstancesDeleteRequest: MessageFns<SqlInstancesDeleteRequest> = {
  encode(message: SqlInstancesDeleteRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.instance !== "") {
      writer.uint32(10).string(message.instance);
    }
    if (message.project !== "") {
      writer.uint32(18).string(message.project);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): SqlInstancesDeleteRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseSqlInstancesDeleteRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.instance = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.project = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): SqlInstancesDeleteRequest {
    return {
      instance: isSet(object.instance) ? globalThis.String(object.instance) : "",
      project: isSet(object.project) ? globalThis.String(object.project) : "",
    };
  },

  toJSON(message: SqlInstancesDeleteRequest): unknown {
    const obj: any = {};
    if (message.instance !== "") {
      obj.instance = message.instance;
    }
    if (message.project !== "") {
      obj.project = message.project;
    }
    return obj;
  },

  create(base?: DeepPartial<SqlInstancesDeleteRequest>): SqlInstancesDeleteRequest {
    return SqlInstancesDeleteRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<SqlInstancesDeleteRequest>): SqlInstancesDeleteRequest {
    const message = createBaseSqlInstancesDeleteRequest();
    message.instance = object.instance ?? "";
    message.project = object.project ?? "";
    return message;
  },
};

function createBaseSqlInstancesDemoteMasterRequest(): SqlInstancesDemoteMasterRequest {
  return { instance: "", project: "", body: undefined };
}

export const SqlInstancesDemoteMasterRequest: MessageFns<SqlInstancesDemoteMasterRequest> = {
  encode(message: SqlInstancesDemoteMasterRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.instance !== "") {
      writer.uint32(10).string(message.instance);
    }
    if (message.project !== "") {
      writer.uint32(18).string(message.project);
    }
    if (message.body !== undefined) {
      InstancesDemoteMasterRequest.encode(message.body, writer.uint32(802).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): SqlInstancesDemoteMasterRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseSqlInstancesDemoteMasterRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.instance = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.project = reader.string();
          continue;
        case 100:
          if (tag !== 802) {
            break;
          }

          message.body = InstancesDemoteMasterRequest.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): SqlInstancesDemoteMasterRequest {
    return {
      instance: isSet(object.instance) ? globalThis.String(object.instance) : "",
      project: isSet(object.project) ? globalThis.String(object.project) : "",
      body: isSet(object.body) ? InstancesDemoteMasterRequest.fromJSON(object.body) : undefined,
    };
  },

  toJSON(message: SqlInstancesDemoteMasterRequest): unknown {
    const obj: any = {};
    if (message.instance !== "") {
      obj.instance = message.instance;
    }
    if (message.project !== "") {
      obj.project = message.project;
    }
    if (message.body !== undefined) {
      obj.body = InstancesDemoteMasterRequest.toJSON(message.body);
    }
    return obj;
  },

  create(base?: DeepPartial<SqlInstancesDemoteMasterRequest>): SqlInstancesDemoteMasterRequest {
    return SqlInstancesDemoteMasterRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<SqlInstancesDemoteMasterRequest>): SqlInstancesDemoteMasterRequest {
    const message = createBaseSqlInstancesDemoteMasterRequest();
    message.instance = object.instance ?? "";
    message.project = object.project ?? "";
    message.body = (object.body !== undefined && object.body !== null)
      ? InstancesDemoteMasterRequest.fromPartial(object.body)
      : undefined;
    return message;
  },
};

function createBaseSqlInstancesDemoteRequest(): SqlInstancesDemoteRequest {
  return { instance: "", project: "", body: undefined };
}

export const SqlInstancesDemoteRequest: MessageFns<SqlInstancesDemoteRequest> = {
  encode(message: SqlInstancesDemoteRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.instance !== "") {
      writer.uint32(10).string(message.instance);
    }
    if (message.project !== "") {
      writer.uint32(18).string(message.project);
    }
    if (message.body !== undefined) {
      InstancesDemoteRequest.encode(message.body, writer.uint32(802).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): SqlInstancesDemoteRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseSqlInstancesDemoteRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.instance = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.project = reader.string();
          continue;
        case 100:
          if (tag !== 802) {
            break;
          }

          message.body = InstancesDemoteRequest.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): SqlInstancesDemoteRequest {
    return {
      instance: isSet(object.instance) ? globalThis.String(object.instance) : "",
      project: isSet(object.project) ? globalThis.String(object.project) : "",
      body: isSet(object.body) ? InstancesDemoteRequest.fromJSON(object.body) : undefined,
    };
  },

  toJSON(message: SqlInstancesDemoteRequest): unknown {
    const obj: any = {};
    if (message.instance !== "") {
      obj.instance = message.instance;
    }
    if (message.project !== "") {
      obj.project = message.project;
    }
    if (message.body !== undefined) {
      obj.body = InstancesDemoteRequest.toJSON(message.body);
    }
    return obj;
  },

  create(base?: DeepPartial<SqlInstancesDemoteRequest>): SqlInstancesDemoteRequest {
    return SqlInstancesDemoteRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<SqlInstancesDemoteRequest>): SqlInstancesDemoteRequest {
    const message = createBaseSqlInstancesDemoteRequest();
    message.instance = object.instance ?? "";
    message.project = object.project ?? "";
    message.body = (object.body !== undefined && object.body !== null)
      ? InstancesDemoteRequest.fromPartial(object.body)
      : undefined;
    return message;
  },
};

function createBaseSqlInstancesExportRequest(): SqlInstancesExportRequest {
  return { instance: "", project: "", body: undefined };
}

export const SqlInstancesExportRequest: MessageFns<SqlInstancesExportRequest> = {
  encode(message: SqlInstancesExportRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.instance !== "") {
      writer.uint32(10).string(message.instance);
    }
    if (message.project !== "") {
      writer.uint32(18).string(message.project);
    }
    if (message.body !== undefined) {
      InstancesExportRequest.encode(message.body, writer.uint32(802).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): SqlInstancesExportRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseSqlInstancesExportRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.instance = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.project = reader.string();
          continue;
        case 100:
          if (tag !== 802) {
            break;
          }

          message.body = InstancesExportRequest.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): SqlInstancesExportRequest {
    return {
      instance: isSet(object.instance) ? globalThis.String(object.instance) : "",
      project: isSet(object.project) ? globalThis.String(object.project) : "",
      body: isSet(object.body) ? InstancesExportRequest.fromJSON(object.body) : undefined,
    };
  },

  toJSON(message: SqlInstancesExportRequest): unknown {
    const obj: any = {};
    if (message.instance !== "") {
      obj.instance = message.instance;
    }
    if (message.project !== "") {
      obj.project = message.project;
    }
    if (message.body !== undefined) {
      obj.body = InstancesExportRequest.toJSON(message.body);
    }
    return obj;
  },

  create(base?: DeepPartial<SqlInstancesExportRequest>): SqlInstancesExportRequest {
    return SqlInstancesExportRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<SqlInstancesExportRequest>): SqlInstancesExportRequest {
    const message = createBaseSqlInstancesExportRequest();
    message.instance = object.instance ?? "";
    message.project = object.project ?? "";
    message.body = (object.body !== undefined && object.body !== null)
      ? InstancesExportRequest.fromPartial(object.body)
      : undefined;
    return message;
  },
};

function createBaseSqlInstancesFailoverRequest(): SqlInstancesFailoverRequest {
  return { instance: "", project: "", body: undefined };
}

export const SqlInstancesFailoverRequest: MessageFns<SqlInstancesFailoverRequest> = {
  encode(message: SqlInstancesFailoverRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.instance !== "") {
      writer.uint32(10).string(message.instance);
    }
    if (message.project !== "") {
      writer.uint32(18).string(message.project);
    }
    if (message.body !== undefined) {
      InstancesFailoverRequest.encode(message.body, writer.uint32(802).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): SqlInstancesFailoverRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseSqlInstancesFailoverRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.instance = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.project = reader.string();
          continue;
        case 100:
          if (tag !== 802) {
            break;
          }

          message.body = InstancesFailoverRequest.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): SqlInstancesFailoverRequest {
    return {
      instance: isSet(object.instance) ? globalThis.String(object.instance) : "",
      project: isSet(object.project) ? globalThis.String(object.project) : "",
      body: isSet(object.body) ? InstancesFailoverRequest.fromJSON(object.body) : undefined,
    };
  },

  toJSON(message: SqlInstancesFailoverRequest): unknown {
    const obj: any = {};
    if (message.instance !== "") {
      obj.instance = message.instance;
    }
    if (message.project !== "") {
      obj.project = message.project;
    }
    if (message.body !== undefined) {
      obj.body = InstancesFailoverRequest.toJSON(message.body);
    }
    return obj;
  },

  create(base?: DeepPartial<SqlInstancesFailoverRequest>): SqlInstancesFailoverRequest {
    return SqlInstancesFailoverRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<SqlInstancesFailoverRequest>): SqlInstancesFailoverRequest {
    const message = createBaseSqlInstancesFailoverRequest();
    message.instance = object.instance ?? "";
    message.project = object.project ?? "";
    message.body = (object.body !== undefined && object.body !== null)
      ? InstancesFailoverRequest.fromPartial(object.body)
      : undefined;
    return message;
  },
};

function createBaseSqlInstancesGetRequest(): SqlInstancesGetRequest {
  return { instance: "", project: "" };
}

export const SqlInstancesGetRequest: MessageFns<SqlInstancesGetRequest> = {
  encode(message: SqlInstancesGetRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.instance !== "") {
      writer.uint32(10).string(message.instance);
    }
    if (message.project !== "") {
      writer.uint32(18).string(message.project);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): SqlInstancesGetRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseSqlInstancesGetRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.instance = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.project = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): SqlInstancesGetRequest {
    return {
      instance: isSet(object.instance) ? globalThis.String(object.instance) : "",
      project: isSet(object.project) ? globalThis.String(object.project) : "",
    };
  },

  toJSON(message: SqlInstancesGetRequest): unknown {
    const obj: any = {};
    if (message.instance !== "") {
      obj.instance = message.instance;
    }
    if (message.project !== "") {
      obj.project = message.project;
    }
    return obj;
  },

  create(base?: DeepPartial<SqlInstancesGetRequest>): SqlInstancesGetRequest {
    return SqlInstancesGetRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<SqlInstancesGetRequest>): SqlInstancesGetRequest {
    const message = createBaseSqlInstancesGetRequest();
    message.instance = object.instance ?? "";
    message.project = object.project ?? "";
    return message;
  },
};

function createBaseSqlInstancesImportRequest(): SqlInstancesImportRequest {
  return { instance: "", project: "", body: undefined };
}

export const SqlInstancesImportRequest: MessageFns<SqlInstancesImportRequest> = {
  encode(message: SqlInstancesImportRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.instance !== "") {
      writer.uint32(10).string(message.instance);
    }
    if (message.project !== "") {
      writer.uint32(18).string(message.project);
    }
    if (message.body !== undefined) {
      InstancesImportRequest.encode(message.body, writer.uint32(802).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): SqlInstancesImportRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseSqlInstancesImportRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.instance = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.project = reader.string();
          continue;
        case 100:
          if (tag !== 802) {
            break;
          }

          message.body = InstancesImportRequest.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): SqlInstancesImportRequest {
    return {
      instance: isSet(object.instance) ? globalThis.String(object.instance) : "",
      project: isSet(object.project) ? globalThis.String(object.project) : "",
      body: isSet(object.body) ? InstancesImportRequest.fromJSON(object.body) : undefined,
    };
  },

  toJSON(message: SqlInstancesImportRequest): unknown {
    const obj: any = {};
    if (message.instance !== "") {
      obj.instance = message.instance;
    }
    if (message.project !== "") {
      obj.project = message.project;
    }
    if (message.body !== undefined) {
      obj.body = InstancesImportRequest.toJSON(message.body);
    }
    return obj;
  },

  create(base?: DeepPartial<SqlInstancesImportRequest>): SqlInstancesImportRequest {
    return SqlInstancesImportRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<SqlInstancesImportRequest>): SqlInstancesImportRequest {
    const message = createBaseSqlInstancesImportRequest();
    message.instance = object.instance ?? "";
    message.project = object.project ?? "";
    message.body = (object.body !== undefined && object.body !== null)
      ? InstancesImportRequest.fromPartial(object.body)
      : undefined;
    return message;
  },
};

function createBaseSqlInstancesInsertRequest(): SqlInstancesInsertRequest {
  return { project: "", body: undefined };
}

export const SqlInstancesInsertRequest: MessageFns<SqlInstancesInsertRequest> = {
  encode(message: SqlInstancesInsertRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.project !== "") {
      writer.uint32(10).string(message.project);
    }
    if (message.body !== undefined) {
      DatabaseInstance.encode(message.body, writer.uint32(802).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): SqlInstancesInsertRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseSqlInstancesInsertRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.project = reader.string();
          continue;
        case 100:
          if (tag !== 802) {
            break;
          }

          message.body = DatabaseInstance.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): SqlInstancesInsertRequest {
    return {
      project: isSet(object.project) ? globalThis.String(object.project) : "",
      body: isSet(object.body) ? DatabaseInstance.fromJSON(object.body) : undefined,
    };
  },

  toJSON(message: SqlInstancesInsertRequest): unknown {
    const obj: any = {};
    if (message.project !== "") {
      obj.project = message.project;
    }
    if (message.body !== undefined) {
      obj.body = DatabaseInstance.toJSON(message.body);
    }
    return obj;
  },

  create(base?: DeepPartial<SqlInstancesInsertRequest>): SqlInstancesInsertRequest {
    return SqlInstancesInsertRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<SqlInstancesInsertRequest>): SqlInstancesInsertRequest {
    const message = createBaseSqlInstancesInsertRequest();
    message.project = object.project ?? "";
    message.body = (object.body !== undefined && object.body !== null)
      ? DatabaseInstance.fromPartial(object.body)
      : undefined;
    return message;
  },
};

function createBaseSqlInstancesListRequest(): SqlInstancesListRequest {
  return { filter: "", maxResults: 0, pageToken: "", project: "" };
}

export const SqlInstancesListRequest: MessageFns<SqlInstancesListRequest> = {
  encode(message: SqlInstancesListRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.filter !== "") {
      writer.uint32(10).string(message.filter);
    }
    if (message.maxResults !== 0) {
      writer.uint32(16).uint32(message.maxResults);
    }
    if (message.pageToken !== "") {
      writer.uint32(26).string(message.pageToken);
    }
    if (message.project !== "") {
      writer.uint32(34).string(message.project);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): SqlInstancesListRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseSqlInstancesListRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.filter = reader.string();
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.maxResults = reader.uint32();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.pageToken = reader.string();
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.project = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): SqlInstancesListRequest {
    return {
      filter: isSet(object.filter) ? globalThis.String(object.filter) : "",
      maxResults: isSet(object.maxResults) ? globalThis.Number(object.maxResults) : 0,
      pageToken: isSet(object.pageToken) ? globalThis.String(object.pageToken) : "",
      project: isSet(object.project) ? globalThis.String(object.project) : "",
    };
  },

  toJSON(message: SqlInstancesListRequest): unknown {
    const obj: any = {};
    if (message.filter !== "") {
      obj.filter = message.filter;
    }
    if (message.maxResults !== 0) {
      obj.maxResults = Math.round(message.maxResults);
    }
    if (message.pageToken !== "") {
      obj.pageToken = message.pageToken;
    }
    if (message.project !== "") {
      obj.project = message.project;
    }
    return obj;
  },

  create(base?: DeepPartial<SqlInstancesListRequest>): SqlInstancesListRequest {
    return SqlInstancesListRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<SqlInstancesListRequest>): SqlInstancesListRequest {
    const message = createBaseSqlInstancesListRequest();
    message.filter = object.filter ?? "";
    message.maxResults = object.maxResults ?? 0;
    message.pageToken = object.pageToken ?? "";
    message.project = object.project ?? "";
    return message;
  },
};

function createBaseSqlInstancesListServerCasRequest(): SqlInstancesListServerCasRequest {
  return { instance: "", project: "" };
}

export const SqlInstancesListServerCasRequest: MessageFns<SqlInstancesListServerCasRequest> = {
  encode(message: SqlInstancesListServerCasRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.instance !== "") {
      writer.uint32(10).string(message.instance);
    }
    if (message.project !== "") {
      writer.uint32(18).string(message.project);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): SqlInstancesListServerCasRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseSqlInstancesListServerCasRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.instance = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.project = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): SqlInstancesListServerCasRequest {
    return {
      instance: isSet(object.instance) ? globalThis.String(object.instance) : "",
      project: isSet(object.project) ? globalThis.String(object.project) : "",
    };
  },

  toJSON(message: SqlInstancesListServerCasRequest): unknown {
    const obj: any = {};
    if (message.instance !== "") {
      obj.instance = message.instance;
    }
    if (message.project !== "") {
      obj.project = message.project;
    }
    return obj;
  },

  create(base?: DeepPartial<SqlInstancesListServerCasRequest>): SqlInstancesListServerCasRequest {
    return SqlInstancesListServerCasRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<SqlInstancesListServerCasRequest>): SqlInstancesListServerCasRequest {
    const message = createBaseSqlInstancesListServerCasRequest();
    message.instance = object.instance ?? "";
    message.project = object.project ?? "";
    return message;
  },
};

function createBaseSqlInstancesPatchRequest(): SqlInstancesPatchRequest {
  return { instance: "", project: "", body: undefined };
}

export const SqlInstancesPatchRequest: MessageFns<SqlInstancesPatchRequest> = {
  encode(message: SqlInstancesPatchRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.instance !== "") {
      writer.uint32(10).string(message.instance);
    }
    if (message.project !== "") {
      writer.uint32(18).string(message.project);
    }
    if (message.body !== undefined) {
      DatabaseInstance.encode(message.body, writer.uint32(802).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): SqlInstancesPatchRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseSqlInstancesPatchRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.instance = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.project = reader.string();
          continue;
        case 100:
          if (tag !== 802) {
            break;
          }

          message.body = DatabaseInstance.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): SqlInstancesPatchRequest {
    return {
      instance: isSet(object.instance) ? globalThis.String(object.instance) : "",
      project: isSet(object.project) ? globalThis.String(object.project) : "",
      body: isSet(object.body) ? DatabaseInstance.fromJSON(object.body) : undefined,
    };
  },

  toJSON(message: SqlInstancesPatchRequest): unknown {
    const obj: any = {};
    if (message.instance !== "") {
      obj.instance = message.instance;
    }
    if (message.project !== "") {
      obj.project = message.project;
    }
    if (message.body !== undefined) {
      obj.body = DatabaseInstance.toJSON(message.body);
    }
    return obj;
  },

  create(base?: DeepPartial<SqlInstancesPatchRequest>): SqlInstancesPatchRequest {
    return SqlInstancesPatchRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<SqlInstancesPatchRequest>): SqlInstancesPatchRequest {
    const message = createBaseSqlInstancesPatchRequest();
    message.instance = object.instance ?? "";
    message.project = object.project ?? "";
    message.body = (object.body !== undefined && object.body !== null)
      ? DatabaseInstance.fromPartial(object.body)
      : undefined;
    return message;
  },
};

function createBaseSqlInstancesPromoteReplicaRequest(): SqlInstancesPromoteReplicaRequest {
  return { instance: "", project: "", failover: false };
}

export const SqlInstancesPromoteReplicaRequest: MessageFns<SqlInstancesPromoteReplicaRequest> = {
  encode(message: SqlInstancesPromoteReplicaRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.instance !== "") {
      writer.uint32(10).string(message.instance);
    }
    if (message.project !== "") {
      writer.uint32(18).string(message.project);
    }
    if (message.failover !== false) {
      writer.uint32(24).bool(message.failover);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): SqlInstancesPromoteReplicaRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseSqlInstancesPromoteReplicaRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.instance = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.project = reader.string();
          continue;
        case 3:
          if (tag !== 24) {
            break;
          }

          message.failover = reader.bool();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): SqlInstancesPromoteReplicaRequest {
    return {
      instance: isSet(object.instance) ? globalThis.String(object.instance) : "",
      project: isSet(object.project) ? globalThis.String(object.project) : "",
      failover: isSet(object.failover) ? globalThis.Boolean(object.failover) : false,
    };
  },

  toJSON(message: SqlInstancesPromoteReplicaRequest): unknown {
    const obj: any = {};
    if (message.instance !== "") {
      obj.instance = message.instance;
    }
    if (message.project !== "") {
      obj.project = message.project;
    }
    if (message.failover !== false) {
      obj.failover = message.failover;
    }
    return obj;
  },

  create(base?: DeepPartial<SqlInstancesPromoteReplicaRequest>): SqlInstancesPromoteReplicaRequest {
    return SqlInstancesPromoteReplicaRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<SqlInstancesPromoteReplicaRequest>): SqlInstancesPromoteReplicaRequest {
    const message = createBaseSqlInstancesPromoteReplicaRequest();
    message.instance = object.instance ?? "";
    message.project = object.project ?? "";
    message.failover = object.failover ?? false;
    return message;
  },
};

function createBaseSqlInstancesSwitchoverRequest(): SqlInstancesSwitchoverRequest {
  return { instance: "", project: "", dbTimeout: undefined };
}

export const SqlInstancesSwitchoverRequest: MessageFns<SqlInstancesSwitchoverRequest> = {
  encode(message: SqlInstancesSwitchoverRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.instance !== "") {
      writer.uint32(10).string(message.instance);
    }
    if (message.project !== "") {
      writer.uint32(18).string(message.project);
    }
    if (message.dbTimeout !== undefined) {
      Duration.encode(message.dbTimeout, writer.uint32(26).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): SqlInstancesSwitchoverRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseSqlInstancesSwitchoverRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.instance = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.project = reader.string();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.dbTimeout = Duration.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): SqlInstancesSwitchoverRequest {
    return {
      instance: isSet(object.instance) ? globalThis.String(object.instance) : "",
      project: isSet(object.project) ? globalThis.String(object.project) : "",
      dbTimeout: isSet(object.dbTimeout) ? Duration.fromJSON(object.dbTimeout) : undefined,
    };
  },

  toJSON(message: SqlInstancesSwitchoverRequest): unknown {
    const obj: any = {};
    if (message.instance !== "") {
      obj.instance = message.instance;
    }
    if (message.project !== "") {
      obj.project = message.project;
    }
    if (message.dbTimeout !== undefined) {
      obj.dbTimeout = Duration.toJSON(message.dbTimeout);
    }
    return obj;
  },

  create(base?: DeepPartial<SqlInstancesSwitchoverRequest>): SqlInstancesSwitchoverRequest {
    return SqlInstancesSwitchoverRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<SqlInstancesSwitchoverRequest>): SqlInstancesSwitchoverRequest {
    const message = createBaseSqlInstancesSwitchoverRequest();
    message.instance = object.instance ?? "";
    message.project = object.project ?? "";
    message.dbTimeout = (object.dbTimeout !== undefined && object.dbTimeout !== null)
      ? Duration.fromPartial(object.dbTimeout)
      : undefined;
    return message;
  },
};

function createBaseSqlInstancesResetSslConfigRequest(): SqlInstancesResetSslConfigRequest {
  return { instance: "", project: "" };
}

export const SqlInstancesResetSslConfigRequest: MessageFns<SqlInstancesResetSslConfigRequest> = {
  encode(message: SqlInstancesResetSslConfigRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.instance !== "") {
      writer.uint32(10).string(message.instance);
    }
    if (message.project !== "") {
      writer.uint32(18).string(message.project);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): SqlInstancesResetSslConfigRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseSqlInstancesResetSslConfigRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.instance = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.project = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): SqlInstancesResetSslConfigRequest {
    return {
      instance: isSet(object.instance) ? globalThis.String(object.instance) : "",
      project: isSet(object.project) ? globalThis.String(object.project) : "",
    };
  },

  toJSON(message: SqlInstancesResetSslConfigRequest): unknown {
    const obj: any = {};
    if (message.instance !== "") {
      obj.instance = message.instance;
    }
    if (message.project !== "") {
      obj.project = message.project;
    }
    return obj;
  },

  create(base?: DeepPartial<SqlInstancesResetSslConfigRequest>): SqlInstancesResetSslConfigRequest {
    return SqlInstancesResetSslConfigRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<SqlInstancesResetSslConfigRequest>): SqlInstancesResetSslConfigRequest {
    const message = createBaseSqlInstancesResetSslConfigRequest();
    message.instance = object.instance ?? "";
    message.project = object.project ?? "";
    return message;
  },
};

function createBaseSqlInstancesRestartRequest(): SqlInstancesRestartRequest {
  return { instance: "", project: "" };
}

export const SqlInstancesRestartRequest: MessageFns<SqlInstancesRestartRequest> = {
  encode(message: SqlInstancesRestartRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.instance !== "") {
      writer.uint32(10).string(message.instance);
    }
    if (message.project !== "") {
      writer.uint32(18).string(message.project);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): SqlInstancesRestartRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseSqlInstancesRestartRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.instance = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.project = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): SqlInstancesRestartRequest {
    return {
      instance: isSet(object.instance) ? globalThis.String(object.instance) : "",
      project: isSet(object.project) ? globalThis.String(object.project) : "",
    };
  },

  toJSON(message: SqlInstancesRestartRequest): unknown {
    const obj: any = {};
    if (message.instance !== "") {
      obj.instance = message.instance;
    }
    if (message.project !== "") {
      obj.project = message.project;
    }
    return obj;
  },

  create(base?: DeepPartial<SqlInstancesRestartRequest>): SqlInstancesRestartRequest {
    return SqlInstancesRestartRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<SqlInstancesRestartRequest>): SqlInstancesRestartRequest {
    const message = createBaseSqlInstancesRestartRequest();
    message.instance = object.instance ?? "";
    message.project = object.project ?? "";
    return message;
  },
};

function createBaseSqlInstancesRestoreBackupRequest(): SqlInstancesRestoreBackupRequest {
  return { instance: "", project: "", body: undefined };
}

export const SqlInstancesRestoreBackupRequest: MessageFns<SqlInstancesRestoreBackupRequest> = {
  encode(message: SqlInstancesRestoreBackupRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.instance !== "") {
      writer.uint32(10).string(message.instance);
    }
    if (message.project !== "") {
      writer.uint32(18).string(message.project);
    }
    if (message.body !== undefined) {
      InstancesRestoreBackupRequest.encode(message.body, writer.uint32(802).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): SqlInstancesRestoreBackupRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseSqlInstancesRestoreBackupRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.instance = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.project = reader.string();
          continue;
        case 100:
          if (tag !== 802) {
            break;
          }

          message.body = InstancesRestoreBackupRequest.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): SqlInstancesRestoreBackupRequest {
    return {
      instance: isSet(object.instance) ? globalThis.String(object.instance) : "",
      project: isSet(object.project) ? globalThis.String(object.project) : "",
      body: isSet(object.body) ? InstancesRestoreBackupRequest.fromJSON(object.body) : undefined,
    };
  },

  toJSON(message: SqlInstancesRestoreBackupRequest): unknown {
    const obj: any = {};
    if (message.instance !== "") {
      obj.instance = message.instance;
    }
    if (message.project !== "") {
      obj.project = message.project;
    }
    if (message.body !== undefined) {
      obj.body = InstancesRestoreBackupRequest.toJSON(message.body);
    }
    return obj;
  },

  create(base?: DeepPartial<SqlInstancesRestoreBackupRequest>): SqlInstancesRestoreBackupRequest {
    return SqlInstancesRestoreBackupRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<SqlInstancesRestoreBackupRequest>): SqlInstancesRestoreBackupRequest {
    const message = createBaseSqlInstancesRestoreBackupRequest();
    message.instance = object.instance ?? "";
    message.project = object.project ?? "";
    message.body = (object.body !== undefined && object.body !== null)
      ? InstancesRestoreBackupRequest.fromPartial(object.body)
      : undefined;
    return message;
  },
};

function createBaseSqlInstancesRotateServerCaRequest(): SqlInstancesRotateServerCaRequest {
  return { instance: "", project: "", body: undefined };
}

export const SqlInstancesRotateServerCaRequest: MessageFns<SqlInstancesRotateServerCaRequest> = {
  encode(message: SqlInstancesRotateServerCaRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.instance !== "") {
      writer.uint32(10).string(message.instance);
    }
    if (message.project !== "") {
      writer.uint32(18).string(message.project);
    }
    if (message.body !== undefined) {
      InstancesRotateServerCaRequest.encode(message.body, writer.uint32(802).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): SqlInstancesRotateServerCaRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseSqlInstancesRotateServerCaRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.instance = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.project = reader.string();
          continue;
        case 100:
          if (tag !== 802) {
            break;
          }

          message.body = InstancesRotateServerCaRequest.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): SqlInstancesRotateServerCaRequest {
    return {
      instance: isSet(object.instance) ? globalThis.String(object.instance) : "",
      project: isSet(object.project) ? globalThis.String(object.project) : "",
      body: isSet(object.body) ? InstancesRotateServerCaRequest.fromJSON(object.body) : undefined,
    };
  },

  toJSON(message: SqlInstancesRotateServerCaRequest): unknown {
    const obj: any = {};
    if (message.instance !== "") {
      obj.instance = message.instance;
    }
    if (message.project !== "") {
      obj.project = message.project;
    }
    if (message.body !== undefined) {
      obj.body = InstancesRotateServerCaRequest.toJSON(message.body);
    }
    return obj;
  },

  create(base?: DeepPartial<SqlInstancesRotateServerCaRequest>): SqlInstancesRotateServerCaRequest {
    return SqlInstancesRotateServerCaRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<SqlInstancesRotateServerCaRequest>): SqlInstancesRotateServerCaRequest {
    const message = createBaseSqlInstancesRotateServerCaRequest();
    message.instance = object.instance ?? "";
    message.project = object.project ?? "";
    message.body = (object.body !== undefined && object.body !== null)
      ? InstancesRotateServerCaRequest.fromPartial(object.body)
      : undefined;
    return message;
  },
};

function createBaseSqlInstancesStartReplicaRequest(): SqlInstancesStartReplicaRequest {
  return { instance: "", project: "" };
}

export const SqlInstancesStartReplicaRequest: MessageFns<SqlInstancesStartReplicaRequest> = {
  encode(message: SqlInstancesStartReplicaRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.instance !== "") {
      writer.uint32(10).string(message.instance);
    }
    if (message.project !== "") {
      writer.uint32(18).string(message.project);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): SqlInstancesStartReplicaRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseSqlInstancesStartReplicaRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.instance = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.project = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): SqlInstancesStartReplicaRequest {
    return {
      instance: isSet(object.instance) ? globalThis.String(object.instance) : "",
      project: isSet(object.project) ? globalThis.String(object.project) : "",
    };
  },

  toJSON(message: SqlInstancesStartReplicaRequest): unknown {
    const obj: any = {};
    if (message.instance !== "") {
      obj.instance = message.instance;
    }
    if (message.project !== "") {
      obj.project = message.project;
    }
    return obj;
  },

  create(base?: DeepPartial<SqlInstancesStartReplicaRequest>): SqlInstancesStartReplicaRequest {
    return SqlInstancesStartReplicaRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<SqlInstancesStartReplicaRequest>): SqlInstancesStartReplicaRequest {
    const message = createBaseSqlInstancesStartReplicaRequest();
    message.instance = object.instance ?? "";
    message.project = object.project ?? "";
    return message;
  },
};

function createBaseSqlInstancesStopReplicaRequest(): SqlInstancesStopReplicaRequest {
  return { instance: "", project: "" };
}

export const SqlInstancesStopReplicaRequest: MessageFns<SqlInstancesStopReplicaRequest> = {
  encode(message: SqlInstancesStopReplicaRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.instance !== "") {
      writer.uint32(10).string(message.instance);
    }
    if (message.project !== "") {
      writer.uint32(18).string(message.project);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): SqlInstancesStopReplicaRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseSqlInstancesStopReplicaRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.instance = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.project = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): SqlInstancesStopReplicaRequest {
    return {
      instance: isSet(object.instance) ? globalThis.String(object.instance) : "",
      project: isSet(object.project) ? globalThis.String(object.project) : "",
    };
  },

  toJSON(message: SqlInstancesStopReplicaRequest): unknown {
    const obj: any = {};
    if (message.instance !== "") {
      obj.instance = message.instance;
    }
    if (message.project !== "") {
      obj.project = message.project;
    }
    return obj;
  },

  create(base?: DeepPartial<SqlInstancesStopReplicaRequest>): SqlInstancesStopReplicaRequest {
    return SqlInstancesStopReplicaRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<SqlInstancesStopReplicaRequest>): SqlInstancesStopReplicaRequest {
    const message = createBaseSqlInstancesStopReplicaRequest();
    message.instance = object.instance ?? "";
    message.project = object.project ?? "";
    return message;
  },
};

function createBaseSqlInstancesTruncateLogRequest(): SqlInstancesTruncateLogRequest {
  return { instance: "", project: "", body: undefined };
}

export const SqlInstancesTruncateLogRequest: MessageFns<SqlInstancesTruncateLogRequest> = {
  encode(message: SqlInstancesTruncateLogRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.instance !== "") {
      writer.uint32(10).string(message.instance);
    }
    if (message.project !== "") {
      writer.uint32(18).string(message.project);
    }
    if (message.body !== undefined) {
      InstancesTruncateLogRequest.encode(message.body, writer.uint32(802).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): SqlInstancesTruncateLogRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseSqlInstancesTruncateLogRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.instance = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.project = reader.string();
          continue;
        case 100:
          if (tag !== 802) {
            break;
          }

          message.body = InstancesTruncateLogRequest.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): SqlInstancesTruncateLogRequest {
    return {
      instance: isSet(object.instance) ? globalThis.String(object.instance) : "",
      project: isSet(object.project) ? globalThis.String(object.project) : "",
      body: isSet(object.body) ? InstancesTruncateLogRequest.fromJSON(object.body) : undefined,
    };
  },

  toJSON(message: SqlInstancesTruncateLogRequest): unknown {
    const obj: any = {};
    if (message.instance !== "") {
      obj.instance = message.instance;
    }
    if (message.project !== "") {
      obj.project = message.project;
    }
    if (message.body !== undefined) {
      obj.body = InstancesTruncateLogRequest.toJSON(message.body);
    }
    return obj;
  },

  create(base?: DeepPartial<SqlInstancesTruncateLogRequest>): SqlInstancesTruncateLogRequest {
    return SqlInstancesTruncateLogRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<SqlInstancesTruncateLogRequest>): SqlInstancesTruncateLogRequest {
    const message = createBaseSqlInstancesTruncateLogRequest();
    message.instance = object.instance ?? "";
    message.project = object.project ?? "";
    message.body = (object.body !== undefined && object.body !== null)
      ? InstancesTruncateLogRequest.fromPartial(object.body)
      : undefined;
    return message;
  },
};

function createBaseSqlInstancesPerformDiskShrinkRequest(): SqlInstancesPerformDiskShrinkRequest {
  return { instance: "", project: "", body: undefined };
}

export const SqlInstancesPerformDiskShrinkRequest: MessageFns<SqlInstancesPerformDiskShrinkRequest> = {
  encode(message: SqlInstancesPerformDiskShrinkRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.instance !== "") {
      writer.uint32(10).string(message.instance);
    }
    if (message.project !== "") {
      writer.uint32(18).string(message.project);
    }
    if (message.body !== undefined) {
      PerformDiskShrinkContext.encode(message.body, writer.uint32(802).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): SqlInstancesPerformDiskShrinkRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseSqlInstancesPerformDiskShrinkRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.instance = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.project = reader.string();
          continue;
        case 100:
          if (tag !== 802) {
            break;
          }

          message.body = PerformDiskShrinkContext.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): SqlInstancesPerformDiskShrinkRequest {
    return {
      instance: isSet(object.instance) ? globalThis.String(object.instance) : "",
      project: isSet(object.project) ? globalThis.String(object.project) : "",
      body: isSet(object.body) ? PerformDiskShrinkContext.fromJSON(object.body) : undefined,
    };
  },

  toJSON(message: SqlInstancesPerformDiskShrinkRequest): unknown {
    const obj: any = {};
    if (message.instance !== "") {
      obj.instance = message.instance;
    }
    if (message.project !== "") {
      obj.project = message.project;
    }
    if (message.body !== undefined) {
      obj.body = PerformDiskShrinkContext.toJSON(message.body);
    }
    return obj;
  },

  create(base?: DeepPartial<SqlInstancesPerformDiskShrinkRequest>): SqlInstancesPerformDiskShrinkRequest {
    return SqlInstancesPerformDiskShrinkRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<SqlInstancesPerformDiskShrinkRequest>): SqlInstancesPerformDiskShrinkRequest {
    const message = createBaseSqlInstancesPerformDiskShrinkRequest();
    message.instance = object.instance ?? "";
    message.project = object.project ?? "";
    message.body = (object.body !== undefined && object.body !== null)
      ? PerformDiskShrinkContext.fromPartial(object.body)
      : undefined;
    return message;
  },
};

function createBaseSqlInstancesUpdateRequest(): SqlInstancesUpdateRequest {
  return { instance: "", project: "", body: undefined };
}

export const SqlInstancesUpdateRequest: MessageFns<SqlInstancesUpdateRequest> = {
  encode(message: SqlInstancesUpdateRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.instance !== "") {
      writer.uint32(10).string(message.instance);
    }
    if (message.project !== "") {
      writer.uint32(18).string(message.project);
    }
    if (message.body !== undefined) {
      DatabaseInstance.encode(message.body, writer.uint32(802).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): SqlInstancesUpdateRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseSqlInstancesUpdateRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.instance = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.project = reader.string();
          continue;
        case 100:
          if (tag !== 802) {
            break;
          }

          message.body = DatabaseInstance.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): SqlInstancesUpdateRequest {
    return {
      instance: isSet(object.instance) ? globalThis.String(object.instance) : "",
      project: isSet(object.project) ? globalThis.String(object.project) : "",
      body: isSet(object.body) ? DatabaseInstance.fromJSON(object.body) : undefined,
    };
  },

  toJSON(message: SqlInstancesUpdateRequest): unknown {
    const obj: any = {};
    if (message.instance !== "") {
      obj.instance = message.instance;
    }
    if (message.project !== "") {
      obj.project = message.project;
    }
    if (message.body !== undefined) {
      obj.body = DatabaseInstance.toJSON(message.body);
    }
    return obj;
  },

  create(base?: DeepPartial<SqlInstancesUpdateRequest>): SqlInstancesUpdateRequest {
    return SqlInstancesUpdateRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<SqlInstancesUpdateRequest>): SqlInstancesUpdateRequest {
    const message = createBaseSqlInstancesUpdateRequest();
    message.instance = object.instance ?? "";
    message.project = object.project ?? "";
    message.body = (object.body !== undefined && object.body !== null)
      ? DatabaseInstance.fromPartial(object.body)
      : undefined;
    return message;
  },
};

function createBaseSqlInstancesRescheduleMaintenanceRequest(): SqlInstancesRescheduleMaintenanceRequest {
  return { instance: "", project: "", body: undefined };
}

export const SqlInstancesRescheduleMaintenanceRequest: MessageFns<SqlInstancesRescheduleMaintenanceRequest> = {
  encode(message: SqlInstancesRescheduleMaintenanceRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.instance !== "") {
      writer.uint32(10).string(message.instance);
    }
    if (message.project !== "") {
      writer.uint32(18).string(message.project);
    }
    if (message.body !== undefined) {
      SqlInstancesRescheduleMaintenanceRequestBody.encode(message.body, writer.uint32(802).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): SqlInstancesRescheduleMaintenanceRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseSqlInstancesRescheduleMaintenanceRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.instance = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.project = reader.string();
          continue;
        case 100:
          if (tag !== 802) {
            break;
          }

          message.body = SqlInstancesRescheduleMaintenanceRequestBody.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): SqlInstancesRescheduleMaintenanceRequest {
    return {
      instance: isSet(object.instance) ? globalThis.String(object.instance) : "",
      project: isSet(object.project) ? globalThis.String(object.project) : "",
      body: isSet(object.body) ? SqlInstancesRescheduleMaintenanceRequestBody.fromJSON(object.body) : undefined,
    };
  },

  toJSON(message: SqlInstancesRescheduleMaintenanceRequest): unknown {
    const obj: any = {};
    if (message.instance !== "") {
      obj.instance = message.instance;
    }
    if (message.project !== "") {
      obj.project = message.project;
    }
    if (message.body !== undefined) {
      obj.body = SqlInstancesRescheduleMaintenanceRequestBody.toJSON(message.body);
    }
    return obj;
  },

  create(base?: DeepPartial<SqlInstancesRescheduleMaintenanceRequest>): SqlInstancesRescheduleMaintenanceRequest {
    return SqlInstancesRescheduleMaintenanceRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<SqlInstancesRescheduleMaintenanceRequest>): SqlInstancesRescheduleMaintenanceRequest {
    const message = createBaseSqlInstancesRescheduleMaintenanceRequest();
    message.instance = object.instance ?? "";
    message.project = object.project ?? "";
    message.body = (object.body !== undefined && object.body !== null)
      ? SqlInstancesRescheduleMaintenanceRequestBody.fromPartial(object.body)
      : undefined;
    return message;
  },
};

function createBaseSqlInstancesReencryptRequest(): SqlInstancesReencryptRequest {
  return { instance: "", project: "", body: undefined };
}

export const SqlInstancesReencryptRequest: MessageFns<SqlInstancesReencryptRequest> = {
  encode(message: SqlInstancesReencryptRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.instance !== "") {
      writer.uint32(10).string(message.instance);
    }
    if (message.project !== "") {
      writer.uint32(18).string(message.project);
    }
    if (message.body !== undefined) {
      InstancesReencryptRequest.encode(message.body, writer.uint32(26).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): SqlInstancesReencryptRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseSqlInstancesReencryptRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.instance = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.project = reader.string();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.body = InstancesReencryptRequest.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): SqlInstancesReencryptRequest {
    return {
      instance: isSet(object.instance) ? globalThis.String(object.instance) : "",
      project: isSet(object.project) ? globalThis.String(object.project) : "",
      body: isSet(object.body) ? InstancesReencryptRequest.fromJSON(object.body) : undefined,
    };
  },

  toJSON(message: SqlInstancesReencryptRequest): unknown {
    const obj: any = {};
    if (message.instance !== "") {
      obj.instance = message.instance;
    }
    if (message.project !== "") {
      obj.project = message.project;
    }
    if (message.body !== undefined) {
      obj.body = InstancesReencryptRequest.toJSON(message.body);
    }
    return obj;
  },

  create(base?: DeepPartial<SqlInstancesReencryptRequest>): SqlInstancesReencryptRequest {
    return SqlInstancesReencryptRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<SqlInstancesReencryptRequest>): SqlInstancesReencryptRequest {
    const message = createBaseSqlInstancesReencryptRequest();
    message.instance = object.instance ?? "";
    message.project = object.project ?? "";
    message.body = (object.body !== undefined && object.body !== null)
      ? InstancesReencryptRequest.fromPartial(object.body)
      : undefined;
    return message;
  },
};

function createBaseInstancesReencryptRequest(): InstancesReencryptRequest {
  return { backupReencryptionConfig: undefined };
}

export const InstancesReencryptRequest: MessageFns<InstancesReencryptRequest> = {
  encode(message: InstancesReencryptRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.backupReencryptionConfig !== undefined) {
      BackupReencryptionConfig.encode(message.backupReencryptionConfig, writer.uint32(10).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): InstancesReencryptRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseInstancesReencryptRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.backupReencryptionConfig = BackupReencryptionConfig.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): InstancesReencryptRequest {
    return {
      backupReencryptionConfig: isSet(object.backupReencryptionConfig)
        ? BackupReencryptionConfig.fromJSON(object.backupReencryptionConfig)
        : undefined,
    };
  },

  toJSON(message: InstancesReencryptRequest): unknown {
    const obj: any = {};
    if (message.backupReencryptionConfig !== undefined) {
      obj.backupReencryptionConfig = BackupReencryptionConfig.toJSON(message.backupReencryptionConfig);
    }
    return obj;
  },

  create(base?: DeepPartial<InstancesReencryptRequest>): InstancesReencryptRequest {
    return InstancesReencryptRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<InstancesReencryptRequest>): InstancesReencryptRequest {
    const message = createBaseInstancesReencryptRequest();
    message.backupReencryptionConfig =
      (object.backupReencryptionConfig !== undefined && object.backupReencryptionConfig !== null)
        ? BackupReencryptionConfig.fromPartial(object.backupReencryptionConfig)
        : undefined;
    return message;
  },
};

function createBaseBackupReencryptionConfig(): BackupReencryptionConfig {
  return { backupLimit: undefined, backupType: undefined };
}

export const BackupReencryptionConfig: MessageFns<BackupReencryptionConfig> = {
  encode(message: BackupReencryptionConfig, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.backupLimit !== undefined) {
      writer.uint32(8).int32(message.backupLimit);
    }
    if (message.backupType !== undefined) {
      writer.uint32(16).int32(message.backupType);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): BackupReencryptionConfig {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseBackupReencryptionConfig();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 8) {
            break;
          }

          message.backupLimit = reader.int32();
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.backupType = reader.int32() as any;
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): BackupReencryptionConfig {
    return {
      backupLimit: isSet(object.backupLimit) ? globalThis.Number(object.backupLimit) : undefined,
      backupType: isSet(object.backupType) ? backupReencryptionConfig_BackupTypeFromJSON(object.backupType) : undefined,
    };
  },

  toJSON(message: BackupReencryptionConfig): unknown {
    const obj: any = {};
    if (message.backupLimit !== undefined) {
      obj.backupLimit = Math.round(message.backupLimit);
    }
    if (message.backupType !== undefined) {
      obj.backupType = backupReencryptionConfig_BackupTypeToJSON(message.backupType);
    }
    return obj;
  },

  create(base?: DeepPartial<BackupReencryptionConfig>): BackupReencryptionConfig {
    return BackupReencryptionConfig.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<BackupReencryptionConfig>): BackupReencryptionConfig {
    const message = createBaseBackupReencryptionConfig();
    message.backupLimit = object.backupLimit ?? undefined;
    message.backupType = object.backupType ?? undefined;
    return message;
  },
};

function createBaseSqlInstancesGetDiskShrinkConfigRequest(): SqlInstancesGetDiskShrinkConfigRequest {
  return { instance: "", project: "" };
}

export const SqlInstancesGetDiskShrinkConfigRequest: MessageFns<SqlInstancesGetDiskShrinkConfigRequest> = {
  encode(message: SqlInstancesGetDiskShrinkConfigRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.instance !== "") {
      writer.uint32(10).string(message.instance);
    }
    if (message.project !== "") {
      writer.uint32(18).string(message.project);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): SqlInstancesGetDiskShrinkConfigRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseSqlInstancesGetDiskShrinkConfigRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.instance = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.project = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): SqlInstancesGetDiskShrinkConfigRequest {
    return {
      instance: isSet(object.instance) ? globalThis.String(object.instance) : "",
      project: isSet(object.project) ? globalThis.String(object.project) : "",
    };
  },

  toJSON(message: SqlInstancesGetDiskShrinkConfigRequest): unknown {
    const obj: any = {};
    if (message.instance !== "") {
      obj.instance = message.instance;
    }
    if (message.project !== "") {
      obj.project = message.project;
    }
    return obj;
  },

  create(base?: DeepPartial<SqlInstancesGetDiskShrinkConfigRequest>): SqlInstancesGetDiskShrinkConfigRequest {
    return SqlInstancesGetDiskShrinkConfigRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<SqlInstancesGetDiskShrinkConfigRequest>): SqlInstancesGetDiskShrinkConfigRequest {
    const message = createBaseSqlInstancesGetDiskShrinkConfigRequest();
    message.instance = object.instance ?? "";
    message.project = object.project ?? "";
    return message;
  },
};

function createBaseSqlInstancesVerifyExternalSyncSettingsRequest(): SqlInstancesVerifyExternalSyncSettingsRequest {
  return {
    instance: "",
    project: "",
    verifyConnectionOnly: false,
    syncMode: 0,
    verifyReplicationOnly: false,
    mysqlSyncConfig: undefined,
    migrationType: 0,
    syncParallelLevel: 0,
  };
}

export const SqlInstancesVerifyExternalSyncSettingsRequest: MessageFns<SqlInstancesVerifyExternalSyncSettingsRequest> =
  {
    encode(
      message: SqlInstancesVerifyExternalSyncSettingsRequest,
      writer: BinaryWriter = new BinaryWriter(),
    ): BinaryWriter {
      if (message.instance !== "") {
        writer.uint32(10).string(message.instance);
      }
      if (message.project !== "") {
        writer.uint32(18).string(message.project);
      }
      if (message.verifyConnectionOnly !== false) {
        writer.uint32(24).bool(message.verifyConnectionOnly);
      }
      if (message.syncMode !== 0) {
        writer.uint32(32).int32(message.syncMode);
      }
      if (message.verifyReplicationOnly !== false) {
        writer.uint32(40).bool(message.verifyReplicationOnly);
      }
      if (message.mysqlSyncConfig !== undefined) {
        MySqlSyncConfig.encode(message.mysqlSyncConfig, writer.uint32(50).fork()).join();
      }
      if (message.migrationType !== 0) {
        writer.uint32(56).int32(message.migrationType);
      }
      if (message.syncParallelLevel !== 0) {
        writer.uint32(64).int32(message.syncParallelLevel);
      }
      return writer;
    },

    decode(input: BinaryReader | Uint8Array, length?: number): SqlInstancesVerifyExternalSyncSettingsRequest {
      const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
      let end = length === undefined ? reader.len : reader.pos + length;
      const message = createBaseSqlInstancesVerifyExternalSyncSettingsRequest();
      while (reader.pos < end) {
        const tag = reader.uint32();
        switch (tag >>> 3) {
          case 1:
            if (tag !== 10) {
              break;
            }

            message.instance = reader.string();
            continue;
          case 2:
            if (tag !== 18) {
              break;
            }

            message.project = reader.string();
            continue;
          case 3:
            if (tag !== 24) {
              break;
            }

            message.verifyConnectionOnly = reader.bool();
            continue;
          case 4:
            if (tag !== 32) {
              break;
            }

            message.syncMode = reader.int32() as any;
            continue;
          case 5:
            if (tag !== 40) {
              break;
            }

            message.verifyReplicationOnly = reader.bool();
            continue;
          case 6:
            if (tag !== 50) {
              break;
            }

            message.mysqlSyncConfig = MySqlSyncConfig.decode(reader, reader.uint32());
            continue;
          case 7:
            if (tag !== 56) {
              break;
            }

            message.migrationType = reader.int32() as any;
            continue;
          case 8:
            if (tag !== 64) {
              break;
            }

            message.syncParallelLevel = reader.int32() as any;
            continue;
        }
        if ((tag & 7) === 4 || tag === 0) {
          break;
        }
        reader.skip(tag & 7);
      }
      return message;
    },

    fromJSON(object: any): SqlInstancesVerifyExternalSyncSettingsRequest {
      return {
        instance: isSet(object.instance) ? globalThis.String(object.instance) : "",
        project: isSet(object.project) ? globalThis.String(object.project) : "",
        verifyConnectionOnly: isSet(object.verifyConnectionOnly)
          ? globalThis.Boolean(object.verifyConnectionOnly)
          : false,
        syncMode: isSet(object.syncMode)
          ? sqlInstancesVerifyExternalSyncSettingsRequest_ExternalSyncModeFromJSON(object.syncMode)
          : 0,
        verifyReplicationOnly: isSet(object.verifyReplicationOnly)
          ? globalThis.Boolean(object.verifyReplicationOnly)
          : false,
        mysqlSyncConfig: isSet(object.mysqlSyncConfig) ? MySqlSyncConfig.fromJSON(object.mysqlSyncConfig) : undefined,
        migrationType: isSet(object.migrationType)
          ? sqlInstancesVerifyExternalSyncSettingsRequest_MigrationTypeFromJSON(object.migrationType)
          : 0,
        syncParallelLevel: isSet(object.syncParallelLevel)
          ? externalSyncParallelLevelFromJSON(object.syncParallelLevel)
          : 0,
      };
    },

    toJSON(message: SqlInstancesVerifyExternalSyncSettingsRequest): unknown {
      const obj: any = {};
      if (message.instance !== "") {
        obj.instance = message.instance;
      }
      if (message.project !== "") {
        obj.project = message.project;
      }
      if (message.verifyConnectionOnly !== false) {
        obj.verifyConnectionOnly = message.verifyConnectionOnly;
      }
      if (message.syncMode !== 0) {
        obj.syncMode = sqlInstancesVerifyExternalSyncSettingsRequest_ExternalSyncModeToJSON(message.syncMode);
      }
      if (message.verifyReplicationOnly !== false) {
        obj.verifyReplicationOnly = message.verifyReplicationOnly;
      }
      if (message.mysqlSyncConfig !== undefined) {
        obj.mysqlSyncConfig = MySqlSyncConfig.toJSON(message.mysqlSyncConfig);
      }
      if (message.migrationType !== 0) {
        obj.migrationType = sqlInstancesVerifyExternalSyncSettingsRequest_MigrationTypeToJSON(message.migrationType);
      }
      if (message.syncParallelLevel !== 0) {
        obj.syncParallelLevel = externalSyncParallelLevelToJSON(message.syncParallelLevel);
      }
      return obj;
    },

    create(
      base?: DeepPartial<SqlInstancesVerifyExternalSyncSettingsRequest>,
    ): SqlInstancesVerifyExternalSyncSettingsRequest {
      return SqlInstancesVerifyExternalSyncSettingsRequest.fromPartial(base ?? {});
    },
    fromPartial(
      object: DeepPartial<SqlInstancesVerifyExternalSyncSettingsRequest>,
    ): SqlInstancesVerifyExternalSyncSettingsRequest {
      const message = createBaseSqlInstancesVerifyExternalSyncSettingsRequest();
      message.instance = object.instance ?? "";
      message.project = object.project ?? "";
      message.verifyConnectionOnly = object.verifyConnectionOnly ?? false;
      message.syncMode = object.syncMode ?? 0;
      message.verifyReplicationOnly = object.verifyReplicationOnly ?? false;
      message.mysqlSyncConfig = (object.mysqlSyncConfig !== undefined && object.mysqlSyncConfig !== null)
        ? MySqlSyncConfig.fromPartial(object.mysqlSyncConfig)
        : undefined;
      message.migrationType = object.migrationType ?? 0;
      message.syncParallelLevel = object.syncParallelLevel ?? 0;
      return message;
    },
  };

function createBaseSqlInstancesStartExternalSyncRequest(): SqlInstancesStartExternalSyncRequest {
  return {
    instance: "",
    project: "",
    syncMode: 0,
    skipVerification: false,
    mysqlSyncConfig: undefined,
    syncParallelLevel: 0,
    migrationType: 0,
  };
}

export const SqlInstancesStartExternalSyncRequest: MessageFns<SqlInstancesStartExternalSyncRequest> = {
  encode(message: SqlInstancesStartExternalSyncRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.instance !== "") {
      writer.uint32(10).string(message.instance);
    }
    if (message.project !== "") {
      writer.uint32(18).string(message.project);
    }
    if (message.syncMode !== 0) {
      writer.uint32(24).int32(message.syncMode);
    }
    if (message.skipVerification !== false) {
      writer.uint32(32).bool(message.skipVerification);
    }
    if (message.mysqlSyncConfig !== undefined) {
      MySqlSyncConfig.encode(message.mysqlSyncConfig, writer.uint32(50).fork()).join();
    }
    if (message.syncParallelLevel !== 0) {
      writer.uint32(56).int32(message.syncParallelLevel);
    }
    if (message.migrationType !== 0) {
      writer.uint32(64).int32(message.migrationType);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): SqlInstancesStartExternalSyncRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseSqlInstancesStartExternalSyncRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.instance = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.project = reader.string();
          continue;
        case 3:
          if (tag !== 24) {
            break;
          }

          message.syncMode = reader.int32() as any;
          continue;
        case 4:
          if (tag !== 32) {
            break;
          }

          message.skipVerification = reader.bool();
          continue;
        case 6:
          if (tag !== 50) {
            break;
          }

          message.mysqlSyncConfig = MySqlSyncConfig.decode(reader, reader.uint32());
          continue;
        case 7:
          if (tag !== 56) {
            break;
          }

          message.syncParallelLevel = reader.int32() as any;
          continue;
        case 8:
          if (tag !== 64) {
            break;
          }

          message.migrationType = reader.int32() as any;
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): SqlInstancesStartExternalSyncRequest {
    return {
      instance: isSet(object.instance) ? globalThis.String(object.instance) : "",
      project: isSet(object.project) ? globalThis.String(object.project) : "",
      syncMode: isSet(object.syncMode)
        ? sqlInstancesVerifyExternalSyncSettingsRequest_ExternalSyncModeFromJSON(object.syncMode)
        : 0,
      skipVerification: isSet(object.skipVerification) ? globalThis.Boolean(object.skipVerification) : false,
      mysqlSyncConfig: isSet(object.mysqlSyncConfig) ? MySqlSyncConfig.fromJSON(object.mysqlSyncConfig) : undefined,
      syncParallelLevel: isSet(object.syncParallelLevel)
        ? externalSyncParallelLevelFromJSON(object.syncParallelLevel)
        : 0,
      migrationType: isSet(object.migrationType)
        ? sqlInstancesVerifyExternalSyncSettingsRequest_MigrationTypeFromJSON(object.migrationType)
        : 0,
    };
  },

  toJSON(message: SqlInstancesStartExternalSyncRequest): unknown {
    const obj: any = {};
    if (message.instance !== "") {
      obj.instance = message.instance;
    }
    if (message.project !== "") {
      obj.project = message.project;
    }
    if (message.syncMode !== 0) {
      obj.syncMode = sqlInstancesVerifyExternalSyncSettingsRequest_ExternalSyncModeToJSON(message.syncMode);
    }
    if (message.skipVerification !== false) {
      obj.skipVerification = message.skipVerification;
    }
    if (message.mysqlSyncConfig !== undefined) {
      obj.mysqlSyncConfig = MySqlSyncConfig.toJSON(message.mysqlSyncConfig);
    }
    if (message.syncParallelLevel !== 0) {
      obj.syncParallelLevel = externalSyncParallelLevelToJSON(message.syncParallelLevel);
    }
    if (message.migrationType !== 0) {
      obj.migrationType = sqlInstancesVerifyExternalSyncSettingsRequest_MigrationTypeToJSON(message.migrationType);
    }
    return obj;
  },

  create(base?: DeepPartial<SqlInstancesStartExternalSyncRequest>): SqlInstancesStartExternalSyncRequest {
    return SqlInstancesStartExternalSyncRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<SqlInstancesStartExternalSyncRequest>): SqlInstancesStartExternalSyncRequest {
    const message = createBaseSqlInstancesStartExternalSyncRequest();
    message.instance = object.instance ?? "";
    message.project = object.project ?? "";
    message.syncMode = object.syncMode ?? 0;
    message.skipVerification = object.skipVerification ?? false;
    message.mysqlSyncConfig = (object.mysqlSyncConfig !== undefined && object.mysqlSyncConfig !== null)
      ? MySqlSyncConfig.fromPartial(object.mysqlSyncConfig)
      : undefined;
    message.syncParallelLevel = object.syncParallelLevel ?? 0;
    message.migrationType = object.migrationType ?? 0;
    return message;
  },
};

function createBaseSqlInstancesResetReplicaSizeRequest(): SqlInstancesResetReplicaSizeRequest {
  return { instance: "", project: "" };
}

export const SqlInstancesResetReplicaSizeRequest: MessageFns<SqlInstancesResetReplicaSizeRequest> = {
  encode(message: SqlInstancesResetReplicaSizeRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.instance !== "") {
      writer.uint32(10).string(message.instance);
    }
    if (message.project !== "") {
      writer.uint32(18).string(message.project);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): SqlInstancesResetReplicaSizeRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseSqlInstancesResetReplicaSizeRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.instance = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.project = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): SqlInstancesResetReplicaSizeRequest {
    return {
      instance: isSet(object.instance) ? globalThis.String(object.instance) : "",
      project: isSet(object.project) ? globalThis.String(object.project) : "",
    };
  },

  toJSON(message: SqlInstancesResetReplicaSizeRequest): unknown {
    const obj: any = {};
    if (message.instance !== "") {
      obj.instance = message.instance;
    }
    if (message.project !== "") {
      obj.project = message.project;
    }
    return obj;
  },

  create(base?: DeepPartial<SqlInstancesResetReplicaSizeRequest>): SqlInstancesResetReplicaSizeRequest {
    return SqlInstancesResetReplicaSizeRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<SqlInstancesResetReplicaSizeRequest>): SqlInstancesResetReplicaSizeRequest {
    const message = createBaseSqlInstancesResetReplicaSizeRequest();
    message.instance = object.instance ?? "";
    message.project = object.project ?? "";
    return message;
  },
};

function createBaseSqlInstancesCreateEphemeralCertRequest(): SqlInstancesCreateEphemeralCertRequest {
  return { instance: "", project: "", body: undefined };
}

export const SqlInstancesCreateEphemeralCertRequest: MessageFns<SqlInstancesCreateEphemeralCertRequest> = {
  encode(message: SqlInstancesCreateEphemeralCertRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.instance !== "") {
      writer.uint32(10).string(message.instance);
    }
    if (message.project !== "") {
      writer.uint32(18).string(message.project);
    }
    if (message.body !== undefined) {
      SslCertsCreateEphemeralRequest.encode(message.body, writer.uint32(802).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): SqlInstancesCreateEphemeralCertRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseSqlInstancesCreateEphemeralCertRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.instance = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.project = reader.string();
          continue;
        case 100:
          if (tag !== 802) {
            break;
          }

          message.body = SslCertsCreateEphemeralRequest.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): SqlInstancesCreateEphemeralCertRequest {
    return {
      instance: isSet(object.instance) ? globalThis.String(object.instance) : "",
      project: isSet(object.project) ? globalThis.String(object.project) : "",
      body: isSet(object.body) ? SslCertsCreateEphemeralRequest.fromJSON(object.body) : undefined,
    };
  },

  toJSON(message: SqlInstancesCreateEphemeralCertRequest): unknown {
    const obj: any = {};
    if (message.instance !== "") {
      obj.instance = message.instance;
    }
    if (message.project !== "") {
      obj.project = message.project;
    }
    if (message.body !== undefined) {
      obj.body = SslCertsCreateEphemeralRequest.toJSON(message.body);
    }
    return obj;
  },

  create(base?: DeepPartial<SqlInstancesCreateEphemeralCertRequest>): SqlInstancesCreateEphemeralCertRequest {
    return SqlInstancesCreateEphemeralCertRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<SqlInstancesCreateEphemeralCertRequest>): SqlInstancesCreateEphemeralCertRequest {
    const message = createBaseSqlInstancesCreateEphemeralCertRequest();
    message.instance = object.instance ?? "";
    message.project = object.project ?? "";
    message.body = (object.body !== undefined && object.body !== null)
      ? SslCertsCreateEphemeralRequest.fromPartial(object.body)
      : undefined;
    return message;
  },
};

function createBaseInstancesCloneRequest(): InstancesCloneRequest {
  return { cloneContext: undefined };
}

export const InstancesCloneRequest: MessageFns<InstancesCloneRequest> = {
  encode(message: InstancesCloneRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.cloneContext !== undefined) {
      CloneContext.encode(message.cloneContext, writer.uint32(10).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): InstancesCloneRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseInstancesCloneRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.cloneContext = CloneContext.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): InstancesCloneRequest {
    return { cloneContext: isSet(object.cloneContext) ? CloneContext.fromJSON(object.cloneContext) : undefined };
  },

  toJSON(message: InstancesCloneRequest): unknown {
    const obj: any = {};
    if (message.cloneContext !== undefined) {
      obj.cloneContext = CloneContext.toJSON(message.cloneContext);
    }
    return obj;
  },

  create(base?: DeepPartial<InstancesCloneRequest>): InstancesCloneRequest {
    return InstancesCloneRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<InstancesCloneRequest>): InstancesCloneRequest {
    const message = createBaseInstancesCloneRequest();
    message.cloneContext = (object.cloneContext !== undefined && object.cloneContext !== null)
      ? CloneContext.fromPartial(object.cloneContext)
      : undefined;
    return message;
  },
};

function createBaseInstancesDemoteMasterRequest(): InstancesDemoteMasterRequest {
  return { demoteMasterContext: undefined };
}

export const InstancesDemoteMasterRequest: MessageFns<InstancesDemoteMasterRequest> = {
  encode(message: InstancesDemoteMasterRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.demoteMasterContext !== undefined) {
      DemoteMasterContext.encode(message.demoteMasterContext, writer.uint32(10).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): InstancesDemoteMasterRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseInstancesDemoteMasterRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.demoteMasterContext = DemoteMasterContext.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): InstancesDemoteMasterRequest {
    return {
      demoteMasterContext: isSet(object.demoteMasterContext)
        ? DemoteMasterContext.fromJSON(object.demoteMasterContext)
        : undefined,
    };
  },

  toJSON(message: InstancesDemoteMasterRequest): unknown {
    const obj: any = {};
    if (message.demoteMasterContext !== undefined) {
      obj.demoteMasterContext = DemoteMasterContext.toJSON(message.demoteMasterContext);
    }
    return obj;
  },

  create(base?: DeepPartial<InstancesDemoteMasterRequest>): InstancesDemoteMasterRequest {
    return InstancesDemoteMasterRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<InstancesDemoteMasterRequest>): InstancesDemoteMasterRequest {
    const message = createBaseInstancesDemoteMasterRequest();
    message.demoteMasterContext = (object.demoteMasterContext !== undefined && object.demoteMasterContext !== null)
      ? DemoteMasterContext.fromPartial(object.demoteMasterContext)
      : undefined;
    return message;
  },
};

function createBaseInstancesDemoteRequest(): InstancesDemoteRequest {
  return { demoteContext: undefined };
}

export const InstancesDemoteRequest: MessageFns<InstancesDemoteRequest> = {
  encode(message: InstancesDemoteRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.demoteContext !== undefined) {
      DemoteContext.encode(message.demoteContext, writer.uint32(10).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): InstancesDemoteRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseInstancesDemoteRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.demoteContext = DemoteContext.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): InstancesDemoteRequest {
    return { demoteContext: isSet(object.demoteContext) ? DemoteContext.fromJSON(object.demoteContext) : undefined };
  },

  toJSON(message: InstancesDemoteRequest): unknown {
    const obj: any = {};
    if (message.demoteContext !== undefined) {
      obj.demoteContext = DemoteContext.toJSON(message.demoteContext);
    }
    return obj;
  },

  create(base?: DeepPartial<InstancesDemoteRequest>): InstancesDemoteRequest {
    return InstancesDemoteRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<InstancesDemoteRequest>): InstancesDemoteRequest {
    const message = createBaseInstancesDemoteRequest();
    message.demoteContext = (object.demoteContext !== undefined && object.demoteContext !== null)
      ? DemoteContext.fromPartial(object.demoteContext)
      : undefined;
    return message;
  },
};

function createBaseInstancesExportRequest(): InstancesExportRequest {
  return { exportContext: undefined };
}

export const InstancesExportRequest: MessageFns<InstancesExportRequest> = {
  encode(message: InstancesExportRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.exportContext !== undefined) {
      ExportContext.encode(message.exportContext, writer.uint32(10).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): InstancesExportRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseInstancesExportRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.exportContext = ExportContext.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): InstancesExportRequest {
    return { exportContext: isSet(object.exportContext) ? ExportContext.fromJSON(object.exportContext) : undefined };
  },

  toJSON(message: InstancesExportRequest): unknown {
    const obj: any = {};
    if (message.exportContext !== undefined) {
      obj.exportContext = ExportContext.toJSON(message.exportContext);
    }
    return obj;
  },

  create(base?: DeepPartial<InstancesExportRequest>): InstancesExportRequest {
    return InstancesExportRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<InstancesExportRequest>): InstancesExportRequest {
    const message = createBaseInstancesExportRequest();
    message.exportContext = (object.exportContext !== undefined && object.exportContext !== null)
      ? ExportContext.fromPartial(object.exportContext)
      : undefined;
    return message;
  },
};

function createBaseInstancesFailoverRequest(): InstancesFailoverRequest {
  return { failoverContext: undefined };
}

export const InstancesFailoverRequest: MessageFns<InstancesFailoverRequest> = {
  encode(message: InstancesFailoverRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.failoverContext !== undefined) {
      FailoverContext.encode(message.failoverContext, writer.uint32(10).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): InstancesFailoverRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseInstancesFailoverRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.failoverContext = FailoverContext.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): InstancesFailoverRequest {
    return {
      failoverContext: isSet(object.failoverContext) ? FailoverContext.fromJSON(object.failoverContext) : undefined,
    };
  },

  toJSON(message: InstancesFailoverRequest): unknown {
    const obj: any = {};
    if (message.failoverContext !== undefined) {
      obj.failoverContext = FailoverContext.toJSON(message.failoverContext);
    }
    return obj;
  },

  create(base?: DeepPartial<InstancesFailoverRequest>): InstancesFailoverRequest {
    return InstancesFailoverRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<InstancesFailoverRequest>): InstancesFailoverRequest {
    const message = createBaseInstancesFailoverRequest();
    message.failoverContext = (object.failoverContext !== undefined && object.failoverContext !== null)
      ? FailoverContext.fromPartial(object.failoverContext)
      : undefined;
    return message;
  },
};

function createBaseSslCertsCreateEphemeralRequest(): SslCertsCreateEphemeralRequest {
  return { publicKey: "", accessToken: "" };
}

export const SslCertsCreateEphemeralRequest: MessageFns<SslCertsCreateEphemeralRequest> = {
  encode(message: SslCertsCreateEphemeralRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.publicKey !== "") {
      writer.uint32(10).string(message.publicKey);
    }
    if (message.accessToken !== "") {
      writer.uint32(18).string(message.accessToken);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): SslCertsCreateEphemeralRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseSslCertsCreateEphemeralRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.publicKey = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.accessToken = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): SslCertsCreateEphemeralRequest {
    return {
      publicKey: isSet(object.publicKey) ? globalThis.String(object.publicKey) : "",
      accessToken: isSet(object.accessToken) ? globalThis.String(object.accessToken) : "",
    };
  },

  toJSON(message: SslCertsCreateEphemeralRequest): unknown {
    const obj: any = {};
    if (message.publicKey !== "") {
      obj.publicKey = message.publicKey;
    }
    if (message.accessToken !== "") {
      obj.accessToken = message.accessToken;
    }
    return obj;
  },

  create(base?: DeepPartial<SslCertsCreateEphemeralRequest>): SslCertsCreateEphemeralRequest {
    return SslCertsCreateEphemeralRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<SslCertsCreateEphemeralRequest>): SslCertsCreateEphemeralRequest {
    const message = createBaseSslCertsCreateEphemeralRequest();
    message.publicKey = object.publicKey ?? "";
    message.accessToken = object.accessToken ?? "";
    return message;
  },
};

function createBaseInstancesImportRequest(): InstancesImportRequest {
  return { importContext: undefined };
}

export const InstancesImportRequest: MessageFns<InstancesImportRequest> = {
  encode(message: InstancesImportRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.importContext !== undefined) {
      ImportContext.encode(message.importContext, writer.uint32(10).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): InstancesImportRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseInstancesImportRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.importContext = ImportContext.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): InstancesImportRequest {
    return { importContext: isSet(object.importContext) ? ImportContext.fromJSON(object.importContext) : undefined };
  },

  toJSON(message: InstancesImportRequest): unknown {
    const obj: any = {};
    if (message.importContext !== undefined) {
      obj.importContext = ImportContext.toJSON(message.importContext);
    }
    return obj;
  },

  create(base?: DeepPartial<InstancesImportRequest>): InstancesImportRequest {
    return InstancesImportRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<InstancesImportRequest>): InstancesImportRequest {
    const message = createBaseInstancesImportRequest();
    message.importContext = (object.importContext !== undefined && object.importContext !== null)
      ? ImportContext.fromPartial(object.importContext)
      : undefined;
    return message;
  },
};

function createBaseInstancesListResponse(): InstancesListResponse {
  return { kind: "", warnings: [], items: [], nextPageToken: "" };
}

export const InstancesListResponse: MessageFns<InstancesListResponse> = {
  encode(message: InstancesListResponse, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.kind !== "") {
      writer.uint32(10).string(message.kind);
    }
    for (const v of message.warnings) {
      ApiWarning.encode(v!, writer.uint32(18).fork()).join();
    }
    for (const v of message.items) {
      DatabaseInstance.encode(v!, writer.uint32(26).fork()).join();
    }
    if (message.nextPageToken !== "") {
      writer.uint32(34).string(message.nextPageToken);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): InstancesListResponse {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseInstancesListResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.kind = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.warnings.push(ApiWarning.decode(reader, reader.uint32()));
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.items.push(DatabaseInstance.decode(reader, reader.uint32()));
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.nextPageToken = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): InstancesListResponse {
    return {
      kind: isSet(object.kind) ? globalThis.String(object.kind) : "",
      warnings: globalThis.Array.isArray(object?.warnings)
        ? object.warnings.map((e: any) => ApiWarning.fromJSON(e))
        : [],
      items: globalThis.Array.isArray(object?.items) ? object.items.map((e: any) => DatabaseInstance.fromJSON(e)) : [],
      nextPageToken: isSet(object.nextPageToken) ? globalThis.String(object.nextPageToken) : "",
    };
  },

  toJSON(message: InstancesListResponse): unknown {
    const obj: any = {};
    if (message.kind !== "") {
      obj.kind = message.kind;
    }
    if (message.warnings?.length) {
      obj.warnings = message.warnings.map((e) => ApiWarning.toJSON(e));
    }
    if (message.items?.length) {
      obj.items = message.items.map((e) => DatabaseInstance.toJSON(e));
    }
    if (message.nextPageToken !== "") {
      obj.nextPageToken = message.nextPageToken;
    }
    return obj;
  },

  create(base?: DeepPartial<InstancesListResponse>): InstancesListResponse {
    return InstancesListResponse.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<InstancesListResponse>): InstancesListResponse {
    const message = createBaseInstancesListResponse();
    message.kind = object.kind ?? "";
    message.warnings = object.warnings?.map((e) => ApiWarning.fromPartial(e)) || [];
    message.items = object.items?.map((e) => DatabaseInstance.fromPartial(e)) || [];
    message.nextPageToken = object.nextPageToken ?? "";
    return message;
  },
};

function createBaseInstancesListServerCasResponse(): InstancesListServerCasResponse {
  return { certs: [], activeVersion: "", kind: "" };
}

export const InstancesListServerCasResponse: MessageFns<InstancesListServerCasResponse> = {
  encode(message: InstancesListServerCasResponse, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.certs) {
      SslCert.encode(v!, writer.uint32(10).fork()).join();
    }
    if (message.activeVersion !== "") {
      writer.uint32(18).string(message.activeVersion);
    }
    if (message.kind !== "") {
      writer.uint32(26).string(message.kind);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): InstancesListServerCasResponse {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseInstancesListServerCasResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.certs.push(SslCert.decode(reader, reader.uint32()));
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.activeVersion = reader.string();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.kind = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): InstancesListServerCasResponse {
    return {
      certs: globalThis.Array.isArray(object?.certs) ? object.certs.map((e: any) => SslCert.fromJSON(e)) : [],
      activeVersion: isSet(object.activeVersion) ? globalThis.String(object.activeVersion) : "",
      kind: isSet(object.kind) ? globalThis.String(object.kind) : "",
    };
  },

  toJSON(message: InstancesListServerCasResponse): unknown {
    const obj: any = {};
    if (message.certs?.length) {
      obj.certs = message.certs.map((e) => SslCert.toJSON(e));
    }
    if (message.activeVersion !== "") {
      obj.activeVersion = message.activeVersion;
    }
    if (message.kind !== "") {
      obj.kind = message.kind;
    }
    return obj;
  },

  create(base?: DeepPartial<InstancesListServerCasResponse>): InstancesListServerCasResponse {
    return InstancesListServerCasResponse.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<InstancesListServerCasResponse>): InstancesListServerCasResponse {
    const message = createBaseInstancesListServerCasResponse();
    message.certs = object.certs?.map((e) => SslCert.fromPartial(e)) || [];
    message.activeVersion = object.activeVersion ?? "";
    message.kind = object.kind ?? "";
    return message;
  },
};

function createBaseInstancesRestoreBackupRequest(): InstancesRestoreBackupRequest {
  return { restoreBackupContext: undefined };
}

export const InstancesRestoreBackupRequest: MessageFns<InstancesRestoreBackupRequest> = {
  encode(message: InstancesRestoreBackupRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.restoreBackupContext !== undefined) {
      RestoreBackupContext.encode(message.restoreBackupContext, writer.uint32(10).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): InstancesRestoreBackupRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseInstancesRestoreBackupRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.restoreBackupContext = RestoreBackupContext.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): InstancesRestoreBackupRequest {
    return {
      restoreBackupContext: isSet(object.restoreBackupContext)
        ? RestoreBackupContext.fromJSON(object.restoreBackupContext)
        : undefined,
    };
  },

  toJSON(message: InstancesRestoreBackupRequest): unknown {
    const obj: any = {};
    if (message.restoreBackupContext !== undefined) {
      obj.restoreBackupContext = RestoreBackupContext.toJSON(message.restoreBackupContext);
    }
    return obj;
  },

  create(base?: DeepPartial<InstancesRestoreBackupRequest>): InstancesRestoreBackupRequest {
    return InstancesRestoreBackupRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<InstancesRestoreBackupRequest>): InstancesRestoreBackupRequest {
    const message = createBaseInstancesRestoreBackupRequest();
    message.restoreBackupContext = (object.restoreBackupContext !== undefined && object.restoreBackupContext !== null)
      ? RestoreBackupContext.fromPartial(object.restoreBackupContext)
      : undefined;
    return message;
  },
};

function createBaseInstancesRotateServerCaRequest(): InstancesRotateServerCaRequest {
  return { rotateServerCaContext: undefined };
}

export const InstancesRotateServerCaRequest: MessageFns<InstancesRotateServerCaRequest> = {
  encode(message: InstancesRotateServerCaRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.rotateServerCaContext !== undefined) {
      RotateServerCaContext.encode(message.rotateServerCaContext, writer.uint32(10).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): InstancesRotateServerCaRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseInstancesRotateServerCaRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.rotateServerCaContext = RotateServerCaContext.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): InstancesRotateServerCaRequest {
    return {
      rotateServerCaContext: isSet(object.rotateServerCaContext)
        ? RotateServerCaContext.fromJSON(object.rotateServerCaContext)
        : undefined,
    };
  },

  toJSON(message: InstancesRotateServerCaRequest): unknown {
    const obj: any = {};
    if (message.rotateServerCaContext !== undefined) {
      obj.rotateServerCaContext = RotateServerCaContext.toJSON(message.rotateServerCaContext);
    }
    return obj;
  },

  create(base?: DeepPartial<InstancesRotateServerCaRequest>): InstancesRotateServerCaRequest {
    return InstancesRotateServerCaRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<InstancesRotateServerCaRequest>): InstancesRotateServerCaRequest {
    const message = createBaseInstancesRotateServerCaRequest();
    message.rotateServerCaContext =
      (object.rotateServerCaContext !== undefined && object.rotateServerCaContext !== null)
        ? RotateServerCaContext.fromPartial(object.rotateServerCaContext)
        : undefined;
    return message;
  },
};

function createBaseInstancesTruncateLogRequest(): InstancesTruncateLogRequest {
  return { truncateLogContext: undefined };
}

export const InstancesTruncateLogRequest: MessageFns<InstancesTruncateLogRequest> = {
  encode(message: InstancesTruncateLogRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.truncateLogContext !== undefined) {
      TruncateLogContext.encode(message.truncateLogContext, writer.uint32(10).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): InstancesTruncateLogRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseInstancesTruncateLogRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.truncateLogContext = TruncateLogContext.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): InstancesTruncateLogRequest {
    return {
      truncateLogContext: isSet(object.truncateLogContext)
        ? TruncateLogContext.fromJSON(object.truncateLogContext)
        : undefined,
    };
  },

  toJSON(message: InstancesTruncateLogRequest): unknown {
    const obj: any = {};
    if (message.truncateLogContext !== undefined) {
      obj.truncateLogContext = TruncateLogContext.toJSON(message.truncateLogContext);
    }
    return obj;
  },

  create(base?: DeepPartial<InstancesTruncateLogRequest>): InstancesTruncateLogRequest {
    return InstancesTruncateLogRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<InstancesTruncateLogRequest>): InstancesTruncateLogRequest {
    const message = createBaseInstancesTruncateLogRequest();
    message.truncateLogContext = (object.truncateLogContext !== undefined && object.truncateLogContext !== null)
      ? TruncateLogContext.fromPartial(object.truncateLogContext)
      : undefined;
    return message;
  },
};

function createBaseInstancesAcquireSsrsLeaseRequest(): InstancesAcquireSsrsLeaseRequest {
  return { acquireSsrsLeaseContext: undefined };
}

export const InstancesAcquireSsrsLeaseRequest: MessageFns<InstancesAcquireSsrsLeaseRequest> = {
  encode(message: InstancesAcquireSsrsLeaseRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.acquireSsrsLeaseContext !== undefined) {
      AcquireSsrsLeaseContext.encode(message.acquireSsrsLeaseContext, writer.uint32(10).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): InstancesAcquireSsrsLeaseRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseInstancesAcquireSsrsLeaseRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.acquireSsrsLeaseContext = AcquireSsrsLeaseContext.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): InstancesAcquireSsrsLeaseRequest {
    return {
      acquireSsrsLeaseContext: isSet(object.acquireSsrsLeaseContext)
        ? AcquireSsrsLeaseContext.fromJSON(object.acquireSsrsLeaseContext)
        : undefined,
    };
  },

  toJSON(message: InstancesAcquireSsrsLeaseRequest): unknown {
    const obj: any = {};
    if (message.acquireSsrsLeaseContext !== undefined) {
      obj.acquireSsrsLeaseContext = AcquireSsrsLeaseContext.toJSON(message.acquireSsrsLeaseContext);
    }
    return obj;
  },

  create(base?: DeepPartial<InstancesAcquireSsrsLeaseRequest>): InstancesAcquireSsrsLeaseRequest {
    return InstancesAcquireSsrsLeaseRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<InstancesAcquireSsrsLeaseRequest>): InstancesAcquireSsrsLeaseRequest {
    const message = createBaseInstancesAcquireSsrsLeaseRequest();
    message.acquireSsrsLeaseContext =
      (object.acquireSsrsLeaseContext !== undefined && object.acquireSsrsLeaseContext !== null)
        ? AcquireSsrsLeaseContext.fromPartial(object.acquireSsrsLeaseContext)
        : undefined;
    return message;
  },
};

function createBaseSqlInstancesVerifyExternalSyncSettingsResponse(): SqlInstancesVerifyExternalSyncSettingsResponse {
  return { kind: "", errors: [], warnings: [] };
}

export const SqlInstancesVerifyExternalSyncSettingsResponse: MessageFns<
  SqlInstancesVerifyExternalSyncSettingsResponse
> = {
  encode(
    message: SqlInstancesVerifyExternalSyncSettingsResponse,
    writer: BinaryWriter = new BinaryWriter(),
  ): BinaryWriter {
    if (message.kind !== "") {
      writer.uint32(10).string(message.kind);
    }
    for (const v of message.errors) {
      SqlExternalSyncSettingError.encode(v!, writer.uint32(18).fork()).join();
    }
    for (const v of message.warnings) {
      SqlExternalSyncSettingError.encode(v!, writer.uint32(26).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): SqlInstancesVerifyExternalSyncSettingsResponse {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseSqlInstancesVerifyExternalSyncSettingsResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.kind = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.errors.push(SqlExternalSyncSettingError.decode(reader, reader.uint32()));
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.warnings.push(SqlExternalSyncSettingError.decode(reader, reader.uint32()));
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): SqlInstancesVerifyExternalSyncSettingsResponse {
    return {
      kind: isSet(object.kind) ? globalThis.String(object.kind) : "",
      errors: globalThis.Array.isArray(object?.errors)
        ? object.errors.map((e: any) => SqlExternalSyncSettingError.fromJSON(e))
        : [],
      warnings: globalThis.Array.isArray(object?.warnings)
        ? object.warnings.map((e: any) => SqlExternalSyncSettingError.fromJSON(e))
        : [],
    };
  },

  toJSON(message: SqlInstancesVerifyExternalSyncSettingsResponse): unknown {
    const obj: any = {};
    if (message.kind !== "") {
      obj.kind = message.kind;
    }
    if (message.errors?.length) {
      obj.errors = message.errors.map((e) => SqlExternalSyncSettingError.toJSON(e));
    }
    if (message.warnings?.length) {
      obj.warnings = message.warnings.map((e) => SqlExternalSyncSettingError.toJSON(e));
    }
    return obj;
  },

  create(
    base?: DeepPartial<SqlInstancesVerifyExternalSyncSettingsResponse>,
  ): SqlInstancesVerifyExternalSyncSettingsResponse {
    return SqlInstancesVerifyExternalSyncSettingsResponse.fromPartial(base ?? {});
  },
  fromPartial(
    object: DeepPartial<SqlInstancesVerifyExternalSyncSettingsResponse>,
  ): SqlInstancesVerifyExternalSyncSettingsResponse {
    const message = createBaseSqlInstancesVerifyExternalSyncSettingsResponse();
    message.kind = object.kind ?? "";
    message.errors = object.errors?.map((e) => SqlExternalSyncSettingError.fromPartial(e)) || [];
    message.warnings = object.warnings?.map((e) => SqlExternalSyncSettingError.fromPartial(e)) || [];
    return message;
  },
};

function createBaseSqlInstancesGetDiskShrinkConfigResponse(): SqlInstancesGetDiskShrinkConfigResponse {
  return { kind: "", minimalTargetSizeGb: Long.ZERO, message: "" };
}

export const SqlInstancesGetDiskShrinkConfigResponse: MessageFns<SqlInstancesGetDiskShrinkConfigResponse> = {
  encode(message: SqlInstancesGetDiskShrinkConfigResponse, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.kind !== "") {
      writer.uint32(10).string(message.kind);
    }
    if (!message.minimalTargetSizeGb.equals(Long.ZERO)) {
      writer.uint32(16).int64(message.minimalTargetSizeGb.toString());
    }
    if (message.message !== "") {
      writer.uint32(26).string(message.message);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): SqlInstancesGetDiskShrinkConfigResponse {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseSqlInstancesGetDiskShrinkConfigResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.kind = reader.string();
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.minimalTargetSizeGb = Long.fromString(reader.int64().toString());
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.message = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): SqlInstancesGetDiskShrinkConfigResponse {
    return {
      kind: isSet(object.kind) ? globalThis.String(object.kind) : "",
      minimalTargetSizeGb: isSet(object.minimalTargetSizeGb) ? Long.fromValue(object.minimalTargetSizeGb) : Long.ZERO,
      message: isSet(object.message) ? globalThis.String(object.message) : "",
    };
  },

  toJSON(message: SqlInstancesGetDiskShrinkConfigResponse): unknown {
    const obj: any = {};
    if (message.kind !== "") {
      obj.kind = message.kind;
    }
    if (!message.minimalTargetSizeGb.equals(Long.ZERO)) {
      obj.minimalTargetSizeGb = (message.minimalTargetSizeGb || Long.ZERO).toString();
    }
    if (message.message !== "") {
      obj.message = message.message;
    }
    return obj;
  },

  create(base?: DeepPartial<SqlInstancesGetDiskShrinkConfigResponse>): SqlInstancesGetDiskShrinkConfigResponse {
    return SqlInstancesGetDiskShrinkConfigResponse.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<SqlInstancesGetDiskShrinkConfigResponse>): SqlInstancesGetDiskShrinkConfigResponse {
    const message = createBaseSqlInstancesGetDiskShrinkConfigResponse();
    message.kind = object.kind ?? "";
    message.minimalTargetSizeGb = (object.minimalTargetSizeGb !== undefined && object.minimalTargetSizeGb !== null)
      ? Long.fromValue(object.minimalTargetSizeGb)
      : Long.ZERO;
    message.message = object.message ?? "";
    return message;
  },
};

function createBaseSqlInstancesGetLatestRecoveryTimeRequest(): SqlInstancesGetLatestRecoveryTimeRequest {
  return { instance: "", project: "" };
}

export const SqlInstancesGetLatestRecoveryTimeRequest: MessageFns<SqlInstancesGetLatestRecoveryTimeRequest> = {
  encode(message: SqlInstancesGetLatestRecoveryTimeRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.instance !== "") {
      writer.uint32(10).string(message.instance);
    }
    if (message.project !== "") {
      writer.uint32(18).string(message.project);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): SqlInstancesGetLatestRecoveryTimeRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseSqlInstancesGetLatestRecoveryTimeRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.instance = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.project = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): SqlInstancesGetLatestRecoveryTimeRequest {
    return {
      instance: isSet(object.instance) ? globalThis.String(object.instance) : "",
      project: isSet(object.project) ? globalThis.String(object.project) : "",
    };
  },

  toJSON(message: SqlInstancesGetLatestRecoveryTimeRequest): unknown {
    const obj: any = {};
    if (message.instance !== "") {
      obj.instance = message.instance;
    }
    if (message.project !== "") {
      obj.project = message.project;
    }
    return obj;
  },

  create(base?: DeepPartial<SqlInstancesGetLatestRecoveryTimeRequest>): SqlInstancesGetLatestRecoveryTimeRequest {
    return SqlInstancesGetLatestRecoveryTimeRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<SqlInstancesGetLatestRecoveryTimeRequest>): SqlInstancesGetLatestRecoveryTimeRequest {
    const message = createBaseSqlInstancesGetLatestRecoveryTimeRequest();
    message.instance = object.instance ?? "";
    message.project = object.project ?? "";
    return message;
  },
};

function createBaseSqlInstancesGetLatestRecoveryTimeResponse(): SqlInstancesGetLatestRecoveryTimeResponse {
  return { kind: "", latestRecoveryTime: undefined };
}

export const SqlInstancesGetLatestRecoveryTimeResponse: MessageFns<SqlInstancesGetLatestRecoveryTimeResponse> = {
  encode(message: SqlInstancesGetLatestRecoveryTimeResponse, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.kind !== "") {
      writer.uint32(10).string(message.kind);
    }
    if (message.latestRecoveryTime !== undefined) {
      Timestamp.encode(toTimestamp(message.latestRecoveryTime), writer.uint32(18).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): SqlInstancesGetLatestRecoveryTimeResponse {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseSqlInstancesGetLatestRecoveryTimeResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.kind = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.latestRecoveryTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): SqlInstancesGetLatestRecoveryTimeResponse {
    return {
      kind: isSet(object.kind) ? globalThis.String(object.kind) : "",
      latestRecoveryTime: isSet(object.latestRecoveryTime) ? fromJsonTimestamp(object.latestRecoveryTime) : undefined,
    };
  },

  toJSON(message: SqlInstancesGetLatestRecoveryTimeResponse): unknown {
    const obj: any = {};
    if (message.kind !== "") {
      obj.kind = message.kind;
    }
    if (message.latestRecoveryTime !== undefined) {
      obj.latestRecoveryTime = message.latestRecoveryTime.toISOString();
    }
    return obj;
  },

  create(base?: DeepPartial<SqlInstancesGetLatestRecoveryTimeResponse>): SqlInstancesGetLatestRecoveryTimeResponse {
    return SqlInstancesGetLatestRecoveryTimeResponse.fromPartial(base ?? {});
  },
  fromPartial(
    object: DeepPartial<SqlInstancesGetLatestRecoveryTimeResponse>,
  ): SqlInstancesGetLatestRecoveryTimeResponse {
    const message = createBaseSqlInstancesGetLatestRecoveryTimeResponse();
    message.kind = object.kind ?? "";
    message.latestRecoveryTime = object.latestRecoveryTime ?? undefined;
    return message;
  },
};

function createBaseCloneContext(): CloneContext {
  return {
    kind: "",
    pitrTimestampMs: Long.ZERO,
    destinationInstanceName: "",
    binLogCoordinates: undefined,
    pointInTime: undefined,
    allocatedIpRange: "",
    databaseNames: [],
    preferredZone: undefined,
  };
}

export const CloneContext: MessageFns<CloneContext> = {
  encode(message: CloneContext, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.kind !== "") {
      writer.uint32(10).string(message.kind);
    }
    if (!message.pitrTimestampMs.equals(Long.ZERO)) {
      writer.uint32(16).int64(message.pitrTimestampMs.toString());
    }
    if (message.destinationInstanceName !== "") {
      writer.uint32(26).string(message.destinationInstanceName);
    }
    if (message.binLogCoordinates !== undefined) {
      BinLogCoordinates.encode(message.binLogCoordinates, writer.uint32(34).fork()).join();
    }
    if (message.pointInTime !== undefined) {
      Timestamp.encode(toTimestamp(message.pointInTime), writer.uint32(42).fork()).join();
    }
    if (message.allocatedIpRange !== "") {
      writer.uint32(50).string(message.allocatedIpRange);
    }
    for (const v of message.databaseNames) {
      writer.uint32(74).string(v!);
    }
    if (message.preferredZone !== undefined) {
      writer.uint32(82).string(message.preferredZone);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): CloneContext {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseCloneContext();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.kind = reader.string();
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.pitrTimestampMs = Long.fromString(reader.int64().toString());
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.destinationInstanceName = reader.string();
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.binLogCoordinates = BinLogCoordinates.decode(reader, reader.uint32());
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.pointInTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        case 6:
          if (tag !== 50) {
            break;
          }

          message.allocatedIpRange = reader.string();
          continue;
        case 9:
          if (tag !== 74) {
            break;
          }

          message.databaseNames.push(reader.string());
          continue;
        case 10:
          if (tag !== 82) {
            break;
          }

          message.preferredZone = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): CloneContext {
    return {
      kind: isSet(object.kind) ? globalThis.String(object.kind) : "",
      pitrTimestampMs: isSet(object.pitrTimestampMs) ? Long.fromValue(object.pitrTimestampMs) : Long.ZERO,
      destinationInstanceName: isSet(object.destinationInstanceName)
        ? globalThis.String(object.destinationInstanceName)
        : "",
      binLogCoordinates: isSet(object.binLogCoordinates)
        ? BinLogCoordinates.fromJSON(object.binLogCoordinates)
        : undefined,
      pointInTime: isSet(object.pointInTime) ? fromJsonTimestamp(object.pointInTime) : undefined,
      allocatedIpRange: isSet(object.allocatedIpRange) ? globalThis.String(object.allocatedIpRange) : "",
      databaseNames: globalThis.Array.isArray(object?.databaseNames)
        ? object.databaseNames.map((e: any) => globalThis.String(e))
        : [],
      preferredZone: isSet(object.preferredZone) ? globalThis.String(object.preferredZone) : undefined,
    };
  },

  toJSON(message: CloneContext): unknown {
    const obj: any = {};
    if (message.kind !== "") {
      obj.kind = message.kind;
    }
    if (!message.pitrTimestampMs.equals(Long.ZERO)) {
      obj.pitrTimestampMs = (message.pitrTimestampMs || Long.ZERO).toString();
    }
    if (message.destinationInstanceName !== "") {
      obj.destinationInstanceName = message.destinationInstanceName;
    }
    if (message.binLogCoordinates !== undefined) {
      obj.binLogCoordinates = BinLogCoordinates.toJSON(message.binLogCoordinates);
    }
    if (message.pointInTime !== undefined) {
      obj.pointInTime = message.pointInTime.toISOString();
    }
    if (message.allocatedIpRange !== "") {
      obj.allocatedIpRange = message.allocatedIpRange;
    }
    if (message.databaseNames?.length) {
      obj.databaseNames = message.databaseNames;
    }
    if (message.preferredZone !== undefined) {
      obj.preferredZone = message.preferredZone;
    }
    return obj;
  },

  create(base?: DeepPartial<CloneContext>): CloneContext {
    return CloneContext.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<CloneContext>): CloneContext {
    const message = createBaseCloneContext();
    message.kind = object.kind ?? "";
    message.pitrTimestampMs = (object.pitrTimestampMs !== undefined && object.pitrTimestampMs !== null)
      ? Long.fromValue(object.pitrTimestampMs)
      : Long.ZERO;
    message.destinationInstanceName = object.destinationInstanceName ?? "";
    message.binLogCoordinates = (object.binLogCoordinates !== undefined && object.binLogCoordinates !== null)
      ? BinLogCoordinates.fromPartial(object.binLogCoordinates)
      : undefined;
    message.pointInTime = object.pointInTime ?? undefined;
    message.allocatedIpRange = object.allocatedIpRange ?? "";
    message.databaseNames = object.databaseNames?.map((e) => e) || [];
    message.preferredZone = object.preferredZone ?? undefined;
    return message;
  },
};

function createBaseBinLogCoordinates(): BinLogCoordinates {
  return { binLogFileName: "", binLogPosition: Long.ZERO, kind: "" };
}

export const BinLogCoordinates: MessageFns<BinLogCoordinates> = {
  encode(message: BinLogCoordinates, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.binLogFileName !== "") {
      writer.uint32(10).string(message.binLogFileName);
    }
    if (!message.binLogPosition.equals(Long.ZERO)) {
      writer.uint32(16).int64(message.binLogPosition.toString());
    }
    if (message.kind !== "") {
      writer.uint32(26).string(message.kind);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): BinLogCoordinates {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseBinLogCoordinates();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.binLogFileName = reader.string();
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.binLogPosition = Long.fromString(reader.int64().toString());
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.kind = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): BinLogCoordinates {
    return {
      binLogFileName: isSet(object.binLogFileName) ? globalThis.String(object.binLogFileName) : "",
      binLogPosition: isSet(object.binLogPosition) ? Long.fromValue(object.binLogPosition) : Long.ZERO,
      kind: isSet(object.kind) ? globalThis.String(object.kind) : "",
    };
  },

  toJSON(message: BinLogCoordinates): unknown {
    const obj: any = {};
    if (message.binLogFileName !== "") {
      obj.binLogFileName = message.binLogFileName;
    }
    if (!message.binLogPosition.equals(Long.ZERO)) {
      obj.binLogPosition = (message.binLogPosition || Long.ZERO).toString();
    }
    if (message.kind !== "") {
      obj.kind = message.kind;
    }
    return obj;
  },

  create(base?: DeepPartial<BinLogCoordinates>): BinLogCoordinates {
    return BinLogCoordinates.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<BinLogCoordinates>): BinLogCoordinates {
    const message = createBaseBinLogCoordinates();
    message.binLogFileName = object.binLogFileName ?? "";
    message.binLogPosition = (object.binLogPosition !== undefined && object.binLogPosition !== null)
      ? Long.fromValue(object.binLogPosition)
      : Long.ZERO;
    message.kind = object.kind ?? "";
    return message;
  },
};

function createBaseDatabaseInstance(): DatabaseInstance {
  return {
    kind: "",
    state: 0,
    databaseVersion: 0,
    settings: undefined,
    etag: "",
    failoverReplica: undefined,
    masterInstanceName: "",
    replicaNames: [],
    maxDiskSize: undefined,
    currentDiskSize: undefined,
    ipAddresses: [],
    serverCaCert: undefined,
    instanceType: 0,
    project: "",
    ipv6Address: "",
    serviceAccountEmailAddress: "",
    onPremisesConfiguration: undefined,
    replicaConfiguration: undefined,
    backendType: 0,
    selfLink: "",
    suspensionReason: [],
    connectionName: "",
    name: "",
    region: "",
    gceZone: "",
    secondaryGceZone: "",
    diskEncryptionConfiguration: undefined,
    diskEncryptionStatus: undefined,
    rootPassword: "",
    scheduledMaintenance: undefined,
    satisfiesPzs: undefined,
    databaseInstalledVersion: "",
    outOfDiskReport: undefined,
    createTime: undefined,
    availableMaintenanceVersions: [],
    maintenanceVersion: "",
    upgradableDatabaseVersions: [],
    sqlNetworkArchitecture: undefined,
    pscServiceAttachmentLink: undefined,
    dnsName: undefined,
    primaryDnsName: undefined,
    writeEndpoint: undefined,
    replicationCluster: undefined,
    geminiConfig: undefined,
    satisfiesPzi: undefined,
    switchTransactionLogsToCloudStorageEnabled: undefined,
  };
}

export const DatabaseInstance: MessageFns<DatabaseInstance> = {
  encode(message: DatabaseInstance, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.kind !== "") {
      writer.uint32(10).string(message.kind);
    }
    if (message.state !== 0) {
      writer.uint32(16).int32(message.state);
    }
    if (message.databaseVersion !== 0) {
      writer.uint32(24).int32(message.databaseVersion);
    }
    if (message.settings !== undefined) {
      Settings.encode(message.settings, writer.uint32(34).fork()).join();
    }
    if (message.etag !== "") {
      writer.uint32(42).string(message.etag);
    }
    if (message.failoverReplica !== undefined) {
      DatabaseInstance_SqlFailoverReplica.encode(message.failoverReplica, writer.uint32(50).fork()).join();
    }
    if (message.masterInstanceName !== "") {
      writer.uint32(58).string(message.masterInstanceName);
    }
    for (const v of message.replicaNames) {
      writer.uint32(66).string(v!);
    }
    if (message.maxDiskSize !== undefined) {
      Int64Value.encode({ value: message.maxDiskSize! }, writer.uint32(74).fork()).join();
    }
    if (message.currentDiskSize !== undefined) {
      Int64Value.encode({ value: message.currentDiskSize! }, writer.uint32(82).fork()).join();
    }
    for (const v of message.ipAddresses) {
      IpMapping.encode(v!, writer.uint32(90).fork()).join();
    }
    if (message.serverCaCert !== undefined) {
      SslCert.encode(message.serverCaCert, writer.uint32(98).fork()).join();
    }
    if (message.instanceType !== 0) {
      writer.uint32(104).int32(message.instanceType);
    }
    if (message.project !== "") {
      writer.uint32(114).string(message.project);
    }
    if (message.ipv6Address !== "") {
      writer.uint32(122).string(message.ipv6Address);
    }
    if (message.serviceAccountEmailAddress !== "") {
      writer.uint32(130).string(message.serviceAccountEmailAddress);
    }
    if (message.onPremisesConfiguration !== undefined) {
      OnPremisesConfiguration.encode(message.onPremisesConfiguration, writer.uint32(138).fork()).join();
    }
    if (message.replicaConfiguration !== undefined) {
      ReplicaConfiguration.encode(message.replicaConfiguration, writer.uint32(146).fork()).join();
    }
    if (message.backendType !== 0) {
      writer.uint32(152).int32(message.backendType);
    }
    if (message.selfLink !== "") {
      writer.uint32(162).string(message.selfLink);
    }
    writer.uint32(170).fork();
    for (const v of message.suspensionReason) {
      writer.int32(v);
    }
    writer.join();
    if (message.connectionName !== "") {
      writer.uint32(178).string(message.connectionName);
    }
    if (message.name !== "") {
      writer.uint32(186).string(message.name);
    }
    if (message.region !== "") {
      writer.uint32(194).string(message.region);
    }
    if (message.gceZone !== "") {
      writer.uint32(202).string(message.gceZone);
    }
    if (message.secondaryGceZone !== "") {
      writer.uint32(274).string(message.secondaryGceZone);
    }
    if (message.diskEncryptionConfiguration !== undefined) {
      DiskEncryptionConfiguration.encode(message.diskEncryptionConfiguration, writer.uint32(210).fork()).join();
    }
    if (message.diskEncryptionStatus !== undefined) {
      DiskEncryptionStatus.encode(message.diskEncryptionStatus, writer.uint32(218).fork()).join();
    }
    if (message.rootPassword !== "") {
      writer.uint32(234).string(message.rootPassword);
    }
    if (message.scheduledMaintenance !== undefined) {
      DatabaseInstance_SqlScheduledMaintenance.encode(message.scheduledMaintenance, writer.uint32(242).fork()).join();
    }
    if (message.satisfiesPzs !== undefined) {
      BoolValue.encode({ value: message.satisfiesPzs! }, writer.uint32(282).fork()).join();
    }
    if (message.databaseInstalledVersion !== "") {
      writer.uint32(322).string(message.databaseInstalledVersion);
    }
    if (message.outOfDiskReport !== undefined) {
      DatabaseInstance_SqlOutOfDiskReport.encode(message.outOfDiskReport, writer.uint32(306).fork()).join();
    }
    if (message.createTime !== undefined) {
      Timestamp.encode(toTimestamp(message.createTime), writer.uint32(314).fork()).join();
    }
    for (const v of message.availableMaintenanceVersions) {
      writer.uint32(330).string(v!);
    }
    if (message.maintenanceVersion !== "") {
      writer.uint32(338).string(message.maintenanceVersion);
    }
    for (const v of message.upgradableDatabaseVersions) {
      AvailableDatabaseVersion.encode(v!, writer.uint32(362).fork()).join();
    }
    if (message.sqlNetworkArchitecture !== undefined) {
      writer.uint32(376).int32(message.sqlNetworkArchitecture);
    }
    if (message.pscServiceAttachmentLink !== undefined) {
      writer.uint32(386).string(message.pscServiceAttachmentLink);
    }
    if (message.dnsName !== undefined) {
      writer.uint32(394).string(message.dnsName);
    }
    if (message.primaryDnsName !== undefined) {
      writer.uint32(410).string(message.primaryDnsName);
    }
    if (message.writeEndpoint !== undefined) {
      writer.uint32(418).string(message.writeEndpoint);
    }
    if (message.replicationCluster !== undefined) {
      ReplicationCluster.encode(message.replicationCluster, writer.uint32(434).fork()).join();
    }
    if (message.geminiConfig !== undefined) {
      GeminiInstanceConfig.encode(message.geminiConfig, writer.uint32(442).fork()).join();
    }
    if (message.satisfiesPzi !== undefined) {
      BoolValue.encode({ value: message.satisfiesPzi! }, writer.uint32(450).fork()).join();
    }
    if (message.switchTransactionLogsToCloudStorageEnabled !== undefined) {
      BoolValue.encode({ value: message.switchTransactionLogsToCloudStorageEnabled! }, writer.uint32(458).fork())
        .join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): DatabaseInstance {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDatabaseInstance();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.kind = reader.string();
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.state = reader.int32() as any;
          continue;
        case 3:
          if (tag !== 24) {
            break;
          }

          message.databaseVersion = reader.int32() as any;
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.settings = Settings.decode(reader, reader.uint32());
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.etag = reader.string();
          continue;
        case 6:
          if (tag !== 50) {
            break;
          }

          message.failoverReplica = DatabaseInstance_SqlFailoverReplica.decode(reader, reader.uint32());
          continue;
        case 7:
          if (tag !== 58) {
            break;
          }

          message.masterInstanceName = reader.string();
          continue;
        case 8:
          if (tag !== 66) {
            break;
          }

          message.replicaNames.push(reader.string());
          continue;
        case 9:
          if (tag !== 74) {
            break;
          }

          message.maxDiskSize = Int64Value.decode(reader, reader.uint32()).value;
          continue;
        case 10:
          if (tag !== 82) {
            break;
          }

          message.currentDiskSize = Int64Value.decode(reader, reader.uint32()).value;
          continue;
        case 11:
          if (tag !== 90) {
            break;
          }

          message.ipAddresses.push(IpMapping.decode(reader, reader.uint32()));
          continue;
        case 12:
          if (tag !== 98) {
            break;
          }

          message.serverCaCert = SslCert.decode(reader, reader.uint32());
          continue;
        case 13:
          if (tag !== 104) {
            break;
          }

          message.instanceType = reader.int32() as any;
          continue;
        case 14:
          if (tag !== 114) {
            break;
          }

          message.project = reader.string();
          continue;
        case 15:
          if (tag !== 122) {
            break;
          }

          message.ipv6Address = reader.string();
          continue;
        case 16:
          if (tag !== 130) {
            break;
          }

          message.serviceAccountEmailAddress = reader.string();
          continue;
        case 17:
          if (tag !== 138) {
            break;
          }

          message.onPremisesConfiguration = OnPremisesConfiguration.decode(reader, reader.uint32());
          continue;
        case 18:
          if (tag !== 146) {
            break;
          }

          message.replicaConfiguration = ReplicaConfiguration.decode(reader, reader.uint32());
          continue;
        case 19:
          if (tag !== 152) {
            break;
          }

          message.backendType = reader.int32() as any;
          continue;
        case 20:
          if (tag !== 162) {
            break;
          }

          message.selfLink = reader.string();
          continue;
        case 21:
          if (tag === 168) {
            message.suspensionReason.push(reader.int32() as any);

            continue;
          }

          if (tag === 170) {
            const end2 = reader.uint32() + reader.pos;
            while (reader.pos < end2) {
              message.suspensionReason.push(reader.int32() as any);
            }

            continue;
          }

          break;
        case 22:
          if (tag !== 178) {
            break;
          }

          message.connectionName = reader.string();
          continue;
        case 23:
          if (tag !== 186) {
            break;
          }

          message.name = reader.string();
          continue;
        case 24:
          if (tag !== 194) {
            break;
          }

          message.region = reader.string();
          continue;
        case 25:
          if (tag !== 202) {
            break;
          }

          message.gceZone = reader.string();
          continue;
        case 34:
          if (tag !== 274) {
            break;
          }

          message.secondaryGceZone = reader.string();
          continue;
        case 26:
          if (tag !== 210) {
            break;
          }

          message.diskEncryptionConfiguration = DiskEncryptionConfiguration.decode(reader, reader.uint32());
          continue;
        case 27:
          if (tag !== 218) {
            break;
          }

          message.diskEncryptionStatus = DiskEncryptionStatus.decode(reader, reader.uint32());
          continue;
        case 29:
          if (tag !== 234) {
            break;
          }

          message.rootPassword = reader.string();
          continue;
        case 30:
          if (tag !== 242) {
            break;
          }

          message.scheduledMaintenance = DatabaseInstance_SqlScheduledMaintenance.decode(reader, reader.uint32());
          continue;
        case 35:
          if (tag !== 282) {
            break;
          }

          message.satisfiesPzs = BoolValue.decode(reader, reader.uint32()).value;
          continue;
        case 40:
          if (tag !== 322) {
            break;
          }

          message.databaseInstalledVersion = reader.string();
          continue;
        case 38:
          if (tag !== 306) {
            break;
          }

          message.outOfDiskReport = DatabaseInstance_SqlOutOfDiskReport.decode(reader, reader.uint32());
          continue;
        case 39:
          if (tag !== 314) {
            break;
          }

          message.createTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        case 41:
          if (tag !== 330) {
            break;
          }

          message.availableMaintenanceVersions.push(reader.string());
          continue;
        case 42:
          if (tag !== 338) {
            break;
          }

          message.maintenanceVersion = reader.string();
          continue;
        case 45:
          if (tag !== 362) {
            break;
          }

          message.upgradableDatabaseVersions.push(AvailableDatabaseVersion.decode(reader, reader.uint32()));
          continue;
        case 47:
          if (tag !== 376) {
            break;
          }

          message.sqlNetworkArchitecture = reader.int32() as any;
          continue;
        case 48:
          if (tag !== 386) {
            break;
          }

          message.pscServiceAttachmentLink = reader.string();
          continue;
        case 49:
          if (tag !== 394) {
            break;
          }

          message.dnsName = reader.string();
          continue;
        case 51:
          if (tag !== 410) {
            break;
          }

          message.primaryDnsName = reader.string();
          continue;
        case 52:
          if (tag !== 418) {
            break;
          }

          message.writeEndpoint = reader.string();
          continue;
        case 54:
          if (tag !== 434) {
            break;
          }

          message.replicationCluster = ReplicationCluster.decode(reader, reader.uint32());
          continue;
        case 55:
          if (tag !== 442) {
            break;
          }

          message.geminiConfig = GeminiInstanceConfig.decode(reader, reader.uint32());
          continue;
        case 56:
          if (tag !== 450) {
            break;
          }

          message.satisfiesPzi = BoolValue.decode(reader, reader.uint32()).value;
          continue;
        case 57:
          if (tag !== 458) {
            break;
          }

          message.switchTransactionLogsToCloudStorageEnabled = BoolValue.decode(reader, reader.uint32()).value;
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): DatabaseInstance {
    return {
      kind: isSet(object.kind) ? globalThis.String(object.kind) : "",
      state: isSet(object.state) ? databaseInstance_SqlInstanceStateFromJSON(object.state) : 0,
      databaseVersion: isSet(object.databaseVersion) ? sqlDatabaseVersionFromJSON(object.databaseVersion) : 0,
      settings: isSet(object.settings) ? Settings.fromJSON(object.settings) : undefined,
      etag: isSet(object.etag) ? globalThis.String(object.etag) : "",
      failoverReplica: isSet(object.failoverReplica)
        ? DatabaseInstance_SqlFailoverReplica.fromJSON(object.failoverReplica)
        : undefined,
      masterInstanceName: isSet(object.masterInstanceName) ? globalThis.String(object.masterInstanceName) : "",
      replicaNames: globalThis.Array.isArray(object?.replicaNames)
        ? object.replicaNames.map((e: any) => globalThis.String(e))
        : [],
      maxDiskSize: isSet(object.maxDiskSize) ? Long.fromValue(object.maxDiskSize) : undefined,
      currentDiskSize: isSet(object.currentDiskSize) ? Long.fromValue(object.currentDiskSize) : undefined,
      ipAddresses: globalThis.Array.isArray(object?.ipAddresses)
        ? object.ipAddresses.map((e: any) => IpMapping.fromJSON(e))
        : [],
      serverCaCert: isSet(object.serverCaCert) ? SslCert.fromJSON(object.serverCaCert) : undefined,
      instanceType: isSet(object.instanceType) ? sqlInstanceTypeFromJSON(object.instanceType) : 0,
      project: isSet(object.project) ? globalThis.String(object.project) : "",
      ipv6Address: isSet(object.ipv6Address) ? globalThis.String(object.ipv6Address) : "",
      serviceAccountEmailAddress: isSet(object.serviceAccountEmailAddress)
        ? globalThis.String(object.serviceAccountEmailAddress)
        : "",
      onPremisesConfiguration: isSet(object.onPremisesConfiguration)
        ? OnPremisesConfiguration.fromJSON(object.onPremisesConfiguration)
        : undefined,
      replicaConfiguration: isSet(object.replicaConfiguration)
        ? ReplicaConfiguration.fromJSON(object.replicaConfiguration)
        : undefined,
      backendType: isSet(object.backendType) ? sqlBackendTypeFromJSON(object.backendType) : 0,
      selfLink: isSet(object.selfLink) ? globalThis.String(object.selfLink) : "",
      suspensionReason: globalThis.Array.isArray(object?.suspensionReason)
        ? object.suspensionReason.map((e: any) => sqlSuspensionReasonFromJSON(e))
        : [],
      connectionName: isSet(object.connectionName) ? globalThis.String(object.connectionName) : "",
      name: isSet(object.name) ? globalThis.String(object.name) : "",
      region: isSet(object.region) ? globalThis.String(object.region) : "",
      gceZone: isSet(object.gceZone) ? globalThis.String(object.gceZone) : "",
      secondaryGceZone: isSet(object.secondaryGceZone) ? globalThis.String(object.secondaryGceZone) : "",
      diskEncryptionConfiguration: isSet(object.diskEncryptionConfiguration)
        ? DiskEncryptionConfiguration.fromJSON(object.diskEncryptionConfiguration)
        : undefined,
      diskEncryptionStatus: isSet(object.diskEncryptionStatus)
        ? DiskEncryptionStatus.fromJSON(object.diskEncryptionStatus)
        : undefined,
      rootPassword: isSet(object.rootPassword) ? globalThis.String(object.rootPassword) : "",
      scheduledMaintenance: isSet(object.scheduledMaintenance)
        ? DatabaseInstance_SqlScheduledMaintenance.fromJSON(object.scheduledMaintenance)
        : undefined,
      satisfiesPzs: isSet(object.satisfiesPzs) ? Boolean(object.satisfiesPzs) : undefined,
      databaseInstalledVersion: isSet(object.databaseInstalledVersion)
        ? globalThis.String(object.databaseInstalledVersion)
        : "",
      outOfDiskReport: isSet(object.outOfDiskReport)
        ? DatabaseInstance_SqlOutOfDiskReport.fromJSON(object.outOfDiskReport)
        : undefined,
      createTime: isSet(object.createTime) ? fromJsonTimestamp(object.createTime) : undefined,
      availableMaintenanceVersions: globalThis.Array.isArray(object?.availableMaintenanceVersions)
        ? object.availableMaintenanceVersions.map((e: any) => globalThis.String(e))
        : [],
      maintenanceVersion: isSet(object.maintenanceVersion) ? globalThis.String(object.maintenanceVersion) : "",
      upgradableDatabaseVersions: globalThis.Array.isArray(object?.upgradableDatabaseVersions)
        ? object.upgradableDatabaseVersions.map((e: any) => AvailableDatabaseVersion.fromJSON(e))
        : [],
      sqlNetworkArchitecture: isSet(object.sqlNetworkArchitecture)
        ? databaseInstance_SqlNetworkArchitectureFromJSON(object.sqlNetworkArchitecture)
        : undefined,
      pscServiceAttachmentLink: isSet(object.pscServiceAttachmentLink)
        ? globalThis.String(object.pscServiceAttachmentLink)
        : undefined,
      dnsName: isSet(object.dnsName) ? globalThis.String(object.dnsName) : undefined,
      primaryDnsName: isSet(object.primaryDnsName) ? globalThis.String(object.primaryDnsName) : undefined,
      writeEndpoint: isSet(object.writeEndpoint) ? globalThis.String(object.writeEndpoint) : undefined,
      replicationCluster: isSet(object.replicationCluster)
        ? ReplicationCluster.fromJSON(object.replicationCluster)
        : undefined,
      geminiConfig: isSet(object.geminiConfig) ? GeminiInstanceConfig.fromJSON(object.geminiConfig) : undefined,
      satisfiesPzi: isSet(object.satisfiesPzi) ? Boolean(object.satisfiesPzi) : undefined,
      switchTransactionLogsToCloudStorageEnabled: isSet(object.switchTransactionLogsToCloudStorageEnabled)
        ? Boolean(object.switchTransactionLogsToCloudStorageEnabled)
        : undefined,
    };
  },

  toJSON(message: DatabaseInstance): unknown {
    const obj: any = {};
    if (message.kind !== "") {
      obj.kind = message.kind;
    }
    if (message.state !== 0) {
      obj.state = databaseInstance_SqlInstanceStateToJSON(message.state);
    }
    if (message.databaseVersion !== 0) {
      obj.databaseVersion = sqlDatabaseVersionToJSON(message.databaseVersion);
    }
    if (message.settings !== undefined) {
      obj.settings = Settings.toJSON(message.settings);
    }
    if (message.etag !== "") {
      obj.etag = message.etag;
    }
    if (message.failoverReplica !== undefined) {
      obj.failoverReplica = DatabaseInstance_SqlFailoverReplica.toJSON(message.failoverReplica);
    }
    if (message.masterInstanceName !== "") {
      obj.masterInstanceName = message.masterInstanceName;
    }
    if (message.replicaNames?.length) {
      obj.replicaNames = message.replicaNames;
    }
    if (message.maxDiskSize !== undefined) {
      obj.maxDiskSize = message.maxDiskSize;
    }
    if (message.currentDiskSize !== undefined) {
      obj.currentDiskSize = message.currentDiskSize;
    }
    if (message.ipAddresses?.length) {
      obj.ipAddresses = message.ipAddresses.map((e) => IpMapping.toJSON(e));
    }
    if (message.serverCaCert !== undefined) {
      obj.serverCaCert = SslCert.toJSON(message.serverCaCert);
    }
    if (message.instanceType !== 0) {
      obj.instanceType = sqlInstanceTypeToJSON(message.instanceType);
    }
    if (message.project !== "") {
      obj.project = message.project;
    }
    if (message.ipv6Address !== "") {
      obj.ipv6Address = message.ipv6Address;
    }
    if (message.serviceAccountEmailAddress !== "") {
      obj.serviceAccountEmailAddress = message.serviceAccountEmailAddress;
    }
    if (message.onPremisesConfiguration !== undefined) {
      obj.onPremisesConfiguration = OnPremisesConfiguration.toJSON(message.onPremisesConfiguration);
    }
    if (message.replicaConfiguration !== undefined) {
      obj.replicaConfiguration = ReplicaConfiguration.toJSON(message.replicaConfiguration);
    }
    if (message.backendType !== 0) {
      obj.backendType = sqlBackendTypeToJSON(message.backendType);
    }
    if (message.selfLink !== "") {
      obj.selfLink = message.selfLink;
    }
    if (message.suspensionReason?.length) {
      obj.suspensionReason = message.suspensionReason.map((e) => sqlSuspensionReasonToJSON(e));
    }
    if (message.connectionName !== "") {
      obj.connectionName = message.connectionName;
    }
    if (message.name !== "") {
      obj.name = message.name;
    }
    if (message.region !== "") {
      obj.region = message.region;
    }
    if (message.gceZone !== "") {
      obj.gceZone = message.gceZone;
    }
    if (message.secondaryGceZone !== "") {
      obj.secondaryGceZone = message.secondaryGceZone;
    }
    if (message.diskEncryptionConfiguration !== undefined) {
      obj.diskEncryptionConfiguration = DiskEncryptionConfiguration.toJSON(message.diskEncryptionConfiguration);
    }
    if (message.diskEncryptionStatus !== undefined) {
      obj.diskEncryptionStatus = DiskEncryptionStatus.toJSON(message.diskEncryptionStatus);
    }
    if (message.rootPassword !== "") {
      obj.rootPassword = message.rootPassword;
    }
    if (message.scheduledMaintenance !== undefined) {
      obj.scheduledMaintenance = DatabaseInstance_SqlScheduledMaintenance.toJSON(message.scheduledMaintenance);
    }
    if (message.satisfiesPzs !== undefined) {
      obj.satisfiesPzs = message.satisfiesPzs;
    }
    if (message.databaseInstalledVersion !== "") {
      obj.databaseInstalledVersion = message.databaseInstalledVersion;
    }
    if (message.outOfDiskReport !== undefined) {
      obj.outOfDiskReport = DatabaseInstance_SqlOutOfDiskReport.toJSON(message.outOfDiskReport);
    }
    if (message.createTime !== undefined) {
      obj.createTime = message.createTime.toISOString();
    }
    if (message.availableMaintenanceVersions?.length) {
      obj.availableMaintenanceVersions = message.availableMaintenanceVersions;
    }
    if (message.maintenanceVersion !== "") {
      obj.maintenanceVersion = message.maintenanceVersion;
    }
    if (message.upgradableDatabaseVersions?.length) {
      obj.upgradableDatabaseVersions = message.upgradableDatabaseVersions.map((e) =>
        AvailableDatabaseVersion.toJSON(e)
      );
    }
    if (message.sqlNetworkArchitecture !== undefined) {
      obj.sqlNetworkArchitecture = databaseInstance_SqlNetworkArchitectureToJSON(message.sqlNetworkArchitecture);
    }
    if (message.pscServiceAttachmentLink !== undefined) {
      obj.pscServiceAttachmentLink = message.pscServiceAttachmentLink;
    }
    if (message.dnsName !== undefined) {
      obj.dnsName = message.dnsName;
    }
    if (message.primaryDnsName !== undefined) {
      obj.primaryDnsName = message.primaryDnsName;
    }
    if (message.writeEndpoint !== undefined) {
      obj.writeEndpoint = message.writeEndpoint;
    }
    if (message.replicationCluster !== undefined) {
      obj.replicationCluster = ReplicationCluster.toJSON(message.replicationCluster);
    }
    if (message.geminiConfig !== undefined) {
      obj.geminiConfig = GeminiInstanceConfig.toJSON(message.geminiConfig);
    }
    if (message.satisfiesPzi !== undefined) {
      obj.satisfiesPzi = message.satisfiesPzi;
    }
    if (message.switchTransactionLogsToCloudStorageEnabled !== undefined) {
      obj.switchTransactionLogsToCloudStorageEnabled = message.switchTransactionLogsToCloudStorageEnabled;
    }
    return obj;
  },

  create(base?: DeepPartial<DatabaseInstance>): DatabaseInstance {
    return DatabaseInstance.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<DatabaseInstance>): DatabaseInstance {
    const message = createBaseDatabaseInstance();
    message.kind = object.kind ?? "";
    message.state = object.state ?? 0;
    message.databaseVersion = object.databaseVersion ?? 0;
    message.settings = (object.settings !== undefined && object.settings !== null)
      ? Settings.fromPartial(object.settings)
      : undefined;
    message.etag = object.etag ?? "";
    message.failoverReplica = (object.failoverReplica !== undefined && object.failoverReplica !== null)
      ? DatabaseInstance_SqlFailoverReplica.fromPartial(object.failoverReplica)
      : undefined;
    message.masterInstanceName = object.masterInstanceName ?? "";
    message.replicaNames = object.replicaNames?.map((e) => e) || [];
    message.maxDiskSize = (object.maxDiskSize !== undefined && object.maxDiskSize !== null)
      ? Long.fromValue(object.maxDiskSize)
      : undefined;
    message.currentDiskSize = (object.currentDiskSize !== undefined && object.currentDiskSize !== null)
      ? Long.fromValue(object.currentDiskSize)
      : undefined;
    message.ipAddresses = object.ipAddresses?.map((e) => IpMapping.fromPartial(e)) || [];
    message.serverCaCert = (object.serverCaCert !== undefined && object.serverCaCert !== null)
      ? SslCert.fromPartial(object.serverCaCert)
      : undefined;
    message.instanceType = object.instanceType ?? 0;
    message.project = object.project ?? "";
    message.ipv6Address = object.ipv6Address ?? "";
    message.serviceAccountEmailAddress = object.serviceAccountEmailAddress ?? "";
    message.onPremisesConfiguration =
      (object.onPremisesConfiguration !== undefined && object.onPremisesConfiguration !== null)
        ? OnPremisesConfiguration.fromPartial(object.onPremisesConfiguration)
        : undefined;
    message.replicaConfiguration = (object.replicaConfiguration !== undefined && object.replicaConfiguration !== null)
      ? ReplicaConfiguration.fromPartial(object.replicaConfiguration)
      : undefined;
    message.backendType = object.backendType ?? 0;
    message.selfLink = object.selfLink ?? "";
    message.suspensionReason = object.suspensionReason?.map((e) => e) || [];
    message.connectionName = object.connectionName ?? "";
    message.name = object.name ?? "";
    message.region = object.region ?? "";
    message.gceZone = object.gceZone ?? "";
    message.secondaryGceZone = object.secondaryGceZone ?? "";
    message.diskEncryptionConfiguration =
      (object.diskEncryptionConfiguration !== undefined && object.diskEncryptionConfiguration !== null)
        ? DiskEncryptionConfiguration.fromPartial(object.diskEncryptionConfiguration)
        : undefined;
    message.diskEncryptionStatus = (object.diskEncryptionStatus !== undefined && object.diskEncryptionStatus !== null)
      ? DiskEncryptionStatus.fromPartial(object.diskEncryptionStatus)
      : undefined;
    message.rootPassword = object.rootPassword ?? "";
    message.scheduledMaintenance = (object.scheduledMaintenance !== undefined && object.scheduledMaintenance !== null)
      ? DatabaseInstance_SqlScheduledMaintenance.fromPartial(object.scheduledMaintenance)
      : undefined;
    message.satisfiesPzs = object.satisfiesPzs ?? undefined;
    message.databaseInstalledVersion = object.databaseInstalledVersion ?? "";
    message.outOfDiskReport = (object.outOfDiskReport !== undefined && object.outOfDiskReport !== null)
      ? DatabaseInstance_SqlOutOfDiskReport.fromPartial(object.outOfDiskReport)
      : undefined;
    message.createTime = object.createTime ?? undefined;
    message.availableMaintenanceVersions = object.availableMaintenanceVersions?.map((e) => e) || [];
    message.maintenanceVersion = object.maintenanceVersion ?? "";
    message.upgradableDatabaseVersions =
      object.upgradableDatabaseVersions?.map((e) => AvailableDatabaseVersion.fromPartial(e)) || [];
    message.sqlNetworkArchitecture = object.sqlNetworkArchitecture ?? undefined;
    message.pscServiceAttachmentLink = object.pscServiceAttachmentLink ?? undefined;
    message.dnsName = object.dnsName ?? undefined;
    message.primaryDnsName = object.primaryDnsName ?? undefined;
    message.writeEndpoint = object.writeEndpoint ?? undefined;
    message.replicationCluster = (object.replicationCluster !== undefined && object.replicationCluster !== null)
      ? ReplicationCluster.fromPartial(object.replicationCluster)
      : undefined;
    message.geminiConfig = (object.geminiConfig !== undefined && object.geminiConfig !== null)
      ? GeminiInstanceConfig.fromPartial(object.geminiConfig)
      : undefined;
    message.satisfiesPzi = object.satisfiesPzi ?? undefined;
    message.switchTransactionLogsToCloudStorageEnabled = object.switchTransactionLogsToCloudStorageEnabled ?? undefined;
    return message;
  },
};

function createBaseDatabaseInstance_SqlFailoverReplica(): DatabaseInstance_SqlFailoverReplica {
  return { name: "", available: undefined };
}

export const DatabaseInstance_SqlFailoverReplica: MessageFns<DatabaseInstance_SqlFailoverReplica> = {
  encode(message: DatabaseInstance_SqlFailoverReplica, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    if (message.available !== undefined) {
      BoolValue.encode({ value: message.available! }, writer.uint32(18).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): DatabaseInstance_SqlFailoverReplica {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDatabaseInstance_SqlFailoverReplica();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.available = BoolValue.decode(reader, reader.uint32()).value;
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): DatabaseInstance_SqlFailoverReplica {
    return {
      name: isSet(object.name) ? globalThis.String(object.name) : "",
      available: isSet(object.available) ? Boolean(object.available) : undefined,
    };
  },

  toJSON(message: DatabaseInstance_SqlFailoverReplica): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    if (message.available !== undefined) {
      obj.available = message.available;
    }
    return obj;
  },

  create(base?: DeepPartial<DatabaseInstance_SqlFailoverReplica>): DatabaseInstance_SqlFailoverReplica {
    return DatabaseInstance_SqlFailoverReplica.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<DatabaseInstance_SqlFailoverReplica>): DatabaseInstance_SqlFailoverReplica {
    const message = createBaseDatabaseInstance_SqlFailoverReplica();
    message.name = object.name ?? "";
    message.available = object.available ?? undefined;
    return message;
  },
};

function createBaseDatabaseInstance_SqlScheduledMaintenance(): DatabaseInstance_SqlScheduledMaintenance {
  return { startTime: undefined, canDefer: false, canReschedule: false, scheduleDeadlineTime: undefined };
}

export const DatabaseInstance_SqlScheduledMaintenance: MessageFns<DatabaseInstance_SqlScheduledMaintenance> = {
  encode(message: DatabaseInstance_SqlScheduledMaintenance, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.startTime !== undefined) {
      Timestamp.encode(toTimestamp(message.startTime), writer.uint32(10).fork()).join();
    }
    if (message.canDefer !== false) {
      writer.uint32(16).bool(message.canDefer);
    }
    if (message.canReschedule !== false) {
      writer.uint32(24).bool(message.canReschedule);
    }
    if (message.scheduleDeadlineTime !== undefined) {
      Timestamp.encode(toTimestamp(message.scheduleDeadlineTime), writer.uint32(34).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): DatabaseInstance_SqlScheduledMaintenance {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDatabaseInstance_SqlScheduledMaintenance();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.startTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.canDefer = reader.bool();
          continue;
        case 3:
          if (tag !== 24) {
            break;
          }

          message.canReschedule = reader.bool();
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.scheduleDeadlineTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): DatabaseInstance_SqlScheduledMaintenance {
    return {
      startTime: isSet(object.startTime) ? fromJsonTimestamp(object.startTime) : undefined,
      canDefer: isSet(object.canDefer) ? globalThis.Boolean(object.canDefer) : false,
      canReschedule: isSet(object.canReschedule) ? globalThis.Boolean(object.canReschedule) : false,
      scheduleDeadlineTime: isSet(object.scheduleDeadlineTime)
        ? fromJsonTimestamp(object.scheduleDeadlineTime)
        : undefined,
    };
  },

  toJSON(message: DatabaseInstance_SqlScheduledMaintenance): unknown {
    const obj: any = {};
    if (message.startTime !== undefined) {
      obj.startTime = message.startTime.toISOString();
    }
    if (message.canDefer !== false) {
      obj.canDefer = message.canDefer;
    }
    if (message.canReschedule !== false) {
      obj.canReschedule = message.canReschedule;
    }
    if (message.scheduleDeadlineTime !== undefined) {
      obj.scheduleDeadlineTime = message.scheduleDeadlineTime.toISOString();
    }
    return obj;
  },

  create(base?: DeepPartial<DatabaseInstance_SqlScheduledMaintenance>): DatabaseInstance_SqlScheduledMaintenance {
    return DatabaseInstance_SqlScheduledMaintenance.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<DatabaseInstance_SqlScheduledMaintenance>): DatabaseInstance_SqlScheduledMaintenance {
    const message = createBaseDatabaseInstance_SqlScheduledMaintenance();
    message.startTime = object.startTime ?? undefined;
    message.canDefer = object.canDefer ?? false;
    message.canReschedule = object.canReschedule ?? false;
    message.scheduleDeadlineTime = object.scheduleDeadlineTime ?? undefined;
    return message;
  },
};

function createBaseDatabaseInstance_SqlOutOfDiskReport(): DatabaseInstance_SqlOutOfDiskReport {
  return { sqlOutOfDiskState: undefined, sqlMinRecommendedIncreaseSizeGb: undefined };
}

export const DatabaseInstance_SqlOutOfDiskReport: MessageFns<DatabaseInstance_SqlOutOfDiskReport> = {
  encode(message: DatabaseInstance_SqlOutOfDiskReport, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.sqlOutOfDiskState !== undefined) {
      writer.uint32(8).int32(message.sqlOutOfDiskState);
    }
    if (message.sqlMinRecommendedIncreaseSizeGb !== undefined) {
      writer.uint32(16).int32(message.sqlMinRecommendedIncreaseSizeGb);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): DatabaseInstance_SqlOutOfDiskReport {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDatabaseInstance_SqlOutOfDiskReport();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 8) {
            break;
          }

          message.sqlOutOfDiskState = reader.int32() as any;
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.sqlMinRecommendedIncreaseSizeGb = reader.int32();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): DatabaseInstance_SqlOutOfDiskReport {
    return {
      sqlOutOfDiskState: isSet(object.sqlOutOfDiskState)
        ? databaseInstance_SqlOutOfDiskReport_SqlOutOfDiskStateFromJSON(object.sqlOutOfDiskState)
        : undefined,
      sqlMinRecommendedIncreaseSizeGb: isSet(object.sqlMinRecommendedIncreaseSizeGb)
        ? globalThis.Number(object.sqlMinRecommendedIncreaseSizeGb)
        : undefined,
    };
  },

  toJSON(message: DatabaseInstance_SqlOutOfDiskReport): unknown {
    const obj: any = {};
    if (message.sqlOutOfDiskState !== undefined) {
      obj.sqlOutOfDiskState = databaseInstance_SqlOutOfDiskReport_SqlOutOfDiskStateToJSON(message.sqlOutOfDiskState);
    }
    if (message.sqlMinRecommendedIncreaseSizeGb !== undefined) {
      obj.sqlMinRecommendedIncreaseSizeGb = Math.round(message.sqlMinRecommendedIncreaseSizeGb);
    }
    return obj;
  },

  create(base?: DeepPartial<DatabaseInstance_SqlOutOfDiskReport>): DatabaseInstance_SqlOutOfDiskReport {
    return DatabaseInstance_SqlOutOfDiskReport.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<DatabaseInstance_SqlOutOfDiskReport>): DatabaseInstance_SqlOutOfDiskReport {
    const message = createBaseDatabaseInstance_SqlOutOfDiskReport();
    message.sqlOutOfDiskState = object.sqlOutOfDiskState ?? undefined;
    message.sqlMinRecommendedIncreaseSizeGb = object.sqlMinRecommendedIncreaseSizeGb ?? undefined;
    return message;
  },
};

function createBaseGeminiInstanceConfig(): GeminiInstanceConfig {
  return {
    entitled: undefined,
    googleVacuumMgmtEnabled: undefined,
    oomSessionCancelEnabled: undefined,
    activeQueryEnabled: undefined,
    indexAdvisorEnabled: undefined,
    flagRecommenderEnabled: undefined,
  };
}

export const GeminiInstanceConfig: MessageFns<GeminiInstanceConfig> = {
  encode(message: GeminiInstanceConfig, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.entitled !== undefined) {
      writer.uint32(8).bool(message.entitled);
    }
    if (message.googleVacuumMgmtEnabled !== undefined) {
      writer.uint32(16).bool(message.googleVacuumMgmtEnabled);
    }
    if (message.oomSessionCancelEnabled !== undefined) {
      writer.uint32(24).bool(message.oomSessionCancelEnabled);
    }
    if (message.activeQueryEnabled !== undefined) {
      writer.uint32(32).bool(message.activeQueryEnabled);
    }
    if (message.indexAdvisorEnabled !== undefined) {
      writer.uint32(40).bool(message.indexAdvisorEnabled);
    }
    if (message.flagRecommenderEnabled !== undefined) {
      writer.uint32(48).bool(message.flagRecommenderEnabled);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): GeminiInstanceConfig {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseGeminiInstanceConfig();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 8) {
            break;
          }

          message.entitled = reader.bool();
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.googleVacuumMgmtEnabled = reader.bool();
          continue;
        case 3:
          if (tag !== 24) {
            break;
          }

          message.oomSessionCancelEnabled = reader.bool();
          continue;
        case 4:
          if (tag !== 32) {
            break;
          }

          message.activeQueryEnabled = reader.bool();
          continue;
        case 5:
          if (tag !== 40) {
            break;
          }

          message.indexAdvisorEnabled = reader.bool();
          continue;
        case 6:
          if (tag !== 48) {
            break;
          }

          message.flagRecommenderEnabled = reader.bool();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): GeminiInstanceConfig {
    return {
      entitled: isSet(object.entitled) ? globalThis.Boolean(object.entitled) : undefined,
      googleVacuumMgmtEnabled: isSet(object.googleVacuumMgmtEnabled)
        ? globalThis.Boolean(object.googleVacuumMgmtEnabled)
        : undefined,
      oomSessionCancelEnabled: isSet(object.oomSessionCancelEnabled)
        ? globalThis.Boolean(object.oomSessionCancelEnabled)
        : undefined,
      activeQueryEnabled: isSet(object.activeQueryEnabled) ? globalThis.Boolean(object.activeQueryEnabled) : undefined,
      indexAdvisorEnabled: isSet(object.indexAdvisorEnabled)
        ? globalThis.Boolean(object.indexAdvisorEnabled)
        : undefined,
      flagRecommenderEnabled: isSet(object.flagRecommenderEnabled)
        ? globalThis.Boolean(object.flagRecommenderEnabled)
        : undefined,
    };
  },

  toJSON(message: GeminiInstanceConfig): unknown {
    const obj: any = {};
    if (message.entitled !== undefined) {
      obj.entitled = message.entitled;
    }
    if (message.googleVacuumMgmtEnabled !== undefined) {
      obj.googleVacuumMgmtEnabled = message.googleVacuumMgmtEnabled;
    }
    if (message.oomSessionCancelEnabled !== undefined) {
      obj.oomSessionCancelEnabled = message.oomSessionCancelEnabled;
    }
    if (message.activeQueryEnabled !== undefined) {
      obj.activeQueryEnabled = message.activeQueryEnabled;
    }
    if (message.indexAdvisorEnabled !== undefined) {
      obj.indexAdvisorEnabled = message.indexAdvisorEnabled;
    }
    if (message.flagRecommenderEnabled !== undefined) {
      obj.flagRecommenderEnabled = message.flagRecommenderEnabled;
    }
    return obj;
  },

  create(base?: DeepPartial<GeminiInstanceConfig>): GeminiInstanceConfig {
    return GeminiInstanceConfig.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<GeminiInstanceConfig>): GeminiInstanceConfig {
    const message = createBaseGeminiInstanceConfig();
    message.entitled = object.entitled ?? undefined;
    message.googleVacuumMgmtEnabled = object.googleVacuumMgmtEnabled ?? undefined;
    message.oomSessionCancelEnabled = object.oomSessionCancelEnabled ?? undefined;
    message.activeQueryEnabled = object.activeQueryEnabled ?? undefined;
    message.indexAdvisorEnabled = object.indexAdvisorEnabled ?? undefined;
    message.flagRecommenderEnabled = object.flagRecommenderEnabled ?? undefined;
    return message;
  },
};

function createBaseReplicationCluster(): ReplicationCluster {
  return { psaWriteEndpoint: "", failoverDrReplicaName: "", drReplica: false };
}

export const ReplicationCluster: MessageFns<ReplicationCluster> = {
  encode(message: ReplicationCluster, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.psaWriteEndpoint !== "") {
      writer.uint32(10).string(message.psaWriteEndpoint);
    }
    if (message.failoverDrReplicaName !== "") {
      writer.uint32(18).string(message.failoverDrReplicaName);
    }
    if (message.drReplica !== false) {
      writer.uint32(32).bool(message.drReplica);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ReplicationCluster {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseReplicationCluster();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.psaWriteEndpoint = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.failoverDrReplicaName = reader.string();
          continue;
        case 4:
          if (tag !== 32) {
            break;
          }

          message.drReplica = reader.bool();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ReplicationCluster {
    return {
      psaWriteEndpoint: isSet(object.psaWriteEndpoint) ? globalThis.String(object.psaWriteEndpoint) : "",
      failoverDrReplicaName: isSet(object.failoverDrReplicaName) ? globalThis.String(object.failoverDrReplicaName) : "",
      drReplica: isSet(object.drReplica) ? globalThis.Boolean(object.drReplica) : false,
    };
  },

  toJSON(message: ReplicationCluster): unknown {
    const obj: any = {};
    if (message.psaWriteEndpoint !== "") {
      obj.psaWriteEndpoint = message.psaWriteEndpoint;
    }
    if (message.failoverDrReplicaName !== "") {
      obj.failoverDrReplicaName = message.failoverDrReplicaName;
    }
    if (message.drReplica !== false) {
      obj.drReplica = message.drReplica;
    }
    return obj;
  },

  create(base?: DeepPartial<ReplicationCluster>): ReplicationCluster {
    return ReplicationCluster.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ReplicationCluster>): ReplicationCluster {
    const message = createBaseReplicationCluster();
    message.psaWriteEndpoint = object.psaWriteEndpoint ?? "";
    message.failoverDrReplicaName = object.failoverDrReplicaName ?? "";
    message.drReplica = object.drReplica ?? false;
    return message;
  },
};

function createBaseAvailableDatabaseVersion(): AvailableDatabaseVersion {
  return { majorVersion: undefined, name: undefined, displayName: undefined };
}

export const AvailableDatabaseVersion: MessageFns<AvailableDatabaseVersion> = {
  encode(message: AvailableDatabaseVersion, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.majorVersion !== undefined) {
      writer.uint32(26).string(message.majorVersion);
    }
    if (message.name !== undefined) {
      writer.uint32(66).string(message.name);
    }
    if (message.displayName !== undefined) {
      writer.uint32(74).string(message.displayName);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): AvailableDatabaseVersion {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseAvailableDatabaseVersion();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 3:
          if (tag !== 26) {
            break;
          }

          message.majorVersion = reader.string();
          continue;
        case 8:
          if (tag !== 66) {
            break;
          }

          message.name = reader.string();
          continue;
        case 9:
          if (tag !== 74) {
            break;
          }

          message.displayName = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): AvailableDatabaseVersion {
    return {
      majorVersion: isSet(object.majorVersion) ? globalThis.String(object.majorVersion) : undefined,
      name: isSet(object.name) ? globalThis.String(object.name) : undefined,
      displayName: isSet(object.displayName) ? globalThis.String(object.displayName) : undefined,
    };
  },

  toJSON(message: AvailableDatabaseVersion): unknown {
    const obj: any = {};
    if (message.majorVersion !== undefined) {
      obj.majorVersion = message.majorVersion;
    }
    if (message.name !== undefined) {
      obj.name = message.name;
    }
    if (message.displayName !== undefined) {
      obj.displayName = message.displayName;
    }
    return obj;
  },

  create(base?: DeepPartial<AvailableDatabaseVersion>): AvailableDatabaseVersion {
    return AvailableDatabaseVersion.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<AvailableDatabaseVersion>): AvailableDatabaseVersion {
    const message = createBaseAvailableDatabaseVersion();
    message.majorVersion = object.majorVersion ?? undefined;
    message.name = object.name ?? undefined;
    message.displayName = object.displayName ?? undefined;
    return message;
  },
};

function createBaseSqlInstancesRescheduleMaintenanceRequestBody(): SqlInstancesRescheduleMaintenanceRequestBody {
  return { reschedule: undefined };
}

export const SqlInstancesRescheduleMaintenanceRequestBody: MessageFns<SqlInstancesRescheduleMaintenanceRequestBody> = {
  encode(
    message: SqlInstancesRescheduleMaintenanceRequestBody,
    writer: BinaryWriter = new BinaryWriter(),
  ): BinaryWriter {
    if (message.reschedule !== undefined) {
      SqlInstancesRescheduleMaintenanceRequestBody_Reschedule.encode(message.reschedule, writer.uint32(26).fork())
        .join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): SqlInstancesRescheduleMaintenanceRequestBody {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseSqlInstancesRescheduleMaintenanceRequestBody();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 3:
          if (tag !== 26) {
            break;
          }

          message.reschedule = SqlInstancesRescheduleMaintenanceRequestBody_Reschedule.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): SqlInstancesRescheduleMaintenanceRequestBody {
    return {
      reschedule: isSet(object.reschedule)
        ? SqlInstancesRescheduleMaintenanceRequestBody_Reschedule.fromJSON(object.reschedule)
        : undefined,
    };
  },

  toJSON(message: SqlInstancesRescheduleMaintenanceRequestBody): unknown {
    const obj: any = {};
    if (message.reschedule !== undefined) {
      obj.reschedule = SqlInstancesRescheduleMaintenanceRequestBody_Reschedule.toJSON(message.reschedule);
    }
    return obj;
  },

  create(
    base?: DeepPartial<SqlInstancesRescheduleMaintenanceRequestBody>,
  ): SqlInstancesRescheduleMaintenanceRequestBody {
    return SqlInstancesRescheduleMaintenanceRequestBody.fromPartial(base ?? {});
  },
  fromPartial(
    object: DeepPartial<SqlInstancesRescheduleMaintenanceRequestBody>,
  ): SqlInstancesRescheduleMaintenanceRequestBody {
    const message = createBaseSqlInstancesRescheduleMaintenanceRequestBody();
    message.reschedule = (object.reschedule !== undefined && object.reschedule !== null)
      ? SqlInstancesRescheduleMaintenanceRequestBody_Reschedule.fromPartial(object.reschedule)
      : undefined;
    return message;
  },
};

function createBaseSqlInstancesRescheduleMaintenanceRequestBody_Reschedule(): SqlInstancesRescheduleMaintenanceRequestBody_Reschedule {
  return { rescheduleType: 0, scheduleTime: undefined };
}

export const SqlInstancesRescheduleMaintenanceRequestBody_Reschedule: MessageFns<
  SqlInstancesRescheduleMaintenanceRequestBody_Reschedule
> = {
  encode(
    message: SqlInstancesRescheduleMaintenanceRequestBody_Reschedule,
    writer: BinaryWriter = new BinaryWriter(),
  ): BinaryWriter {
    if (message.rescheduleType !== 0) {
      writer.uint32(8).int32(message.rescheduleType);
    }
    if (message.scheduleTime !== undefined) {
      Timestamp.encode(toTimestamp(message.scheduleTime), writer.uint32(18).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): SqlInstancesRescheduleMaintenanceRequestBody_Reschedule {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseSqlInstancesRescheduleMaintenanceRequestBody_Reschedule();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 8) {
            break;
          }

          message.rescheduleType = reader.int32() as any;
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.scheduleTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): SqlInstancesRescheduleMaintenanceRequestBody_Reschedule {
    return {
      rescheduleType: isSet(object.rescheduleType)
        ? sqlInstancesRescheduleMaintenanceRequestBody_RescheduleTypeFromJSON(object.rescheduleType)
        : 0,
      scheduleTime: isSet(object.scheduleTime) ? fromJsonTimestamp(object.scheduleTime) : undefined,
    };
  },

  toJSON(message: SqlInstancesRescheduleMaintenanceRequestBody_Reschedule): unknown {
    const obj: any = {};
    if (message.rescheduleType !== 0) {
      obj.rescheduleType = sqlInstancesRescheduleMaintenanceRequestBody_RescheduleTypeToJSON(message.rescheduleType);
    }
    if (message.scheduleTime !== undefined) {
      obj.scheduleTime = message.scheduleTime.toISOString();
    }
    return obj;
  },

  create(
    base?: DeepPartial<SqlInstancesRescheduleMaintenanceRequestBody_Reschedule>,
  ): SqlInstancesRescheduleMaintenanceRequestBody_Reschedule {
    return SqlInstancesRescheduleMaintenanceRequestBody_Reschedule.fromPartial(base ?? {});
  },
  fromPartial(
    object: DeepPartial<SqlInstancesRescheduleMaintenanceRequestBody_Reschedule>,
  ): SqlInstancesRescheduleMaintenanceRequestBody_Reschedule {
    const message = createBaseSqlInstancesRescheduleMaintenanceRequestBody_Reschedule();
    message.rescheduleType = object.rescheduleType ?? 0;
    message.scheduleTime = object.scheduleTime ?? undefined;
    return message;
  },
};

function createBaseDemoteMasterContext(): DemoteMasterContext {
  return {
    kind: "",
    verifyGtidConsistency: undefined,
    masterInstanceName: "",
    replicaConfiguration: undefined,
    skipReplicationSetup: false,
  };
}

export const DemoteMasterContext: MessageFns<DemoteMasterContext> = {
  encode(message: DemoteMasterContext, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.kind !== "") {
      writer.uint32(10).string(message.kind);
    }
    if (message.verifyGtidConsistency !== undefined) {
      BoolValue.encode({ value: message.verifyGtidConsistency! }, writer.uint32(18).fork()).join();
    }
    if (message.masterInstanceName !== "") {
      writer.uint32(26).string(message.masterInstanceName);
    }
    if (message.replicaConfiguration !== undefined) {
      DemoteMasterConfiguration.encode(message.replicaConfiguration, writer.uint32(34).fork()).join();
    }
    if (message.skipReplicationSetup !== false) {
      writer.uint32(40).bool(message.skipReplicationSetup);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): DemoteMasterContext {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDemoteMasterContext();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.kind = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.verifyGtidConsistency = BoolValue.decode(reader, reader.uint32()).value;
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.masterInstanceName = reader.string();
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.replicaConfiguration = DemoteMasterConfiguration.decode(reader, reader.uint32());
          continue;
        case 5:
          if (tag !== 40) {
            break;
          }

          message.skipReplicationSetup = reader.bool();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): DemoteMasterContext {
    return {
      kind: isSet(object.kind) ? globalThis.String(object.kind) : "",
      verifyGtidConsistency: isSet(object.verifyGtidConsistency) ? Boolean(object.verifyGtidConsistency) : undefined,
      masterInstanceName: isSet(object.masterInstanceName) ? globalThis.String(object.masterInstanceName) : "",
      replicaConfiguration: isSet(object.replicaConfiguration)
        ? DemoteMasterConfiguration.fromJSON(object.replicaConfiguration)
        : undefined,
      skipReplicationSetup: isSet(object.skipReplicationSetup)
        ? globalThis.Boolean(object.skipReplicationSetup)
        : false,
    };
  },

  toJSON(message: DemoteMasterContext): unknown {
    const obj: any = {};
    if (message.kind !== "") {
      obj.kind = message.kind;
    }
    if (message.verifyGtidConsistency !== undefined) {
      obj.verifyGtidConsistency = message.verifyGtidConsistency;
    }
    if (message.masterInstanceName !== "") {
      obj.masterInstanceName = message.masterInstanceName;
    }
    if (message.replicaConfiguration !== undefined) {
      obj.replicaConfiguration = DemoteMasterConfiguration.toJSON(message.replicaConfiguration);
    }
    if (message.skipReplicationSetup !== false) {
      obj.skipReplicationSetup = message.skipReplicationSetup;
    }
    return obj;
  },

  create(base?: DeepPartial<DemoteMasterContext>): DemoteMasterContext {
    return DemoteMasterContext.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<DemoteMasterContext>): DemoteMasterContext {
    const message = createBaseDemoteMasterContext();
    message.kind = object.kind ?? "";
    message.verifyGtidConsistency = object.verifyGtidConsistency ?? undefined;
    message.masterInstanceName = object.masterInstanceName ?? "";
    message.replicaConfiguration = (object.replicaConfiguration !== undefined && object.replicaConfiguration !== null)
      ? DemoteMasterConfiguration.fromPartial(object.replicaConfiguration)
      : undefined;
    message.skipReplicationSetup = object.skipReplicationSetup ?? false;
    return message;
  },
};

function createBaseDemoteContext(): DemoteContext {
  return { kind: "", sourceRepresentativeInstanceName: "" };
}

export const DemoteContext: MessageFns<DemoteContext> = {
  encode(message: DemoteContext, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.kind !== "") {
      writer.uint32(10).string(message.kind);
    }
    if (message.sourceRepresentativeInstanceName !== "") {
      writer.uint32(18).string(message.sourceRepresentativeInstanceName);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): DemoteContext {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDemoteContext();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.kind = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.sourceRepresentativeInstanceName = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): DemoteContext {
    return {
      kind: isSet(object.kind) ? globalThis.String(object.kind) : "",
      sourceRepresentativeInstanceName: isSet(object.sourceRepresentativeInstanceName)
        ? globalThis.String(object.sourceRepresentativeInstanceName)
        : "",
    };
  },

  toJSON(message: DemoteContext): unknown {
    const obj: any = {};
    if (message.kind !== "") {
      obj.kind = message.kind;
    }
    if (message.sourceRepresentativeInstanceName !== "") {
      obj.sourceRepresentativeInstanceName = message.sourceRepresentativeInstanceName;
    }
    return obj;
  },

  create(base?: DeepPartial<DemoteContext>): DemoteContext {
    return DemoteContext.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<DemoteContext>): DemoteContext {
    const message = createBaseDemoteContext();
    message.kind = object.kind ?? "";
    message.sourceRepresentativeInstanceName = object.sourceRepresentativeInstanceName ?? "";
    return message;
  },
};

function createBaseFailoverContext(): FailoverContext {
  return { settingsVersion: Long.ZERO, kind: "" };
}

export const FailoverContext: MessageFns<FailoverContext> = {
  encode(message: FailoverContext, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (!message.settingsVersion.equals(Long.ZERO)) {
      writer.uint32(8).int64(message.settingsVersion.toString());
    }
    if (message.kind !== "") {
      writer.uint32(18).string(message.kind);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): FailoverContext {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseFailoverContext();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 8) {
            break;
          }

          message.settingsVersion = Long.fromString(reader.int64().toString());
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.kind = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): FailoverContext {
    return {
      settingsVersion: isSet(object.settingsVersion) ? Long.fromValue(object.settingsVersion) : Long.ZERO,
      kind: isSet(object.kind) ? globalThis.String(object.kind) : "",
    };
  },

  toJSON(message: FailoverContext): unknown {
    const obj: any = {};
    if (!message.settingsVersion.equals(Long.ZERO)) {
      obj.settingsVersion = (message.settingsVersion || Long.ZERO).toString();
    }
    if (message.kind !== "") {
      obj.kind = message.kind;
    }
    return obj;
  },

  create(base?: DeepPartial<FailoverContext>): FailoverContext {
    return FailoverContext.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<FailoverContext>): FailoverContext {
    const message = createBaseFailoverContext();
    message.settingsVersion = (object.settingsVersion !== undefined && object.settingsVersion !== null)
      ? Long.fromValue(object.settingsVersion)
      : Long.ZERO;
    message.kind = object.kind ?? "";
    return message;
  },
};

function createBaseRestoreBackupContext(): RestoreBackupContext {
  return { kind: "", backupRunId: Long.ZERO, instanceId: "", project: "" };
}

export const RestoreBackupContext: MessageFns<RestoreBackupContext> = {
  encode(message: RestoreBackupContext, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.kind !== "") {
      writer.uint32(10).string(message.kind);
    }
    if (!message.backupRunId.equals(Long.ZERO)) {
      writer.uint32(16).int64(message.backupRunId.toString());
    }
    if (message.instanceId !== "") {
      writer.uint32(26).string(message.instanceId);
    }
    if (message.project !== "") {
      writer.uint32(34).string(message.project);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): RestoreBackupContext {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseRestoreBackupContext();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.kind = reader.string();
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.backupRunId = Long.fromString(reader.int64().toString());
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.instanceId = reader.string();
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.project = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): RestoreBackupContext {
    return {
      kind: isSet(object.kind) ? globalThis.String(object.kind) : "",
      backupRunId: isSet(object.backupRunId) ? Long.fromValue(object.backupRunId) : Long.ZERO,
      instanceId: isSet(object.instanceId) ? globalThis.String(object.instanceId) : "",
      project: isSet(object.project) ? globalThis.String(object.project) : "",
    };
  },

  toJSON(message: RestoreBackupContext): unknown {
    const obj: any = {};
    if (message.kind !== "") {
      obj.kind = message.kind;
    }
    if (!message.backupRunId.equals(Long.ZERO)) {
      obj.backupRunId = (message.backupRunId || Long.ZERO).toString();
    }
    if (message.instanceId !== "") {
      obj.instanceId = message.instanceId;
    }
    if (message.project !== "") {
      obj.project = message.project;
    }
    return obj;
  },

  create(base?: DeepPartial<RestoreBackupContext>): RestoreBackupContext {
    return RestoreBackupContext.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<RestoreBackupContext>): RestoreBackupContext {
    const message = createBaseRestoreBackupContext();
    message.kind = object.kind ?? "";
    message.backupRunId = (object.backupRunId !== undefined && object.backupRunId !== null)
      ? Long.fromValue(object.backupRunId)
      : Long.ZERO;
    message.instanceId = object.instanceId ?? "";
    message.project = object.project ?? "";
    return message;
  },
};

function createBaseRotateServerCaContext(): RotateServerCaContext {
  return { kind: "", nextVersion: "" };
}

export const RotateServerCaContext: MessageFns<RotateServerCaContext> = {
  encode(message: RotateServerCaContext, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.kind !== "") {
      writer.uint32(10).string(message.kind);
    }
    if (message.nextVersion !== "") {
      writer.uint32(18).string(message.nextVersion);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): RotateServerCaContext {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseRotateServerCaContext();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.kind = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.nextVersion = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): RotateServerCaContext {
    return {
      kind: isSet(object.kind) ? globalThis.String(object.kind) : "",
      nextVersion: isSet(object.nextVersion) ? globalThis.String(object.nextVersion) : "",
    };
  },

  toJSON(message: RotateServerCaContext): unknown {
    const obj: any = {};
    if (message.kind !== "") {
      obj.kind = message.kind;
    }
    if (message.nextVersion !== "") {
      obj.nextVersion = message.nextVersion;
    }
    return obj;
  },

  create(base?: DeepPartial<RotateServerCaContext>): RotateServerCaContext {
    return RotateServerCaContext.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<RotateServerCaContext>): RotateServerCaContext {
    const message = createBaseRotateServerCaContext();
    message.kind = object.kind ?? "";
    message.nextVersion = object.nextVersion ?? "";
    return message;
  },
};

function createBaseTruncateLogContext(): TruncateLogContext {
  return { kind: "", logType: "" };
}

export const TruncateLogContext: MessageFns<TruncateLogContext> = {
  encode(message: TruncateLogContext, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.kind !== "") {
      writer.uint32(10).string(message.kind);
    }
    if (message.logType !== "") {
      writer.uint32(18).string(message.logType);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): TruncateLogContext {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseTruncateLogContext();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.kind = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.logType = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): TruncateLogContext {
    return {
      kind: isSet(object.kind) ? globalThis.String(object.kind) : "",
      logType: isSet(object.logType) ? globalThis.String(object.logType) : "",
    };
  },

  toJSON(message: TruncateLogContext): unknown {
    const obj: any = {};
    if (message.kind !== "") {
      obj.kind = message.kind;
    }
    if (message.logType !== "") {
      obj.logType = message.logType;
    }
    return obj;
  },

  create(base?: DeepPartial<TruncateLogContext>): TruncateLogContext {
    return TruncateLogContext.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<TruncateLogContext>): TruncateLogContext {
    const message = createBaseTruncateLogContext();
    message.kind = object.kind ?? "";
    message.logType = object.logType ?? "";
    return message;
  },
};

function createBaseSqlExternalSyncSettingError(): SqlExternalSyncSettingError {
  return { kind: "", type: 0, detail: "" };
}

export const SqlExternalSyncSettingError: MessageFns<SqlExternalSyncSettingError> = {
  encode(message: SqlExternalSyncSettingError, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.kind !== "") {
      writer.uint32(10).string(message.kind);
    }
    if (message.type !== 0) {
      writer.uint32(16).int32(message.type);
    }
    if (message.detail !== "") {
      writer.uint32(26).string(message.detail);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): SqlExternalSyncSettingError {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseSqlExternalSyncSettingError();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.kind = reader.string();
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.type = reader.int32() as any;
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.detail = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): SqlExternalSyncSettingError {
    return {
      kind: isSet(object.kind) ? globalThis.String(object.kind) : "",
      type: isSet(object.type) ? sqlExternalSyncSettingError_SqlExternalSyncSettingErrorTypeFromJSON(object.type) : 0,
      detail: isSet(object.detail) ? globalThis.String(object.detail) : "",
    };
  },

  toJSON(message: SqlExternalSyncSettingError): unknown {
    const obj: any = {};
    if (message.kind !== "") {
      obj.kind = message.kind;
    }
    if (message.type !== 0) {
      obj.type = sqlExternalSyncSettingError_SqlExternalSyncSettingErrorTypeToJSON(message.type);
    }
    if (message.detail !== "") {
      obj.detail = message.detail;
    }
    return obj;
  },

  create(base?: DeepPartial<SqlExternalSyncSettingError>): SqlExternalSyncSettingError {
    return SqlExternalSyncSettingError.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<SqlExternalSyncSettingError>): SqlExternalSyncSettingError {
    const message = createBaseSqlExternalSyncSettingError();
    message.kind = object.kind ?? "";
    message.type = object.type ?? 0;
    message.detail = object.detail ?? "";
    return message;
  },
};

function createBaseOnPremisesConfiguration(): OnPremisesConfiguration {
  return {
    hostPort: "",
    kind: "",
    username: "",
    password: "",
    caCertificate: "",
    clientCertificate: "",
    clientKey: "",
    dumpFilePath: "",
    sourceInstance: undefined,
  };
}

export const OnPremisesConfiguration: MessageFns<OnPremisesConfiguration> = {
  encode(message: OnPremisesConfiguration, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.hostPort !== "") {
      writer.uint32(10).string(message.hostPort);
    }
    if (message.kind !== "") {
      writer.uint32(18).string(message.kind);
    }
    if (message.username !== "") {
      writer.uint32(26).string(message.username);
    }
    if (message.password !== "") {
      writer.uint32(34).string(message.password);
    }
    if (message.caCertificate !== "") {
      writer.uint32(42).string(message.caCertificate);
    }
    if (message.clientCertificate !== "") {
      writer.uint32(50).string(message.clientCertificate);
    }
    if (message.clientKey !== "") {
      writer.uint32(58).string(message.clientKey);
    }
    if (message.dumpFilePath !== "") {
      writer.uint32(66).string(message.dumpFilePath);
    }
    if (message.sourceInstance !== undefined) {
      InstanceReference.encode(message.sourceInstance, writer.uint32(122).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): OnPremisesConfiguration {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseOnPremisesConfiguration();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.hostPort = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.kind = reader.string();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.username = reader.string();
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.password = reader.string();
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.caCertificate = reader.string();
          continue;
        case 6:
          if (tag !== 50) {
            break;
          }

          message.clientCertificate = reader.string();
          continue;
        case 7:
          if (tag !== 58) {
            break;
          }

          message.clientKey = reader.string();
          continue;
        case 8:
          if (tag !== 66) {
            break;
          }

          message.dumpFilePath = reader.string();
          continue;
        case 15:
          if (tag !== 122) {
            break;
          }

          message.sourceInstance = InstanceReference.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): OnPremisesConfiguration {
    return {
      hostPort: isSet(object.hostPort) ? globalThis.String(object.hostPort) : "",
      kind: isSet(object.kind) ? globalThis.String(object.kind) : "",
      username: isSet(object.username) ? globalThis.String(object.username) : "",
      password: isSet(object.password) ? globalThis.String(object.password) : "",
      caCertificate: isSet(object.caCertificate) ? globalThis.String(object.caCertificate) : "",
      clientCertificate: isSet(object.clientCertificate) ? globalThis.String(object.clientCertificate) : "",
      clientKey: isSet(object.clientKey) ? globalThis.String(object.clientKey) : "",
      dumpFilePath: isSet(object.dumpFilePath) ? globalThis.String(object.dumpFilePath) : "",
      sourceInstance: isSet(object.sourceInstance) ? InstanceReference.fromJSON(object.sourceInstance) : undefined,
    };
  },

  toJSON(message: OnPremisesConfiguration): unknown {
    const obj: any = {};
    if (message.hostPort !== "") {
      obj.hostPort = message.hostPort;
    }
    if (message.kind !== "") {
      obj.kind = message.kind;
    }
    if (message.username !== "") {
      obj.username = message.username;
    }
    if (message.password !== "") {
      obj.password = message.password;
    }
    if (message.caCertificate !== "") {
      obj.caCertificate = message.caCertificate;
    }
    if (message.clientCertificate !== "") {
      obj.clientCertificate = message.clientCertificate;
    }
    if (message.clientKey !== "") {
      obj.clientKey = message.clientKey;
    }
    if (message.dumpFilePath !== "") {
      obj.dumpFilePath = message.dumpFilePath;
    }
    if (message.sourceInstance !== undefined) {
      obj.sourceInstance = InstanceReference.toJSON(message.sourceInstance);
    }
    return obj;
  },

  create(base?: DeepPartial<OnPremisesConfiguration>): OnPremisesConfiguration {
    return OnPremisesConfiguration.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<OnPremisesConfiguration>): OnPremisesConfiguration {
    const message = createBaseOnPremisesConfiguration();
    message.hostPort = object.hostPort ?? "";
    message.kind = object.kind ?? "";
    message.username = object.username ?? "";
    message.password = object.password ?? "";
    message.caCertificate = object.caCertificate ?? "";
    message.clientCertificate = object.clientCertificate ?? "";
    message.clientKey = object.clientKey ?? "";
    message.dumpFilePath = object.dumpFilePath ?? "";
    message.sourceInstance = (object.sourceInstance !== undefined && object.sourceInstance !== null)
      ? InstanceReference.fromPartial(object.sourceInstance)
      : undefined;
    return message;
  },
};

function createBaseReplicaConfiguration(): ReplicaConfiguration {
  return { kind: "", mysqlReplicaConfiguration: undefined, failoverTarget: undefined, cascadableReplica: undefined };
}

export const ReplicaConfiguration: MessageFns<ReplicaConfiguration> = {
  encode(message: ReplicaConfiguration, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.kind !== "") {
      writer.uint32(10).string(message.kind);
    }
    if (message.mysqlReplicaConfiguration !== undefined) {
      MySqlReplicaConfiguration.encode(message.mysqlReplicaConfiguration, writer.uint32(18).fork()).join();
    }
    if (message.failoverTarget !== undefined) {
      BoolValue.encode({ value: message.failoverTarget! }, writer.uint32(26).fork()).join();
    }
    if (message.cascadableReplica !== undefined) {
      BoolValue.encode({ value: message.cascadableReplica! }, writer.uint32(42).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ReplicaConfiguration {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseReplicaConfiguration();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.kind = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.mysqlReplicaConfiguration = MySqlReplicaConfiguration.decode(reader, reader.uint32());
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.failoverTarget = BoolValue.decode(reader, reader.uint32()).value;
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.cascadableReplica = BoolValue.decode(reader, reader.uint32()).value;
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ReplicaConfiguration {
    return {
      kind: isSet(object.kind) ? globalThis.String(object.kind) : "",
      mysqlReplicaConfiguration: isSet(object.mysqlReplicaConfiguration)
        ? MySqlReplicaConfiguration.fromJSON(object.mysqlReplicaConfiguration)
        : undefined,
      failoverTarget: isSet(object.failoverTarget) ? Boolean(object.failoverTarget) : undefined,
      cascadableReplica: isSet(object.cascadableReplica) ? Boolean(object.cascadableReplica) : undefined,
    };
  },

  toJSON(message: ReplicaConfiguration): unknown {
    const obj: any = {};
    if (message.kind !== "") {
      obj.kind = message.kind;
    }
    if (message.mysqlReplicaConfiguration !== undefined) {
      obj.mysqlReplicaConfiguration = MySqlReplicaConfiguration.toJSON(message.mysqlReplicaConfiguration);
    }
    if (message.failoverTarget !== undefined) {
      obj.failoverTarget = message.failoverTarget;
    }
    if (message.cascadableReplica !== undefined) {
      obj.cascadableReplica = message.cascadableReplica;
    }
    return obj;
  },

  create(base?: DeepPartial<ReplicaConfiguration>): ReplicaConfiguration {
    return ReplicaConfiguration.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ReplicaConfiguration>): ReplicaConfiguration {
    const message = createBaseReplicaConfiguration();
    message.kind = object.kind ?? "";
    message.mysqlReplicaConfiguration =
      (object.mysqlReplicaConfiguration !== undefined && object.mysqlReplicaConfiguration !== null)
        ? MySqlReplicaConfiguration.fromPartial(object.mysqlReplicaConfiguration)
        : undefined;
    message.failoverTarget = object.failoverTarget ?? undefined;
    message.cascadableReplica = object.cascadableReplica ?? undefined;
    return message;
  },
};

function createBaseSqlInstancesAcquireSsrsLeaseRequest(): SqlInstancesAcquireSsrsLeaseRequest {
  return { instance: "", project: "", body: undefined };
}

export const SqlInstancesAcquireSsrsLeaseRequest: MessageFns<SqlInstancesAcquireSsrsLeaseRequest> = {
  encode(message: SqlInstancesAcquireSsrsLeaseRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.instance !== "") {
      writer.uint32(10).string(message.instance);
    }
    if (message.project !== "") {
      writer.uint32(18).string(message.project);
    }
    if (message.body !== undefined) {
      InstancesAcquireSsrsLeaseRequest.encode(message.body, writer.uint32(802).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): SqlInstancesAcquireSsrsLeaseRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseSqlInstancesAcquireSsrsLeaseRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.instance = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.project = reader.string();
          continue;
        case 100:
          if (tag !== 802) {
            break;
          }

          message.body = InstancesAcquireSsrsLeaseRequest.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): SqlInstancesAcquireSsrsLeaseRequest {
    return {
      instance: isSet(object.instance) ? globalThis.String(object.instance) : "",
      project: isSet(object.project) ? globalThis.String(object.project) : "",
      body: isSet(object.body) ? InstancesAcquireSsrsLeaseRequest.fromJSON(object.body) : undefined,
    };
  },

  toJSON(message: SqlInstancesAcquireSsrsLeaseRequest): unknown {
    const obj: any = {};
    if (message.instance !== "") {
      obj.instance = message.instance;
    }
    if (message.project !== "") {
      obj.project = message.project;
    }
    if (message.body !== undefined) {
      obj.body = InstancesAcquireSsrsLeaseRequest.toJSON(message.body);
    }
    return obj;
  },

  create(base?: DeepPartial<SqlInstancesAcquireSsrsLeaseRequest>): SqlInstancesAcquireSsrsLeaseRequest {
    return SqlInstancesAcquireSsrsLeaseRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<SqlInstancesAcquireSsrsLeaseRequest>): SqlInstancesAcquireSsrsLeaseRequest {
    const message = createBaseSqlInstancesAcquireSsrsLeaseRequest();
    message.instance = object.instance ?? "";
    message.project = object.project ?? "";
    message.body = (object.body !== undefined && object.body !== null)
      ? InstancesAcquireSsrsLeaseRequest.fromPartial(object.body)
      : undefined;
    return message;
  },
};

function createBaseSqlInstancesAcquireSsrsLeaseResponse(): SqlInstancesAcquireSsrsLeaseResponse {
  return { operationId: "" };
}

export const SqlInstancesAcquireSsrsLeaseResponse: MessageFns<SqlInstancesAcquireSsrsLeaseResponse> = {
  encode(message: SqlInstancesAcquireSsrsLeaseResponse, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.operationId !== "") {
      writer.uint32(10).string(message.operationId);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): SqlInstancesAcquireSsrsLeaseResponse {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseSqlInstancesAcquireSsrsLeaseResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.operationId = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): SqlInstancesAcquireSsrsLeaseResponse {
    return { operationId: isSet(object.operationId) ? globalThis.String(object.operationId) : "" };
  },

  toJSON(message: SqlInstancesAcquireSsrsLeaseResponse): unknown {
    const obj: any = {};
    if (message.operationId !== "") {
      obj.operationId = message.operationId;
    }
    return obj;
  },

  create(base?: DeepPartial<SqlInstancesAcquireSsrsLeaseResponse>): SqlInstancesAcquireSsrsLeaseResponse {
    return SqlInstancesAcquireSsrsLeaseResponse.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<SqlInstancesAcquireSsrsLeaseResponse>): SqlInstancesAcquireSsrsLeaseResponse {
    const message = createBaseSqlInstancesAcquireSsrsLeaseResponse();
    message.operationId = object.operationId ?? "";
    return message;
  },
};

function createBaseSqlInstancesReleaseSsrsLeaseRequest(): SqlInstancesReleaseSsrsLeaseRequest {
  return { instance: "", project: "" };
}

export const SqlInstancesReleaseSsrsLeaseRequest: MessageFns<SqlInstancesReleaseSsrsLeaseRequest> = {
  encode(message: SqlInstancesReleaseSsrsLeaseRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.instance !== "") {
      writer.uint32(10).string(message.instance);
    }
    if (message.project !== "") {
      writer.uint32(18).string(message.project);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): SqlInstancesReleaseSsrsLeaseRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseSqlInstancesReleaseSsrsLeaseRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.instance = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.project = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): SqlInstancesReleaseSsrsLeaseRequest {
    return {
      instance: isSet(object.instance) ? globalThis.String(object.instance) : "",
      project: isSet(object.project) ? globalThis.String(object.project) : "",
    };
  },

  toJSON(message: SqlInstancesReleaseSsrsLeaseRequest): unknown {
    const obj: any = {};
    if (message.instance !== "") {
      obj.instance = message.instance;
    }
    if (message.project !== "") {
      obj.project = message.project;
    }
    return obj;
  },

  create(base?: DeepPartial<SqlInstancesReleaseSsrsLeaseRequest>): SqlInstancesReleaseSsrsLeaseRequest {
    return SqlInstancesReleaseSsrsLeaseRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<SqlInstancesReleaseSsrsLeaseRequest>): SqlInstancesReleaseSsrsLeaseRequest {
    const message = createBaseSqlInstancesReleaseSsrsLeaseRequest();
    message.instance = object.instance ?? "";
    message.project = object.project ?? "";
    return message;
  },
};

function createBaseSqlInstancesReleaseSsrsLeaseResponse(): SqlInstancesReleaseSsrsLeaseResponse {
  return { operationId: "" };
}

export const SqlInstancesReleaseSsrsLeaseResponse: MessageFns<SqlInstancesReleaseSsrsLeaseResponse> = {
  encode(message: SqlInstancesReleaseSsrsLeaseResponse, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.operationId !== "") {
      writer.uint32(10).string(message.operationId);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): SqlInstancesReleaseSsrsLeaseResponse {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseSqlInstancesReleaseSsrsLeaseResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.operationId = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): SqlInstancesReleaseSsrsLeaseResponse {
    return { operationId: isSet(object.operationId) ? globalThis.String(object.operationId) : "" };
  },

  toJSON(message: SqlInstancesReleaseSsrsLeaseResponse): unknown {
    const obj: any = {};
    if (message.operationId !== "") {
      obj.operationId = message.operationId;
    }
    return obj;
  },

  create(base?: DeepPartial<SqlInstancesReleaseSsrsLeaseResponse>): SqlInstancesReleaseSsrsLeaseResponse {
    return SqlInstancesReleaseSsrsLeaseResponse.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<SqlInstancesReleaseSsrsLeaseResponse>): SqlInstancesReleaseSsrsLeaseResponse {
    const message = createBaseSqlInstancesReleaseSsrsLeaseResponse();
    message.operationId = object.operationId ?? "";
    return message;
  },
};

/** Service to manage Cloud SQL instances. */
export type SqlInstancesServiceDefinition = typeof SqlInstancesServiceDefinition;
export const SqlInstancesServiceDefinition = {
  name: "SqlInstancesService",
  fullName: "google.cloud.sql.v1.SqlInstancesService",
  methods: {
    /**
     * Adds a new trusted Certificate Authority (CA) version for the specified
     * instance. Required to prepare for a certificate rotation. If a CA version
     * was previously added but never used in a certificate rotation, this
     * operation replaces that version. There cannot be more than one CA version
     * waiting to be rotated in. For instances that have enabled Certificate
     * Authority Service (CAS) based server CA, please use AddServerCertificate to
     * add a new server certificate.
     */
    addServerCa: {
      name: "AddServerCa",
      requestType: SqlInstancesAddServerCaRequest,
      requestStream: false,
      responseType: Operation,
      responseStream: false,
      options: {
        _unknownFields: {
          578365826: [
            Buffer.from([
              57,
              34,
              55,
              47,
              118,
              49,
              47,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              123,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              125,
              47,
              105,
              110,
              115,
              116,
              97,
              110,
              99,
              101,
              115,
              47,
              123,
              105,
              110,
              115,
              116,
              97,
              110,
              99,
              101,
              125,
              47,
              97,
              100,
              100,
              83,
              101,
              114,
              118,
              101,
              114,
              67,
              97,
            ]),
          ],
        },
      },
    },
    /**
     * Creates a Cloud SQL instance as a clone of the source instance. Using this
     * operation might cause your instance to restart.
     */
    clone: {
      name: "Clone",
      requestType: SqlInstancesCloneRequest,
      requestStream: false,
      responseType: Operation,
      responseStream: false,
      options: {
        _unknownFields: {
          578365826: [
            Buffer.from([
              57,
              58,
              4,
              98,
              111,
              100,
              121,
              34,
              49,
              47,
              118,
              49,
              47,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              123,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              125,
              47,
              105,
              110,
              115,
              116,
              97,
              110,
              99,
              101,
              115,
              47,
              123,
              105,
              110,
              115,
              116,
              97,
              110,
              99,
              101,
              125,
              47,
              99,
              108,
              111,
              110,
              101,
            ]),
          ],
        },
      },
    },
    /** Deletes a Cloud SQL instance. */
    delete: {
      name: "Delete",
      requestType: SqlInstancesDeleteRequest,
      requestStream: false,
      responseType: Operation,
      responseStream: false,
      options: {
        _unknownFields: {
          578365826: [
            Buffer.from([
              45,
              42,
              43,
              47,
              118,
              49,
              47,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              123,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              125,
              47,
              105,
              110,
              115,
              116,
              97,
              110,
              99,
              101,
              115,
              47,
              123,
              105,
              110,
              115,
              116,
              97,
              110,
              99,
              101,
              125,
            ]),
          ],
        },
      },
    },
    /**
     * Demotes the stand-alone instance to be a Cloud SQL read replica for an
     * external database server.
     */
    demoteMaster: {
      name: "DemoteMaster",
      requestType: SqlInstancesDemoteMasterRequest,
      requestStream: false,
      responseType: Operation,
      responseStream: false,
      options: {
        _unknownFields: {
          578365826: [
            Buffer.from([
              64,
              58,
              4,
              98,
              111,
              100,
              121,
              34,
              56,
              47,
              118,
              49,
              47,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              123,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              125,
              47,
              105,
              110,
              115,
              116,
              97,
              110,
              99,
              101,
              115,
              47,
              123,
              105,
              110,
              115,
              116,
              97,
              110,
              99,
              101,
              125,
              47,
              100,
              101,
              109,
              111,
              116,
              101,
              77,
              97,
              115,
              116,
              101,
              114,
            ]),
          ],
        },
      },
    },
    /**
     * Demotes an existing standalone instance to be a Cloud SQL read replica
     * for an external database server.
     */
    demote: {
      name: "Demote",
      requestType: SqlInstancesDemoteRequest,
      requestStream: false,
      responseType: Operation,
      responseStream: false,
      options: {
        _unknownFields: {
          578365826: [
            Buffer.from([
              58,
              58,
              4,
              98,
              111,
              100,
              121,
              34,
              50,
              47,
              118,
              49,
              47,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              123,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              125,
              47,
              105,
              110,
              115,
              116,
              97,
              110,
              99,
              101,
              115,
              47,
              123,
              105,
              110,
              115,
              116,
              97,
              110,
              99,
              101,
              125,
              47,
              100,
              101,
              109,
              111,
              116,
              101,
            ]),
          ],
        },
      },
    },
    /**
     * Exports data from a Cloud SQL instance to a Cloud Storage bucket as a SQL
     * dump or CSV file.
     */
    export: {
      name: "Export",
      requestType: SqlInstancesExportRequest,
      requestStream: false,
      responseType: Operation,
      responseStream: false,
      options: {
        _unknownFields: {
          578365826: [
            Buffer.from([
              58,
              58,
              4,
              98,
              111,
              100,
              121,
              34,
              50,
              47,
              118,
              49,
              47,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              123,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              125,
              47,
              105,
              110,
              115,
              116,
              97,
              110,
              99,
              101,
              115,
              47,
              123,
              105,
              110,
              115,
              116,
              97,
              110,
              99,
              101,
              125,
              47,
              101,
              120,
              112,
              111,
              114,
              116,
            ]),
          ],
        },
      },
    },
    /**
     * Initiates a manual failover of a high availability (HA) primary instance
     * to a standby instance, which becomes the primary instance. Users are
     * then rerouted to the new primary. For more information, see the
     * [Overview of high
     * availability](https://cloud.google.com/sql/docs/mysql/high-availability)
     * page in the Cloud SQL documentation.
     * If using Legacy HA (MySQL only), this causes the instance to failover to
     * its failover replica instance.
     */
    failover: {
      name: "Failover",
      requestType: SqlInstancesFailoverRequest,
      requestStream: false,
      responseType: Operation,
      responseStream: false,
      options: {
        _unknownFields: {
          578365826: [
            Buffer.from([
              60,
              58,
              4,
              98,
              111,
              100,
              121,
              34,
              52,
              47,
              118,
              49,
              47,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              123,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              125,
              47,
              105,
              110,
              115,
              116,
              97,
              110,
              99,
              101,
              115,
              47,
              123,
              105,
              110,
              115,
              116,
              97,
              110,
              99,
              101,
              125,
              47,
              102,
              97,
              105,
              108,
              111,
              118,
              101,
              114,
            ]),
          ],
        },
      },
    },
    /** Reencrypt CMEK instance with latest key version. */
    reencrypt: {
      name: "Reencrypt",
      requestType: SqlInstancesReencryptRequest,
      requestStream: false,
      responseType: Operation,
      responseStream: false,
      options: {
        _unknownFields: {
          578365826: [
            Buffer.from([
              61,
              58,
              4,
              98,
              111,
              100,
              121,
              34,
              53,
              47,
              118,
              49,
              47,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              123,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              125,
              47,
              105,
              110,
              115,
              116,
              97,
              110,
              99,
              101,
              115,
              47,
              123,
              105,
              110,
              115,
              116,
              97,
              110,
              99,
              101,
              125,
              47,
              114,
              101,
              101,
              110,
              99,
              114,
              121,
              112,
              116,
            ]),
          ],
        },
      },
    },
    /** Retrieves a resource containing information about a Cloud SQL instance. */
    get: {
      name: "Get",
      requestType: SqlInstancesGetRequest,
      requestStream: false,
      responseType: DatabaseInstance,
      responseStream: false,
      options: {
        _unknownFields: {
          578365826: [
            Buffer.from([
              45,
              18,
              43,
              47,
              118,
              49,
              47,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              123,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              125,
              47,
              105,
              110,
              115,
              116,
              97,
              110,
              99,
              101,
              115,
              47,
              123,
              105,
              110,
              115,
              116,
              97,
              110,
              99,
              101,
              125,
            ]),
          ],
        },
      },
    },
    /**
     * Imports data into a Cloud SQL instance from a SQL dump  or CSV file in
     * Cloud Storage.
     */
    import: {
      name: "Import",
      requestType: SqlInstancesImportRequest,
      requestStream: false,
      responseType: Operation,
      responseStream: false,
      options: {
        _unknownFields: {
          578365826: [
            Buffer.from([
              58,
              58,
              4,
              98,
              111,
              100,
              121,
              34,
              50,
              47,
              118,
              49,
              47,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              123,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              125,
              47,
              105,
              110,
              115,
              116,
              97,
              110,
              99,
              101,
              115,
              47,
              123,
              105,
              110,
              115,
              116,
              97,
              110,
              99,
              101,
              125,
              47,
              105,
              109,
              112,
              111,
              114,
              116,
            ]),
          ],
        },
      },
    },
    /** Creates a new Cloud SQL instance. */
    insert: {
      name: "Insert",
      requestType: SqlInstancesInsertRequest,
      requestStream: false,
      responseType: Operation,
      responseStream: false,
      options: {
        _unknownFields: {
          578365826: [
            Buffer.from([
              40,
              58,
              4,
              98,
              111,
              100,
              121,
              34,
              32,
              47,
              118,
              49,
              47,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              123,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              125,
              47,
              105,
              110,
              115,
              116,
              97,
              110,
              99,
              101,
              115,
            ]),
          ],
        },
      },
    },
    /** Lists instances under a given project. */
    list: {
      name: "List",
      requestType: SqlInstancesListRequest,
      requestStream: false,
      responseType: InstancesListResponse,
      responseStream: false,
      options: {
        _unknownFields: {
          578365826: [
            Buffer.from([
              34,
              18,
              32,
              47,
              118,
              49,
              47,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              123,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              125,
              47,
              105,
              110,
              115,
              116,
              97,
              110,
              99,
              101,
              115,
            ]),
          ],
        },
      },
    },
    /**
     * Lists all of the trusted Certificate Authorities (CAs) for the specified
     * instance. There can be up to three CAs listed: the CA that was used to sign
     * the certificate that is currently in use, a CA that has been added but not
     * yet used to sign a certificate, and a CA used to sign a certificate that
     * has previously rotated out.
     */
    listServerCas: {
      name: "ListServerCas",
      requestType: SqlInstancesListServerCasRequest,
      requestStream: false,
      responseType: InstancesListServerCasResponse,
      responseStream: false,
      options: {
        _unknownFields: {
          578365826: [
            Buffer.from([
              59,
              18,
              57,
              47,
              118,
              49,
              47,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              123,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              125,
              47,
              105,
              110,
              115,
              116,
              97,
              110,
              99,
              101,
              115,
              47,
              123,
              105,
              110,
              115,
              116,
              97,
              110,
              99,
              101,
              125,
              47,
              108,
              105,
              115,
              116,
              83,
              101,
              114,
              118,
              101,
              114,
              67,
              97,
              115,
            ]),
          ],
        },
      },
    },
    /**
     * Partially updates settings of a Cloud SQL instance by merging the request
     * with the current configuration. This method supports patch semantics.
     */
    patch: {
      name: "Patch",
      requestType: SqlInstancesPatchRequest,
      requestStream: false,
      responseType: Operation,
      responseStream: false,
      options: {
        _unknownFields: {
          578365826: [
            Buffer.from([
              51,
              58,
              4,
              98,
              111,
              100,
              121,
              50,
              43,
              47,
              118,
              49,
              47,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              123,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              125,
              47,
              105,
              110,
              115,
              116,
              97,
              110,
              99,
              101,
              115,
              47,
              123,
              105,
              110,
              115,
              116,
              97,
              110,
              99,
              101,
              125,
            ]),
          ],
        },
      },
    },
    /**
     * Promotes the read replica instance to be an independent Cloud SQL
     * primary instance.
     * Using this operation might cause your instance to restart.
     */
    promoteReplica: {
      name: "PromoteReplica",
      requestType: SqlInstancesPromoteReplicaRequest,
      requestStream: false,
      responseType: Operation,
      responseStream: false,
      options: {
        _unknownFields: {
          578365826: [
            Buffer.from([
              60,
              34,
              58,
              47,
              118,
              49,
              47,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              123,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              125,
              47,
              105,
              110,
              115,
              116,
              97,
              110,
              99,
              101,
              115,
              47,
              123,
              105,
              110,
              115,
              116,
              97,
              110,
              99,
              101,
              125,
              47,
              112,
              114,
              111,
              109,
              111,
              116,
              101,
              82,
              101,
              112,
              108,
              105,
              99,
              97,
            ]),
          ],
        },
      },
    },
    /**
     * Switches over from the primary instance to the designated DR replica
     * instance.
     */
    switchover: {
      name: "Switchover",
      requestType: SqlInstancesSwitchoverRequest,
      requestStream: false,
      responseType: Operation,
      responseStream: false,
      options: {
        _unknownFields: {
          578365826: [
            Buffer.from([
              56,
              34,
              54,
              47,
              118,
              49,
              47,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              123,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              125,
              47,
              105,
              110,
              115,
              116,
              97,
              110,
              99,
              101,
              115,
              47,
              123,
              105,
              110,
              115,
              116,
              97,
              110,
              99,
              101,
              125,
              47,
              115,
              119,
              105,
              116,
              99,
              104,
              111,
              118,
              101,
              114,
            ]),
          ],
        },
      },
    },
    /**
     * Deletes all client certificates and generates a new server SSL certificate
     * for the instance.
     */
    resetSslConfig: {
      name: "ResetSslConfig",
      requestType: SqlInstancesResetSslConfigRequest,
      requestStream: false,
      responseType: Operation,
      responseStream: false,
      options: {
        _unknownFields: {
          578365826: [
            Buffer.from([
              60,
              34,
              58,
              47,
              118,
              49,
              47,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              123,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              125,
              47,
              105,
              110,
              115,
              116,
              97,
              110,
              99,
              101,
              115,
              47,
              123,
              105,
              110,
              115,
              116,
              97,
              110,
              99,
              101,
              125,
              47,
              114,
              101,
              115,
              101,
              116,
              83,
              115,
              108,
              67,
              111,
              110,
              102,
              105,
              103,
            ]),
          ],
        },
      },
    },
    /** Restarts a Cloud SQL instance. */
    restart: {
      name: "Restart",
      requestType: SqlInstancesRestartRequest,
      requestStream: false,
      responseType: Operation,
      responseStream: false,
      options: {
        _unknownFields: {
          578365826: [
            Buffer.from([
              53,
              34,
              51,
              47,
              118,
              49,
              47,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              123,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              125,
              47,
              105,
              110,
              115,
              116,
              97,
              110,
              99,
              101,
              115,
              47,
              123,
              105,
              110,
              115,
              116,
              97,
              110,
              99,
              101,
              125,
              47,
              114,
              101,
              115,
              116,
              97,
              114,
              116,
            ]),
          ],
        },
      },
    },
    /**
     * Restores a backup of a Cloud SQL instance. Using this operation might cause
     * your instance to restart.
     */
    restoreBackup: {
      name: "RestoreBackup",
      requestType: SqlInstancesRestoreBackupRequest,
      requestStream: false,
      responseType: Operation,
      responseStream: false,
      options: {
        _unknownFields: {
          578365826: [
            Buffer.from([
              65,
              58,
              4,
              98,
              111,
              100,
              121,
              34,
              57,
              47,
              118,
              49,
              47,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              123,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              125,
              47,
              105,
              110,
              115,
              116,
              97,
              110,
              99,
              101,
              115,
              47,
              123,
              105,
              110,
              115,
              116,
              97,
              110,
              99,
              101,
              125,
              47,
              114,
              101,
              115,
              116,
              111,
              114,
              101,
              66,
              97,
              99,
              107,
              117,
              112,
            ]),
          ],
        },
      },
    },
    /**
     * Rotates the server certificate to one signed by the Certificate Authority
     * (CA) version previously added with the addServerCA method. For instances
     * that have enabled Certificate Authority Service (CAS) based server CA,
     * please use RotateServerCertificate to rotate the server certificate.
     */
    rotateServerCa: {
      name: "RotateServerCa",
      requestType: SqlInstancesRotateServerCaRequest,
      requestStream: false,
      responseType: Operation,
      responseStream: false,
      options: {
        _unknownFields: {
          578365826: [
            Buffer.from([
              66,
              58,
              4,
              98,
              111,
              100,
              121,
              34,
              58,
              47,
              118,
              49,
              47,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              123,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              125,
              47,
              105,
              110,
              115,
              116,
              97,
              110,
              99,
              101,
              115,
              47,
              123,
              105,
              110,
              115,
              116,
              97,
              110,
              99,
              101,
              125,
              47,
              114,
              111,
              116,
              97,
              116,
              101,
              83,
              101,
              114,
              118,
              101,
              114,
              67,
              97,
            ]),
          ],
        },
      },
    },
    /** Starts the replication in the read replica instance. */
    startReplica: {
      name: "StartReplica",
      requestType: SqlInstancesStartReplicaRequest,
      requestStream: false,
      responseType: Operation,
      responseStream: false,
      options: {
        _unknownFields: {
          578365826: [
            Buffer.from([
              58,
              34,
              56,
              47,
              118,
              49,
              47,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              123,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              125,
              47,
              105,
              110,
              115,
              116,
              97,
              110,
              99,
              101,
              115,
              47,
              123,
              105,
              110,
              115,
              116,
              97,
              110,
              99,
              101,
              125,
              47,
              115,
              116,
              97,
              114,
              116,
              82,
              101,
              112,
              108,
              105,
              99,
              97,
            ]),
          ],
        },
      },
    },
    /** Stops the replication in the read replica instance. */
    stopReplica: {
      name: "StopReplica",
      requestType: SqlInstancesStopReplicaRequest,
      requestStream: false,
      responseType: Operation,
      responseStream: false,
      options: {
        _unknownFields: {
          578365826: [
            Buffer.from([
              57,
              34,
              55,
              47,
              118,
              49,
              47,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              123,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              125,
              47,
              105,
              110,
              115,
              116,
              97,
              110,
              99,
              101,
              115,
              47,
              123,
              105,
              110,
              115,
              116,
              97,
              110,
              99,
              101,
              125,
              47,
              115,
              116,
              111,
              112,
              82,
              101,
              112,
              108,
              105,
              99,
              97,
            ]),
          ],
        },
      },
    },
    /**
     * Truncate MySQL general and slow query log tables
     * MySQL only.
     */
    truncateLog: {
      name: "TruncateLog",
      requestType: SqlInstancesTruncateLogRequest,
      requestStream: false,
      responseType: Operation,
      responseStream: false,
      options: {
        _unknownFields: {
          578365826: [
            Buffer.from([
              63,
              58,
              4,
              98,
              111,
              100,
              121,
              34,
              55,
              47,
              118,
              49,
              47,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              123,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              125,
              47,
              105,
              110,
              115,
              116,
              97,
              110,
              99,
              101,
              115,
              47,
              123,
              105,
              110,
              115,
              116,
              97,
              110,
              99,
              101,
              125,
              47,
              116,
              114,
              117,
              110,
              99,
              97,
              116,
              101,
              76,
              111,
              103,
            ]),
          ],
        },
      },
    },
    /**
     * Updates settings of a Cloud SQL instance. Using this operation might cause
     * your instance to restart.
     */
    update: {
      name: "Update",
      requestType: SqlInstancesUpdateRequest,
      requestStream: false,
      responseType: Operation,
      responseStream: false,
      options: {
        _unknownFields: {
          578365826: [
            Buffer.from([
              51,
              58,
              4,
              98,
              111,
              100,
              121,
              26,
              43,
              47,
              118,
              49,
              47,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              123,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              125,
              47,
              105,
              110,
              115,
              116,
              97,
              110,
              99,
              101,
              115,
              47,
              123,
              105,
              110,
              115,
              116,
              97,
              110,
              99,
              101,
              125,
            ]),
          ],
        },
      },
    },
    /**
     * Generates a short-lived X509 certificate containing the provided public key
     * and signed by a private key specific to the target instance. Users may use
     * the certificate to authenticate as themselves when connecting to the
     * database.
     */
    createEphemeral: {
      name: "CreateEphemeral",
      requestType: SqlInstancesCreateEphemeralCertRequest,
      requestStream: false,
      responseType: SslCert,
      responseStream: false,
      options: {
        _unknownFields: {
          578365826: [
            Buffer.from([
              67,
              58,
              4,
              98,
              111,
              100,
              121,
              34,
              59,
              47,
              118,
              49,
              47,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              123,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              125,
              47,
              105,
              110,
              115,
              116,
              97,
              110,
              99,
              101,
              115,
              47,
              123,
              105,
              110,
              115,
              116,
              97,
              110,
              99,
              101,
              125,
              47,
              99,
              114,
              101,
              97,
              116,
              101,
              69,
              112,
              104,
              101,
              109,
              101,
              114,
              97,
              108,
            ]),
          ],
        },
      },
    },
    /** Reschedules the maintenance on the given instance. */
    rescheduleMaintenance: {
      name: "RescheduleMaintenance",
      requestType: SqlInstancesRescheduleMaintenanceRequest,
      requestStream: false,
      responseType: Operation,
      responseStream: false,
      options: {
        _unknownFields: {
          578365826: [
            Buffer.from([
              73,
              58,
              4,
              98,
              111,
              100,
              121,
              34,
              65,
              47,
              118,
              49,
              47,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              123,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              125,
              47,
              105,
              110,
              115,
              116,
              97,
              110,
              99,
              101,
              115,
              47,
              123,
              105,
              110,
              115,
              116,
              97,
              110,
              99,
              101,
              125,
              47,
              114,
              101,
              115,
              99,
              104,
              101,
              100,
              117,
              108,
              101,
              77,
              97,
              105,
              110,
              116,
              101,
              110,
              97,
              110,
              99,
              101,
            ]),
          ],
        },
      },
    },
    /** Verify External primary instance external sync settings. */
    verifyExternalSyncSettings: {
      name: "VerifyExternalSyncSettings",
      requestType: SqlInstancesVerifyExternalSyncSettingsRequest,
      requestStream: false,
      responseType: SqlInstancesVerifyExternalSyncSettingsResponse,
      responseStream: false,
      options: {
        _unknownFields: {
          578365826: [
            Buffer.from([
              75,
              58,
              1,
              42,
              34,
              70,
              47,
              118,
              49,
              47,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              123,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              125,
              47,
              105,
              110,
              115,
              116,
              97,
              110,
              99,
              101,
              115,
              47,
              123,
              105,
              110,
              115,
              116,
              97,
              110,
              99,
              101,
              125,
              47,
              118,
              101,
              114,
              105,
              102,
              121,
              69,
              120,
              116,
              101,
              114,
              110,
              97,
              108,
              83,
              121,
              110,
              99,
              83,
              101,
              116,
              116,
              105,
              110,
              103,
              115,
            ]),
          ],
        },
      },
    },
    /** Start External primary instance migration. */
    startExternalSync: {
      name: "StartExternalSync",
      requestType: SqlInstancesStartExternalSyncRequest,
      requestStream: false,
      responseType: Operation,
      responseStream: false,
      options: {
        _unknownFields: {
          578365826: [
            Buffer.from([
              66,
              58,
              1,
              42,
              34,
              61,
              47,
              118,
              49,
              47,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              123,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              125,
              47,
              105,
              110,
              115,
              116,
              97,
              110,
              99,
              101,
              115,
              47,
              123,
              105,
              110,
              115,
              116,
              97,
              110,
              99,
              101,
              125,
              47,
              115,
              116,
              97,
              114,
              116,
              69,
              120,
              116,
              101,
              114,
              110,
              97,
              108,
              83,
              121,
              110,
              99,
            ]),
          ],
        },
      },
    },
    /** Perform Disk Shrink on primary instance. */
    performDiskShrink: {
      name: "PerformDiskShrink",
      requestType: SqlInstancesPerformDiskShrinkRequest,
      requestStream: false,
      responseType: Operation,
      responseStream: false,
      options: {
        _unknownFields: {
          578365826: [
            Buffer.from([
              69,
              58,
              4,
              98,
              111,
              100,
              121,
              34,
              61,
              47,
              118,
              49,
              47,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              123,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              125,
              47,
              105,
              110,
              115,
              116,
              97,
              110,
              99,
              101,
              115,
              47,
              123,
              105,
              110,
              115,
              116,
              97,
              110,
              99,
              101,
              125,
              47,
              112,
              101,
              114,
              102,
              111,
              114,
              109,
              68,
              105,
              115,
              107,
              83,
              104,
              114,
              105,
              110,
              107,
            ]),
          ],
        },
      },
    },
    /** Get Disk Shrink Config for a given instance. */
    getDiskShrinkConfig: {
      name: "GetDiskShrinkConfig",
      requestType: SqlInstancesGetDiskShrinkConfigRequest,
      requestStream: false,
      responseType: SqlInstancesGetDiskShrinkConfigResponse,
      responseStream: false,
      options: {
        _unknownFields: {
          578365826: [
            Buffer.from([
              65,
              18,
              63,
              47,
              118,
              49,
              47,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              123,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              125,
              47,
              105,
              110,
              115,
              116,
              97,
              110,
              99,
              101,
              115,
              47,
              123,
              105,
              110,
              115,
              116,
              97,
              110,
              99,
              101,
              125,
              47,
              103,
              101,
              116,
              68,
              105,
              115,
              107,
              83,
              104,
              114,
              105,
              110,
              107,
              67,
              111,
              110,
              102,
              105,
              103,
            ]),
          ],
        },
      },
    },
    /** Reset Replica Size to primary instance disk size. */
    resetReplicaSize: {
      name: "ResetReplicaSize",
      requestType: SqlInstancesResetReplicaSizeRequest,
      requestStream: false,
      responseType: Operation,
      responseStream: false,
      options: {
        _unknownFields: {
          578365826: [
            Buffer.from([
              65,
              58,
              1,
              42,
              34,
              60,
              47,
              118,
              49,
              47,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              123,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              125,
              47,
              105,
              110,
              115,
              116,
              97,
              110,
              99,
              101,
              115,
              47,
              123,
              105,
              110,
              115,
              116,
              97,
              110,
              99,
              101,
              125,
              47,
              114,
              101,
              115,
              101,
              116,
              82,
              101,
              112,
              108,
              105,
              99,
              97,
              83,
              105,
              122,
              101,
            ]),
          ],
        },
      },
    },
    /** Get Latest Recovery Time for a given instance. */
    getLatestRecoveryTime: {
      name: "GetLatestRecoveryTime",
      requestType: SqlInstancesGetLatestRecoveryTimeRequest,
      requestStream: false,
      responseType: SqlInstancesGetLatestRecoveryTimeResponse,
      responseStream: false,
      options: {
        _unknownFields: {
          578365826: [
            Buffer.from([
              67,
              18,
              65,
              47,
              118,
              49,
              47,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              123,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              125,
              47,
              105,
              110,
              115,
              116,
              97,
              110,
              99,
              101,
              115,
              47,
              123,
              105,
              110,
              115,
              116,
              97,
              110,
              99,
              101,
              125,
              47,
              103,
              101,
              116,
              76,
              97,
              116,
              101,
              115,
              116,
              82,
              101,
              99,
              111,
              118,
              101,
              114,
              121,
              84,
              105,
              109,
              101,
            ]),
          ],
        },
      },
    },
    /** Acquire a lease for the setup of SQL Server Reporting Services (SSRS). */
    acquireSsrsLease: {
      name: "AcquireSsrsLease",
      requestType: SqlInstancesAcquireSsrsLeaseRequest,
      requestStream: false,
      responseType: SqlInstancesAcquireSsrsLeaseResponse,
      responseStream: false,
      options: {
        _unknownFields: {
          578365826: [
            Buffer.from([
              68,
              58,
              4,
              98,
              111,
              100,
              121,
              34,
              60,
              47,
              118,
              49,
              47,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              123,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              125,
              47,
              105,
              110,
              115,
              116,
              97,
              110,
              99,
              101,
              115,
              47,
              123,
              105,
              110,
              115,
              116,
              97,
              110,
              99,
              101,
              125,
              47,
              97,
              99,
              113,
              117,
              105,
              114,
              101,
              83,
              115,
              114,
              115,
              76,
              101,
              97,
              115,
              101,
            ]),
          ],
        },
      },
    },
    /** Release a lease for the setup of SQL Server Reporting Services (SSRS). */
    releaseSsrsLease: {
      name: "ReleaseSsrsLease",
      requestType: SqlInstancesReleaseSsrsLeaseRequest,
      requestStream: false,
      responseType: SqlInstancesReleaseSsrsLeaseResponse,
      responseStream: false,
      options: {
        _unknownFields: {
          578365826: [
            Buffer.from([
              62,
              34,
              60,
              47,
              118,
              49,
              47,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              123,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              125,
              47,
              105,
              110,
              115,
              116,
              97,
              110,
              99,
              101,
              115,
              47,
              123,
              105,
              110,
              115,
              116,
              97,
              110,
              99,
              101,
              125,
              47,
              114,
              101,
              108,
              101,
              97,
              115,
              101,
              83,
              115,
              114,
              115,
              76,
              101,
              97,
              115,
              101,
            ]),
          ],
        },
      },
    },
  },
} as const;

export interface SqlInstancesServiceImplementation<CallContextExt = {}> {
  /**
   * Adds a new trusted Certificate Authority (CA) version for the specified
   * instance. Required to prepare for a certificate rotation. If a CA version
   * was previously added but never used in a certificate rotation, this
   * operation replaces that version. There cannot be more than one CA version
   * waiting to be rotated in. For instances that have enabled Certificate
   * Authority Service (CAS) based server CA, please use AddServerCertificate to
   * add a new server certificate.
   */
  addServerCa(
    request: SqlInstancesAddServerCaRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<Operation>>;
  /**
   * Creates a Cloud SQL instance as a clone of the source instance. Using this
   * operation might cause your instance to restart.
   */
  clone(request: SqlInstancesCloneRequest, context: CallContext & CallContextExt): Promise<DeepPartial<Operation>>;
  /** Deletes a Cloud SQL instance. */
  delete(request: SqlInstancesDeleteRequest, context: CallContext & CallContextExt): Promise<DeepPartial<Operation>>;
  /**
   * Demotes the stand-alone instance to be a Cloud SQL read replica for an
   * external database server.
   */
  demoteMaster(
    request: SqlInstancesDemoteMasterRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<Operation>>;
  /**
   * Demotes an existing standalone instance to be a Cloud SQL read replica
   * for an external database server.
   */
  demote(request: SqlInstancesDemoteRequest, context: CallContext & CallContextExt): Promise<DeepPartial<Operation>>;
  /**
   * Exports data from a Cloud SQL instance to a Cloud Storage bucket as a SQL
   * dump or CSV file.
   */
  export(request: SqlInstancesExportRequest, context: CallContext & CallContextExt): Promise<DeepPartial<Operation>>;
  /**
   * Initiates a manual failover of a high availability (HA) primary instance
   * to a standby instance, which becomes the primary instance. Users are
   * then rerouted to the new primary. For more information, see the
   * [Overview of high
   * availability](https://cloud.google.com/sql/docs/mysql/high-availability)
   * page in the Cloud SQL documentation.
   * If using Legacy HA (MySQL only), this causes the instance to failover to
   * its failover replica instance.
   */
  failover(
    request: SqlInstancesFailoverRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<Operation>>;
  /** Reencrypt CMEK instance with latest key version. */
  reencrypt(
    request: SqlInstancesReencryptRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<Operation>>;
  /** Retrieves a resource containing information about a Cloud SQL instance. */
  get(request: SqlInstancesGetRequest, context: CallContext & CallContextExt): Promise<DeepPartial<DatabaseInstance>>;
  /**
   * Imports data into a Cloud SQL instance from a SQL dump  or CSV file in
   * Cloud Storage.
   */
  import(request: SqlInstancesImportRequest, context: CallContext & CallContextExt): Promise<DeepPartial<Operation>>;
  /** Creates a new Cloud SQL instance. */
  insert(request: SqlInstancesInsertRequest, context: CallContext & CallContextExt): Promise<DeepPartial<Operation>>;
  /** Lists instances under a given project. */
  list(
    request: SqlInstancesListRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<InstancesListResponse>>;
  /**
   * Lists all of the trusted Certificate Authorities (CAs) for the specified
   * instance. There can be up to three CAs listed: the CA that was used to sign
   * the certificate that is currently in use, a CA that has been added but not
   * yet used to sign a certificate, and a CA used to sign a certificate that
   * has previously rotated out.
   */
  listServerCas(
    request: SqlInstancesListServerCasRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<InstancesListServerCasResponse>>;
  /**
   * Partially updates settings of a Cloud SQL instance by merging the request
   * with the current configuration. This method supports patch semantics.
   */
  patch(request: SqlInstancesPatchRequest, context: CallContext & CallContextExt): Promise<DeepPartial<Operation>>;
  /**
   * Promotes the read replica instance to be an independent Cloud SQL
   * primary instance.
   * Using this operation might cause your instance to restart.
   */
  promoteReplica(
    request: SqlInstancesPromoteReplicaRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<Operation>>;
  /**
   * Switches over from the primary instance to the designated DR replica
   * instance.
   */
  switchover(
    request: SqlInstancesSwitchoverRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<Operation>>;
  /**
   * Deletes all client certificates and generates a new server SSL certificate
   * for the instance.
   */
  resetSslConfig(
    request: SqlInstancesResetSslConfigRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<Operation>>;
  /** Restarts a Cloud SQL instance. */
  restart(request: SqlInstancesRestartRequest, context: CallContext & CallContextExt): Promise<DeepPartial<Operation>>;
  /**
   * Restores a backup of a Cloud SQL instance. Using this operation might cause
   * your instance to restart.
   */
  restoreBackup(
    request: SqlInstancesRestoreBackupRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<Operation>>;
  /**
   * Rotates the server certificate to one signed by the Certificate Authority
   * (CA) version previously added with the addServerCA method. For instances
   * that have enabled Certificate Authority Service (CAS) based server CA,
   * please use RotateServerCertificate to rotate the server certificate.
   */
  rotateServerCa(
    request: SqlInstancesRotateServerCaRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<Operation>>;
  /** Starts the replication in the read replica instance. */
  startReplica(
    request: SqlInstancesStartReplicaRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<Operation>>;
  /** Stops the replication in the read replica instance. */
  stopReplica(
    request: SqlInstancesStopReplicaRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<Operation>>;
  /**
   * Truncate MySQL general and slow query log tables
   * MySQL only.
   */
  truncateLog(
    request: SqlInstancesTruncateLogRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<Operation>>;
  /**
   * Updates settings of a Cloud SQL instance. Using this operation might cause
   * your instance to restart.
   */
  update(request: SqlInstancesUpdateRequest, context: CallContext & CallContextExt): Promise<DeepPartial<Operation>>;
  /**
   * Generates a short-lived X509 certificate containing the provided public key
   * and signed by a private key specific to the target instance. Users may use
   * the certificate to authenticate as themselves when connecting to the
   * database.
   */
  createEphemeral(
    request: SqlInstancesCreateEphemeralCertRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<SslCert>>;
  /** Reschedules the maintenance on the given instance. */
  rescheduleMaintenance(
    request: SqlInstancesRescheduleMaintenanceRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<Operation>>;
  /** Verify External primary instance external sync settings. */
  verifyExternalSyncSettings(
    request: SqlInstancesVerifyExternalSyncSettingsRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<SqlInstancesVerifyExternalSyncSettingsResponse>>;
  /** Start External primary instance migration. */
  startExternalSync(
    request: SqlInstancesStartExternalSyncRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<Operation>>;
  /** Perform Disk Shrink on primary instance. */
  performDiskShrink(
    request: SqlInstancesPerformDiskShrinkRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<Operation>>;
  /** Get Disk Shrink Config for a given instance. */
  getDiskShrinkConfig(
    request: SqlInstancesGetDiskShrinkConfigRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<SqlInstancesGetDiskShrinkConfigResponse>>;
  /** Reset Replica Size to primary instance disk size. */
  resetReplicaSize(
    request: SqlInstancesResetReplicaSizeRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<Operation>>;
  /** Get Latest Recovery Time for a given instance. */
  getLatestRecoveryTime(
    request: SqlInstancesGetLatestRecoveryTimeRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<SqlInstancesGetLatestRecoveryTimeResponse>>;
  /** Acquire a lease for the setup of SQL Server Reporting Services (SSRS). */
  acquireSsrsLease(
    request: SqlInstancesAcquireSsrsLeaseRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<SqlInstancesAcquireSsrsLeaseResponse>>;
  /** Release a lease for the setup of SQL Server Reporting Services (SSRS). */
  releaseSsrsLease(
    request: SqlInstancesReleaseSsrsLeaseRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<SqlInstancesReleaseSsrsLeaseResponse>>;
}

export interface SqlInstancesServiceClient<CallOptionsExt = {}> {
  /**
   * Adds a new trusted Certificate Authority (CA) version for the specified
   * instance. Required to prepare for a certificate rotation. If a CA version
   * was previously added but never used in a certificate rotation, this
   * operation replaces that version. There cannot be more than one CA version
   * waiting to be rotated in. For instances that have enabled Certificate
   * Authority Service (CAS) based server CA, please use AddServerCertificate to
   * add a new server certificate.
   */
  addServerCa(
    request: DeepPartial<SqlInstancesAddServerCaRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<Operation>;
  /**
   * Creates a Cloud SQL instance as a clone of the source instance. Using this
   * operation might cause your instance to restart.
   */
  clone(request: DeepPartial<SqlInstancesCloneRequest>, options?: CallOptions & CallOptionsExt): Promise<Operation>;
  /** Deletes a Cloud SQL instance. */
  delete(request: DeepPartial<SqlInstancesDeleteRequest>, options?: CallOptions & CallOptionsExt): Promise<Operation>;
  /**
   * Demotes the stand-alone instance to be a Cloud SQL read replica for an
   * external database server.
   */
  demoteMaster(
    request: DeepPartial<SqlInstancesDemoteMasterRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<Operation>;
  /**
   * Demotes an existing standalone instance to be a Cloud SQL read replica
   * for an external database server.
   */
  demote(request: DeepPartial<SqlInstancesDemoteRequest>, options?: CallOptions & CallOptionsExt): Promise<Operation>;
  /**
   * Exports data from a Cloud SQL instance to a Cloud Storage bucket as a SQL
   * dump or CSV file.
   */
  export(request: DeepPartial<SqlInstancesExportRequest>, options?: CallOptions & CallOptionsExt): Promise<Operation>;
  /**
   * Initiates a manual failover of a high availability (HA) primary instance
   * to a standby instance, which becomes the primary instance. Users are
   * then rerouted to the new primary. For more information, see the
   * [Overview of high
   * availability](https://cloud.google.com/sql/docs/mysql/high-availability)
   * page in the Cloud SQL documentation.
   * If using Legacy HA (MySQL only), this causes the instance to failover to
   * its failover replica instance.
   */
  failover(
    request: DeepPartial<SqlInstancesFailoverRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<Operation>;
  /** Reencrypt CMEK instance with latest key version. */
  reencrypt(
    request: DeepPartial<SqlInstancesReencryptRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<Operation>;
  /** Retrieves a resource containing information about a Cloud SQL instance. */
  get(request: DeepPartial<SqlInstancesGetRequest>, options?: CallOptions & CallOptionsExt): Promise<DatabaseInstance>;
  /**
   * Imports data into a Cloud SQL instance from a SQL dump  or CSV file in
   * Cloud Storage.
   */
  import(request: DeepPartial<SqlInstancesImportRequest>, options?: CallOptions & CallOptionsExt): Promise<Operation>;
  /** Creates a new Cloud SQL instance. */
  insert(request: DeepPartial<SqlInstancesInsertRequest>, options?: CallOptions & CallOptionsExt): Promise<Operation>;
  /** Lists instances under a given project. */
  list(
    request: DeepPartial<SqlInstancesListRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<InstancesListResponse>;
  /**
   * Lists all of the trusted Certificate Authorities (CAs) for the specified
   * instance. There can be up to three CAs listed: the CA that was used to sign
   * the certificate that is currently in use, a CA that has been added but not
   * yet used to sign a certificate, and a CA used to sign a certificate that
   * has previously rotated out.
   */
  listServerCas(
    request: DeepPartial<SqlInstancesListServerCasRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<InstancesListServerCasResponse>;
  /**
   * Partially updates settings of a Cloud SQL instance by merging the request
   * with the current configuration. This method supports patch semantics.
   */
  patch(request: DeepPartial<SqlInstancesPatchRequest>, options?: CallOptions & CallOptionsExt): Promise<Operation>;
  /**
   * Promotes the read replica instance to be an independent Cloud SQL
   * primary instance.
   * Using this operation might cause your instance to restart.
   */
  promoteReplica(
    request: DeepPartial<SqlInstancesPromoteReplicaRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<Operation>;
  /**
   * Switches over from the primary instance to the designated DR replica
   * instance.
   */
  switchover(
    request: DeepPartial<SqlInstancesSwitchoverRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<Operation>;
  /**
   * Deletes all client certificates and generates a new server SSL certificate
   * for the instance.
   */
  resetSslConfig(
    request: DeepPartial<SqlInstancesResetSslConfigRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<Operation>;
  /** Restarts a Cloud SQL instance. */
  restart(request: DeepPartial<SqlInstancesRestartRequest>, options?: CallOptions & CallOptionsExt): Promise<Operation>;
  /**
   * Restores a backup of a Cloud SQL instance. Using this operation might cause
   * your instance to restart.
   */
  restoreBackup(
    request: DeepPartial<SqlInstancesRestoreBackupRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<Operation>;
  /**
   * Rotates the server certificate to one signed by the Certificate Authority
   * (CA) version previously added with the addServerCA method. For instances
   * that have enabled Certificate Authority Service (CAS) based server CA,
   * please use RotateServerCertificate to rotate the server certificate.
   */
  rotateServerCa(
    request: DeepPartial<SqlInstancesRotateServerCaRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<Operation>;
  /** Starts the replication in the read replica instance. */
  startReplica(
    request: DeepPartial<SqlInstancesStartReplicaRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<Operation>;
  /** Stops the replication in the read replica instance. */
  stopReplica(
    request: DeepPartial<SqlInstancesStopReplicaRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<Operation>;
  /**
   * Truncate MySQL general and slow query log tables
   * MySQL only.
   */
  truncateLog(
    request: DeepPartial<SqlInstancesTruncateLogRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<Operation>;
  /**
   * Updates settings of a Cloud SQL instance. Using this operation might cause
   * your instance to restart.
   */
  update(request: DeepPartial<SqlInstancesUpdateRequest>, options?: CallOptions & CallOptionsExt): Promise<Operation>;
  /**
   * Generates a short-lived X509 certificate containing the provided public key
   * and signed by a private key specific to the target instance. Users may use
   * the certificate to authenticate as themselves when connecting to the
   * database.
   */
  createEphemeral(
    request: DeepPartial<SqlInstancesCreateEphemeralCertRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<SslCert>;
  /** Reschedules the maintenance on the given instance. */
  rescheduleMaintenance(
    request: DeepPartial<SqlInstancesRescheduleMaintenanceRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<Operation>;
  /** Verify External primary instance external sync settings. */
  verifyExternalSyncSettings(
    request: DeepPartial<SqlInstancesVerifyExternalSyncSettingsRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<SqlInstancesVerifyExternalSyncSettingsResponse>;
  /** Start External primary instance migration. */
  startExternalSync(
    request: DeepPartial<SqlInstancesStartExternalSyncRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<Operation>;
  /** Perform Disk Shrink on primary instance. */
  performDiskShrink(
    request: DeepPartial<SqlInstancesPerformDiskShrinkRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<Operation>;
  /** Get Disk Shrink Config for a given instance. */
  getDiskShrinkConfig(
    request: DeepPartial<SqlInstancesGetDiskShrinkConfigRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<SqlInstancesGetDiskShrinkConfigResponse>;
  /** Reset Replica Size to primary instance disk size. */
  resetReplicaSize(
    request: DeepPartial<SqlInstancesResetReplicaSizeRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<Operation>;
  /** Get Latest Recovery Time for a given instance. */
  getLatestRecoveryTime(
    request: DeepPartial<SqlInstancesGetLatestRecoveryTimeRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<SqlInstancesGetLatestRecoveryTimeResponse>;
  /** Acquire a lease for the setup of SQL Server Reporting Services (SSRS). */
  acquireSsrsLease(
    request: DeepPartial<SqlInstancesAcquireSsrsLeaseRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<SqlInstancesAcquireSsrsLeaseResponse>;
  /** Release a lease for the setup of SQL Server Reporting Services (SSRS). */
  releaseSsrsLease(
    request: DeepPartial<SqlInstancesReleaseSsrsLeaseRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<SqlInstancesReleaseSsrsLeaseResponse>;
}

type Builtin = Date | Function | Uint8Array | string | number | boolean | undefined;

export type DeepPartial<T> = T extends Builtin ? T
  : T extends Long ? string | number | Long : T extends globalThis.Array<infer U> ? globalThis.Array<DeepPartial<U>>
  : T extends ReadonlyArray<infer U> ? ReadonlyArray<DeepPartial<U>>
  : T extends {} ? { [K in keyof T]?: DeepPartial<T[K]> }
  : Partial<T>;

function toTimestamp(date: Date): Timestamp {
  const seconds = numberToLong(Math.trunc(date.getTime() / 1_000));
  const nanos = (date.getTime() % 1_000) * 1_000_000;
  return { seconds, nanos };
}

function fromTimestamp(t: Timestamp): Date {
  let millis = (t.seconds.toNumber() || 0) * 1_000;
  millis += (t.nanos || 0) / 1_000_000;
  return new globalThis.Date(millis);
}

function fromJsonTimestamp(o: any): Date {
  if (o instanceof globalThis.Date) {
    return o;
  } else if (typeof o === "string") {
    return new globalThis.Date(o);
  } else {
    return fromTimestamp(Timestamp.fromJSON(o));
  }
}

function numberToLong(number: number) {
  return Long.fromNumber(number);
}

function isSet(value: any): boolean {
  return value !== null && value !== undefined;
}

export interface MessageFns<T> {
  encode(message: T, writer?: BinaryWriter): BinaryWriter;
  decode(input: BinaryReader | Uint8Array, length?: number): T;
  fromJSON(object: any): T;
  toJSON(message: T): unknown;
  create(base?: DeepPartial<T>): T;
  fromPartial(object: DeepPartial<T>): T;
}
