// Code generated by protoc-gen-ts_proto. DO NOT EDIT.
// versions:
//   protoc-gen-ts_proto  v2.2.0
//   protoc               unknown
// source: google/cloud/dialogflow/v2/conversation_model.proto

/* eslint-disable */
import { BinaryReader, BinaryWriter } from "@bufbuild/protobuf/wire";
import Long from "long";
import { type CallContext, type CallOptions } from "nice-grpc-common";
import { Operation } from "../../../longrunning/operations.js";
import { Timestamp } from "../../../protobuf/timestamp.js";

export const protobufPackage = "google.cloud.dialogflow.v2";

/** Represents a conversation model. */
export interface ConversationModel {
  /**
   * ConversationModel resource name. Format:
   * `projects/<Project ID>/conversationModels/<Conversation Model ID>`
   */
  name: string;
  /** Required. The display name of the model. At most 64 bytes long. */
  displayName: string;
  /** Output only. Creation time of this model. */
  createTime:
    | Date
    | undefined;
  /** Required. Datasets used to create model. */
  datasets: InputDataset[];
  /**
   * Output only. State of the model. A model can only serve prediction requests
   * after it gets deployed.
   */
  state: ConversationModel_State;
  /**
   * Language code for the conversation model. If not specified, the language
   * is en-US. Language at ConversationModel should be set for all non en-us
   * languages.
   * This should be a [BCP-47](https://www.rfc-editor.org/rfc/bcp/bcp47.txt)
   * language tag. Example: "en-US".
   */
  languageCode: string;
  /** Metadata for article suggestion models. */
  articleSuggestionModelMetadata?:
    | ArticleSuggestionModelMetadata
    | undefined;
  /** Metadata for smart reply models. */
  smartReplyModelMetadata?:
    | SmartReplyModelMetadata
    | undefined;
  /**
   * Output only. A read only boolean field reflecting Zone Separation
   * status of the model.
   */
  satisfiesPzs?:
    | boolean
    | undefined;
  /**
   * Output only. A read only boolean field reflecting Zone Isolation status
   * of the model.
   */
  satisfiesPzi?: boolean | undefined;
}

/** State of the model. */
export enum ConversationModel_State {
  /** STATE_UNSPECIFIED - Should not be used, an un-set enum has this value by default. */
  STATE_UNSPECIFIED = 0,
  /** CREATING - Model being created. */
  CREATING = 1,
  /** UNDEPLOYED - Model is not deployed but ready to deploy. */
  UNDEPLOYED = 2,
  /** DEPLOYING - Model is deploying. */
  DEPLOYING = 3,
  /** DEPLOYED - Model is deployed and ready to use. */
  DEPLOYED = 4,
  /** UNDEPLOYING - Model is undeploying. */
  UNDEPLOYING = 5,
  /** DELETING - Model is deleting. */
  DELETING = 6,
  /** FAILED - Model is in error state. Not ready to deploy and use. */
  FAILED = 7,
  /**
   * PENDING - Model is being created but the training has not started,
   * The model may remain in this state until there is enough capacity to
   * start training.
   */
  PENDING = 8,
  UNRECOGNIZED = -1,
}

export function conversationModel_StateFromJSON(object: any): ConversationModel_State {
  switch (object) {
    case 0:
    case "STATE_UNSPECIFIED":
      return ConversationModel_State.STATE_UNSPECIFIED;
    case 1:
    case "CREATING":
      return ConversationModel_State.CREATING;
    case 2:
    case "UNDEPLOYED":
      return ConversationModel_State.UNDEPLOYED;
    case 3:
    case "DEPLOYING":
      return ConversationModel_State.DEPLOYING;
    case 4:
    case "DEPLOYED":
      return ConversationModel_State.DEPLOYED;
    case 5:
    case "UNDEPLOYING":
      return ConversationModel_State.UNDEPLOYING;
    case 6:
    case "DELETING":
      return ConversationModel_State.DELETING;
    case 7:
    case "FAILED":
      return ConversationModel_State.FAILED;
    case 8:
    case "PENDING":
      return ConversationModel_State.PENDING;
    case -1:
    case "UNRECOGNIZED":
    default:
      return ConversationModel_State.UNRECOGNIZED;
  }
}

export function conversationModel_StateToJSON(object: ConversationModel_State): string {
  switch (object) {
    case ConversationModel_State.STATE_UNSPECIFIED:
      return "STATE_UNSPECIFIED";
    case ConversationModel_State.CREATING:
      return "CREATING";
    case ConversationModel_State.UNDEPLOYED:
      return "UNDEPLOYED";
    case ConversationModel_State.DEPLOYING:
      return "DEPLOYING";
    case ConversationModel_State.DEPLOYED:
      return "DEPLOYED";
    case ConversationModel_State.UNDEPLOYING:
      return "UNDEPLOYING";
    case ConversationModel_State.DELETING:
      return "DELETING";
    case ConversationModel_State.FAILED:
      return "FAILED";
    case ConversationModel_State.PENDING:
      return "PENDING";
    case ConversationModel_State.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/** Model type. */
export enum ConversationModel_ModelType {
  /** MODEL_TYPE_UNSPECIFIED - ModelType unspecified. */
  MODEL_TYPE_UNSPECIFIED = 0,
  /** SMART_REPLY_DUAL_ENCODER_MODEL - ModelType smart reply dual encoder model. */
  SMART_REPLY_DUAL_ENCODER_MODEL = 2,
  /** SMART_REPLY_BERT_MODEL - ModelType smart reply bert model. */
  SMART_REPLY_BERT_MODEL = 6,
  UNRECOGNIZED = -1,
}

export function conversationModel_ModelTypeFromJSON(object: any): ConversationModel_ModelType {
  switch (object) {
    case 0:
    case "MODEL_TYPE_UNSPECIFIED":
      return ConversationModel_ModelType.MODEL_TYPE_UNSPECIFIED;
    case 2:
    case "SMART_REPLY_DUAL_ENCODER_MODEL":
      return ConversationModel_ModelType.SMART_REPLY_DUAL_ENCODER_MODEL;
    case 6:
    case "SMART_REPLY_BERT_MODEL":
      return ConversationModel_ModelType.SMART_REPLY_BERT_MODEL;
    case -1:
    case "UNRECOGNIZED":
    default:
      return ConversationModel_ModelType.UNRECOGNIZED;
  }
}

export function conversationModel_ModelTypeToJSON(object: ConversationModel_ModelType): string {
  switch (object) {
    case ConversationModel_ModelType.MODEL_TYPE_UNSPECIFIED:
      return "MODEL_TYPE_UNSPECIFIED";
    case ConversationModel_ModelType.SMART_REPLY_DUAL_ENCODER_MODEL:
      return "SMART_REPLY_DUAL_ENCODER_MODEL";
    case ConversationModel_ModelType.SMART_REPLY_BERT_MODEL:
      return "SMART_REPLY_BERT_MODEL";
    case ConversationModel_ModelType.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/** Represents evaluation result of a conversation model. */
export interface ConversationModelEvaluation {
  /**
   * The resource name of the evaluation. Format:
   * `projects/<Project ID>/conversationModels/<Conversation Model
   * ID>/evaluations/<Evaluation ID>`
   */
  name: string;
  /** Optional. The display name of the model evaluation. At most 64 bytes long. */
  displayName: string;
  /** Optional. The configuration of the evaluation task. */
  evaluationConfig:
    | EvaluationConfig
    | undefined;
  /** Output only. Creation time of this model. */
  createTime:
    | Date
    | undefined;
  /** Output only. Only available when model is for smart reply. */
  smartReplyMetrics?:
    | SmartReplyMetrics
    | undefined;
  /**
   * Output only. Human eval template in csv format.
   * It tooks real-world conversations provided through input dataset, generates
   * example suggestions for customer to verify quality of the model.
   * For Smart Reply, the generated csv file contains columns of
   * Context, (Suggestions,Q1,Q2)*3, Actual reply.
   * Context contains at most 10 latest messages in the conversation prior to
   * the current suggestion.
   * Q1: "Would you send it as the next message of agent?"
   * Evaluated based on whether the suggest is appropriate to be sent by
   * agent in current context.
   * Q2: "Does the suggestion move the conversation closer to resolution?"
   * Evaluated based on whether the suggestion provide solutions, or answers
   * customer's question or collect information from customer to resolve the
   * customer's issue.
   * Actual reply column contains the actual agent reply sent in the context.
   */
  rawHumanEvalTemplateCsv: string;
}

/** The configuration for model evaluation. */
export interface EvaluationConfig {
  /** Required. Datasets used for evaluation. */
  datasets: InputDataset[];
  /** Configuration for smart reply model evalution. */
  smartReplyConfig?:
    | EvaluationConfig_SmartReplyConfig
    | undefined;
  /** Configuration for smart compose model evalution. */
  smartComposeConfig?: EvaluationConfig_SmartComposeConfig | undefined;
}

/** Smart reply specific configuration for evaluation job. */
export interface EvaluationConfig_SmartReplyConfig {
  /**
   * The allowlist document resource name.
   * Format: `projects/<Project ID>/knowledgeBases/<Knowledge Base
   * ID>/documents/<Document ID>`. Only used for smart reply model.
   */
  allowlistDocument: string;
  /**
   * Required. The model to be evaluated can return multiple results with
   * confidence score on each query. These results will be sorted by the
   * descending order of the scores and we only keep the first
   * max_result_count results as the final results to evaluate.
   */
  maxResultCount: number;
}

/** Smart compose specific configuration for evaluation job. */
export interface EvaluationConfig_SmartComposeConfig {
  /**
   * The allowlist document resource name.
   * Format: `projects/<Project ID>/knowledgeBases/<Knowledge Base
   * ID>/documents/<Document ID>`. Only used for smart compose model.
   */
  allowlistDocument: string;
  /**
   * Required. The model to be evaluated can return multiple results with
   * confidence score on each query. These results will be sorted by the
   * descending order of the scores and we only keep the first
   * max_result_count results as the final results to evaluate.
   */
  maxResultCount: number;
}

/**
 * InputDataset used to create model or do evaluation.
 * NextID:5
 */
export interface InputDataset {
  /**
   * Required. ConversationDataset resource name. Format:
   * `projects/<Project ID>/locations/<Location
   * ID>/conversationDatasets/<Conversation Dataset ID>`
   */
  dataset: string;
}

/** Metadata for article suggestion models. */
export interface ArticleSuggestionModelMetadata {
  /**
   * Optional. Type of the article suggestion model. If not provided, model_type
   * is used.
   */
  trainingModelType: ConversationModel_ModelType;
}

/** Metadata for smart reply models. */
export interface SmartReplyModelMetadata {
  /**
   * Optional. Type of the smart reply model. If not provided, model_type is
   * used.
   */
  trainingModelType: ConversationModel_ModelType;
}

/** The evaluation metrics for smart reply model. */
export interface SmartReplyMetrics {
  /**
   * Percentage of target participant messages in the evaluation dataset for
   * which similar messages have appeared at least once in the allowlist. Should
   * be [0, 1].
   */
  allowlistCoverage: number;
  /** Metrics of top n smart replies, sorted by [TopNMetric.n][]. */
  topNMetrics: SmartReplyMetrics_TopNMetrics[];
  /** Total number of conversations used to generate this metric. */
  conversationCount: Long;
}

/** Evaluation metrics when retrieving `n` smart replies with the model. */
export interface SmartReplyMetrics_TopNMetrics {
  /**
   * Number of retrieved smart replies. For example, when `n` is 3, this
   * evaluation contains metrics for when Dialogflow retrieves 3 smart replies
   * with the model.
   */
  n: number;
  /**
   * Defined as `number of queries whose top n smart replies have at least one
   * similar (token match similarity above the defined threshold) reply as the
   * real reply` divided by `number of queries with at least one smart reply`.
   * Value ranges from 0.0 to 1.0 inclusive.
   */
  recall: number;
}

/**
 * The request message for
 * [ConversationModels.CreateConversationModel][google.cloud.dialogflow.v2.ConversationModels.CreateConversationModel]
 */
export interface CreateConversationModelRequest {
  /**
   * The project to create conversation model for. Format:
   * `projects/<Project ID>`
   */
  parent: string;
  /** Required. The conversation model to create. */
  conversationModel: ConversationModel | undefined;
}

/**
 * The request message for
 * [ConversationModels.GetConversationModel][google.cloud.dialogflow.v2.ConversationModels.GetConversationModel]
 */
export interface GetConversationModelRequest {
  /**
   * Required. The conversation model to retrieve. Format:
   * `projects/<Project ID>/conversationModels/<Conversation Model ID>`
   */
  name: string;
}

/**
 * The request message for
 * [ConversationModels.ListConversationModels][google.cloud.dialogflow.v2.ConversationModels.ListConversationModels]
 */
export interface ListConversationModelsRequest {
  /**
   * Required. The project to list all conversation models for.
   * Format: `projects/<Project ID>`
   */
  parent: string;
  /**
   * Optional. Maximum number of conversation models to return in a single
   * page. By default 100 and at most 1000.
   */
  pageSize: number;
  /** Optional. The next_page_token value returned from a previous list request. */
  pageToken: string;
}

/**
 * The response message for
 * [ConversationModels.ListConversationModels][google.cloud.dialogflow.v2.ConversationModels.ListConversationModels]
 */
export interface ListConversationModelsResponse {
  /** The list of models to return. */
  conversationModels: ConversationModel[];
  /**
   * Token to retrieve the next page of results, or empty if there are no more
   * results in the list.
   */
  nextPageToken: string;
}

/**
 * The request message for
 * [ConversationModels.DeleteConversationModel][google.cloud.dialogflow.v2.ConversationModels.DeleteConversationModel]
 */
export interface DeleteConversationModelRequest {
  /**
   * Required. The conversation model to delete. Format:
   * `projects/<Project ID>/conversationModels/<Conversation Model ID>`
   */
  name: string;
}

/**
 * The request message for
 * [ConversationModels.DeployConversationModel][google.cloud.dialogflow.v2.ConversationModels.DeployConversationModel]
 */
export interface DeployConversationModelRequest {
  /**
   * Required. The conversation model to deploy. Format:
   * `projects/<Project ID>/conversationModels/<Conversation Model ID>`
   */
  name: string;
}

/**
 * The request message for
 * [ConversationModels.UndeployConversationModel][google.cloud.dialogflow.v2.ConversationModels.UndeployConversationModel]
 */
export interface UndeployConversationModelRequest {
  /**
   * Required. The conversation model to undeploy. Format:
   * `projects/<Project ID>/conversationModels/<Conversation Model ID>`
   */
  name: string;
}

/**
 * The request message for
 * [ConversationModels.GetConversationModelEvaluation][google.cloud.dialogflow.v2.ConversationModels.GetConversationModelEvaluation]
 */
export interface GetConversationModelEvaluationRequest {
  /**
   * Required. The conversation model evaluation resource name. Format:
   * `projects/<Project ID>/conversationModels/<Conversation Model
   * ID>/evaluations/<Evaluation ID>`
   */
  name: string;
}

/**
 * The request message for
 * [ConversationModels.ListConversationModelEvaluations][google.cloud.dialogflow.v2.ConversationModels.ListConversationModelEvaluations]
 */
export interface ListConversationModelEvaluationsRequest {
  /**
   * Required. The conversation model resource name. Format:
   * `projects/<Project ID>/conversationModels/<Conversation Model ID>`
   */
  parent: string;
  /**
   * Optional. Maximum number of evaluations to return in a
   * single page. By default 100 and at most 1000.
   */
  pageSize: number;
  /** Optional. The next_page_token value returned from a previous list request. */
  pageToken: string;
}

/**
 * The response message for
 * [ConversationModels.ListConversationModelEvaluations][google.cloud.dialogflow.v2.ConversationModels.ListConversationModelEvaluations]
 */
export interface ListConversationModelEvaluationsResponse {
  /** The list of evaluations to return. */
  conversationModelEvaluations: ConversationModelEvaluation[];
  /**
   * Token to retrieve the next page of results, or empty if there are no more
   * results in the list.
   */
  nextPageToken: string;
}

/**
 * The request message for
 * [ConversationModels.CreateConversationModelEvaluation][google.cloud.dialogflow.v2.ConversationModels.CreateConversationModelEvaluation]
 */
export interface CreateConversationModelEvaluationRequest {
  /**
   * Required. The conversation model resource name. Format:
   * `projects/<Project ID>/locations/<Location
   * ID>/conversationModels/<Conversation Model ID>`
   */
  parent: string;
  /** Required. The conversation model evaluation to be created. */
  conversationModelEvaluation: ConversationModelEvaluation | undefined;
}

/**
 * Metadata for a
 * [ConversationModels.CreateConversationModel][google.cloud.dialogflow.v2.ConversationModels.CreateConversationModel]
 * operation.
 */
export interface CreateConversationModelOperationMetadata {
  /**
   * The resource name of the conversation model. Format:
   * `projects/<Project ID>/conversationModels/<Conversation Model Id>`
   */
  conversationModel: string;
  /** State of CreateConversationModel operation. */
  state: CreateConversationModelOperationMetadata_State;
  /**
   * Timestamp when the request to create conversation model is submitted. The
   * time is measured on server side.
   */
  createTime: Date | undefined;
}

/** State of CreateConversationModel operation. */
export enum CreateConversationModelOperationMetadata_State {
  /** STATE_UNSPECIFIED - Invalid. */
  STATE_UNSPECIFIED = 0,
  /**
   * PENDING - Request is submitted, but training has not started yet.
   * The model may remain in this state until there is enough capacity to
   * start training.
   */
  PENDING = 1,
  /** SUCCEEDED - The training has succeeded. */
  SUCCEEDED = 2,
  /** FAILED - The training has succeeded. */
  FAILED = 3,
  /** CANCELLED - The training has been cancelled. */
  CANCELLED = 4,
  /** CANCELLING - The training is in cancelling state. */
  CANCELLING = 5,
  /** TRAINING - Custom model is training. */
  TRAINING = 6,
  UNRECOGNIZED = -1,
}

export function createConversationModelOperationMetadata_StateFromJSON(
  object: any,
): CreateConversationModelOperationMetadata_State {
  switch (object) {
    case 0:
    case "STATE_UNSPECIFIED":
      return CreateConversationModelOperationMetadata_State.STATE_UNSPECIFIED;
    case 1:
    case "PENDING":
      return CreateConversationModelOperationMetadata_State.PENDING;
    case 2:
    case "SUCCEEDED":
      return CreateConversationModelOperationMetadata_State.SUCCEEDED;
    case 3:
    case "FAILED":
      return CreateConversationModelOperationMetadata_State.FAILED;
    case 4:
    case "CANCELLED":
      return CreateConversationModelOperationMetadata_State.CANCELLED;
    case 5:
    case "CANCELLING":
      return CreateConversationModelOperationMetadata_State.CANCELLING;
    case 6:
    case "TRAINING":
      return CreateConversationModelOperationMetadata_State.TRAINING;
    case -1:
    case "UNRECOGNIZED":
    default:
      return CreateConversationModelOperationMetadata_State.UNRECOGNIZED;
  }
}

export function createConversationModelOperationMetadata_StateToJSON(
  object: CreateConversationModelOperationMetadata_State,
): string {
  switch (object) {
    case CreateConversationModelOperationMetadata_State.STATE_UNSPECIFIED:
      return "STATE_UNSPECIFIED";
    case CreateConversationModelOperationMetadata_State.PENDING:
      return "PENDING";
    case CreateConversationModelOperationMetadata_State.SUCCEEDED:
      return "SUCCEEDED";
    case CreateConversationModelOperationMetadata_State.FAILED:
      return "FAILED";
    case CreateConversationModelOperationMetadata_State.CANCELLED:
      return "CANCELLED";
    case CreateConversationModelOperationMetadata_State.CANCELLING:
      return "CANCELLING";
    case CreateConversationModelOperationMetadata_State.TRAINING:
      return "TRAINING";
    case CreateConversationModelOperationMetadata_State.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/**
 * Metadata for a
 * [ConversationModels.DeployConversationModel][google.cloud.dialogflow.v2.ConversationModels.DeployConversationModel]
 * operation.
 */
export interface DeployConversationModelOperationMetadata {
  /**
   * The resource name of the conversation model. Format:
   * `projects/<Project ID>/conversationModels/<Conversation Model Id>`
   */
  conversationModel: string;
  /**
   * Timestamp when request to deploy conversation model was submitted. The time
   * is measured on server side.
   */
  createTime: Date | undefined;
}

/**
 * Metadata for a
 * [ConversationModels.UndeployConversationModel][google.cloud.dialogflow.v2.ConversationModels.UndeployConversationModel]
 * operation.
 */
export interface UndeployConversationModelOperationMetadata {
  /**
   * The resource name of the conversation model. Format:
   * `projects/<Project ID>/conversationModels/<Conversation Model Id>`
   */
  conversationModel: string;
  /**
   * Timestamp when the request to undeploy conversation model was submitted.
   * The time is measured on server side.
   */
  createTime: Date | undefined;
}

/**
 * Metadata for a
 * [ConversationModels.DeleteConversationModel][google.cloud.dialogflow.v2.ConversationModels.DeleteConversationModel]
 * operation.
 */
export interface DeleteConversationModelOperationMetadata {
  /**
   * The resource name of the conversation model. Format:
   * `projects/<Project ID>/conversationModels/<Conversation Model Id>`
   */
  conversationModel: string;
  /**
   * Timestamp when delete conversation model request was created. The time is
   * measured on server side.
   */
  createTime: Date | undefined;
}

/**
 * Metadata for a
 * [ConversationModels.CreateConversationModelEvaluation][google.cloud.dialogflow.v2.ConversationModels.CreateConversationModelEvaluation]
 * operation.
 */
export interface CreateConversationModelEvaluationOperationMetadata {
  /**
   * The resource name of the conversation model. Format:
   * `projects/<Project ID>/locations/<Location
   * ID>/conversationModels/<Conversation Model Id>/evaluations/<Evaluation Id>`
   */
  conversationModelEvaluation: string;
  /**
   * The resource name of the conversation model. Format:
   * `projects/<Project ID>/locations/<Location
   * ID>/conversationModels/<Conversation Model Id>`
   */
  conversationModel: string;
  /** State of CreateConversationModel operation. */
  state: CreateConversationModelEvaluationOperationMetadata_State;
  /**
   * Timestamp when the request to create conversation model was submitted. The
   * time is measured on server side.
   */
  createTime: Date | undefined;
}

/** State of CreateConversationModel operation. */
export enum CreateConversationModelEvaluationOperationMetadata_State {
  /** STATE_UNSPECIFIED - Operation status not specified. */
  STATE_UNSPECIFIED = 0,
  /** INITIALIZING - The operation is being prepared. */
  INITIALIZING = 1,
  /** RUNNING - The operation is running. */
  RUNNING = 2,
  /** CANCELLED - The operation is cancelled. */
  CANCELLED = 3,
  /** SUCCEEDED - The operation has succeeded. */
  SUCCEEDED = 4,
  /** FAILED - The operation has failed. */
  FAILED = 5,
  UNRECOGNIZED = -1,
}

export function createConversationModelEvaluationOperationMetadata_StateFromJSON(
  object: any,
): CreateConversationModelEvaluationOperationMetadata_State {
  switch (object) {
    case 0:
    case "STATE_UNSPECIFIED":
      return CreateConversationModelEvaluationOperationMetadata_State.STATE_UNSPECIFIED;
    case 1:
    case "INITIALIZING":
      return CreateConversationModelEvaluationOperationMetadata_State.INITIALIZING;
    case 2:
    case "RUNNING":
      return CreateConversationModelEvaluationOperationMetadata_State.RUNNING;
    case 3:
    case "CANCELLED":
      return CreateConversationModelEvaluationOperationMetadata_State.CANCELLED;
    case 4:
    case "SUCCEEDED":
      return CreateConversationModelEvaluationOperationMetadata_State.SUCCEEDED;
    case 5:
    case "FAILED":
      return CreateConversationModelEvaluationOperationMetadata_State.FAILED;
    case -1:
    case "UNRECOGNIZED":
    default:
      return CreateConversationModelEvaluationOperationMetadata_State.UNRECOGNIZED;
  }
}

export function createConversationModelEvaluationOperationMetadata_StateToJSON(
  object: CreateConversationModelEvaluationOperationMetadata_State,
): string {
  switch (object) {
    case CreateConversationModelEvaluationOperationMetadata_State.STATE_UNSPECIFIED:
      return "STATE_UNSPECIFIED";
    case CreateConversationModelEvaluationOperationMetadata_State.INITIALIZING:
      return "INITIALIZING";
    case CreateConversationModelEvaluationOperationMetadata_State.RUNNING:
      return "RUNNING";
    case CreateConversationModelEvaluationOperationMetadata_State.CANCELLED:
      return "CANCELLED";
    case CreateConversationModelEvaluationOperationMetadata_State.SUCCEEDED:
      return "SUCCEEDED";
    case CreateConversationModelEvaluationOperationMetadata_State.FAILED:
      return "FAILED";
    case CreateConversationModelEvaluationOperationMetadata_State.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

function createBaseConversationModel(): ConversationModel {
  return {
    name: "",
    displayName: "",
    createTime: undefined,
    datasets: [],
    state: 0,
    languageCode: "",
    articleSuggestionModelMetadata: undefined,
    smartReplyModelMetadata: undefined,
    satisfiesPzs: undefined,
    satisfiesPzi: undefined,
  };
}

export const ConversationModel: MessageFns<ConversationModel> = {
  encode(message: ConversationModel, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    if (message.displayName !== "") {
      writer.uint32(18).string(message.displayName);
    }
    if (message.createTime !== undefined) {
      Timestamp.encode(toTimestamp(message.createTime), writer.uint32(26).fork()).join();
    }
    for (const v of message.datasets) {
      InputDataset.encode(v!, writer.uint32(34).fork()).join();
    }
    if (message.state !== 0) {
      writer.uint32(56).int32(message.state);
    }
    if (message.languageCode !== "") {
      writer.uint32(154).string(message.languageCode);
    }
    if (message.articleSuggestionModelMetadata !== undefined) {
      ArticleSuggestionModelMetadata.encode(message.articleSuggestionModelMetadata, writer.uint32(66).fork()).join();
    }
    if (message.smartReplyModelMetadata !== undefined) {
      SmartReplyModelMetadata.encode(message.smartReplyModelMetadata, writer.uint32(74).fork()).join();
    }
    if (message.satisfiesPzs !== undefined) {
      writer.uint32(200).bool(message.satisfiesPzs);
    }
    if (message.satisfiesPzi !== undefined) {
      writer.uint32(208).bool(message.satisfiesPzi);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ConversationModel {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseConversationModel();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.displayName = reader.string();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.createTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.datasets.push(InputDataset.decode(reader, reader.uint32()));
          continue;
        case 7:
          if (tag !== 56) {
            break;
          }

          message.state = reader.int32() as any;
          continue;
        case 19:
          if (tag !== 154) {
            break;
          }

          message.languageCode = reader.string();
          continue;
        case 8:
          if (tag !== 66) {
            break;
          }

          message.articleSuggestionModelMetadata = ArticleSuggestionModelMetadata.decode(reader, reader.uint32());
          continue;
        case 9:
          if (tag !== 74) {
            break;
          }

          message.smartReplyModelMetadata = SmartReplyModelMetadata.decode(reader, reader.uint32());
          continue;
        case 25:
          if (tag !== 200) {
            break;
          }

          message.satisfiesPzs = reader.bool();
          continue;
        case 26:
          if (tag !== 208) {
            break;
          }

          message.satisfiesPzi = reader.bool();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ConversationModel {
    return {
      name: isSet(object.name) ? globalThis.String(object.name) : "",
      displayName: isSet(object.displayName) ? globalThis.String(object.displayName) : "",
      createTime: isSet(object.createTime) ? fromJsonTimestamp(object.createTime) : undefined,
      datasets: globalThis.Array.isArray(object?.datasets)
        ? object.datasets.map((e: any) => InputDataset.fromJSON(e))
        : [],
      state: isSet(object.state) ? conversationModel_StateFromJSON(object.state) : 0,
      languageCode: isSet(object.languageCode) ? globalThis.String(object.languageCode) : "",
      articleSuggestionModelMetadata: isSet(object.articleSuggestionModelMetadata)
        ? ArticleSuggestionModelMetadata.fromJSON(object.articleSuggestionModelMetadata)
        : undefined,
      smartReplyModelMetadata: isSet(object.smartReplyModelMetadata)
        ? SmartReplyModelMetadata.fromJSON(object.smartReplyModelMetadata)
        : undefined,
      satisfiesPzs: isSet(object.satisfiesPzs) ? globalThis.Boolean(object.satisfiesPzs) : undefined,
      satisfiesPzi: isSet(object.satisfiesPzi) ? globalThis.Boolean(object.satisfiesPzi) : undefined,
    };
  },

  toJSON(message: ConversationModel): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    if (message.displayName !== "") {
      obj.displayName = message.displayName;
    }
    if (message.createTime !== undefined) {
      obj.createTime = message.createTime.toISOString();
    }
    if (message.datasets?.length) {
      obj.datasets = message.datasets.map((e) => InputDataset.toJSON(e));
    }
    if (message.state !== 0) {
      obj.state = conversationModel_StateToJSON(message.state);
    }
    if (message.languageCode !== "") {
      obj.languageCode = message.languageCode;
    }
    if (message.articleSuggestionModelMetadata !== undefined) {
      obj.articleSuggestionModelMetadata = ArticleSuggestionModelMetadata.toJSON(
        message.articleSuggestionModelMetadata,
      );
    }
    if (message.smartReplyModelMetadata !== undefined) {
      obj.smartReplyModelMetadata = SmartReplyModelMetadata.toJSON(message.smartReplyModelMetadata);
    }
    if (message.satisfiesPzs !== undefined) {
      obj.satisfiesPzs = message.satisfiesPzs;
    }
    if (message.satisfiesPzi !== undefined) {
      obj.satisfiesPzi = message.satisfiesPzi;
    }
    return obj;
  },

  create(base?: DeepPartial<ConversationModel>): ConversationModel {
    return ConversationModel.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ConversationModel>): ConversationModel {
    const message = createBaseConversationModel();
    message.name = object.name ?? "";
    message.displayName = object.displayName ?? "";
    message.createTime = object.createTime ?? undefined;
    message.datasets = object.datasets?.map((e) => InputDataset.fromPartial(e)) || [];
    message.state = object.state ?? 0;
    message.languageCode = object.languageCode ?? "";
    message.articleSuggestionModelMetadata =
      (object.articleSuggestionModelMetadata !== undefined && object.articleSuggestionModelMetadata !== null)
        ? ArticleSuggestionModelMetadata.fromPartial(object.articleSuggestionModelMetadata)
        : undefined;
    message.smartReplyModelMetadata =
      (object.smartReplyModelMetadata !== undefined && object.smartReplyModelMetadata !== null)
        ? SmartReplyModelMetadata.fromPartial(object.smartReplyModelMetadata)
        : undefined;
    message.satisfiesPzs = object.satisfiesPzs ?? undefined;
    message.satisfiesPzi = object.satisfiesPzi ?? undefined;
    return message;
  },
};

function createBaseConversationModelEvaluation(): ConversationModelEvaluation {
  return {
    name: "",
    displayName: "",
    evaluationConfig: undefined,
    createTime: undefined,
    smartReplyMetrics: undefined,
    rawHumanEvalTemplateCsv: "",
  };
}

export const ConversationModelEvaluation: MessageFns<ConversationModelEvaluation> = {
  encode(message: ConversationModelEvaluation, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    if (message.displayName !== "") {
      writer.uint32(18).string(message.displayName);
    }
    if (message.evaluationConfig !== undefined) {
      EvaluationConfig.encode(message.evaluationConfig, writer.uint32(50).fork()).join();
    }
    if (message.createTime !== undefined) {
      Timestamp.encode(toTimestamp(message.createTime), writer.uint32(26).fork()).join();
    }
    if (message.smartReplyMetrics !== undefined) {
      SmartReplyMetrics.encode(message.smartReplyMetrics, writer.uint32(42).fork()).join();
    }
    if (message.rawHumanEvalTemplateCsv !== "") {
      writer.uint32(66).string(message.rawHumanEvalTemplateCsv);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ConversationModelEvaluation {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseConversationModelEvaluation();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.displayName = reader.string();
          continue;
        case 6:
          if (tag !== 50) {
            break;
          }

          message.evaluationConfig = EvaluationConfig.decode(reader, reader.uint32());
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.createTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.smartReplyMetrics = SmartReplyMetrics.decode(reader, reader.uint32());
          continue;
        case 8:
          if (tag !== 66) {
            break;
          }

          message.rawHumanEvalTemplateCsv = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ConversationModelEvaluation {
    return {
      name: isSet(object.name) ? globalThis.String(object.name) : "",
      displayName: isSet(object.displayName) ? globalThis.String(object.displayName) : "",
      evaluationConfig: isSet(object.evaluationConfig) ? EvaluationConfig.fromJSON(object.evaluationConfig) : undefined,
      createTime: isSet(object.createTime) ? fromJsonTimestamp(object.createTime) : undefined,
      smartReplyMetrics: isSet(object.smartReplyMetrics)
        ? SmartReplyMetrics.fromJSON(object.smartReplyMetrics)
        : undefined,
      rawHumanEvalTemplateCsv: isSet(object.rawHumanEvalTemplateCsv)
        ? globalThis.String(object.rawHumanEvalTemplateCsv)
        : "",
    };
  },

  toJSON(message: ConversationModelEvaluation): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    if (message.displayName !== "") {
      obj.displayName = message.displayName;
    }
    if (message.evaluationConfig !== undefined) {
      obj.evaluationConfig = EvaluationConfig.toJSON(message.evaluationConfig);
    }
    if (message.createTime !== undefined) {
      obj.createTime = message.createTime.toISOString();
    }
    if (message.smartReplyMetrics !== undefined) {
      obj.smartReplyMetrics = SmartReplyMetrics.toJSON(message.smartReplyMetrics);
    }
    if (message.rawHumanEvalTemplateCsv !== "") {
      obj.rawHumanEvalTemplateCsv = message.rawHumanEvalTemplateCsv;
    }
    return obj;
  },

  create(base?: DeepPartial<ConversationModelEvaluation>): ConversationModelEvaluation {
    return ConversationModelEvaluation.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ConversationModelEvaluation>): ConversationModelEvaluation {
    const message = createBaseConversationModelEvaluation();
    message.name = object.name ?? "";
    message.displayName = object.displayName ?? "";
    message.evaluationConfig = (object.evaluationConfig !== undefined && object.evaluationConfig !== null)
      ? EvaluationConfig.fromPartial(object.evaluationConfig)
      : undefined;
    message.createTime = object.createTime ?? undefined;
    message.smartReplyMetrics = (object.smartReplyMetrics !== undefined && object.smartReplyMetrics !== null)
      ? SmartReplyMetrics.fromPartial(object.smartReplyMetrics)
      : undefined;
    message.rawHumanEvalTemplateCsv = object.rawHumanEvalTemplateCsv ?? "";
    return message;
  },
};

function createBaseEvaluationConfig(): EvaluationConfig {
  return { datasets: [], smartReplyConfig: undefined, smartComposeConfig: undefined };
}

export const EvaluationConfig: MessageFns<EvaluationConfig> = {
  encode(message: EvaluationConfig, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.datasets) {
      InputDataset.encode(v!, writer.uint32(26).fork()).join();
    }
    if (message.smartReplyConfig !== undefined) {
      EvaluationConfig_SmartReplyConfig.encode(message.smartReplyConfig, writer.uint32(18).fork()).join();
    }
    if (message.smartComposeConfig !== undefined) {
      EvaluationConfig_SmartComposeConfig.encode(message.smartComposeConfig, writer.uint32(34).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): EvaluationConfig {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseEvaluationConfig();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 3:
          if (tag !== 26) {
            break;
          }

          message.datasets.push(InputDataset.decode(reader, reader.uint32()));
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.smartReplyConfig = EvaluationConfig_SmartReplyConfig.decode(reader, reader.uint32());
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.smartComposeConfig = EvaluationConfig_SmartComposeConfig.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): EvaluationConfig {
    return {
      datasets: globalThis.Array.isArray(object?.datasets)
        ? object.datasets.map((e: any) => InputDataset.fromJSON(e))
        : [],
      smartReplyConfig: isSet(object.smartReplyConfig)
        ? EvaluationConfig_SmartReplyConfig.fromJSON(object.smartReplyConfig)
        : undefined,
      smartComposeConfig: isSet(object.smartComposeConfig)
        ? EvaluationConfig_SmartComposeConfig.fromJSON(object.smartComposeConfig)
        : undefined,
    };
  },

  toJSON(message: EvaluationConfig): unknown {
    const obj: any = {};
    if (message.datasets?.length) {
      obj.datasets = message.datasets.map((e) => InputDataset.toJSON(e));
    }
    if (message.smartReplyConfig !== undefined) {
      obj.smartReplyConfig = EvaluationConfig_SmartReplyConfig.toJSON(message.smartReplyConfig);
    }
    if (message.smartComposeConfig !== undefined) {
      obj.smartComposeConfig = EvaluationConfig_SmartComposeConfig.toJSON(message.smartComposeConfig);
    }
    return obj;
  },

  create(base?: DeepPartial<EvaluationConfig>): EvaluationConfig {
    return EvaluationConfig.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<EvaluationConfig>): EvaluationConfig {
    const message = createBaseEvaluationConfig();
    message.datasets = object.datasets?.map((e) => InputDataset.fromPartial(e)) || [];
    message.smartReplyConfig = (object.smartReplyConfig !== undefined && object.smartReplyConfig !== null)
      ? EvaluationConfig_SmartReplyConfig.fromPartial(object.smartReplyConfig)
      : undefined;
    message.smartComposeConfig = (object.smartComposeConfig !== undefined && object.smartComposeConfig !== null)
      ? EvaluationConfig_SmartComposeConfig.fromPartial(object.smartComposeConfig)
      : undefined;
    return message;
  },
};

function createBaseEvaluationConfig_SmartReplyConfig(): EvaluationConfig_SmartReplyConfig {
  return { allowlistDocument: "", maxResultCount: 0 };
}

export const EvaluationConfig_SmartReplyConfig: MessageFns<EvaluationConfig_SmartReplyConfig> = {
  encode(message: EvaluationConfig_SmartReplyConfig, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.allowlistDocument !== "") {
      writer.uint32(10).string(message.allowlistDocument);
    }
    if (message.maxResultCount !== 0) {
      writer.uint32(16).int32(message.maxResultCount);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): EvaluationConfig_SmartReplyConfig {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseEvaluationConfig_SmartReplyConfig();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.allowlistDocument = reader.string();
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.maxResultCount = reader.int32();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): EvaluationConfig_SmartReplyConfig {
    return {
      allowlistDocument: isSet(object.allowlistDocument) ? globalThis.String(object.allowlistDocument) : "",
      maxResultCount: isSet(object.maxResultCount) ? globalThis.Number(object.maxResultCount) : 0,
    };
  },

  toJSON(message: EvaluationConfig_SmartReplyConfig): unknown {
    const obj: any = {};
    if (message.allowlistDocument !== "") {
      obj.allowlistDocument = message.allowlistDocument;
    }
    if (message.maxResultCount !== 0) {
      obj.maxResultCount = Math.round(message.maxResultCount);
    }
    return obj;
  },

  create(base?: DeepPartial<EvaluationConfig_SmartReplyConfig>): EvaluationConfig_SmartReplyConfig {
    return EvaluationConfig_SmartReplyConfig.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<EvaluationConfig_SmartReplyConfig>): EvaluationConfig_SmartReplyConfig {
    const message = createBaseEvaluationConfig_SmartReplyConfig();
    message.allowlistDocument = object.allowlistDocument ?? "";
    message.maxResultCount = object.maxResultCount ?? 0;
    return message;
  },
};

function createBaseEvaluationConfig_SmartComposeConfig(): EvaluationConfig_SmartComposeConfig {
  return { allowlistDocument: "", maxResultCount: 0 };
}

export const EvaluationConfig_SmartComposeConfig: MessageFns<EvaluationConfig_SmartComposeConfig> = {
  encode(message: EvaluationConfig_SmartComposeConfig, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.allowlistDocument !== "") {
      writer.uint32(10).string(message.allowlistDocument);
    }
    if (message.maxResultCount !== 0) {
      writer.uint32(16).int32(message.maxResultCount);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): EvaluationConfig_SmartComposeConfig {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseEvaluationConfig_SmartComposeConfig();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.allowlistDocument = reader.string();
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.maxResultCount = reader.int32();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): EvaluationConfig_SmartComposeConfig {
    return {
      allowlistDocument: isSet(object.allowlistDocument) ? globalThis.String(object.allowlistDocument) : "",
      maxResultCount: isSet(object.maxResultCount) ? globalThis.Number(object.maxResultCount) : 0,
    };
  },

  toJSON(message: EvaluationConfig_SmartComposeConfig): unknown {
    const obj: any = {};
    if (message.allowlistDocument !== "") {
      obj.allowlistDocument = message.allowlistDocument;
    }
    if (message.maxResultCount !== 0) {
      obj.maxResultCount = Math.round(message.maxResultCount);
    }
    return obj;
  },

  create(base?: DeepPartial<EvaluationConfig_SmartComposeConfig>): EvaluationConfig_SmartComposeConfig {
    return EvaluationConfig_SmartComposeConfig.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<EvaluationConfig_SmartComposeConfig>): EvaluationConfig_SmartComposeConfig {
    const message = createBaseEvaluationConfig_SmartComposeConfig();
    message.allowlistDocument = object.allowlistDocument ?? "";
    message.maxResultCount = object.maxResultCount ?? 0;
    return message;
  },
};

function createBaseInputDataset(): InputDataset {
  return { dataset: "" };
}

export const InputDataset: MessageFns<InputDataset> = {
  encode(message: InputDataset, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.dataset !== "") {
      writer.uint32(10).string(message.dataset);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): InputDataset {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseInputDataset();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.dataset = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): InputDataset {
    return { dataset: isSet(object.dataset) ? globalThis.String(object.dataset) : "" };
  },

  toJSON(message: InputDataset): unknown {
    const obj: any = {};
    if (message.dataset !== "") {
      obj.dataset = message.dataset;
    }
    return obj;
  },

  create(base?: DeepPartial<InputDataset>): InputDataset {
    return InputDataset.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<InputDataset>): InputDataset {
    const message = createBaseInputDataset();
    message.dataset = object.dataset ?? "";
    return message;
  },
};

function createBaseArticleSuggestionModelMetadata(): ArticleSuggestionModelMetadata {
  return { trainingModelType: 0 };
}

export const ArticleSuggestionModelMetadata: MessageFns<ArticleSuggestionModelMetadata> = {
  encode(message: ArticleSuggestionModelMetadata, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.trainingModelType !== 0) {
      writer.uint32(24).int32(message.trainingModelType);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ArticleSuggestionModelMetadata {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseArticleSuggestionModelMetadata();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 3:
          if (tag !== 24) {
            break;
          }

          message.trainingModelType = reader.int32() as any;
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ArticleSuggestionModelMetadata {
    return {
      trainingModelType: isSet(object.trainingModelType)
        ? conversationModel_ModelTypeFromJSON(object.trainingModelType)
        : 0,
    };
  },

  toJSON(message: ArticleSuggestionModelMetadata): unknown {
    const obj: any = {};
    if (message.trainingModelType !== 0) {
      obj.trainingModelType = conversationModel_ModelTypeToJSON(message.trainingModelType);
    }
    return obj;
  },

  create(base?: DeepPartial<ArticleSuggestionModelMetadata>): ArticleSuggestionModelMetadata {
    return ArticleSuggestionModelMetadata.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ArticleSuggestionModelMetadata>): ArticleSuggestionModelMetadata {
    const message = createBaseArticleSuggestionModelMetadata();
    message.trainingModelType = object.trainingModelType ?? 0;
    return message;
  },
};

function createBaseSmartReplyModelMetadata(): SmartReplyModelMetadata {
  return { trainingModelType: 0 };
}

export const SmartReplyModelMetadata: MessageFns<SmartReplyModelMetadata> = {
  encode(message: SmartReplyModelMetadata, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.trainingModelType !== 0) {
      writer.uint32(48).int32(message.trainingModelType);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): SmartReplyModelMetadata {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseSmartReplyModelMetadata();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 6:
          if (tag !== 48) {
            break;
          }

          message.trainingModelType = reader.int32() as any;
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): SmartReplyModelMetadata {
    return {
      trainingModelType: isSet(object.trainingModelType)
        ? conversationModel_ModelTypeFromJSON(object.trainingModelType)
        : 0,
    };
  },

  toJSON(message: SmartReplyModelMetadata): unknown {
    const obj: any = {};
    if (message.trainingModelType !== 0) {
      obj.trainingModelType = conversationModel_ModelTypeToJSON(message.trainingModelType);
    }
    return obj;
  },

  create(base?: DeepPartial<SmartReplyModelMetadata>): SmartReplyModelMetadata {
    return SmartReplyModelMetadata.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<SmartReplyModelMetadata>): SmartReplyModelMetadata {
    const message = createBaseSmartReplyModelMetadata();
    message.trainingModelType = object.trainingModelType ?? 0;
    return message;
  },
};

function createBaseSmartReplyMetrics(): SmartReplyMetrics {
  return { allowlistCoverage: 0, topNMetrics: [], conversationCount: Long.ZERO };
}

export const SmartReplyMetrics: MessageFns<SmartReplyMetrics> = {
  encode(message: SmartReplyMetrics, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.allowlistCoverage !== 0) {
      writer.uint32(13).float(message.allowlistCoverage);
    }
    for (const v of message.topNMetrics) {
      SmartReplyMetrics_TopNMetrics.encode(v!, writer.uint32(18).fork()).join();
    }
    if (!message.conversationCount.equals(Long.ZERO)) {
      writer.uint32(24).int64(message.conversationCount.toString());
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): SmartReplyMetrics {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseSmartReplyMetrics();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 13) {
            break;
          }

          message.allowlistCoverage = reader.float();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.topNMetrics.push(SmartReplyMetrics_TopNMetrics.decode(reader, reader.uint32()));
          continue;
        case 3:
          if (tag !== 24) {
            break;
          }

          message.conversationCount = Long.fromString(reader.int64().toString());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): SmartReplyMetrics {
    return {
      allowlistCoverage: isSet(object.allowlistCoverage) ? globalThis.Number(object.allowlistCoverage) : 0,
      topNMetrics: globalThis.Array.isArray(object?.topNMetrics)
        ? object.topNMetrics.map((e: any) => SmartReplyMetrics_TopNMetrics.fromJSON(e))
        : [],
      conversationCount: isSet(object.conversationCount) ? Long.fromValue(object.conversationCount) : Long.ZERO,
    };
  },

  toJSON(message: SmartReplyMetrics): unknown {
    const obj: any = {};
    if (message.allowlistCoverage !== 0) {
      obj.allowlistCoverage = message.allowlistCoverage;
    }
    if (message.topNMetrics?.length) {
      obj.topNMetrics = message.topNMetrics.map((e) => SmartReplyMetrics_TopNMetrics.toJSON(e));
    }
    if (!message.conversationCount.equals(Long.ZERO)) {
      obj.conversationCount = (message.conversationCount || Long.ZERO).toString();
    }
    return obj;
  },

  create(base?: DeepPartial<SmartReplyMetrics>): SmartReplyMetrics {
    return SmartReplyMetrics.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<SmartReplyMetrics>): SmartReplyMetrics {
    const message = createBaseSmartReplyMetrics();
    message.allowlistCoverage = object.allowlistCoverage ?? 0;
    message.topNMetrics = object.topNMetrics?.map((e) => SmartReplyMetrics_TopNMetrics.fromPartial(e)) || [];
    message.conversationCount = (object.conversationCount !== undefined && object.conversationCount !== null)
      ? Long.fromValue(object.conversationCount)
      : Long.ZERO;
    return message;
  },
};

function createBaseSmartReplyMetrics_TopNMetrics(): SmartReplyMetrics_TopNMetrics {
  return { n: 0, recall: 0 };
}

export const SmartReplyMetrics_TopNMetrics: MessageFns<SmartReplyMetrics_TopNMetrics> = {
  encode(message: SmartReplyMetrics_TopNMetrics, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.n !== 0) {
      writer.uint32(8).int32(message.n);
    }
    if (message.recall !== 0) {
      writer.uint32(21).float(message.recall);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): SmartReplyMetrics_TopNMetrics {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseSmartReplyMetrics_TopNMetrics();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 8) {
            break;
          }

          message.n = reader.int32();
          continue;
        case 2:
          if (tag !== 21) {
            break;
          }

          message.recall = reader.float();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): SmartReplyMetrics_TopNMetrics {
    return {
      n: isSet(object.n) ? globalThis.Number(object.n) : 0,
      recall: isSet(object.recall) ? globalThis.Number(object.recall) : 0,
    };
  },

  toJSON(message: SmartReplyMetrics_TopNMetrics): unknown {
    const obj: any = {};
    if (message.n !== 0) {
      obj.n = Math.round(message.n);
    }
    if (message.recall !== 0) {
      obj.recall = message.recall;
    }
    return obj;
  },

  create(base?: DeepPartial<SmartReplyMetrics_TopNMetrics>): SmartReplyMetrics_TopNMetrics {
    return SmartReplyMetrics_TopNMetrics.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<SmartReplyMetrics_TopNMetrics>): SmartReplyMetrics_TopNMetrics {
    const message = createBaseSmartReplyMetrics_TopNMetrics();
    message.n = object.n ?? 0;
    message.recall = object.recall ?? 0;
    return message;
  },
};

function createBaseCreateConversationModelRequest(): CreateConversationModelRequest {
  return { parent: "", conversationModel: undefined };
}

export const CreateConversationModelRequest: MessageFns<CreateConversationModelRequest> = {
  encode(message: CreateConversationModelRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.parent !== "") {
      writer.uint32(10).string(message.parent);
    }
    if (message.conversationModel !== undefined) {
      ConversationModel.encode(message.conversationModel, writer.uint32(18).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): CreateConversationModelRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseCreateConversationModelRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.parent = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.conversationModel = ConversationModel.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): CreateConversationModelRequest {
    return {
      parent: isSet(object.parent) ? globalThis.String(object.parent) : "",
      conversationModel: isSet(object.conversationModel)
        ? ConversationModel.fromJSON(object.conversationModel)
        : undefined,
    };
  },

  toJSON(message: CreateConversationModelRequest): unknown {
    const obj: any = {};
    if (message.parent !== "") {
      obj.parent = message.parent;
    }
    if (message.conversationModel !== undefined) {
      obj.conversationModel = ConversationModel.toJSON(message.conversationModel);
    }
    return obj;
  },

  create(base?: DeepPartial<CreateConversationModelRequest>): CreateConversationModelRequest {
    return CreateConversationModelRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<CreateConversationModelRequest>): CreateConversationModelRequest {
    const message = createBaseCreateConversationModelRequest();
    message.parent = object.parent ?? "";
    message.conversationModel = (object.conversationModel !== undefined && object.conversationModel !== null)
      ? ConversationModel.fromPartial(object.conversationModel)
      : undefined;
    return message;
  },
};

function createBaseGetConversationModelRequest(): GetConversationModelRequest {
  return { name: "" };
}

export const GetConversationModelRequest: MessageFns<GetConversationModelRequest> = {
  encode(message: GetConversationModelRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): GetConversationModelRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseGetConversationModelRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): GetConversationModelRequest {
    return { name: isSet(object.name) ? globalThis.String(object.name) : "" };
  },

  toJSON(message: GetConversationModelRequest): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    return obj;
  },

  create(base?: DeepPartial<GetConversationModelRequest>): GetConversationModelRequest {
    return GetConversationModelRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<GetConversationModelRequest>): GetConversationModelRequest {
    const message = createBaseGetConversationModelRequest();
    message.name = object.name ?? "";
    return message;
  },
};

function createBaseListConversationModelsRequest(): ListConversationModelsRequest {
  return { parent: "", pageSize: 0, pageToken: "" };
}

export const ListConversationModelsRequest: MessageFns<ListConversationModelsRequest> = {
  encode(message: ListConversationModelsRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.parent !== "") {
      writer.uint32(10).string(message.parent);
    }
    if (message.pageSize !== 0) {
      writer.uint32(16).int32(message.pageSize);
    }
    if (message.pageToken !== "") {
      writer.uint32(26).string(message.pageToken);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ListConversationModelsRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseListConversationModelsRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.parent = reader.string();
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.pageSize = reader.int32();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.pageToken = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ListConversationModelsRequest {
    return {
      parent: isSet(object.parent) ? globalThis.String(object.parent) : "",
      pageSize: isSet(object.pageSize) ? globalThis.Number(object.pageSize) : 0,
      pageToken: isSet(object.pageToken) ? globalThis.String(object.pageToken) : "",
    };
  },

  toJSON(message: ListConversationModelsRequest): unknown {
    const obj: any = {};
    if (message.parent !== "") {
      obj.parent = message.parent;
    }
    if (message.pageSize !== 0) {
      obj.pageSize = Math.round(message.pageSize);
    }
    if (message.pageToken !== "") {
      obj.pageToken = message.pageToken;
    }
    return obj;
  },

  create(base?: DeepPartial<ListConversationModelsRequest>): ListConversationModelsRequest {
    return ListConversationModelsRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ListConversationModelsRequest>): ListConversationModelsRequest {
    const message = createBaseListConversationModelsRequest();
    message.parent = object.parent ?? "";
    message.pageSize = object.pageSize ?? 0;
    message.pageToken = object.pageToken ?? "";
    return message;
  },
};

function createBaseListConversationModelsResponse(): ListConversationModelsResponse {
  return { conversationModels: [], nextPageToken: "" };
}

export const ListConversationModelsResponse: MessageFns<ListConversationModelsResponse> = {
  encode(message: ListConversationModelsResponse, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.conversationModels) {
      ConversationModel.encode(v!, writer.uint32(10).fork()).join();
    }
    if (message.nextPageToken !== "") {
      writer.uint32(18).string(message.nextPageToken);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ListConversationModelsResponse {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseListConversationModelsResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.conversationModels.push(ConversationModel.decode(reader, reader.uint32()));
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.nextPageToken = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ListConversationModelsResponse {
    return {
      conversationModels: globalThis.Array.isArray(object?.conversationModels)
        ? object.conversationModels.map((e: any) => ConversationModel.fromJSON(e))
        : [],
      nextPageToken: isSet(object.nextPageToken) ? globalThis.String(object.nextPageToken) : "",
    };
  },

  toJSON(message: ListConversationModelsResponse): unknown {
    const obj: any = {};
    if (message.conversationModels?.length) {
      obj.conversationModels = message.conversationModels.map((e) => ConversationModel.toJSON(e));
    }
    if (message.nextPageToken !== "") {
      obj.nextPageToken = message.nextPageToken;
    }
    return obj;
  },

  create(base?: DeepPartial<ListConversationModelsResponse>): ListConversationModelsResponse {
    return ListConversationModelsResponse.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ListConversationModelsResponse>): ListConversationModelsResponse {
    const message = createBaseListConversationModelsResponse();
    message.conversationModels = object.conversationModels?.map((e) => ConversationModel.fromPartial(e)) || [];
    message.nextPageToken = object.nextPageToken ?? "";
    return message;
  },
};

function createBaseDeleteConversationModelRequest(): DeleteConversationModelRequest {
  return { name: "" };
}

export const DeleteConversationModelRequest: MessageFns<DeleteConversationModelRequest> = {
  encode(message: DeleteConversationModelRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): DeleteConversationModelRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDeleteConversationModelRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): DeleteConversationModelRequest {
    return { name: isSet(object.name) ? globalThis.String(object.name) : "" };
  },

  toJSON(message: DeleteConversationModelRequest): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    return obj;
  },

  create(base?: DeepPartial<DeleteConversationModelRequest>): DeleteConversationModelRequest {
    return DeleteConversationModelRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<DeleteConversationModelRequest>): DeleteConversationModelRequest {
    const message = createBaseDeleteConversationModelRequest();
    message.name = object.name ?? "";
    return message;
  },
};

function createBaseDeployConversationModelRequest(): DeployConversationModelRequest {
  return { name: "" };
}

export const DeployConversationModelRequest: MessageFns<DeployConversationModelRequest> = {
  encode(message: DeployConversationModelRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): DeployConversationModelRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDeployConversationModelRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): DeployConversationModelRequest {
    return { name: isSet(object.name) ? globalThis.String(object.name) : "" };
  },

  toJSON(message: DeployConversationModelRequest): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    return obj;
  },

  create(base?: DeepPartial<DeployConversationModelRequest>): DeployConversationModelRequest {
    return DeployConversationModelRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<DeployConversationModelRequest>): DeployConversationModelRequest {
    const message = createBaseDeployConversationModelRequest();
    message.name = object.name ?? "";
    return message;
  },
};

function createBaseUndeployConversationModelRequest(): UndeployConversationModelRequest {
  return { name: "" };
}

export const UndeployConversationModelRequest: MessageFns<UndeployConversationModelRequest> = {
  encode(message: UndeployConversationModelRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): UndeployConversationModelRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseUndeployConversationModelRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): UndeployConversationModelRequest {
    return { name: isSet(object.name) ? globalThis.String(object.name) : "" };
  },

  toJSON(message: UndeployConversationModelRequest): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    return obj;
  },

  create(base?: DeepPartial<UndeployConversationModelRequest>): UndeployConversationModelRequest {
    return UndeployConversationModelRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<UndeployConversationModelRequest>): UndeployConversationModelRequest {
    const message = createBaseUndeployConversationModelRequest();
    message.name = object.name ?? "";
    return message;
  },
};

function createBaseGetConversationModelEvaluationRequest(): GetConversationModelEvaluationRequest {
  return { name: "" };
}

export const GetConversationModelEvaluationRequest: MessageFns<GetConversationModelEvaluationRequest> = {
  encode(message: GetConversationModelEvaluationRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): GetConversationModelEvaluationRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseGetConversationModelEvaluationRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): GetConversationModelEvaluationRequest {
    return { name: isSet(object.name) ? globalThis.String(object.name) : "" };
  },

  toJSON(message: GetConversationModelEvaluationRequest): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    return obj;
  },

  create(base?: DeepPartial<GetConversationModelEvaluationRequest>): GetConversationModelEvaluationRequest {
    return GetConversationModelEvaluationRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<GetConversationModelEvaluationRequest>): GetConversationModelEvaluationRequest {
    const message = createBaseGetConversationModelEvaluationRequest();
    message.name = object.name ?? "";
    return message;
  },
};

function createBaseListConversationModelEvaluationsRequest(): ListConversationModelEvaluationsRequest {
  return { parent: "", pageSize: 0, pageToken: "" };
}

export const ListConversationModelEvaluationsRequest: MessageFns<ListConversationModelEvaluationsRequest> = {
  encode(message: ListConversationModelEvaluationsRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.parent !== "") {
      writer.uint32(10).string(message.parent);
    }
    if (message.pageSize !== 0) {
      writer.uint32(16).int32(message.pageSize);
    }
    if (message.pageToken !== "") {
      writer.uint32(26).string(message.pageToken);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ListConversationModelEvaluationsRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseListConversationModelEvaluationsRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.parent = reader.string();
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.pageSize = reader.int32();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.pageToken = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ListConversationModelEvaluationsRequest {
    return {
      parent: isSet(object.parent) ? globalThis.String(object.parent) : "",
      pageSize: isSet(object.pageSize) ? globalThis.Number(object.pageSize) : 0,
      pageToken: isSet(object.pageToken) ? globalThis.String(object.pageToken) : "",
    };
  },

  toJSON(message: ListConversationModelEvaluationsRequest): unknown {
    const obj: any = {};
    if (message.parent !== "") {
      obj.parent = message.parent;
    }
    if (message.pageSize !== 0) {
      obj.pageSize = Math.round(message.pageSize);
    }
    if (message.pageToken !== "") {
      obj.pageToken = message.pageToken;
    }
    return obj;
  },

  create(base?: DeepPartial<ListConversationModelEvaluationsRequest>): ListConversationModelEvaluationsRequest {
    return ListConversationModelEvaluationsRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ListConversationModelEvaluationsRequest>): ListConversationModelEvaluationsRequest {
    const message = createBaseListConversationModelEvaluationsRequest();
    message.parent = object.parent ?? "";
    message.pageSize = object.pageSize ?? 0;
    message.pageToken = object.pageToken ?? "";
    return message;
  },
};

function createBaseListConversationModelEvaluationsResponse(): ListConversationModelEvaluationsResponse {
  return { conversationModelEvaluations: [], nextPageToken: "" };
}

export const ListConversationModelEvaluationsResponse: MessageFns<ListConversationModelEvaluationsResponse> = {
  encode(message: ListConversationModelEvaluationsResponse, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.conversationModelEvaluations) {
      ConversationModelEvaluation.encode(v!, writer.uint32(10).fork()).join();
    }
    if (message.nextPageToken !== "") {
      writer.uint32(18).string(message.nextPageToken);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ListConversationModelEvaluationsResponse {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseListConversationModelEvaluationsResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.conversationModelEvaluations.push(ConversationModelEvaluation.decode(reader, reader.uint32()));
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.nextPageToken = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ListConversationModelEvaluationsResponse {
    return {
      conversationModelEvaluations: globalThis.Array.isArray(object?.conversationModelEvaluations)
        ? object.conversationModelEvaluations.map((e: any) => ConversationModelEvaluation.fromJSON(e))
        : [],
      nextPageToken: isSet(object.nextPageToken) ? globalThis.String(object.nextPageToken) : "",
    };
  },

  toJSON(message: ListConversationModelEvaluationsResponse): unknown {
    const obj: any = {};
    if (message.conversationModelEvaluations?.length) {
      obj.conversationModelEvaluations = message.conversationModelEvaluations.map((e) =>
        ConversationModelEvaluation.toJSON(e)
      );
    }
    if (message.nextPageToken !== "") {
      obj.nextPageToken = message.nextPageToken;
    }
    return obj;
  },

  create(base?: DeepPartial<ListConversationModelEvaluationsResponse>): ListConversationModelEvaluationsResponse {
    return ListConversationModelEvaluationsResponse.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ListConversationModelEvaluationsResponse>): ListConversationModelEvaluationsResponse {
    const message = createBaseListConversationModelEvaluationsResponse();
    message.conversationModelEvaluations =
      object.conversationModelEvaluations?.map((e) => ConversationModelEvaluation.fromPartial(e)) || [];
    message.nextPageToken = object.nextPageToken ?? "";
    return message;
  },
};

function createBaseCreateConversationModelEvaluationRequest(): CreateConversationModelEvaluationRequest {
  return { parent: "", conversationModelEvaluation: undefined };
}

export const CreateConversationModelEvaluationRequest: MessageFns<CreateConversationModelEvaluationRequest> = {
  encode(message: CreateConversationModelEvaluationRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.parent !== "") {
      writer.uint32(10).string(message.parent);
    }
    if (message.conversationModelEvaluation !== undefined) {
      ConversationModelEvaluation.encode(message.conversationModelEvaluation, writer.uint32(18).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): CreateConversationModelEvaluationRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseCreateConversationModelEvaluationRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.parent = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.conversationModelEvaluation = ConversationModelEvaluation.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): CreateConversationModelEvaluationRequest {
    return {
      parent: isSet(object.parent) ? globalThis.String(object.parent) : "",
      conversationModelEvaluation: isSet(object.conversationModelEvaluation)
        ? ConversationModelEvaluation.fromJSON(object.conversationModelEvaluation)
        : undefined,
    };
  },

  toJSON(message: CreateConversationModelEvaluationRequest): unknown {
    const obj: any = {};
    if (message.parent !== "") {
      obj.parent = message.parent;
    }
    if (message.conversationModelEvaluation !== undefined) {
      obj.conversationModelEvaluation = ConversationModelEvaluation.toJSON(message.conversationModelEvaluation);
    }
    return obj;
  },

  create(base?: DeepPartial<CreateConversationModelEvaluationRequest>): CreateConversationModelEvaluationRequest {
    return CreateConversationModelEvaluationRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<CreateConversationModelEvaluationRequest>): CreateConversationModelEvaluationRequest {
    const message = createBaseCreateConversationModelEvaluationRequest();
    message.parent = object.parent ?? "";
    message.conversationModelEvaluation =
      (object.conversationModelEvaluation !== undefined && object.conversationModelEvaluation !== null)
        ? ConversationModelEvaluation.fromPartial(object.conversationModelEvaluation)
        : undefined;
    return message;
  },
};

function createBaseCreateConversationModelOperationMetadata(): CreateConversationModelOperationMetadata {
  return { conversationModel: "", state: 0, createTime: undefined };
}

export const CreateConversationModelOperationMetadata: MessageFns<CreateConversationModelOperationMetadata> = {
  encode(message: CreateConversationModelOperationMetadata, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.conversationModel !== "") {
      writer.uint32(10).string(message.conversationModel);
    }
    if (message.state !== 0) {
      writer.uint32(16).int32(message.state);
    }
    if (message.createTime !== undefined) {
      Timestamp.encode(toTimestamp(message.createTime), writer.uint32(26).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): CreateConversationModelOperationMetadata {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseCreateConversationModelOperationMetadata();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.conversationModel = reader.string();
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.state = reader.int32() as any;
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.createTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): CreateConversationModelOperationMetadata {
    return {
      conversationModel: isSet(object.conversationModel) ? globalThis.String(object.conversationModel) : "",
      state: isSet(object.state) ? createConversationModelOperationMetadata_StateFromJSON(object.state) : 0,
      createTime: isSet(object.createTime) ? fromJsonTimestamp(object.createTime) : undefined,
    };
  },

  toJSON(message: CreateConversationModelOperationMetadata): unknown {
    const obj: any = {};
    if (message.conversationModel !== "") {
      obj.conversationModel = message.conversationModel;
    }
    if (message.state !== 0) {
      obj.state = createConversationModelOperationMetadata_StateToJSON(message.state);
    }
    if (message.createTime !== undefined) {
      obj.createTime = message.createTime.toISOString();
    }
    return obj;
  },

  create(base?: DeepPartial<CreateConversationModelOperationMetadata>): CreateConversationModelOperationMetadata {
    return CreateConversationModelOperationMetadata.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<CreateConversationModelOperationMetadata>): CreateConversationModelOperationMetadata {
    const message = createBaseCreateConversationModelOperationMetadata();
    message.conversationModel = object.conversationModel ?? "";
    message.state = object.state ?? 0;
    message.createTime = object.createTime ?? undefined;
    return message;
  },
};

function createBaseDeployConversationModelOperationMetadata(): DeployConversationModelOperationMetadata {
  return { conversationModel: "", createTime: undefined };
}

export const DeployConversationModelOperationMetadata: MessageFns<DeployConversationModelOperationMetadata> = {
  encode(message: DeployConversationModelOperationMetadata, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.conversationModel !== "") {
      writer.uint32(10).string(message.conversationModel);
    }
    if (message.createTime !== undefined) {
      Timestamp.encode(toTimestamp(message.createTime), writer.uint32(26).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): DeployConversationModelOperationMetadata {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDeployConversationModelOperationMetadata();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.conversationModel = reader.string();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.createTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): DeployConversationModelOperationMetadata {
    return {
      conversationModel: isSet(object.conversationModel) ? globalThis.String(object.conversationModel) : "",
      createTime: isSet(object.createTime) ? fromJsonTimestamp(object.createTime) : undefined,
    };
  },

  toJSON(message: DeployConversationModelOperationMetadata): unknown {
    const obj: any = {};
    if (message.conversationModel !== "") {
      obj.conversationModel = message.conversationModel;
    }
    if (message.createTime !== undefined) {
      obj.createTime = message.createTime.toISOString();
    }
    return obj;
  },

  create(base?: DeepPartial<DeployConversationModelOperationMetadata>): DeployConversationModelOperationMetadata {
    return DeployConversationModelOperationMetadata.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<DeployConversationModelOperationMetadata>): DeployConversationModelOperationMetadata {
    const message = createBaseDeployConversationModelOperationMetadata();
    message.conversationModel = object.conversationModel ?? "";
    message.createTime = object.createTime ?? undefined;
    return message;
  },
};

function createBaseUndeployConversationModelOperationMetadata(): UndeployConversationModelOperationMetadata {
  return { conversationModel: "", createTime: undefined };
}

export const UndeployConversationModelOperationMetadata: MessageFns<UndeployConversationModelOperationMetadata> = {
  encode(message: UndeployConversationModelOperationMetadata, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.conversationModel !== "") {
      writer.uint32(10).string(message.conversationModel);
    }
    if (message.createTime !== undefined) {
      Timestamp.encode(toTimestamp(message.createTime), writer.uint32(26).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): UndeployConversationModelOperationMetadata {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseUndeployConversationModelOperationMetadata();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.conversationModel = reader.string();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.createTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): UndeployConversationModelOperationMetadata {
    return {
      conversationModel: isSet(object.conversationModel) ? globalThis.String(object.conversationModel) : "",
      createTime: isSet(object.createTime) ? fromJsonTimestamp(object.createTime) : undefined,
    };
  },

  toJSON(message: UndeployConversationModelOperationMetadata): unknown {
    const obj: any = {};
    if (message.conversationModel !== "") {
      obj.conversationModel = message.conversationModel;
    }
    if (message.createTime !== undefined) {
      obj.createTime = message.createTime.toISOString();
    }
    return obj;
  },

  create(base?: DeepPartial<UndeployConversationModelOperationMetadata>): UndeployConversationModelOperationMetadata {
    return UndeployConversationModelOperationMetadata.fromPartial(base ?? {});
  },
  fromPartial(
    object: DeepPartial<UndeployConversationModelOperationMetadata>,
  ): UndeployConversationModelOperationMetadata {
    const message = createBaseUndeployConversationModelOperationMetadata();
    message.conversationModel = object.conversationModel ?? "";
    message.createTime = object.createTime ?? undefined;
    return message;
  },
};

function createBaseDeleteConversationModelOperationMetadata(): DeleteConversationModelOperationMetadata {
  return { conversationModel: "", createTime: undefined };
}

export const DeleteConversationModelOperationMetadata: MessageFns<DeleteConversationModelOperationMetadata> = {
  encode(message: DeleteConversationModelOperationMetadata, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.conversationModel !== "") {
      writer.uint32(10).string(message.conversationModel);
    }
    if (message.createTime !== undefined) {
      Timestamp.encode(toTimestamp(message.createTime), writer.uint32(26).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): DeleteConversationModelOperationMetadata {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDeleteConversationModelOperationMetadata();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.conversationModel = reader.string();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.createTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): DeleteConversationModelOperationMetadata {
    return {
      conversationModel: isSet(object.conversationModel) ? globalThis.String(object.conversationModel) : "",
      createTime: isSet(object.createTime) ? fromJsonTimestamp(object.createTime) : undefined,
    };
  },

  toJSON(message: DeleteConversationModelOperationMetadata): unknown {
    const obj: any = {};
    if (message.conversationModel !== "") {
      obj.conversationModel = message.conversationModel;
    }
    if (message.createTime !== undefined) {
      obj.createTime = message.createTime.toISOString();
    }
    return obj;
  },

  create(base?: DeepPartial<DeleteConversationModelOperationMetadata>): DeleteConversationModelOperationMetadata {
    return DeleteConversationModelOperationMetadata.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<DeleteConversationModelOperationMetadata>): DeleteConversationModelOperationMetadata {
    const message = createBaseDeleteConversationModelOperationMetadata();
    message.conversationModel = object.conversationModel ?? "";
    message.createTime = object.createTime ?? undefined;
    return message;
  },
};

function createBaseCreateConversationModelEvaluationOperationMetadata(): CreateConversationModelEvaluationOperationMetadata {
  return { conversationModelEvaluation: "", conversationModel: "", state: 0, createTime: undefined };
}

export const CreateConversationModelEvaluationOperationMetadata: MessageFns<
  CreateConversationModelEvaluationOperationMetadata
> = {
  encode(
    message: CreateConversationModelEvaluationOperationMetadata,
    writer: BinaryWriter = new BinaryWriter(),
  ): BinaryWriter {
    if (message.conversationModelEvaluation !== "") {
      writer.uint32(10).string(message.conversationModelEvaluation);
    }
    if (message.conversationModel !== "") {
      writer.uint32(34).string(message.conversationModel);
    }
    if (message.state !== 0) {
      writer.uint32(16).int32(message.state);
    }
    if (message.createTime !== undefined) {
      Timestamp.encode(toTimestamp(message.createTime), writer.uint32(26).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): CreateConversationModelEvaluationOperationMetadata {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseCreateConversationModelEvaluationOperationMetadata();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.conversationModelEvaluation = reader.string();
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.conversationModel = reader.string();
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.state = reader.int32() as any;
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.createTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): CreateConversationModelEvaluationOperationMetadata {
    return {
      conversationModelEvaluation: isSet(object.conversationModelEvaluation)
        ? globalThis.String(object.conversationModelEvaluation)
        : "",
      conversationModel: isSet(object.conversationModel) ? globalThis.String(object.conversationModel) : "",
      state: isSet(object.state) ? createConversationModelEvaluationOperationMetadata_StateFromJSON(object.state) : 0,
      createTime: isSet(object.createTime) ? fromJsonTimestamp(object.createTime) : undefined,
    };
  },

  toJSON(message: CreateConversationModelEvaluationOperationMetadata): unknown {
    const obj: any = {};
    if (message.conversationModelEvaluation !== "") {
      obj.conversationModelEvaluation = message.conversationModelEvaluation;
    }
    if (message.conversationModel !== "") {
      obj.conversationModel = message.conversationModel;
    }
    if (message.state !== 0) {
      obj.state = createConversationModelEvaluationOperationMetadata_StateToJSON(message.state);
    }
    if (message.createTime !== undefined) {
      obj.createTime = message.createTime.toISOString();
    }
    return obj;
  },

  create(
    base?: DeepPartial<CreateConversationModelEvaluationOperationMetadata>,
  ): CreateConversationModelEvaluationOperationMetadata {
    return CreateConversationModelEvaluationOperationMetadata.fromPartial(base ?? {});
  },
  fromPartial(
    object: DeepPartial<CreateConversationModelEvaluationOperationMetadata>,
  ): CreateConversationModelEvaluationOperationMetadata {
    const message = createBaseCreateConversationModelEvaluationOperationMetadata();
    message.conversationModelEvaluation = object.conversationModelEvaluation ?? "";
    message.conversationModel = object.conversationModel ?? "";
    message.state = object.state ?? 0;
    message.createTime = object.createTime ?? undefined;
    return message;
  },
};

/** Manages a collection of models for human agent assistant. */
export type ConversationModelsDefinition = typeof ConversationModelsDefinition;
export const ConversationModelsDefinition = {
  name: "ConversationModels",
  fullName: "google.cloud.dialogflow.v2.ConversationModels",
  methods: {
    /**
     * Creates a model.
     *
     * This method is a [long-running
     * operation](https://cloud.google.com/dialogflow/es/docs/how/long-running-operations).
     * The returned `Operation` type has the following method-specific fields:
     *
     * - `metadata`:
     * [CreateConversationModelOperationMetadata][google.cloud.dialogflow.v2.CreateConversationModelOperationMetadata]
     * - `response`:
     * [ConversationModel][google.cloud.dialogflow.v2.ConversationModel]
     */
    createConversationModel: {
      name: "CreateConversationModel",
      requestType: CreateConversationModelRequest,
      requestStream: false,
      responseType: Operation,
      responseStream: false,
      options: {
        _unknownFields: {
          8394: [
            Buffer.from([
              61,
              10,
              17,
              67,
              111,
              110,
              118,
              101,
              114,
              115,
              97,
              116,
              105,
              111,
              110,
              77,
              111,
              100,
              101,
              108,
              18,
              40,
              67,
              114,
              101,
              97,
              116,
              101,
              67,
              111,
              110,
              118,
              101,
              114,
              115,
              97,
              116,
              105,
              111,
              110,
              77,
              111,
              100,
              101,
              108,
              79,
              112,
              101,
              114,
              97,
              116,
              105,
              111,
              110,
              77,
              101,
              116,
              97,
              100,
              97,
              116,
              97,
            ]),
          ],
          8410: [
            Buffer.from([
              25,
              112,
              97,
              114,
              101,
              110,
              116,
              44,
              99,
              111,
              110,
              118,
              101,
              114,
              115,
              97,
              116,
              105,
              111,
              110,
              95,
              109,
              111,
              100,
              101,
              108,
            ]),
          ],
          578365826: [
            Buffer.from([
              142,
              1,
              58,
              18,
              99,
              111,
              110,
              118,
              101,
              114,
              115,
              97,
              116,
              105,
              111,
              110,
              95,
              109,
              111,
              100,
              101,
              108,
              90,
              76,
              58,
              18,
              99,
              111,
              110,
              118,
              101,
              114,
              115,
              97,
              116,
              105,
              111,
              110,
              95,
              109,
              111,
              100,
              101,
              108,
              34,
              54,
              47,
              118,
              50,
              47,
              123,
              112,
              97,
              114,
              101,
              110,
              116,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              125,
              47,
              99,
              111,
              110,
              118,
              101,
              114,
              115,
              97,
              116,
              105,
              111,
              110,
              77,
              111,
              100,
              101,
              108,
              115,
              34,
              42,
              47,
              118,
              50,
              47,
              123,
              112,
              97,
              114,
              101,
              110,
              116,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              125,
              47,
              99,
              111,
              110,
              118,
              101,
              114,
              115,
              97,
              116,
              105,
              111,
              110,
              77,
              111,
              100,
              101,
              108,
              115,
            ]),
          ],
        },
      },
    },
    /** Gets conversation model. */
    getConversationModel: {
      name: "GetConversationModel",
      requestType: GetConversationModelRequest,
      requestStream: false,
      responseType: ConversationModel,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [Buffer.from([4, 110, 97, 109, 101])],
          578365826: [
            Buffer.from([
              102,
              90,
              56,
              18,
              54,
              47,
              118,
              50,
              47,
              123,
              110,
              97,
              109,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              99,
              111,
              110,
              118,
              101,
              114,
              115,
              97,
              116,
              105,
              111,
              110,
              77,
              111,
              100,
              101,
              108,
              115,
              47,
              42,
              125,
              18,
              42,
              47,
              118,
              50,
              47,
              123,
              110,
              97,
              109,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              99,
              111,
              110,
              118,
              101,
              114,
              115,
              97,
              116,
              105,
              111,
              110,
              77,
              111,
              100,
              101,
              108,
              115,
              47,
              42,
              125,
            ]),
          ],
        },
      },
    },
    /** Lists conversation models. */
    listConversationModels: {
      name: "ListConversationModels",
      requestType: ListConversationModelsRequest,
      requestStream: false,
      responseType: ListConversationModelsResponse,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [Buffer.from([6, 112, 97, 114, 101, 110, 116])],
          578365826: [
            Buffer.from([
              102,
              90,
              56,
              18,
              54,
              47,
              118,
              50,
              47,
              123,
              112,
              97,
              114,
              101,
              110,
              116,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              125,
              47,
              99,
              111,
              110,
              118,
              101,
              114,
              115,
              97,
              116,
              105,
              111,
              110,
              77,
              111,
              100,
              101,
              108,
              115,
              18,
              42,
              47,
              118,
              50,
              47,
              123,
              112,
              97,
              114,
              101,
              110,
              116,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              125,
              47,
              99,
              111,
              110,
              118,
              101,
              114,
              115,
              97,
              116,
              105,
              111,
              110,
              77,
              111,
              100,
              101,
              108,
              115,
            ]),
          ],
        },
      },
    },
    /**
     * Deletes a model.
     *
     * This method is a [long-running
     * operation](https://cloud.google.com/dialogflow/es/docs/how/long-running-operations).
     * The returned `Operation` type has the following method-specific fields:
     *
     * - `metadata`:
     * [DeleteConversationModelOperationMetadata][google.cloud.dialogflow.v2.DeleteConversationModelOperationMetadata]
     * - `response`: An [Empty
     *   message](https://developers.google.com/protocol-buffers/docs/reference/google.protobuf#empty)
     */
    deleteConversationModel: {
      name: "DeleteConversationModel",
      requestType: DeleteConversationModelRequest,
      requestStream: false,
      responseType: Operation,
      responseStream: false,
      options: {
        _unknownFields: {
          8394: [
            Buffer.from([
              65,
              10,
              21,
              103,
              111,
              111,
              103,
              108,
              101,
              46,
              112,
              114,
              111,
              116,
              111,
              98,
              117,
              102,
              46,
              69,
              109,
              112,
              116,
              121,
              18,
              40,
              68,
              101,
              108,
              101,
              116,
              101,
              67,
              111,
              110,
              118,
              101,
              114,
              115,
              97,
              116,
              105,
              111,
              110,
              77,
              111,
              100,
              101,
              108,
              79,
              112,
              101,
              114,
              97,
              116,
              105,
              111,
              110,
              77,
              101,
              116,
              97,
              100,
              97,
              116,
              97,
            ]),
          ],
          8410: [Buffer.from([4, 110, 97, 109, 101])],
          578365826: [
            Buffer.from([
              102,
              90,
              56,
              42,
              54,
              47,
              118,
              50,
              47,
              123,
              110,
              97,
              109,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              99,
              111,
              110,
              118,
              101,
              114,
              115,
              97,
              116,
              105,
              111,
              110,
              77,
              111,
              100,
              101,
              108,
              115,
              47,
              42,
              125,
              42,
              42,
              47,
              118,
              50,
              47,
              123,
              110,
              97,
              109,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              99,
              111,
              110,
              118,
              101,
              114,
              115,
              97,
              116,
              105,
              111,
              110,
              77,
              111,
              100,
              101,
              108,
              115,
              47,
              42,
              125,
            ]),
          ],
        },
      },
    },
    /**
     * Deploys a model. If a model is already deployed, deploying it
     * has no effect. A model can only serve prediction requests after it gets
     * deployed. For article suggestion, custom model will not be used unless
     * it is deployed.
     *
     * This method is a [long-running
     * operation](https://cloud.google.com/dialogflow/es/docs/how/long-running-operations).
     * The returned `Operation` type has the following method-specific fields:
     *
     * - `metadata`:
     * [DeployConversationModelOperationMetadata][google.cloud.dialogflow.v2.DeployConversationModelOperationMetadata]
     * - `response`: An [Empty
     *   message](https://developers.google.com/protocol-buffers/docs/reference/google.protobuf#empty)
     */
    deployConversationModel: {
      name: "DeployConversationModel",
      requestType: DeployConversationModelRequest,
      requestStream: false,
      responseType: Operation,
      responseStream: false,
      options: {
        _unknownFields: {
          8394: [
            Buffer.from([
              65,
              10,
              21,
              103,
              111,
              111,
              103,
              108,
              101,
              46,
              112,
              114,
              111,
              116,
              111,
              98,
              117,
              102,
              46,
              69,
              109,
              112,
              116,
              121,
              18,
              40,
              68,
              101,
              112,
              108,
              111,
              121,
              67,
              111,
              110,
              118,
              101,
              114,
              115,
              97,
              116,
              105,
              111,
              110,
              77,
              111,
              100,
              101,
              108,
              79,
              112,
              101,
              114,
              97,
              116,
              105,
              111,
              110,
              77,
              101,
              116,
              97,
              100,
              97,
              116,
              97,
            ]),
          ],
          578365826: [
            Buffer.from([
              122,
              58,
              1,
              42,
              90,
              66,
              58,
              1,
              42,
              34,
              61,
              47,
              118,
              50,
              47,
              123,
              110,
              97,
              109,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              99,
              111,
              110,
              118,
              101,
              114,
              115,
              97,
              116,
              105,
              111,
              110,
              77,
              111,
              100,
              101,
              108,
              115,
              47,
              42,
              125,
              58,
              100,
              101,
              112,
              108,
              111,
              121,
              34,
              49,
              47,
              118,
              50,
              47,
              123,
              110,
              97,
              109,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              99,
              111,
              110,
              118,
              101,
              114,
              115,
              97,
              116,
              105,
              111,
              110,
              77,
              111,
              100,
              101,
              108,
              115,
              47,
              42,
              125,
              58,
              100,
              101,
              112,
              108,
              111,
              121,
            ]),
          ],
        },
      },
    },
    /**
     * Undeploys a model. If the model is not deployed this method has no effect.
     * If the model is currently being used:
     *   - For article suggestion, article suggestion will fallback to the default
     *     model if model is undeployed.
     *
     * This method is a [long-running
     * operation](https://cloud.google.com/dialogflow/es/docs/how/long-running-operations).
     * The returned `Operation` type has the following method-specific fields:
     *
     * - `metadata`:
     * [UndeployConversationModelOperationMetadata][google.cloud.dialogflow.v2.UndeployConversationModelOperationMetadata]
     * - `response`: An [Empty
     *   message](https://developers.google.com/protocol-buffers/docs/reference/google.protobuf#empty)
     */
    undeployConversationModel: {
      name: "UndeployConversationModel",
      requestType: UndeployConversationModelRequest,
      requestStream: false,
      responseType: Operation,
      responseStream: false,
      options: {
        _unknownFields: {
          8394: [
            Buffer.from([
              67,
              10,
              21,
              103,
              111,
              111,
              103,
              108,
              101,
              46,
              112,
              114,
              111,
              116,
              111,
              98,
              117,
              102,
              46,
              69,
              109,
              112,
              116,
              121,
              18,
              42,
              85,
              110,
              100,
              101,
              112,
              108,
              111,
              121,
              67,
              111,
              110,
              118,
              101,
              114,
              115,
              97,
              116,
              105,
              111,
              110,
              77,
              111,
              100,
              101,
              108,
              79,
              112,
              101,
              114,
              97,
              116,
              105,
              111,
              110,
              77,
              101,
              116,
              97,
              100,
              97,
              116,
              97,
            ]),
          ],
          578365826: [
            Buffer.from([
              126,
              58,
              1,
              42,
              90,
              68,
              58,
              1,
              42,
              34,
              63,
              47,
              118,
              50,
              47,
              123,
              110,
              97,
              109,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              99,
              111,
              110,
              118,
              101,
              114,
              115,
              97,
              116,
              105,
              111,
              110,
              77,
              111,
              100,
              101,
              108,
              115,
              47,
              42,
              125,
              58,
              117,
              110,
              100,
              101,
              112,
              108,
              111,
              121,
              34,
              51,
              47,
              118,
              50,
              47,
              123,
              110,
              97,
              109,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              99,
              111,
              110,
              118,
              101,
              114,
              115,
              97,
              116,
              105,
              111,
              110,
              77,
              111,
              100,
              101,
              108,
              115,
              47,
              42,
              125,
              58,
              117,
              110,
              100,
              101,
              112,
              108,
              111,
              121,
            ]),
          ],
        },
      },
    },
    /** Gets an evaluation of conversation model. */
    getConversationModelEvaluation: {
      name: "GetConversationModelEvaluation",
      requestType: GetConversationModelEvaluationRequest,
      requestStream: false,
      responseType: ConversationModelEvaluation,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [Buffer.from([4, 110, 97, 109, 101])],
          578365826: [
            Buffer.from([
              130,
              1,
              90,
              70,
              18,
              68,
              47,
              118,
              50,
              47,
              123,
              110,
              97,
              109,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              99,
              111,
              110,
              118,
              101,
              114,
              115,
              97,
              116,
              105,
              111,
              110,
              77,
              111,
              100,
              101,
              108,
              115,
              47,
              42,
              47,
              101,
              118,
              97,
              108,
              117,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              125,
              18,
              56,
              47,
              118,
              50,
              47,
              123,
              110,
              97,
              109,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              99,
              111,
              110,
              118,
              101,
              114,
              115,
              97,
              116,
              105,
              111,
              110,
              77,
              111,
              100,
              101,
              108,
              115,
              47,
              42,
              47,
              101,
              118,
              97,
              108,
              117,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              125,
            ]),
          ],
        },
      },
    },
    /** Lists evaluations of a conversation model. */
    listConversationModelEvaluations: {
      name: "ListConversationModelEvaluations",
      requestType: ListConversationModelEvaluationsRequest,
      requestStream: false,
      responseType: ListConversationModelEvaluationsResponse,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [Buffer.from([6, 112, 97, 114, 101, 110, 116])],
          578365826: [
            Buffer.from([
              130,
              1,
              90,
              70,
              18,
              68,
              47,
              118,
              50,
              47,
              123,
              112,
              97,
              114,
              101,
              110,
              116,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              99,
              111,
              110,
              118,
              101,
              114,
              115,
              97,
              116,
              105,
              111,
              110,
              77,
              111,
              100,
              101,
              108,
              115,
              47,
              42,
              125,
              47,
              101,
              118,
              97,
              108,
              117,
              97,
              116,
              105,
              111,
              110,
              115,
              18,
              56,
              47,
              118,
              50,
              47,
              123,
              112,
              97,
              114,
              101,
              110,
              116,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              99,
              111,
              110,
              118,
              101,
              114,
              115,
              97,
              116,
              105,
              111,
              110,
              77,
              111,
              100,
              101,
              108,
              115,
              47,
              42,
              125,
              47,
              101,
              118,
              97,
              108,
              117,
              97,
              116,
              105,
              111,
              110,
              115,
            ]),
          ],
        },
      },
    },
    /** Creates evaluation of a conversation model. */
    createConversationModelEvaluation: {
      name: "CreateConversationModelEvaluation",
      requestType: CreateConversationModelEvaluationRequest,
      requestStream: false,
      responseType: Operation,
      responseStream: false,
      options: {
        _unknownFields: {
          8394: [
            Buffer.from([
              81,
              10,
              27,
              67,
              111,
              110,
              118,
              101,
              114,
              115,
              97,
              116,
              105,
              111,
              110,
              77,
              111,
              100,
              101,
              108,
              69,
              118,
              97,
              108,
              117,
              97,
              116,
              105,
              111,
              110,
              18,
              50,
              67,
              114,
              101,
              97,
              116,
              101,
              67,
              111,
              110,
              118,
              101,
              114,
              115,
              97,
              116,
              105,
              111,
              110,
              77,
              111,
              100,
              101,
              108,
              69,
              118,
              97,
              108,
              117,
              97,
              116,
              105,
              111,
              110,
              79,
              112,
              101,
              114,
              97,
              116,
              105,
              111,
              110,
              77,
              101,
              116,
              97,
              100,
              97,
              116,
              97,
            ]),
          ],
          8410: [
            Buffer.from([
              36,
              112,
              97,
              114,
              101,
              110,
              116,
              44,
              99,
              111,
              110,
              118,
              101,
              114,
              115,
              97,
              116,
              105,
              111,
              110,
              95,
              109,
              111,
              100,
              101,
              108,
              95,
              101,
              118,
              97,
              108,
              117,
              97,
              116,
              105,
              111,
              110,
            ]),
          ],
          578365826: [
            Buffer.from([
              73,
              58,
              1,
              42,
              34,
              68,
              47,
              118,
              50,
              47,
              123,
              112,
              97,
              114,
              101,
              110,
              116,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              99,
              111,
              110,
              118,
              101,
              114,
              115,
              97,
              116,
              105,
              111,
              110,
              77,
              111,
              100,
              101,
              108,
              115,
              47,
              42,
              125,
              47,
              101,
              118,
              97,
              108,
              117,
              97,
              116,
              105,
              111,
              110,
              115,
            ]),
          ],
        },
      },
    },
  },
} as const;

export interface ConversationModelsServiceImplementation<CallContextExt = {}> {
  /**
   * Creates a model.
   *
   * This method is a [long-running
   * operation](https://cloud.google.com/dialogflow/es/docs/how/long-running-operations).
   * The returned `Operation` type has the following method-specific fields:
   *
   * - `metadata`:
   * [CreateConversationModelOperationMetadata][google.cloud.dialogflow.v2.CreateConversationModelOperationMetadata]
   * - `response`:
   * [ConversationModel][google.cloud.dialogflow.v2.ConversationModel]
   */
  createConversationModel(
    request: CreateConversationModelRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<Operation>>;
  /** Gets conversation model. */
  getConversationModel(
    request: GetConversationModelRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<ConversationModel>>;
  /** Lists conversation models. */
  listConversationModels(
    request: ListConversationModelsRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<ListConversationModelsResponse>>;
  /**
   * Deletes a model.
   *
   * This method is a [long-running
   * operation](https://cloud.google.com/dialogflow/es/docs/how/long-running-operations).
   * The returned `Operation` type has the following method-specific fields:
   *
   * - `metadata`:
   * [DeleteConversationModelOperationMetadata][google.cloud.dialogflow.v2.DeleteConversationModelOperationMetadata]
   * - `response`: An [Empty
   *   message](https://developers.google.com/protocol-buffers/docs/reference/google.protobuf#empty)
   */
  deleteConversationModel(
    request: DeleteConversationModelRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<Operation>>;
  /**
   * Deploys a model. If a model is already deployed, deploying it
   * has no effect. A model can only serve prediction requests after it gets
   * deployed. For article suggestion, custom model will not be used unless
   * it is deployed.
   *
   * This method is a [long-running
   * operation](https://cloud.google.com/dialogflow/es/docs/how/long-running-operations).
   * The returned `Operation` type has the following method-specific fields:
   *
   * - `metadata`:
   * [DeployConversationModelOperationMetadata][google.cloud.dialogflow.v2.DeployConversationModelOperationMetadata]
   * - `response`: An [Empty
   *   message](https://developers.google.com/protocol-buffers/docs/reference/google.protobuf#empty)
   */
  deployConversationModel(
    request: DeployConversationModelRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<Operation>>;
  /**
   * Undeploys a model. If the model is not deployed this method has no effect.
   * If the model is currently being used:
   *   - For article suggestion, article suggestion will fallback to the default
   *     model if model is undeployed.
   *
   * This method is a [long-running
   * operation](https://cloud.google.com/dialogflow/es/docs/how/long-running-operations).
   * The returned `Operation` type has the following method-specific fields:
   *
   * - `metadata`:
   * [UndeployConversationModelOperationMetadata][google.cloud.dialogflow.v2.UndeployConversationModelOperationMetadata]
   * - `response`: An [Empty
   *   message](https://developers.google.com/protocol-buffers/docs/reference/google.protobuf#empty)
   */
  undeployConversationModel(
    request: UndeployConversationModelRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<Operation>>;
  /** Gets an evaluation of conversation model. */
  getConversationModelEvaluation(
    request: GetConversationModelEvaluationRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<ConversationModelEvaluation>>;
  /** Lists evaluations of a conversation model. */
  listConversationModelEvaluations(
    request: ListConversationModelEvaluationsRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<ListConversationModelEvaluationsResponse>>;
  /** Creates evaluation of a conversation model. */
  createConversationModelEvaluation(
    request: CreateConversationModelEvaluationRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<Operation>>;
}

export interface ConversationModelsClient<CallOptionsExt = {}> {
  /**
   * Creates a model.
   *
   * This method is a [long-running
   * operation](https://cloud.google.com/dialogflow/es/docs/how/long-running-operations).
   * The returned `Operation` type has the following method-specific fields:
   *
   * - `metadata`:
   * [CreateConversationModelOperationMetadata][google.cloud.dialogflow.v2.CreateConversationModelOperationMetadata]
   * - `response`:
   * [ConversationModel][google.cloud.dialogflow.v2.ConversationModel]
   */
  createConversationModel(
    request: DeepPartial<CreateConversationModelRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<Operation>;
  /** Gets conversation model. */
  getConversationModel(
    request: DeepPartial<GetConversationModelRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<ConversationModel>;
  /** Lists conversation models. */
  listConversationModels(
    request: DeepPartial<ListConversationModelsRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<ListConversationModelsResponse>;
  /**
   * Deletes a model.
   *
   * This method is a [long-running
   * operation](https://cloud.google.com/dialogflow/es/docs/how/long-running-operations).
   * The returned `Operation` type has the following method-specific fields:
   *
   * - `metadata`:
   * [DeleteConversationModelOperationMetadata][google.cloud.dialogflow.v2.DeleteConversationModelOperationMetadata]
   * - `response`: An [Empty
   *   message](https://developers.google.com/protocol-buffers/docs/reference/google.protobuf#empty)
   */
  deleteConversationModel(
    request: DeepPartial<DeleteConversationModelRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<Operation>;
  /**
   * Deploys a model. If a model is already deployed, deploying it
   * has no effect. A model can only serve prediction requests after it gets
   * deployed. For article suggestion, custom model will not be used unless
   * it is deployed.
   *
   * This method is a [long-running
   * operation](https://cloud.google.com/dialogflow/es/docs/how/long-running-operations).
   * The returned `Operation` type has the following method-specific fields:
   *
   * - `metadata`:
   * [DeployConversationModelOperationMetadata][google.cloud.dialogflow.v2.DeployConversationModelOperationMetadata]
   * - `response`: An [Empty
   *   message](https://developers.google.com/protocol-buffers/docs/reference/google.protobuf#empty)
   */
  deployConversationModel(
    request: DeepPartial<DeployConversationModelRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<Operation>;
  /**
   * Undeploys a model. If the model is not deployed this method has no effect.
   * If the model is currently being used:
   *   - For article suggestion, article suggestion will fallback to the default
   *     model if model is undeployed.
   *
   * This method is a [long-running
   * operation](https://cloud.google.com/dialogflow/es/docs/how/long-running-operations).
   * The returned `Operation` type has the following method-specific fields:
   *
   * - `metadata`:
   * [UndeployConversationModelOperationMetadata][google.cloud.dialogflow.v2.UndeployConversationModelOperationMetadata]
   * - `response`: An [Empty
   *   message](https://developers.google.com/protocol-buffers/docs/reference/google.protobuf#empty)
   */
  undeployConversationModel(
    request: DeepPartial<UndeployConversationModelRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<Operation>;
  /** Gets an evaluation of conversation model. */
  getConversationModelEvaluation(
    request: DeepPartial<GetConversationModelEvaluationRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<ConversationModelEvaluation>;
  /** Lists evaluations of a conversation model. */
  listConversationModelEvaluations(
    request: DeepPartial<ListConversationModelEvaluationsRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<ListConversationModelEvaluationsResponse>;
  /** Creates evaluation of a conversation model. */
  createConversationModelEvaluation(
    request: DeepPartial<CreateConversationModelEvaluationRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<Operation>;
}

type Builtin = Date | Function | Uint8Array | string | number | boolean | undefined;

export type DeepPartial<T> = T extends Builtin ? T
  : T extends Long ? string | number | Long : T extends globalThis.Array<infer U> ? globalThis.Array<DeepPartial<U>>
  : T extends ReadonlyArray<infer U> ? ReadonlyArray<DeepPartial<U>>
  : T extends {} ? { [K in keyof T]?: DeepPartial<T[K]> }
  : Partial<T>;

function toTimestamp(date: Date): Timestamp {
  const seconds = numberToLong(Math.trunc(date.getTime() / 1_000));
  const nanos = (date.getTime() % 1_000) * 1_000_000;
  return { seconds, nanos };
}

function fromTimestamp(t: Timestamp): Date {
  let millis = (t.seconds.toNumber() || 0) * 1_000;
  millis += (t.nanos || 0) / 1_000_000;
  return new globalThis.Date(millis);
}

function fromJsonTimestamp(o: any): Date {
  if (o instanceof globalThis.Date) {
    return o;
  } else if (typeof o === "string") {
    return new globalThis.Date(o);
  } else {
    return fromTimestamp(Timestamp.fromJSON(o));
  }
}

function numberToLong(number: number) {
  return Long.fromNumber(number);
}

function isSet(value: any): boolean {
  return value !== null && value !== undefined;
}

export interface MessageFns<T> {
  encode(message: T, writer?: BinaryWriter): BinaryWriter;
  decode(input: BinaryReader | Uint8Array, length?: number): T;
  fromJSON(object: any): T;
  toJSON(message: T): unknown;
  create(base?: DeepPartial<T>): T;
  fromPartial(object: DeepPartial<T>): T;
}
