// Code generated by protoc-gen-ts_proto. DO NOT EDIT.
// versions:
//   protoc-gen-ts_proto  v2.2.0
//   protoc               unknown
// source: google/cloud/dialogflow/cx/v3beta1/generative_settings.proto

/* eslint-disable */
import { BinaryReader, BinaryWriter } from "@bufbuild/protobuf/wire";
import Long from "long";
import { SafetySettings } from "./safety_settings.js";

export const protobufPackage = "google.cloud.dialogflow.cx.v3beta1";

/** Settings for Generative AI. */
export interface GenerativeSettings {
  /**
   * Format: `projects/<Project ID>/locations/<Location ID>/agents/<Agent
   * ID>/generativeSettings`.
   */
  name: string;
  /** Settings for Generative Fallback. */
  fallbackSettings:
    | GenerativeSettings_FallbackSettings
    | undefined;
  /** Settings for Generative Safety. */
  generativeSafetySettings:
    | SafetySettings
    | undefined;
  /** Settings for knowledge connector. */
  knowledgeConnectorSettings:
    | GenerativeSettings_KnowledgeConnectorSettings
    | undefined;
  /** Language for this settings. */
  languageCode: string;
  /** LLM model settings. */
  llmModelSettings: LlmModelSettings | undefined;
}

/** Settings for Generative Fallback. */
export interface GenerativeSettings_FallbackSettings {
  /** Display name of the selected prompt. */
  selectedPrompt: string;
  /**
   * Stored prompts that can be selected, for example default templates like
   * "conservative" or "chatty", or user defined ones.
   */
  promptTemplates: GenerativeSettings_FallbackSettings_PromptTemplate[];
}

/** Prompt template. */
export interface GenerativeSettings_FallbackSettings_PromptTemplate {
  /** Prompt name. */
  displayName: string;
  /**
   * Prompt text that is sent to a LLM on no-match default, placeholders are
   * filled downstream. For example: "Here is a conversation $conversation,
   * a response is: "
   */
  promptText: string;
  /**
   * If the flag is true, the prompt is frozen and cannot be modified by
   * users.
   */
  frozen: boolean;
}

/**
 * Settings for knowledge connector. These parameters are used for LLM prompt
 * like "You are <agent>. You are a helpful and verbose <agent_identity> at
 * <business>, <business_description>. Your task is to help humans on
 * <agent_scope>".
 */
export interface GenerativeSettings_KnowledgeConnectorSettings {
  /**
   * Name of the company, organization or other entity that the agent
   * represents. Used for knowledge connector LLM prompt and for knowledge
   * search.
   */
  business: string;
  /** Name of the virtual agent. Used for LLM prompt. Can be left empty. */
  agent: string;
  /** Identity of the agent, e.g. "virtual agent", "AI assistant". */
  agentIdentity: string;
  /**
   * Company description, used for LLM prompt, e.g. "a family company selling
   * freshly roasted coffee beans".
   */
  businessDescription: string;
  /**
   * Agent scope, e.g. "Example company website", "internal Example
   * company website for employees", "manual of car owner".
   */
  agentScope: string;
  /**
   * Whether to disable fallback to Data Store search results (in case the LLM
   * couldn't pick a proper answer). Per default the feature is enabled.
   */
  disableDataStoreFallback: boolean;
}

/** Settings for LLM models. */
export interface LlmModelSettings {
  /** The selected LLM model. */
  model: string;
  /** The custom prompt to use. */
  promptText: string;
}

function createBaseGenerativeSettings(): GenerativeSettings {
  return {
    name: "",
    fallbackSettings: undefined,
    generativeSafetySettings: undefined,
    knowledgeConnectorSettings: undefined,
    languageCode: "",
    llmModelSettings: undefined,
  };
}

export const GenerativeSettings: MessageFns<GenerativeSettings> = {
  encode(message: GenerativeSettings, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(42).string(message.name);
    }
    if (message.fallbackSettings !== undefined) {
      GenerativeSettings_FallbackSettings.encode(message.fallbackSettings, writer.uint32(10).fork()).join();
    }
    if (message.generativeSafetySettings !== undefined) {
      SafetySettings.encode(message.generativeSafetySettings, writer.uint32(26).fork()).join();
    }
    if (message.knowledgeConnectorSettings !== undefined) {
      GenerativeSettings_KnowledgeConnectorSettings.encode(message.knowledgeConnectorSettings, writer.uint32(58).fork())
        .join();
    }
    if (message.languageCode !== "") {
      writer.uint32(34).string(message.languageCode);
    }
    if (message.llmModelSettings !== undefined) {
      LlmModelSettings.encode(message.llmModelSettings, writer.uint32(66).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): GenerativeSettings {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseGenerativeSettings();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 5:
          if (tag !== 42) {
            break;
          }

          message.name = reader.string();
          continue;
        case 1:
          if (tag !== 10) {
            break;
          }

          message.fallbackSettings = GenerativeSettings_FallbackSettings.decode(reader, reader.uint32());
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.generativeSafetySettings = SafetySettings.decode(reader, reader.uint32());
          continue;
        case 7:
          if (tag !== 58) {
            break;
          }

          message.knowledgeConnectorSettings = GenerativeSettings_KnowledgeConnectorSettings.decode(
            reader,
            reader.uint32(),
          );
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.languageCode = reader.string();
          continue;
        case 8:
          if (tag !== 66) {
            break;
          }

          message.llmModelSettings = LlmModelSettings.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): GenerativeSettings {
    return {
      name: isSet(object.name) ? globalThis.String(object.name) : "",
      fallbackSettings: isSet(object.fallbackSettings)
        ? GenerativeSettings_FallbackSettings.fromJSON(object.fallbackSettings)
        : undefined,
      generativeSafetySettings: isSet(object.generativeSafetySettings)
        ? SafetySettings.fromJSON(object.generativeSafetySettings)
        : undefined,
      knowledgeConnectorSettings: isSet(object.knowledgeConnectorSettings)
        ? GenerativeSettings_KnowledgeConnectorSettings.fromJSON(object.knowledgeConnectorSettings)
        : undefined,
      languageCode: isSet(object.languageCode) ? globalThis.String(object.languageCode) : "",
      llmModelSettings: isSet(object.llmModelSettings) ? LlmModelSettings.fromJSON(object.llmModelSettings) : undefined,
    };
  },

  toJSON(message: GenerativeSettings): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    if (message.fallbackSettings !== undefined) {
      obj.fallbackSettings = GenerativeSettings_FallbackSettings.toJSON(message.fallbackSettings);
    }
    if (message.generativeSafetySettings !== undefined) {
      obj.generativeSafetySettings = SafetySettings.toJSON(message.generativeSafetySettings);
    }
    if (message.knowledgeConnectorSettings !== undefined) {
      obj.knowledgeConnectorSettings = GenerativeSettings_KnowledgeConnectorSettings.toJSON(
        message.knowledgeConnectorSettings,
      );
    }
    if (message.languageCode !== "") {
      obj.languageCode = message.languageCode;
    }
    if (message.llmModelSettings !== undefined) {
      obj.llmModelSettings = LlmModelSettings.toJSON(message.llmModelSettings);
    }
    return obj;
  },

  create(base?: DeepPartial<GenerativeSettings>): GenerativeSettings {
    return GenerativeSettings.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<GenerativeSettings>): GenerativeSettings {
    const message = createBaseGenerativeSettings();
    message.name = object.name ?? "";
    message.fallbackSettings = (object.fallbackSettings !== undefined && object.fallbackSettings !== null)
      ? GenerativeSettings_FallbackSettings.fromPartial(object.fallbackSettings)
      : undefined;
    message.generativeSafetySettings =
      (object.generativeSafetySettings !== undefined && object.generativeSafetySettings !== null)
        ? SafetySettings.fromPartial(object.generativeSafetySettings)
        : undefined;
    message.knowledgeConnectorSettings =
      (object.knowledgeConnectorSettings !== undefined && object.knowledgeConnectorSettings !== null)
        ? GenerativeSettings_KnowledgeConnectorSettings.fromPartial(object.knowledgeConnectorSettings)
        : undefined;
    message.languageCode = object.languageCode ?? "";
    message.llmModelSettings = (object.llmModelSettings !== undefined && object.llmModelSettings !== null)
      ? LlmModelSettings.fromPartial(object.llmModelSettings)
      : undefined;
    return message;
  },
};

function createBaseGenerativeSettings_FallbackSettings(): GenerativeSettings_FallbackSettings {
  return { selectedPrompt: "", promptTemplates: [] };
}

export const GenerativeSettings_FallbackSettings: MessageFns<GenerativeSettings_FallbackSettings> = {
  encode(message: GenerativeSettings_FallbackSettings, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.selectedPrompt !== "") {
      writer.uint32(26).string(message.selectedPrompt);
    }
    for (const v of message.promptTemplates) {
      GenerativeSettings_FallbackSettings_PromptTemplate.encode(v!, writer.uint32(34).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): GenerativeSettings_FallbackSettings {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseGenerativeSettings_FallbackSettings();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 3:
          if (tag !== 26) {
            break;
          }

          message.selectedPrompt = reader.string();
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.promptTemplates.push(
            GenerativeSettings_FallbackSettings_PromptTemplate.decode(reader, reader.uint32()),
          );
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): GenerativeSettings_FallbackSettings {
    return {
      selectedPrompt: isSet(object.selectedPrompt) ? globalThis.String(object.selectedPrompt) : "",
      promptTemplates: globalThis.Array.isArray(object?.promptTemplates)
        ? object.promptTemplates.map((e: any) => GenerativeSettings_FallbackSettings_PromptTemplate.fromJSON(e))
        : [],
    };
  },

  toJSON(message: GenerativeSettings_FallbackSettings): unknown {
    const obj: any = {};
    if (message.selectedPrompt !== "") {
      obj.selectedPrompt = message.selectedPrompt;
    }
    if (message.promptTemplates?.length) {
      obj.promptTemplates = message.promptTemplates.map((e) =>
        GenerativeSettings_FallbackSettings_PromptTemplate.toJSON(e)
      );
    }
    return obj;
  },

  create(base?: DeepPartial<GenerativeSettings_FallbackSettings>): GenerativeSettings_FallbackSettings {
    return GenerativeSettings_FallbackSettings.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<GenerativeSettings_FallbackSettings>): GenerativeSettings_FallbackSettings {
    const message = createBaseGenerativeSettings_FallbackSettings();
    message.selectedPrompt = object.selectedPrompt ?? "";
    message.promptTemplates =
      object.promptTemplates?.map((e) => GenerativeSettings_FallbackSettings_PromptTemplate.fromPartial(e)) || [];
    return message;
  },
};

function createBaseGenerativeSettings_FallbackSettings_PromptTemplate(): GenerativeSettings_FallbackSettings_PromptTemplate {
  return { displayName: "", promptText: "", frozen: false };
}

export const GenerativeSettings_FallbackSettings_PromptTemplate: MessageFns<
  GenerativeSettings_FallbackSettings_PromptTemplate
> = {
  encode(
    message: GenerativeSettings_FallbackSettings_PromptTemplate,
    writer: BinaryWriter = new BinaryWriter(),
  ): BinaryWriter {
    if (message.displayName !== "") {
      writer.uint32(10).string(message.displayName);
    }
    if (message.promptText !== "") {
      writer.uint32(18).string(message.promptText);
    }
    if (message.frozen !== false) {
      writer.uint32(24).bool(message.frozen);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): GenerativeSettings_FallbackSettings_PromptTemplate {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseGenerativeSettings_FallbackSettings_PromptTemplate();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.displayName = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.promptText = reader.string();
          continue;
        case 3:
          if (tag !== 24) {
            break;
          }

          message.frozen = reader.bool();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): GenerativeSettings_FallbackSettings_PromptTemplate {
    return {
      displayName: isSet(object.displayName) ? globalThis.String(object.displayName) : "",
      promptText: isSet(object.promptText) ? globalThis.String(object.promptText) : "",
      frozen: isSet(object.frozen) ? globalThis.Boolean(object.frozen) : false,
    };
  },

  toJSON(message: GenerativeSettings_FallbackSettings_PromptTemplate): unknown {
    const obj: any = {};
    if (message.displayName !== "") {
      obj.displayName = message.displayName;
    }
    if (message.promptText !== "") {
      obj.promptText = message.promptText;
    }
    if (message.frozen !== false) {
      obj.frozen = message.frozen;
    }
    return obj;
  },

  create(
    base?: DeepPartial<GenerativeSettings_FallbackSettings_PromptTemplate>,
  ): GenerativeSettings_FallbackSettings_PromptTemplate {
    return GenerativeSettings_FallbackSettings_PromptTemplate.fromPartial(base ?? {});
  },
  fromPartial(
    object: DeepPartial<GenerativeSettings_FallbackSettings_PromptTemplate>,
  ): GenerativeSettings_FallbackSettings_PromptTemplate {
    const message = createBaseGenerativeSettings_FallbackSettings_PromptTemplate();
    message.displayName = object.displayName ?? "";
    message.promptText = object.promptText ?? "";
    message.frozen = object.frozen ?? false;
    return message;
  },
};

function createBaseGenerativeSettings_KnowledgeConnectorSettings(): GenerativeSettings_KnowledgeConnectorSettings {
  return {
    business: "",
    agent: "",
    agentIdentity: "",
    businessDescription: "",
    agentScope: "",
    disableDataStoreFallback: false,
  };
}

export const GenerativeSettings_KnowledgeConnectorSettings: MessageFns<GenerativeSettings_KnowledgeConnectorSettings> =
  {
    encode(
      message: GenerativeSettings_KnowledgeConnectorSettings,
      writer: BinaryWriter = new BinaryWriter(),
    ): BinaryWriter {
      if (message.business !== "") {
        writer.uint32(10).string(message.business);
      }
      if (message.agent !== "") {
        writer.uint32(18).string(message.agent);
      }
      if (message.agentIdentity !== "") {
        writer.uint32(26).string(message.agentIdentity);
      }
      if (message.businessDescription !== "") {
        writer.uint32(34).string(message.businessDescription);
      }
      if (message.agentScope !== "") {
        writer.uint32(42).string(message.agentScope);
      }
      if (message.disableDataStoreFallback !== false) {
        writer.uint32(64).bool(message.disableDataStoreFallback);
      }
      return writer;
    },

    decode(input: BinaryReader | Uint8Array, length?: number): GenerativeSettings_KnowledgeConnectorSettings {
      const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
      let end = length === undefined ? reader.len : reader.pos + length;
      const message = createBaseGenerativeSettings_KnowledgeConnectorSettings();
      while (reader.pos < end) {
        const tag = reader.uint32();
        switch (tag >>> 3) {
          case 1:
            if (tag !== 10) {
              break;
            }

            message.business = reader.string();
            continue;
          case 2:
            if (tag !== 18) {
              break;
            }

            message.agent = reader.string();
            continue;
          case 3:
            if (tag !== 26) {
              break;
            }

            message.agentIdentity = reader.string();
            continue;
          case 4:
            if (tag !== 34) {
              break;
            }

            message.businessDescription = reader.string();
            continue;
          case 5:
            if (tag !== 42) {
              break;
            }

            message.agentScope = reader.string();
            continue;
          case 8:
            if (tag !== 64) {
              break;
            }

            message.disableDataStoreFallback = reader.bool();
            continue;
        }
        if ((tag & 7) === 4 || tag === 0) {
          break;
        }
        reader.skip(tag & 7);
      }
      return message;
    },

    fromJSON(object: any): GenerativeSettings_KnowledgeConnectorSettings {
      return {
        business: isSet(object.business) ? globalThis.String(object.business) : "",
        agent: isSet(object.agent) ? globalThis.String(object.agent) : "",
        agentIdentity: isSet(object.agentIdentity) ? globalThis.String(object.agentIdentity) : "",
        businessDescription: isSet(object.businessDescription) ? globalThis.String(object.businessDescription) : "",
        agentScope: isSet(object.agentScope) ? globalThis.String(object.agentScope) : "",
        disableDataStoreFallback: isSet(object.disableDataStoreFallback)
          ? globalThis.Boolean(object.disableDataStoreFallback)
          : false,
      };
    },

    toJSON(message: GenerativeSettings_KnowledgeConnectorSettings): unknown {
      const obj: any = {};
      if (message.business !== "") {
        obj.business = message.business;
      }
      if (message.agent !== "") {
        obj.agent = message.agent;
      }
      if (message.agentIdentity !== "") {
        obj.agentIdentity = message.agentIdentity;
      }
      if (message.businessDescription !== "") {
        obj.businessDescription = message.businessDescription;
      }
      if (message.agentScope !== "") {
        obj.agentScope = message.agentScope;
      }
      if (message.disableDataStoreFallback !== false) {
        obj.disableDataStoreFallback = message.disableDataStoreFallback;
      }
      return obj;
    },

    create(
      base?: DeepPartial<GenerativeSettings_KnowledgeConnectorSettings>,
    ): GenerativeSettings_KnowledgeConnectorSettings {
      return GenerativeSettings_KnowledgeConnectorSettings.fromPartial(base ?? {});
    },
    fromPartial(
      object: DeepPartial<GenerativeSettings_KnowledgeConnectorSettings>,
    ): GenerativeSettings_KnowledgeConnectorSettings {
      const message = createBaseGenerativeSettings_KnowledgeConnectorSettings();
      message.business = object.business ?? "";
      message.agent = object.agent ?? "";
      message.agentIdentity = object.agentIdentity ?? "";
      message.businessDescription = object.businessDescription ?? "";
      message.agentScope = object.agentScope ?? "";
      message.disableDataStoreFallback = object.disableDataStoreFallback ?? false;
      return message;
    },
  };

function createBaseLlmModelSettings(): LlmModelSettings {
  return { model: "", promptText: "" };
}

export const LlmModelSettings: MessageFns<LlmModelSettings> = {
  encode(message: LlmModelSettings, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.model !== "") {
      writer.uint32(10).string(message.model);
    }
    if (message.promptText !== "") {
      writer.uint32(18).string(message.promptText);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): LlmModelSettings {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseLlmModelSettings();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.model = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.promptText = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): LlmModelSettings {
    return {
      model: isSet(object.model) ? globalThis.String(object.model) : "",
      promptText: isSet(object.promptText) ? globalThis.String(object.promptText) : "",
    };
  },

  toJSON(message: LlmModelSettings): unknown {
    const obj: any = {};
    if (message.model !== "") {
      obj.model = message.model;
    }
    if (message.promptText !== "") {
      obj.promptText = message.promptText;
    }
    return obj;
  },

  create(base?: DeepPartial<LlmModelSettings>): LlmModelSettings {
    return LlmModelSettings.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<LlmModelSettings>): LlmModelSettings {
    const message = createBaseLlmModelSettings();
    message.model = object.model ?? "";
    message.promptText = object.promptText ?? "";
    return message;
  },
};

type Builtin = Date | Function | Uint8Array | string | number | boolean | undefined;

export type DeepPartial<T> = T extends Builtin ? T
  : T extends Long ? string | number | Long : T extends globalThis.Array<infer U> ? globalThis.Array<DeepPartial<U>>
  : T extends ReadonlyArray<infer U> ? ReadonlyArray<DeepPartial<U>>
  : T extends {} ? { [K in keyof T]?: DeepPartial<T[K]> }
  : Partial<T>;

function isSet(value: any): boolean {
  return value !== null && value !== undefined;
}

export interface MessageFns<T> {
  encode(message: T, writer?: BinaryWriter): BinaryWriter;
  decode(input: BinaryReader | Uint8Array, length?: number): T;
  fromJSON(object: any): T;
  toJSON(message: T): unknown;
  create(base?: DeepPartial<T>): T;
  fromPartial(object: DeepPartial<T>): T;
}
