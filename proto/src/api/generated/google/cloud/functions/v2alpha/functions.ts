// Code generated by protoc-gen-ts_proto. DO NOT EDIT.
// versions:
//   protoc-gen-ts_proto  v2.2.0
//   protoc               unknown
// source: google/cloud/functions/v2alpha/functions.proto

/* eslint-disable */
import { BinaryReader, BinaryWriter } from "@bufbuild/protobuf/wire";
import Long from "long";
import { type CallContext, type CallOptions } from "nice-grpc-common";
import { Operation } from "../../../longrunning/operations.js";
import { Any } from "../../../protobuf/any.js";
import { FieldMask } from "../../../protobuf/field_mask.js";
import { Timestamp } from "../../../protobuf/timestamp.js";
import { DateMessage } from "../../../type/date.js";

export const protobufPackage = "google.cloud.functions.v2alpha";

/** The type of the long running operation. */
export enum OperationType {
  /** OPERATIONTYPE_UNSPECIFIED - Unspecified */
  OPERATIONTYPE_UNSPECIFIED = 0,
  /** CREATE_FUNCTION - CreateFunction */
  CREATE_FUNCTION = 1,
  /** UPDATE_FUNCTION - UpdateFunction */
  UPDATE_FUNCTION = 2,
  /** DELETE_FUNCTION - DeleteFunction */
  DELETE_FUNCTION = 3,
  UNRECOGNIZED = -1,
}

export function operationTypeFromJSON(object: any): OperationType {
  switch (object) {
    case 0:
    case "OPERATIONTYPE_UNSPECIFIED":
      return OperationType.OPERATIONTYPE_UNSPECIFIED;
    case 1:
    case "CREATE_FUNCTION":
      return OperationType.CREATE_FUNCTION;
    case 2:
    case "UPDATE_FUNCTION":
      return OperationType.UPDATE_FUNCTION;
    case 3:
    case "DELETE_FUNCTION":
      return OperationType.DELETE_FUNCTION;
    case -1:
    case "UNRECOGNIZED":
    default:
      return OperationType.UNRECOGNIZED;
  }
}

export function operationTypeToJSON(object: OperationType): string {
  switch (object) {
    case OperationType.OPERATIONTYPE_UNSPECIFIED:
      return "OPERATIONTYPE_UNSPECIFIED";
    case OperationType.CREATE_FUNCTION:
      return "CREATE_FUNCTION";
    case OperationType.UPDATE_FUNCTION:
      return "UPDATE_FUNCTION";
    case OperationType.DELETE_FUNCTION:
      return "DELETE_FUNCTION";
    case OperationType.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/** The environment the function is hosted on. */
export enum Environment {
  /** ENVIRONMENT_UNSPECIFIED - Unspecified */
  ENVIRONMENT_UNSPECIFIED = 0,
  /** GEN_1 - Gen 1 */
  GEN_1 = 1,
  /** GEN_2 - Gen 2 */
  GEN_2 = 2,
  UNRECOGNIZED = -1,
}

export function environmentFromJSON(object: any): Environment {
  switch (object) {
    case 0:
    case "ENVIRONMENT_UNSPECIFIED":
      return Environment.ENVIRONMENT_UNSPECIFIED;
    case 1:
    case "GEN_1":
      return Environment.GEN_1;
    case 2:
    case "GEN_2":
      return Environment.GEN_2;
    case -1:
    case "UNRECOGNIZED":
    default:
      return Environment.UNRECOGNIZED;
  }
}

export function environmentToJSON(object: Environment): string {
  switch (object) {
    case Environment.ENVIRONMENT_UNSPECIFIED:
      return "ENVIRONMENT_UNSPECIFIED";
    case Environment.GEN_1:
      return "GEN_1";
    case Environment.GEN_2:
      return "GEN_2";
    case Environment.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/**
 * Describes a Cloud Function that contains user computation executed in
 * response to an event. It encapsulates function and trigger configurations.
 */
export interface Function {
  /**
   * A user-defined name of the function. Function names must be unique
   * globally and match pattern `projects/* /locations/* /functions/*`
   */
  name: string;
  /** User-provided description of a function. */
  description: string;
  /**
   * Describes the Build step of the function that builds a container from the
   * given source.
   */
  buildConfig:
    | BuildConfig
    | undefined;
  /**
   * Describes the Service being deployed. Currently deploys services to Cloud
   * Run (fully managed).
   */
  serviceConfig:
    | ServiceConfig
    | undefined;
  /**
   * An Eventarc trigger managed by Google Cloud Functions that fires events in
   * response to a condition in another service.
   */
  eventTrigger:
    | EventTrigger
    | undefined;
  /** Output only. State of the function. */
  state: Function_State;
  /** Output only. The last update timestamp of a Cloud Function. */
  updateTime:
    | Date
    | undefined;
  /** Labels associated with this Cloud Function. */
  labels: { [key: string]: string };
  /** Output only. State Messages for this Cloud Function. */
  stateMessages: StateMessage[];
  /** Describe whether the function is 1st Gen or 2nd Gen. */
  environment: Environment;
  /** Output only. The deployed url for the function. */
  url: string;
  /**
   * [Preview] Resource name of a KMS crypto key (managed by the user) used to
   * encrypt/decrypt function resources.
   *
   * It must match the pattern
   * `projects/{project}/locations/{location}/keyRings/{key_ring}/cryptoKeys/{crypto_key}`.
   */
  kmsKeyName: string;
  /** Output only. Reserved for future use. */
  satisfiesPzs: boolean;
  /**
   * Output only. The create timestamp of a Cloud Function. This is only
   * applicable to 2nd Gen functions.
   */
  createTime: Date | undefined;
}

/** Describes the current state of the function. */
export enum Function_State {
  /** STATE_UNSPECIFIED - Not specified. Invalid state. */
  STATE_UNSPECIFIED = 0,
  /** ACTIVE - Function has been successfully deployed and is serving. */
  ACTIVE = 1,
  /** FAILED - Function deployment failed and the function is not serving. */
  FAILED = 2,
  /** DEPLOYING - Function is being created or updated. */
  DEPLOYING = 3,
  /** DELETING - Function is being deleted. */
  DELETING = 4,
  /**
   * UNKNOWN - Function deployment failed and the function serving state is undefined.
   * The function should be updated or deleted to move it out of this state.
   */
  UNKNOWN = 5,
  UNRECOGNIZED = -1,
}

export function function_StateFromJSON(object: any): Function_State {
  switch (object) {
    case 0:
    case "STATE_UNSPECIFIED":
      return Function_State.STATE_UNSPECIFIED;
    case 1:
    case "ACTIVE":
      return Function_State.ACTIVE;
    case 2:
    case "FAILED":
      return Function_State.FAILED;
    case 3:
    case "DEPLOYING":
      return Function_State.DEPLOYING;
    case 4:
    case "DELETING":
      return Function_State.DELETING;
    case 5:
    case "UNKNOWN":
      return Function_State.UNKNOWN;
    case -1:
    case "UNRECOGNIZED":
    default:
      return Function_State.UNRECOGNIZED;
  }
}

export function function_StateToJSON(object: Function_State): string {
  switch (object) {
    case Function_State.STATE_UNSPECIFIED:
      return "STATE_UNSPECIFIED";
    case Function_State.ACTIVE:
      return "ACTIVE";
    case Function_State.FAILED:
      return "FAILED";
    case Function_State.DEPLOYING:
      return "DEPLOYING";
    case Function_State.DELETING:
      return "DELETING";
    case Function_State.UNKNOWN:
      return "UNKNOWN";
    case Function_State.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

export interface Function_LabelsEntry {
  key: string;
  value: string;
}

/** Informational messages about the state of the Cloud Function or Operation. */
export interface StateMessage {
  /** Severity of the state message. */
  severity: StateMessage_Severity;
  /** One-word CamelCase type of the state message. */
  type: string;
  /** The message. */
  message: string;
}

/** Severity of the state message. */
export enum StateMessage_Severity {
  /** SEVERITY_UNSPECIFIED - Not specified. Invalid severity. */
  SEVERITY_UNSPECIFIED = 0,
  /** ERROR - ERROR-level severity. */
  ERROR = 1,
  /** WARNING - WARNING-level severity. */
  WARNING = 2,
  /** INFO - INFO-level severity. */
  INFO = 3,
  UNRECOGNIZED = -1,
}

export function stateMessage_SeverityFromJSON(object: any): StateMessage_Severity {
  switch (object) {
    case 0:
    case "SEVERITY_UNSPECIFIED":
      return StateMessage_Severity.SEVERITY_UNSPECIFIED;
    case 1:
    case "ERROR":
      return StateMessage_Severity.ERROR;
    case 2:
    case "WARNING":
      return StateMessage_Severity.WARNING;
    case 3:
    case "INFO":
      return StateMessage_Severity.INFO;
    case -1:
    case "UNRECOGNIZED":
    default:
      return StateMessage_Severity.UNRECOGNIZED;
  }
}

export function stateMessage_SeverityToJSON(object: StateMessage_Severity): string {
  switch (object) {
    case StateMessage_Severity.SEVERITY_UNSPECIFIED:
      return "SEVERITY_UNSPECIFIED";
    case StateMessage_Severity.ERROR:
      return "ERROR";
    case StateMessage_Severity.WARNING:
      return "WARNING";
    case StateMessage_Severity.INFO:
      return "INFO";
    case StateMessage_Severity.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/** Location of the source in an archive file in Google Cloud Storage. */
export interface StorageSource {
  /**
   * Google Cloud Storage bucket containing the source (see
   * [Bucket Name
   * Requirements](https://cloud.google.com/storage/docs/bucket-naming#requirements)).
   */
  bucket: string;
  /**
   * Google Cloud Storage object containing the source.
   *
   * This object must be a gzipped archive file (`.tar.gz`) containing source to
   * build.
   */
  object: string;
  /**
   * Google Cloud Storage generation for the object. If the generation is
   * omitted, the latest generation will be used.
   */
  generation: Long;
  /**
   * When the specified storage bucket is a 1st gen function uploard url bucket,
   * this field should be set as the generated upload url for 1st gen
   * deployment.
   */
  sourceUploadUrl: string;
}

/** Location of the source in a Google Cloud Source Repository. */
export interface RepoSource {
  /**
   * Regex matching branches to build.
   *
   * The syntax of the regular expressions accepted is the syntax accepted by
   * RE2 and described at https://github.com/google/re2/wiki/Syntax
   */
  branchName?:
    | string
    | undefined;
  /**
   * Regex matching tags to build.
   *
   * The syntax of the regular expressions accepted is the syntax accepted by
   * RE2 and described at https://github.com/google/re2/wiki/Syntax
   */
  tagName?:
    | string
    | undefined;
  /** Explicit commit SHA to build. */
  commitSha?:
    | string
    | undefined;
  /**
   * ID of the project that owns the Cloud Source Repository. If omitted, the
   * project ID requesting the build is assumed.
   */
  projectId: string;
  /** Name of the Cloud Source Repository. */
  repoName: string;
  /**
   * Directory, relative to the source root, in which to run the build.
   *
   * This must be a relative path. If a step's `dir` is specified and is an
   * absolute path, this value is ignored for that step's execution.
   * eg. helloworld (no leading slash allowed)
   */
  dir: string;
  /**
   * Only trigger a build if the revision regex does NOT match the revision
   * regex.
   */
  invertRegex: boolean;
}

/** The location of the function source code. */
export interface Source {
  /** If provided, get the source from this location in Google Cloud Storage. */
  storageSource?:
    | StorageSource
    | undefined;
  /**
   * If provided, get the source from this location in a Cloud Source
   * Repository.
   */
  repoSource?:
    | RepoSource
    | undefined;
  /**
   * If provided, get the source from GitHub repository. This option is valid
   * only for GCF 1st Gen function.
   * Example: https://github.com/<user>/<repo>/blob/<commit>/<path-to-code>
   */
  gitUri?: string | undefined;
}

/**
 * Provenance of the source. Ways to find the original source, or verify that
 * some source was used for this build.
 */
export interface SourceProvenance {
  /**
   * A copy of the build's `source.storage_source`, if exists, with any
   * generations resolved.
   */
  resolvedStorageSource:
    | StorageSource
    | undefined;
  /**
   * A copy of the build's `source.repo_source`, if exists, with any
   * revisions resolved.
   */
  resolvedRepoSource:
    | RepoSource
    | undefined;
  /**
   * A copy of the build's `source.git_uri`, if exists, with any commits
   * resolved.
   */
  gitUri: string;
}

/**
 * Describes the Build step of the function that builds a container from the
 * given source.
 */
export interface BuildConfig {
  automaticUpdatePolicy?: AutomaticUpdatePolicy | undefined;
  onDeployUpdatePolicy?:
    | OnDeployUpdatePolicy
    | undefined;
  /**
   * Output only. The Cloud Build name of the latest successful deployment of
   * the function.
   */
  build: string;
  /**
   * The runtime in which to run the function. Required when deploying a new
   * function, optional when updating an existing function. For a complete
   * list of possible choices, see the
   * [`gcloud` command
   * reference](https://cloud.google.com/sdk/gcloud/reference/functions/deploy#--runtime).
   */
  runtime: string;
  /**
   * The name of the function (as defined in source code) that will be
   * executed. Defaults to the resource name suffix, if not specified. For
   * backward compatibility, if function with given name is not found, then the
   * system will try to use function named "function".
   * For Node.js this is name of a function exported by the module specified
   * in `source_location`.
   */
  entryPoint: string;
  /** The location of the function source code. */
  source:
    | Source
    | undefined;
  /** Output only. A permanent fixed identifier for source. */
  sourceProvenance:
    | SourceProvenance
    | undefined;
  /**
   * Name of the Cloud Build Custom Worker Pool that should be used to build the
   * function. The format of this field is
   * `projects/{project}/locations/{region}/workerPools/{workerPool}` where
   * {project} and {region} are the project id and region respectively where the
   * worker pool is defined and {workerPool} is the short name of the worker
   * pool.
   *
   * If the project id is not the same as the function, then the Cloud
   * Functions Service Agent
   * (service-<project_number>@gcf-admin-robot.iam.gserviceaccount.com) must be
   * granted the role Cloud Build Custom Workers Builder
   * (roles/cloudbuild.customworkers.builder) in the project.
   */
  workerPool: string;
  /** User-provided build-time environment variables for the function */
  environmentVariables: { [key: string]: string };
  /**
   * Docker Registry to use for this deployment. This configuration is only
   * applicable to 1st Gen functions, 2nd Gen functions can only use Artifact
   * Registry.
   *
   * If unspecified, it defaults to `ARTIFACT_REGISTRY`.
   * If `docker_repository` field is specified, this field should either be left
   * unspecified or set to `ARTIFACT_REGISTRY`.
   */
  dockerRegistry: BuildConfig_DockerRegistry;
  /**
   * Repository in Artifact Registry to which the function docker image will be
   * pushed after it is built by Cloud Build. If specified by user, it is
   * created and managed by user with a customer managed encryption key.
   * Otherwise, GCF will create and use a repository named 'gcf-artifacts'
   * for every deployed region.
   *
   * It must match the pattern
   * `projects/{project}/locations/{location}/repositories/{repository}`.
   *
   * Cross-project repositories are not supported.
   * Cross-location repositories are not supported.
   * Repository format must be 'DOCKER'.
   */
  dockerRepository: string;
  /**
   * Service account to be used for building the container. The format of this
   * field is `projects/{projectId}/serviceAccounts/{serviceAccountEmail}`.
   */
  serviceAccount: string;
}

/** Docker Registry to use for storing function Docker images. */
export enum BuildConfig_DockerRegistry {
  /** DOCKER_REGISTRY_UNSPECIFIED - Unspecified. */
  DOCKER_REGISTRY_UNSPECIFIED = 0,
  /**
   * CONTAINER_REGISTRY - Docker images will be stored in multi-regional Container Registry
   * repositories named `gcf`.
   */
  CONTAINER_REGISTRY = 1,
  /**
   * ARTIFACT_REGISTRY - Docker images will be stored in regional Artifact Registry repositories.
   * By default, GCF will create and use repositories named `gcf-artifacts`
   * in every region in which a function is deployed. But the repository to
   * use can also be specified by the user using the `docker_repository`
   * field.
   */
  ARTIFACT_REGISTRY = 2,
  UNRECOGNIZED = -1,
}

export function buildConfig_DockerRegistryFromJSON(object: any): BuildConfig_DockerRegistry {
  switch (object) {
    case 0:
    case "DOCKER_REGISTRY_UNSPECIFIED":
      return BuildConfig_DockerRegistry.DOCKER_REGISTRY_UNSPECIFIED;
    case 1:
    case "CONTAINER_REGISTRY":
      return BuildConfig_DockerRegistry.CONTAINER_REGISTRY;
    case 2:
    case "ARTIFACT_REGISTRY":
      return BuildConfig_DockerRegistry.ARTIFACT_REGISTRY;
    case -1:
    case "UNRECOGNIZED":
    default:
      return BuildConfig_DockerRegistry.UNRECOGNIZED;
  }
}

export function buildConfig_DockerRegistryToJSON(object: BuildConfig_DockerRegistry): string {
  switch (object) {
    case BuildConfig_DockerRegistry.DOCKER_REGISTRY_UNSPECIFIED:
      return "DOCKER_REGISTRY_UNSPECIFIED";
    case BuildConfig_DockerRegistry.CONTAINER_REGISTRY:
      return "CONTAINER_REGISTRY";
    case BuildConfig_DockerRegistry.ARTIFACT_REGISTRY:
      return "ARTIFACT_REGISTRY";
    case BuildConfig_DockerRegistry.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

export interface BuildConfig_EnvironmentVariablesEntry {
  key: string;
  value: string;
}

/**
 * Describes the Service being deployed.
 * Currently Supported : Cloud Run (fully managed).
 */
export interface ServiceConfig {
  /**
   * Output only. Name of the service associated with a Function.
   * The format of this field is
   * `projects/{project}/locations/{region}/services/{service}`
   */
  service: string;
  /**
   * The function execution timeout. Execution is considered failed and
   * can be terminated if the function is not completed at the end of the
   * timeout period. Defaults to 60 seconds.
   */
  timeoutSeconds: number;
  /**
   * The amount of memory available for a function.
   * Defaults to 256M. Supported units are k, M, G, Mi, Gi. If no unit is
   * supplied the value is interpreted as bytes.
   * See
   * https://github.com/kubernetes/kubernetes/blob/master/staging/src/k8s.io/apimachinery/pkg/api/resource/quantity.go
   * a full description.
   */
  availableMemory: string;
  /**
   * The number of CPUs used in a single container instance.
   * Default value is calculated from available memory.
   * Supports the same values as Cloud Run, see
   * https://cloud.google.com/run/docs/reference/rest/v1/Container#resourcerequirements
   * Example: "1" indicates 1 vCPU
   */
  availableCpu: string;
  /** Environment variables that shall be available during function execution. */
  environmentVariables: { [key: string]: string };
  /**
   * The limit on the maximum number of function instances that may coexist at a
   * given time.
   *
   * In some cases, such as rapid traffic surges, Cloud Functions may, for a
   * short period of time, create more instances than the specified max
   * instances limit. If your function cannot tolerate this temporary behavior,
   * you may want to factor in a safety margin and set a lower max instances
   * value than your function can tolerate.
   *
   * See the [Max
   * Instances](https://cloud.google.com/functions/docs/max-instances) Guide for
   * more details.
   */
  maxInstanceCount: number;
  /**
   * The limit on the minimum number of function instances that may coexist at a
   * given time.
   *
   * Function instances are kept in idle state for a short period after they
   * finished executing the request to reduce cold start time for subsequent
   * requests. Setting a minimum instance count will ensure that the given
   * number of instances are kept running in idle state always. This can help
   * with cold start times when jump in incoming request count occurs after the
   * idle instance would have been stopped in the default case.
   */
  minInstanceCount: number;
  /**
   * The Serverless VPC Access connector that this cloud function can connect
   * to. The format of this field is `projects/* /locations/* /connectors/*`.
   */
  vpcConnector: string;
  /**
   * The egress settings for the connector, controlling what traffic is diverted
   * through it.
   */
  vpcConnectorEgressSettings: ServiceConfig_VpcConnectorEgressSettings;
  /**
   * The ingress settings for the function, controlling what traffic can reach
   * it.
   */
  ingressSettings: ServiceConfig_IngressSettings;
  /** Output only. URI of the Service deployed. */
  uri: string;
  /**
   * The email of the service's service account. If empty, defaults to
   * `{project_number}-compute@developer.gserviceaccount.com`.
   */
  serviceAccountEmail: string;
  /**
   * Whether 100% of traffic is routed to the latest revision.
   * On CreateFunction and UpdateFunction, when set to true, the revision being
   * deployed will serve 100% of traffic, ignoring any traffic split settings,
   * if any. On GetFunction, true will be returned if the latest revision is
   * serving 100% of traffic.
   */
  allTrafficOnLatestRevision: boolean;
  /** Secret environment variables configuration. */
  secretEnvironmentVariables: SecretEnvVar[];
  /** Secret volumes configuration. */
  secretVolumes: SecretVolume[];
  /** Output only. The name of service revision. */
  revision: string;
  /**
   * Sets the maximum number of concurrent requests that each instance
   * can receive. Defaults to 1.
   */
  maxInstanceRequestConcurrency: number;
  /**
   * Security level configure whether the function only accepts https.
   * This configuration is only applicable to 1st Gen functions with Http
   * trigger. By default https is optional for 1st Gen functions; 2nd Gen
   * functions are https ONLY.
   */
  securityLevel: ServiceConfig_SecurityLevel;
  /**
   * Optional. The binary authorization policy to be checked when deploying the
   * Cloud Run service.
   */
  binaryAuthorizationPolicy: string;
}

/**
 * Available egress settings.
 *
 * This controls what traffic is diverted through the VPC Access Connector
 * resource. By default PRIVATE_RANGES_ONLY will be used.
 */
export enum ServiceConfig_VpcConnectorEgressSettings {
  /** VPC_CONNECTOR_EGRESS_SETTINGS_UNSPECIFIED - Unspecified. */
  VPC_CONNECTOR_EGRESS_SETTINGS_UNSPECIFIED = 0,
  /** PRIVATE_RANGES_ONLY - Use the VPC Access Connector only for private IP space from RFC1918. */
  PRIVATE_RANGES_ONLY = 1,
  /**
   * ALL_TRAFFIC - Force the use of VPC Access Connector for all egress traffic from the
   * function.
   */
  ALL_TRAFFIC = 2,
  UNRECOGNIZED = -1,
}

export function serviceConfig_VpcConnectorEgressSettingsFromJSON(
  object: any,
): ServiceConfig_VpcConnectorEgressSettings {
  switch (object) {
    case 0:
    case "VPC_CONNECTOR_EGRESS_SETTINGS_UNSPECIFIED":
      return ServiceConfig_VpcConnectorEgressSettings.VPC_CONNECTOR_EGRESS_SETTINGS_UNSPECIFIED;
    case 1:
    case "PRIVATE_RANGES_ONLY":
      return ServiceConfig_VpcConnectorEgressSettings.PRIVATE_RANGES_ONLY;
    case 2:
    case "ALL_TRAFFIC":
      return ServiceConfig_VpcConnectorEgressSettings.ALL_TRAFFIC;
    case -1:
    case "UNRECOGNIZED":
    default:
      return ServiceConfig_VpcConnectorEgressSettings.UNRECOGNIZED;
  }
}

export function serviceConfig_VpcConnectorEgressSettingsToJSON(
  object: ServiceConfig_VpcConnectorEgressSettings,
): string {
  switch (object) {
    case ServiceConfig_VpcConnectorEgressSettings.VPC_CONNECTOR_EGRESS_SETTINGS_UNSPECIFIED:
      return "VPC_CONNECTOR_EGRESS_SETTINGS_UNSPECIFIED";
    case ServiceConfig_VpcConnectorEgressSettings.PRIVATE_RANGES_ONLY:
      return "PRIVATE_RANGES_ONLY";
    case ServiceConfig_VpcConnectorEgressSettings.ALL_TRAFFIC:
      return "ALL_TRAFFIC";
    case ServiceConfig_VpcConnectorEgressSettings.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/**
 * Available ingress settings.
 *
 * This controls what traffic can reach the function.
 *
 * If unspecified, ALLOW_ALL will be used.
 */
export enum ServiceConfig_IngressSettings {
  /** INGRESS_SETTINGS_UNSPECIFIED - Unspecified. */
  INGRESS_SETTINGS_UNSPECIFIED = 0,
  /** ALLOW_ALL - Allow HTTP traffic from public and private sources. */
  ALLOW_ALL = 1,
  /** ALLOW_INTERNAL_ONLY - Allow HTTP traffic from only private VPC sources. */
  ALLOW_INTERNAL_ONLY = 2,
  /** ALLOW_INTERNAL_AND_GCLB - Allow HTTP traffic from private VPC sources and through GCLB. */
  ALLOW_INTERNAL_AND_GCLB = 3,
  UNRECOGNIZED = -1,
}

export function serviceConfig_IngressSettingsFromJSON(object: any): ServiceConfig_IngressSettings {
  switch (object) {
    case 0:
    case "INGRESS_SETTINGS_UNSPECIFIED":
      return ServiceConfig_IngressSettings.INGRESS_SETTINGS_UNSPECIFIED;
    case 1:
    case "ALLOW_ALL":
      return ServiceConfig_IngressSettings.ALLOW_ALL;
    case 2:
    case "ALLOW_INTERNAL_ONLY":
      return ServiceConfig_IngressSettings.ALLOW_INTERNAL_ONLY;
    case 3:
    case "ALLOW_INTERNAL_AND_GCLB":
      return ServiceConfig_IngressSettings.ALLOW_INTERNAL_AND_GCLB;
    case -1:
    case "UNRECOGNIZED":
    default:
      return ServiceConfig_IngressSettings.UNRECOGNIZED;
  }
}

export function serviceConfig_IngressSettingsToJSON(object: ServiceConfig_IngressSettings): string {
  switch (object) {
    case ServiceConfig_IngressSettings.INGRESS_SETTINGS_UNSPECIFIED:
      return "INGRESS_SETTINGS_UNSPECIFIED";
    case ServiceConfig_IngressSettings.ALLOW_ALL:
      return "ALLOW_ALL";
    case ServiceConfig_IngressSettings.ALLOW_INTERNAL_ONLY:
      return "ALLOW_INTERNAL_ONLY";
    case ServiceConfig_IngressSettings.ALLOW_INTERNAL_AND_GCLB:
      return "ALLOW_INTERNAL_AND_GCLB";
    case ServiceConfig_IngressSettings.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/**
 * Available security level settings.
 *
 * This enforces security protocol on function URL.
 *
 * Security level is only configurable for 1st Gen functions, If unspecified,
 * SECURE_OPTIONAL will be used. 2nd Gen functions are SECURE_ALWAYS ONLY.
 */
export enum ServiceConfig_SecurityLevel {
  /** SECURITY_LEVEL_UNSPECIFIED - Unspecified. */
  SECURITY_LEVEL_UNSPECIFIED = 0,
  /**
   * SECURE_ALWAYS - Requests for a URL that match this handler that do not use HTTPS are
   * automatically redirected to the HTTPS URL with the same path. Query
   * parameters are reserved for the redirect.
   */
  SECURE_ALWAYS = 1,
  /**
   * SECURE_OPTIONAL - Both HTTP and HTTPS requests with URLs that match the handler succeed
   * without redirects. The application can examine the request to determine
   * which protocol was used and respond accordingly.
   */
  SECURE_OPTIONAL = 2,
  UNRECOGNIZED = -1,
}

export function serviceConfig_SecurityLevelFromJSON(object: any): ServiceConfig_SecurityLevel {
  switch (object) {
    case 0:
    case "SECURITY_LEVEL_UNSPECIFIED":
      return ServiceConfig_SecurityLevel.SECURITY_LEVEL_UNSPECIFIED;
    case 1:
    case "SECURE_ALWAYS":
      return ServiceConfig_SecurityLevel.SECURE_ALWAYS;
    case 2:
    case "SECURE_OPTIONAL":
      return ServiceConfig_SecurityLevel.SECURE_OPTIONAL;
    case -1:
    case "UNRECOGNIZED":
    default:
      return ServiceConfig_SecurityLevel.UNRECOGNIZED;
  }
}

export function serviceConfig_SecurityLevelToJSON(object: ServiceConfig_SecurityLevel): string {
  switch (object) {
    case ServiceConfig_SecurityLevel.SECURITY_LEVEL_UNSPECIFIED:
      return "SECURITY_LEVEL_UNSPECIFIED";
    case ServiceConfig_SecurityLevel.SECURE_ALWAYS:
      return "SECURE_ALWAYS";
    case ServiceConfig_SecurityLevel.SECURE_OPTIONAL:
      return "SECURE_OPTIONAL";
    case ServiceConfig_SecurityLevel.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

export interface ServiceConfig_EnvironmentVariablesEntry {
  key: string;
  value: string;
}

/**
 * Configuration for a secret environment variable. It has the information
 * necessary to fetch the secret value from secret manager and expose it as an
 * environment variable.
 */
export interface SecretEnvVar {
  /** Name of the environment variable. */
  key: string;
  /**
   * Project identifier (preferably project number but can also be the
   * project ID) of the project that contains the secret. If not set, it is
   * assumed that the secret is in the same project as the function.
   */
  projectId: string;
  /** Name of the secret in secret manager (not the full resource name). */
  secret: string;
  /**
   * Version of the secret (version number or the string 'latest'). It is
   * recommended to use a numeric version for secret environment variables as
   * any updates to the secret value is not reflected until new instances
   * start.
   */
  version: string;
}

/**
 * Configuration for a secret volume. It has the information necessary to fetch
 * the secret value from secret manager and make it available as files mounted
 * at the requested paths within the application container.
 */
export interface SecretVolume {
  /**
   * The path within the container to mount the secret volume. For example,
   * setting the mount_path as `/etc/secrets` would mount the secret value files
   * under the `/etc/secrets` directory. This directory will also be completely
   * shadowed and unavailable to mount any other secrets.
   * Recommended mount path: /etc/secrets
   */
  mountPath: string;
  /**
   * Project identifier (preferably project number but can also be the project
   * ID) of the project that contains the secret. If not set, it is
   * assumed that the secret is in the same project as the function.
   */
  projectId: string;
  /** Name of the secret in secret manager (not the full resource name). */
  secret: string;
  /**
   * List of secret versions to mount for this secret. If empty, the `latest`
   * version of the secret will be made available in a file named after the
   * secret under the mount point.
   */
  versions: SecretVolume_SecretVersion[];
}

/** Configuration for a single version. */
export interface SecretVolume_SecretVersion {
  /**
   * Version of the secret (version number or the string 'latest'). It is
   * preferable to use `latest` version with secret volumes as secret value
   * changes are reflected immediately.
   */
  version: string;
  /**
   * Relative path of the file under the mount path where the secret value for
   * this version will be fetched and made available. For example, setting the
   * mount_path as '/etc/secrets' and path as `secret_foo` would mount the
   * secret value file at `/etc/secrets/secret_foo`.
   */
  path: string;
}

/**
 * Describes EventTrigger, used to request events to be sent from another
 * service.
 */
export interface EventTrigger {
  /**
   * Output only. The resource name of the Eventarc trigger. The format of this
   * field is `projects/{project}/locations/{region}/triggers/{trigger}`.
   */
  trigger: string;
  /**
   * The region that the trigger will be in. The trigger will only receive
   * events originating in this region. It can be the same
   * region as the function, a different region or multi-region, or the global
   * region. If not provided, defaults to the same region as the function.
   */
  triggerRegion: string;
  /**
   * Required. The type of event to observe. For example:
   * `google.cloud.audit.log.v1.written` or
   * `google.cloud.pubsub.topic.v1.messagePublished`.
   */
  eventType: string;
  /** Criteria used to filter events. */
  eventFilters: EventFilter[];
  /**
   * Optional. The name of a Pub/Sub topic in the same project that will be used
   * as the transport topic for the event delivery. Format:
   * `projects/{project}/topics/{topic}`.
   *
   * This is only valid for events of type
   * `google.cloud.pubsub.topic.v1.messagePublished`. The topic provided here
   * will not be deleted at function deletion.
   */
  pubsubTopic: string;
  /**
   * Optional. The email of the trigger's service account. The service account
   * must have permission to invoke Cloud Run services, the permission is
   * `run.routes.invoke`.
   * If empty, defaults to the Compute Engine default service account:
   * `{project_number}-compute@developer.gserviceaccount.com`.
   */
  serviceAccountEmail: string;
  /**
   * Optional. If unset, then defaults to ignoring failures (i.e. not retrying
   * them).
   */
  retryPolicy: EventTrigger_RetryPolicy;
  /**
   * Optional. The name of the channel associated with the trigger in
   * `projects/{project}/locations/{location}/channels/{channel}` format.
   * You must provide a channel to receive events from Eventarc SaaS partners.
   */
  channel: string;
  /**
   * Optional. The hostname of the service that 1st Gen function should be
   * observed.
   *
   * If no string is provided, the default service implementing the API will
   * be used. For example, `storage.googleapis.com` is the default for all
   * event types in the `google.storage` namespace.
   *
   * The field is only applicable to 1st Gen functions.
   */
  service: string;
}

/**
 * Describes the retry policy in case of function's execution failure.
 * Retried execution is charged as any other execution.
 */
export enum EventTrigger_RetryPolicy {
  /** RETRY_POLICY_UNSPECIFIED - Not specified. */
  RETRY_POLICY_UNSPECIFIED = 0,
  /** RETRY_POLICY_DO_NOT_RETRY - Do not retry. */
  RETRY_POLICY_DO_NOT_RETRY = 1,
  /**
   * RETRY_POLICY_RETRY - Retry on any failure, retry up to 7 days with an exponential backoff
   * (capped at 10 seconds).
   */
  RETRY_POLICY_RETRY = 2,
  UNRECOGNIZED = -1,
}

export function eventTrigger_RetryPolicyFromJSON(object: any): EventTrigger_RetryPolicy {
  switch (object) {
    case 0:
    case "RETRY_POLICY_UNSPECIFIED":
      return EventTrigger_RetryPolicy.RETRY_POLICY_UNSPECIFIED;
    case 1:
    case "RETRY_POLICY_DO_NOT_RETRY":
      return EventTrigger_RetryPolicy.RETRY_POLICY_DO_NOT_RETRY;
    case 2:
    case "RETRY_POLICY_RETRY":
      return EventTrigger_RetryPolicy.RETRY_POLICY_RETRY;
    case -1:
    case "UNRECOGNIZED":
    default:
      return EventTrigger_RetryPolicy.UNRECOGNIZED;
  }
}

export function eventTrigger_RetryPolicyToJSON(object: EventTrigger_RetryPolicy): string {
  switch (object) {
    case EventTrigger_RetryPolicy.RETRY_POLICY_UNSPECIFIED:
      return "RETRY_POLICY_UNSPECIFIED";
    case EventTrigger_RetryPolicy.RETRY_POLICY_DO_NOT_RETRY:
      return "RETRY_POLICY_DO_NOT_RETRY";
    case EventTrigger_RetryPolicy.RETRY_POLICY_RETRY:
      return "RETRY_POLICY_RETRY";
    case EventTrigger_RetryPolicy.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/** Filters events based on exact matches on the CloudEvents attributes. */
export interface EventFilter {
  /** Required. The name of a CloudEvents attribute. */
  attribute: string;
  /** Required. The value for the attribute. */
  value: string;
  /**
   * Optional. The operator used for matching the events with the value of the
   * filter. If not specified, only events that have an exact key-value pair
   * specified in the filter are matched. The only allowed value is
   * `match-path-pattern`.
   */
  operator: string;
}

/** Request for the `GetFunction` method. */
export interface GetFunctionRequest {
  /** Required. The name of the function which details should be obtained. */
  name: string;
  /**
   * Optional. The optional version of the 1st gen function whose details should
   * be obtained. The version of a 1st gen function is an integer that starts
   * from 1 and gets incremented on redeployments. GCF may keep historical
   * configs for old versions of 1st gen function. This field can be specified
   * to fetch the historical configs. This field is valid only for GCF 1st gen
   * function.
   */
  revision: string;
}

/** Request for the `ListFunctions` method. */
export interface ListFunctionsRequest {
  /**
   * Required. The project and location from which the function should be
   * listed, specified in the format `projects/* /locations/*` If you want to
   * list functions in all locations, use "-" in place of a location. When
   * listing functions in all locations, if one or more location(s) are
   * unreachable, the response will contain functions from all reachable
   * locations along with the names of any unreachable locations.
   */
  parent: string;
  /**
   * Maximum number of functions to return per call. The largest allowed
   * page_size is 1,000, if the page_size is omitted or specified as greater
   * than 1,000 then it will be replaced as 1,000. The size of the list
   * response can be less than specified when used with filters.
   */
  pageSize: number;
  /**
   * The value returned by the last
   * `ListFunctionsResponse`; indicates that
   * this is a continuation of a prior `ListFunctions` call, and that the
   * system should return the next page of data.
   */
  pageToken: string;
  /**
   * The filter for Functions that match the filter expression,
   * following the syntax outlined in https://google.aip.dev/160.
   */
  filter: string;
  /**
   * The sorting order of the resources returned. Value should be a comma
   * separated list of fields. The default sorting oder is ascending.
   * See https://google.aip.dev/132#ordering.
   */
  orderBy: string;
}

/** Response for the `ListFunctions` method. */
export interface ListFunctionsResponse {
  /** The functions that match the request. */
  functions: Function[];
  /**
   * A token, which can be sent as `page_token` to retrieve the next page.
   * If this field is omitted, there are no subsequent pages.
   */
  nextPageToken: string;
  /**
   * Locations that could not be reached. The response does not include any
   * functions from these locations.
   */
  unreachable: string[];
}

/** Request for the `CreateFunction` method. */
export interface CreateFunctionRequest {
  /**
   * Required. The project and location in which the function should be created,
   * specified in the format `projects/* /locations/*`
   */
  parent: string;
  /** Required. Function to be created. */
  function:
    | Function
    | undefined;
  /**
   * The ID to use for the function, which will become the final component of
   * the function's resource name.
   *
   * This value should be 4-63 characters, and valid characters
   * are /[a-z][0-9]-/.
   */
  functionId: string;
}

/** Request for the `UpdateFunction` method. */
export interface UpdateFunctionRequest {
  /** Required. New version of the function. */
  function:
    | Function
    | undefined;
  /**
   * The list of fields to be updated.
   * If no field mask is provided, all fields will be updated.
   */
  updateMask: string[] | undefined;
}

/** Request for the `DeleteFunction` method. */
export interface DeleteFunctionRequest {
  /** Required. The name of the function which should be deleted. */
  name: string;
}

/** Request of `GenerateSourceUploadUrl` method. */
export interface GenerateUploadUrlRequest {
  /**
   * Required. The project and location in which the Google Cloud Storage signed
   * URL should be generated, specified in the format `projects/* /locations/*`.
   */
  parent: string;
  /**
   * [Preview] Resource name of a KMS crypto key (managed by the user) used to
   * encrypt/decrypt function source code objects in intermediate Cloud Storage
   * buckets. When you generate an upload url and upload your source code, it
   * gets copied to an intermediate Cloud Storage bucket. The source code is
   * then copied to a versioned directory in the sources bucket in the consumer
   * project during the function deployment.
   *
   * It must match the pattern
   * `projects/{project}/locations/{location}/keyRings/{key_ring}/cryptoKeys/{crypto_key}`.
   *
   * The Google Cloud Functions service account
   * (service-{project_number}@gcf-admin-robot.iam.gserviceaccount.com) must be
   * granted the role 'Cloud KMS CryptoKey Encrypter/Decrypter
   * (roles/cloudkms.cryptoKeyEncrypterDecrypter)' on the
   * Key/KeyRing/Project/Organization (least access preferred).
   */
  kmsKeyName: string;
  /**
   * The function environment the generated upload url will be used for.
   * The upload url for 2nd Gen functions can also be used for 1st gen
   * functions, but not vice versa. If not specified, 2nd generation-style
   * upload URLs are generated.
   */
  environment: Environment;
}

/** Response of `GenerateSourceUploadUrl` method. */
export interface GenerateUploadUrlResponse {
  /**
   * The generated Google Cloud Storage signed URL that should be used for a
   * function source code upload. The uploaded file should be a zip archive
   * which contains a function.
   */
  uploadUrl: string;
  /**
   * The location of the source code in the upload bucket.
   *
   * Once the archive is uploaded using the `upload_url` use this field to
   * set the `function.build_config.source.storage_source`
   * during CreateFunction and UpdateFunction.
   *
   * Generation defaults to 0, as Cloud Storage provides a new generation only
   * upon uploading a new object or version of an object.
   */
  storageSource: StorageSource | undefined;
}

/** Request of `GenerateDownloadUrl` method. */
export interface GenerateDownloadUrlRequest {
  /**
   * Required. The name of function for which source code Google Cloud Storage
   * signed URL should be generated.
   */
  name: string;
}

/** Response of `GenerateDownloadUrl` method. */
export interface GenerateDownloadUrlResponse {
  /**
   * The generated Google Cloud Storage signed URL that should be used for
   * function source code download.
   */
  downloadUrl: string;
}

/** Request for the `ListRuntimes` method. */
export interface ListRuntimesRequest {
  /**
   * Required. The project and location from which the runtimes should be
   * listed, specified in the format `projects/* /locations/*`
   */
  parent: string;
  /**
   * The filter for Runtimes that match the filter expression,
   * following the syntax outlined in https://google.aip.dev/160.
   */
  filter: string;
}

/** Response for the `ListRuntimes` method. */
export interface ListRuntimesResponse {
  /** The runtimes that match the request. */
  runtimes: ListRuntimesResponse_Runtime[];
}

/** The various stages that a runtime can be in. */
export enum ListRuntimesResponse_RuntimeStage {
  /** RUNTIME_STAGE_UNSPECIFIED - Not specified. */
  RUNTIME_STAGE_UNSPECIFIED = 0,
  /** DEVELOPMENT - The runtime is in development. */
  DEVELOPMENT = 1,
  /** ALPHA - The runtime is in the Alpha stage. */
  ALPHA = 2,
  /** BETA - The runtime is in the Beta stage. */
  BETA = 3,
  /** GA - The runtime is generally available. */
  GA = 4,
  /** DEPRECATED - The runtime is deprecated. */
  DEPRECATED = 5,
  /** DECOMMISSIONED - The runtime is no longer supported. */
  DECOMMISSIONED = 6,
  UNRECOGNIZED = -1,
}

export function listRuntimesResponse_RuntimeStageFromJSON(object: any): ListRuntimesResponse_RuntimeStage {
  switch (object) {
    case 0:
    case "RUNTIME_STAGE_UNSPECIFIED":
      return ListRuntimesResponse_RuntimeStage.RUNTIME_STAGE_UNSPECIFIED;
    case 1:
    case "DEVELOPMENT":
      return ListRuntimesResponse_RuntimeStage.DEVELOPMENT;
    case 2:
    case "ALPHA":
      return ListRuntimesResponse_RuntimeStage.ALPHA;
    case 3:
    case "BETA":
      return ListRuntimesResponse_RuntimeStage.BETA;
    case 4:
    case "GA":
      return ListRuntimesResponse_RuntimeStage.GA;
    case 5:
    case "DEPRECATED":
      return ListRuntimesResponse_RuntimeStage.DEPRECATED;
    case 6:
    case "DECOMMISSIONED":
      return ListRuntimesResponse_RuntimeStage.DECOMMISSIONED;
    case -1:
    case "UNRECOGNIZED":
    default:
      return ListRuntimesResponse_RuntimeStage.UNRECOGNIZED;
  }
}

export function listRuntimesResponse_RuntimeStageToJSON(object: ListRuntimesResponse_RuntimeStage): string {
  switch (object) {
    case ListRuntimesResponse_RuntimeStage.RUNTIME_STAGE_UNSPECIFIED:
      return "RUNTIME_STAGE_UNSPECIFIED";
    case ListRuntimesResponse_RuntimeStage.DEVELOPMENT:
      return "DEVELOPMENT";
    case ListRuntimesResponse_RuntimeStage.ALPHA:
      return "ALPHA";
    case ListRuntimesResponse_RuntimeStage.BETA:
      return "BETA";
    case ListRuntimesResponse_RuntimeStage.GA:
      return "GA";
    case ListRuntimesResponse_RuntimeStage.DEPRECATED:
      return "DEPRECATED";
    case ListRuntimesResponse_RuntimeStage.DECOMMISSIONED:
      return "DECOMMISSIONED";
    case ListRuntimesResponse_RuntimeStage.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/**
 * Describes a runtime and any special information (e.g., deprecation status)
 * related to it.
 */
export interface ListRuntimesResponse_Runtime {
  /** The name of the runtime, e.g., 'go113', 'nodejs12', etc. */
  name: string;
  /** The user facing name, eg 'Go 1.13', 'Node.js 12', etc. */
  displayName: string;
  /** The stage of life this runtime is in, e.g., BETA, GA, etc. */
  stage: ListRuntimesResponse_RuntimeStage;
  /** Warning messages, e.g., a deprecation warning. */
  warnings: string[];
  /** The environment for the runtime. */
  environment: Environment;
  /** Deprecation date for the runtime. */
  deprecationDate:
    | DateMessage
    | undefined;
  /** Decommission date for the runtime. */
  decommissionDate: DateMessage | undefined;
}

/**
 * Security patches are applied automatically to the runtime without requiring
 * the function to be redeployed.
 */
export interface AutomaticUpdatePolicy {
}

/** Security patches are only applied when a function is redeployed. */
export interface OnDeployUpdatePolicy {
  /**
   * Output only. contains the runtime version which was used during latest
   * function deployment.
   */
  runtimeVersion: string;
}

/** Represents the metadata of the long-running operation. */
export interface OperationMetadata {
  /** The time the operation was created. */
  createTime:
    | Date
    | undefined;
  /** The time the operation finished running. */
  endTime:
    | Date
    | undefined;
  /** Server-defined resource path for the target of the operation. */
  target: string;
  /** Name of the verb executed by the operation. */
  verb: string;
  /** Human-readable status of the operation, if any. */
  statusDetail: string;
  /**
   * Identifies whether the user has requested cancellation
   * of the operation. Operations that have successfully been cancelled
   * have
   * [google.longrunning.Operation.error][google.longrunning.Operation.error]
   * value with a [google.rpc.Status.code][google.rpc.Status.code] of 1,
   * corresponding to `Code.CANCELLED`.
   */
  cancelRequested: boolean;
  /** API version used to start the operation. */
  apiVersion: string;
  /** The original request that started the operation. */
  requestResource:
    | Any
    | undefined;
  /** Mechanism for reporting in-progress stages */
  stages: Stage[];
  /** The build name of the function for create and update operations. */
  buildName: string;
  /** The operation type. */
  operationType: OperationType;
}

/** Extra GCF specific location information. */
export interface LocationMetadata {
  /** The Cloud Function environments this location supports. */
  environments: Environment[];
}

/** Each Stage of the deployment process */
export interface Stage {
  /** Name of the Stage. This will be unique for each Stage. */
  name: Stage_Name;
  /** Message describing the Stage */
  message: string;
  /** Current state of the Stage */
  state: Stage_State;
  /** Resource of the Stage */
  resource: string;
  /** Link to the current Stage resource */
  resourceUri: string;
  /** State messages from the current Stage. */
  stateMessages: StateMessage[];
}

/** Possible names for a Stage */
export enum Stage_Name {
  /** NAME_UNSPECIFIED - Not specified. Invalid name. */
  NAME_UNSPECIFIED = 0,
  /** ARTIFACT_REGISTRY - Artifact Regsitry Stage */
  ARTIFACT_REGISTRY = 1,
  /** BUILD - Build Stage */
  BUILD = 2,
  /** SERVICE - Service Stage */
  SERVICE = 3,
  /** TRIGGER - Trigger Stage */
  TRIGGER = 4,
  /** SERVICE_ROLLBACK - Service Rollback Stage */
  SERVICE_ROLLBACK = 5,
  /** TRIGGER_ROLLBACK - Trigger Rollback Stage */
  TRIGGER_ROLLBACK = 6,
  UNRECOGNIZED = -1,
}

export function stage_NameFromJSON(object: any): Stage_Name {
  switch (object) {
    case 0:
    case "NAME_UNSPECIFIED":
      return Stage_Name.NAME_UNSPECIFIED;
    case 1:
    case "ARTIFACT_REGISTRY":
      return Stage_Name.ARTIFACT_REGISTRY;
    case 2:
    case "BUILD":
      return Stage_Name.BUILD;
    case 3:
    case "SERVICE":
      return Stage_Name.SERVICE;
    case 4:
    case "TRIGGER":
      return Stage_Name.TRIGGER;
    case 5:
    case "SERVICE_ROLLBACK":
      return Stage_Name.SERVICE_ROLLBACK;
    case 6:
    case "TRIGGER_ROLLBACK":
      return Stage_Name.TRIGGER_ROLLBACK;
    case -1:
    case "UNRECOGNIZED":
    default:
      return Stage_Name.UNRECOGNIZED;
  }
}

export function stage_NameToJSON(object: Stage_Name): string {
  switch (object) {
    case Stage_Name.NAME_UNSPECIFIED:
      return "NAME_UNSPECIFIED";
    case Stage_Name.ARTIFACT_REGISTRY:
      return "ARTIFACT_REGISTRY";
    case Stage_Name.BUILD:
      return "BUILD";
    case Stage_Name.SERVICE:
      return "SERVICE";
    case Stage_Name.TRIGGER:
      return "TRIGGER";
    case Stage_Name.SERVICE_ROLLBACK:
      return "SERVICE_ROLLBACK";
    case Stage_Name.TRIGGER_ROLLBACK:
      return "TRIGGER_ROLLBACK";
    case Stage_Name.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/** Possible states for a Stage */
export enum Stage_State {
  /** STATE_UNSPECIFIED - Not specified. Invalid state. */
  STATE_UNSPECIFIED = 0,
  /** NOT_STARTED - Stage has not started. */
  NOT_STARTED = 1,
  /** IN_PROGRESS - Stage is in progress. */
  IN_PROGRESS = 2,
  /** COMPLETE - Stage has completed. */
  COMPLETE = 3,
  UNRECOGNIZED = -1,
}

export function stage_StateFromJSON(object: any): Stage_State {
  switch (object) {
    case 0:
    case "STATE_UNSPECIFIED":
      return Stage_State.STATE_UNSPECIFIED;
    case 1:
    case "NOT_STARTED":
      return Stage_State.NOT_STARTED;
    case 2:
    case "IN_PROGRESS":
      return Stage_State.IN_PROGRESS;
    case 3:
    case "COMPLETE":
      return Stage_State.COMPLETE;
    case -1:
    case "UNRECOGNIZED":
    default:
      return Stage_State.UNRECOGNIZED;
  }
}

export function stage_StateToJSON(object: Stage_State): string {
  switch (object) {
    case Stage_State.STATE_UNSPECIFIED:
      return "STATE_UNSPECIFIED";
    case Stage_State.NOT_STARTED:
      return "NOT_STARTED";
    case Stage_State.IN_PROGRESS:
      return "IN_PROGRESS";
    case Stage_State.COMPLETE:
      return "COMPLETE";
    case Stage_State.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

function createBaseFunction(): Function {
  return {
    name: "",
    description: "",
    buildConfig: undefined,
    serviceConfig: undefined,
    eventTrigger: undefined,
    state: 0,
    updateTime: undefined,
    labels: {},
    stateMessages: [],
    environment: 0,
    url: "",
    kmsKeyName: "",
    satisfiesPzs: false,
    createTime: undefined,
  };
}

export const Function: MessageFns<Function> = {
  encode(message: Function, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    if (message.description !== "") {
      writer.uint32(18).string(message.description);
    }
    if (message.buildConfig !== undefined) {
      BuildConfig.encode(message.buildConfig, writer.uint32(26).fork()).join();
    }
    if (message.serviceConfig !== undefined) {
      ServiceConfig.encode(message.serviceConfig, writer.uint32(34).fork()).join();
    }
    if (message.eventTrigger !== undefined) {
      EventTrigger.encode(message.eventTrigger, writer.uint32(42).fork()).join();
    }
    if (message.state !== 0) {
      writer.uint32(48).int32(message.state);
    }
    if (message.updateTime !== undefined) {
      Timestamp.encode(toTimestamp(message.updateTime), writer.uint32(58).fork()).join();
    }
    Object.entries(message.labels).forEach(([key, value]) => {
      Function_LabelsEntry.encode({ key: key as any, value }, writer.uint32(66).fork()).join();
    });
    for (const v of message.stateMessages) {
      StateMessage.encode(v!, writer.uint32(74).fork()).join();
    }
    if (message.environment !== 0) {
      writer.uint32(80).int32(message.environment);
    }
    if (message.url !== "") {
      writer.uint32(114).string(message.url);
    }
    if (message.kmsKeyName !== "") {
      writer.uint32(202).string(message.kmsKeyName);
    }
    if (message.satisfiesPzs !== false) {
      writer.uint32(216).bool(message.satisfiesPzs);
    }
    if (message.createTime !== undefined) {
      Timestamp.encode(toTimestamp(message.createTime), writer.uint32(226).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Function {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseFunction();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.description = reader.string();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.buildConfig = BuildConfig.decode(reader, reader.uint32());
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.serviceConfig = ServiceConfig.decode(reader, reader.uint32());
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.eventTrigger = EventTrigger.decode(reader, reader.uint32());
          continue;
        case 6:
          if (tag !== 48) {
            break;
          }

          message.state = reader.int32() as any;
          continue;
        case 7:
          if (tag !== 58) {
            break;
          }

          message.updateTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        case 8:
          if (tag !== 66) {
            break;
          }

          const entry8 = Function_LabelsEntry.decode(reader, reader.uint32());
          if (entry8.value !== undefined) {
            message.labels[entry8.key] = entry8.value;
          }
          continue;
        case 9:
          if (tag !== 74) {
            break;
          }

          message.stateMessages.push(StateMessage.decode(reader, reader.uint32()));
          continue;
        case 10:
          if (tag !== 80) {
            break;
          }

          message.environment = reader.int32() as any;
          continue;
        case 14:
          if (tag !== 114) {
            break;
          }

          message.url = reader.string();
          continue;
        case 25:
          if (tag !== 202) {
            break;
          }

          message.kmsKeyName = reader.string();
          continue;
        case 27:
          if (tag !== 216) {
            break;
          }

          message.satisfiesPzs = reader.bool();
          continue;
        case 28:
          if (tag !== 226) {
            break;
          }

          message.createTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Function {
    return {
      name: isSet(object.name) ? globalThis.String(object.name) : "",
      description: isSet(object.description) ? globalThis.String(object.description) : "",
      buildConfig: isSet(object.buildConfig) ? BuildConfig.fromJSON(object.buildConfig) : undefined,
      serviceConfig: isSet(object.serviceConfig) ? ServiceConfig.fromJSON(object.serviceConfig) : undefined,
      eventTrigger: isSet(object.eventTrigger) ? EventTrigger.fromJSON(object.eventTrigger) : undefined,
      state: isSet(object.state) ? function_StateFromJSON(object.state) : 0,
      updateTime: isSet(object.updateTime) ? fromJsonTimestamp(object.updateTime) : undefined,
      labels: isObject(object.labels)
        ? Object.entries(object.labels).reduce<{ [key: string]: string }>((acc, [key, value]) => {
          acc[key] = String(value);
          return acc;
        }, {})
        : {},
      stateMessages: globalThis.Array.isArray(object?.stateMessages)
        ? object.stateMessages.map((e: any) => StateMessage.fromJSON(e))
        : [],
      environment: isSet(object.environment) ? environmentFromJSON(object.environment) : 0,
      url: isSet(object.url) ? globalThis.String(object.url) : "",
      kmsKeyName: isSet(object.kmsKeyName) ? globalThis.String(object.kmsKeyName) : "",
      satisfiesPzs: isSet(object.satisfiesPzs) ? globalThis.Boolean(object.satisfiesPzs) : false,
      createTime: isSet(object.createTime) ? fromJsonTimestamp(object.createTime) : undefined,
    };
  },

  toJSON(message: Function): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    if (message.description !== "") {
      obj.description = message.description;
    }
    if (message.buildConfig !== undefined) {
      obj.buildConfig = BuildConfig.toJSON(message.buildConfig);
    }
    if (message.serviceConfig !== undefined) {
      obj.serviceConfig = ServiceConfig.toJSON(message.serviceConfig);
    }
    if (message.eventTrigger !== undefined) {
      obj.eventTrigger = EventTrigger.toJSON(message.eventTrigger);
    }
    if (message.state !== 0) {
      obj.state = function_StateToJSON(message.state);
    }
    if (message.updateTime !== undefined) {
      obj.updateTime = message.updateTime.toISOString();
    }
    if (message.labels) {
      const entries = Object.entries(message.labels);
      if (entries.length > 0) {
        obj.labels = {};
        entries.forEach(([k, v]) => {
          obj.labels[k] = v;
        });
      }
    }
    if (message.stateMessages?.length) {
      obj.stateMessages = message.stateMessages.map((e) => StateMessage.toJSON(e));
    }
    if (message.environment !== 0) {
      obj.environment = environmentToJSON(message.environment);
    }
    if (message.url !== "") {
      obj.url = message.url;
    }
    if (message.kmsKeyName !== "") {
      obj.kmsKeyName = message.kmsKeyName;
    }
    if (message.satisfiesPzs !== false) {
      obj.satisfiesPzs = message.satisfiesPzs;
    }
    if (message.createTime !== undefined) {
      obj.createTime = message.createTime.toISOString();
    }
    return obj;
  },

  create(base?: DeepPartial<Function>): Function {
    return Function.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<Function>): Function {
    const message = createBaseFunction();
    message.name = object.name ?? "";
    message.description = object.description ?? "";
    message.buildConfig = (object.buildConfig !== undefined && object.buildConfig !== null)
      ? BuildConfig.fromPartial(object.buildConfig)
      : undefined;
    message.serviceConfig = (object.serviceConfig !== undefined && object.serviceConfig !== null)
      ? ServiceConfig.fromPartial(object.serviceConfig)
      : undefined;
    message.eventTrigger = (object.eventTrigger !== undefined && object.eventTrigger !== null)
      ? EventTrigger.fromPartial(object.eventTrigger)
      : undefined;
    message.state = object.state ?? 0;
    message.updateTime = object.updateTime ?? undefined;
    message.labels = Object.entries(object.labels ?? {}).reduce<{ [key: string]: string }>((acc, [key, value]) => {
      if (value !== undefined) {
        acc[key] = globalThis.String(value);
      }
      return acc;
    }, {});
    message.stateMessages = object.stateMessages?.map((e) => StateMessage.fromPartial(e)) || [];
    message.environment = object.environment ?? 0;
    message.url = object.url ?? "";
    message.kmsKeyName = object.kmsKeyName ?? "";
    message.satisfiesPzs = object.satisfiesPzs ?? false;
    message.createTime = object.createTime ?? undefined;
    return message;
  },
};

function createBaseFunction_LabelsEntry(): Function_LabelsEntry {
  return { key: "", value: "" };
}

export const Function_LabelsEntry: MessageFns<Function_LabelsEntry> = {
  encode(message: Function_LabelsEntry, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.key !== "") {
      writer.uint32(10).string(message.key);
    }
    if (message.value !== "") {
      writer.uint32(18).string(message.value);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Function_LabelsEntry {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseFunction_LabelsEntry();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.key = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.value = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Function_LabelsEntry {
    return {
      key: isSet(object.key) ? globalThis.String(object.key) : "",
      value: isSet(object.value) ? globalThis.String(object.value) : "",
    };
  },

  toJSON(message: Function_LabelsEntry): unknown {
    const obj: any = {};
    if (message.key !== "") {
      obj.key = message.key;
    }
    if (message.value !== "") {
      obj.value = message.value;
    }
    return obj;
  },

  create(base?: DeepPartial<Function_LabelsEntry>): Function_LabelsEntry {
    return Function_LabelsEntry.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<Function_LabelsEntry>): Function_LabelsEntry {
    const message = createBaseFunction_LabelsEntry();
    message.key = object.key ?? "";
    message.value = object.value ?? "";
    return message;
  },
};

function createBaseStateMessage(): StateMessage {
  return { severity: 0, type: "", message: "" };
}

export const StateMessage: MessageFns<StateMessage> = {
  encode(message: StateMessage, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.severity !== 0) {
      writer.uint32(8).int32(message.severity);
    }
    if (message.type !== "") {
      writer.uint32(18).string(message.type);
    }
    if (message.message !== "") {
      writer.uint32(26).string(message.message);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): StateMessage {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseStateMessage();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 8) {
            break;
          }

          message.severity = reader.int32() as any;
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.type = reader.string();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.message = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): StateMessage {
    return {
      severity: isSet(object.severity) ? stateMessage_SeverityFromJSON(object.severity) : 0,
      type: isSet(object.type) ? globalThis.String(object.type) : "",
      message: isSet(object.message) ? globalThis.String(object.message) : "",
    };
  },

  toJSON(message: StateMessage): unknown {
    const obj: any = {};
    if (message.severity !== 0) {
      obj.severity = stateMessage_SeverityToJSON(message.severity);
    }
    if (message.type !== "") {
      obj.type = message.type;
    }
    if (message.message !== "") {
      obj.message = message.message;
    }
    return obj;
  },

  create(base?: DeepPartial<StateMessage>): StateMessage {
    return StateMessage.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<StateMessage>): StateMessage {
    const message = createBaseStateMessage();
    message.severity = object.severity ?? 0;
    message.type = object.type ?? "";
    message.message = object.message ?? "";
    return message;
  },
};

function createBaseStorageSource(): StorageSource {
  return { bucket: "", object: "", generation: Long.ZERO, sourceUploadUrl: "" };
}

export const StorageSource: MessageFns<StorageSource> = {
  encode(message: StorageSource, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.bucket !== "") {
      writer.uint32(10).string(message.bucket);
    }
    if (message.object !== "") {
      writer.uint32(18).string(message.object);
    }
    if (!message.generation.equals(Long.ZERO)) {
      writer.uint32(24).int64(message.generation.toString());
    }
    if (message.sourceUploadUrl !== "") {
      writer.uint32(34).string(message.sourceUploadUrl);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): StorageSource {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseStorageSource();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.bucket = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.object = reader.string();
          continue;
        case 3:
          if (tag !== 24) {
            break;
          }

          message.generation = Long.fromString(reader.int64().toString());
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.sourceUploadUrl = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): StorageSource {
    return {
      bucket: isSet(object.bucket) ? globalThis.String(object.bucket) : "",
      object: isSet(object.object) ? globalThis.String(object.object) : "",
      generation: isSet(object.generation) ? Long.fromValue(object.generation) : Long.ZERO,
      sourceUploadUrl: isSet(object.sourceUploadUrl) ? globalThis.String(object.sourceUploadUrl) : "",
    };
  },

  toJSON(message: StorageSource): unknown {
    const obj: any = {};
    if (message.bucket !== "") {
      obj.bucket = message.bucket;
    }
    if (message.object !== "") {
      obj.object = message.object;
    }
    if (!message.generation.equals(Long.ZERO)) {
      obj.generation = (message.generation || Long.ZERO).toString();
    }
    if (message.sourceUploadUrl !== "") {
      obj.sourceUploadUrl = message.sourceUploadUrl;
    }
    return obj;
  },

  create(base?: DeepPartial<StorageSource>): StorageSource {
    return StorageSource.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<StorageSource>): StorageSource {
    const message = createBaseStorageSource();
    message.bucket = object.bucket ?? "";
    message.object = object.object ?? "";
    message.generation = (object.generation !== undefined && object.generation !== null)
      ? Long.fromValue(object.generation)
      : Long.ZERO;
    message.sourceUploadUrl = object.sourceUploadUrl ?? "";
    return message;
  },
};

function createBaseRepoSource(): RepoSource {
  return {
    branchName: undefined,
    tagName: undefined,
    commitSha: undefined,
    projectId: "",
    repoName: "",
    dir: "",
    invertRegex: false,
  };
}

export const RepoSource: MessageFns<RepoSource> = {
  encode(message: RepoSource, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.branchName !== undefined) {
      writer.uint32(26).string(message.branchName);
    }
    if (message.tagName !== undefined) {
      writer.uint32(34).string(message.tagName);
    }
    if (message.commitSha !== undefined) {
      writer.uint32(42).string(message.commitSha);
    }
    if (message.projectId !== "") {
      writer.uint32(10).string(message.projectId);
    }
    if (message.repoName !== "") {
      writer.uint32(18).string(message.repoName);
    }
    if (message.dir !== "") {
      writer.uint32(50).string(message.dir);
    }
    if (message.invertRegex !== false) {
      writer.uint32(56).bool(message.invertRegex);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): RepoSource {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseRepoSource();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 3:
          if (tag !== 26) {
            break;
          }

          message.branchName = reader.string();
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.tagName = reader.string();
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.commitSha = reader.string();
          continue;
        case 1:
          if (tag !== 10) {
            break;
          }

          message.projectId = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.repoName = reader.string();
          continue;
        case 6:
          if (tag !== 50) {
            break;
          }

          message.dir = reader.string();
          continue;
        case 7:
          if (tag !== 56) {
            break;
          }

          message.invertRegex = reader.bool();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): RepoSource {
    return {
      branchName: isSet(object.branchName) ? globalThis.String(object.branchName) : undefined,
      tagName: isSet(object.tagName) ? globalThis.String(object.tagName) : undefined,
      commitSha: isSet(object.commitSha) ? globalThis.String(object.commitSha) : undefined,
      projectId: isSet(object.projectId) ? globalThis.String(object.projectId) : "",
      repoName: isSet(object.repoName) ? globalThis.String(object.repoName) : "",
      dir: isSet(object.dir) ? globalThis.String(object.dir) : "",
      invertRegex: isSet(object.invertRegex) ? globalThis.Boolean(object.invertRegex) : false,
    };
  },

  toJSON(message: RepoSource): unknown {
    const obj: any = {};
    if (message.branchName !== undefined) {
      obj.branchName = message.branchName;
    }
    if (message.tagName !== undefined) {
      obj.tagName = message.tagName;
    }
    if (message.commitSha !== undefined) {
      obj.commitSha = message.commitSha;
    }
    if (message.projectId !== "") {
      obj.projectId = message.projectId;
    }
    if (message.repoName !== "") {
      obj.repoName = message.repoName;
    }
    if (message.dir !== "") {
      obj.dir = message.dir;
    }
    if (message.invertRegex !== false) {
      obj.invertRegex = message.invertRegex;
    }
    return obj;
  },

  create(base?: DeepPartial<RepoSource>): RepoSource {
    return RepoSource.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<RepoSource>): RepoSource {
    const message = createBaseRepoSource();
    message.branchName = object.branchName ?? undefined;
    message.tagName = object.tagName ?? undefined;
    message.commitSha = object.commitSha ?? undefined;
    message.projectId = object.projectId ?? "";
    message.repoName = object.repoName ?? "";
    message.dir = object.dir ?? "";
    message.invertRegex = object.invertRegex ?? false;
    return message;
  },
};

function createBaseSource(): Source {
  return { storageSource: undefined, repoSource: undefined, gitUri: undefined };
}

export const Source: MessageFns<Source> = {
  encode(message: Source, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.storageSource !== undefined) {
      StorageSource.encode(message.storageSource, writer.uint32(10).fork()).join();
    }
    if (message.repoSource !== undefined) {
      RepoSource.encode(message.repoSource, writer.uint32(18).fork()).join();
    }
    if (message.gitUri !== undefined) {
      writer.uint32(26).string(message.gitUri);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Source {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseSource();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.storageSource = StorageSource.decode(reader, reader.uint32());
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.repoSource = RepoSource.decode(reader, reader.uint32());
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.gitUri = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Source {
    return {
      storageSource: isSet(object.storageSource) ? StorageSource.fromJSON(object.storageSource) : undefined,
      repoSource: isSet(object.repoSource) ? RepoSource.fromJSON(object.repoSource) : undefined,
      gitUri: isSet(object.gitUri) ? globalThis.String(object.gitUri) : undefined,
    };
  },

  toJSON(message: Source): unknown {
    const obj: any = {};
    if (message.storageSource !== undefined) {
      obj.storageSource = StorageSource.toJSON(message.storageSource);
    }
    if (message.repoSource !== undefined) {
      obj.repoSource = RepoSource.toJSON(message.repoSource);
    }
    if (message.gitUri !== undefined) {
      obj.gitUri = message.gitUri;
    }
    return obj;
  },

  create(base?: DeepPartial<Source>): Source {
    return Source.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<Source>): Source {
    const message = createBaseSource();
    message.storageSource = (object.storageSource !== undefined && object.storageSource !== null)
      ? StorageSource.fromPartial(object.storageSource)
      : undefined;
    message.repoSource = (object.repoSource !== undefined && object.repoSource !== null)
      ? RepoSource.fromPartial(object.repoSource)
      : undefined;
    message.gitUri = object.gitUri ?? undefined;
    return message;
  },
};

function createBaseSourceProvenance(): SourceProvenance {
  return { resolvedStorageSource: undefined, resolvedRepoSource: undefined, gitUri: "" };
}

export const SourceProvenance: MessageFns<SourceProvenance> = {
  encode(message: SourceProvenance, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.resolvedStorageSource !== undefined) {
      StorageSource.encode(message.resolvedStorageSource, writer.uint32(10).fork()).join();
    }
    if (message.resolvedRepoSource !== undefined) {
      RepoSource.encode(message.resolvedRepoSource, writer.uint32(18).fork()).join();
    }
    if (message.gitUri !== "") {
      writer.uint32(26).string(message.gitUri);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): SourceProvenance {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseSourceProvenance();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.resolvedStorageSource = StorageSource.decode(reader, reader.uint32());
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.resolvedRepoSource = RepoSource.decode(reader, reader.uint32());
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.gitUri = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): SourceProvenance {
    return {
      resolvedStorageSource: isSet(object.resolvedStorageSource)
        ? StorageSource.fromJSON(object.resolvedStorageSource)
        : undefined,
      resolvedRepoSource: isSet(object.resolvedRepoSource) ? RepoSource.fromJSON(object.resolvedRepoSource) : undefined,
      gitUri: isSet(object.gitUri) ? globalThis.String(object.gitUri) : "",
    };
  },

  toJSON(message: SourceProvenance): unknown {
    const obj: any = {};
    if (message.resolvedStorageSource !== undefined) {
      obj.resolvedStorageSource = StorageSource.toJSON(message.resolvedStorageSource);
    }
    if (message.resolvedRepoSource !== undefined) {
      obj.resolvedRepoSource = RepoSource.toJSON(message.resolvedRepoSource);
    }
    if (message.gitUri !== "") {
      obj.gitUri = message.gitUri;
    }
    return obj;
  },

  create(base?: DeepPartial<SourceProvenance>): SourceProvenance {
    return SourceProvenance.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<SourceProvenance>): SourceProvenance {
    const message = createBaseSourceProvenance();
    message.resolvedStorageSource =
      (object.resolvedStorageSource !== undefined && object.resolvedStorageSource !== null)
        ? StorageSource.fromPartial(object.resolvedStorageSource)
        : undefined;
    message.resolvedRepoSource = (object.resolvedRepoSource !== undefined && object.resolvedRepoSource !== null)
      ? RepoSource.fromPartial(object.resolvedRepoSource)
      : undefined;
    message.gitUri = object.gitUri ?? "";
    return message;
  },
};

function createBaseBuildConfig(): BuildConfig {
  return {
    automaticUpdatePolicy: undefined,
    onDeployUpdatePolicy: undefined,
    build: "",
    runtime: "",
    entryPoint: "",
    source: undefined,
    sourceProvenance: undefined,
    workerPool: "",
    environmentVariables: {},
    dockerRegistry: 0,
    dockerRepository: "",
    serviceAccount: "",
  };
}

export const BuildConfig: MessageFns<BuildConfig> = {
  encode(message: BuildConfig, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.automaticUpdatePolicy !== undefined) {
      AutomaticUpdatePolicy.encode(message.automaticUpdatePolicy, writer.uint32(322).fork()).join();
    }
    if (message.onDeployUpdatePolicy !== undefined) {
      OnDeployUpdatePolicy.encode(message.onDeployUpdatePolicy, writer.uint32(330).fork()).join();
    }
    if (message.build !== "") {
      writer.uint32(10).string(message.build);
    }
    if (message.runtime !== "") {
      writer.uint32(18).string(message.runtime);
    }
    if (message.entryPoint !== "") {
      writer.uint32(26).string(message.entryPoint);
    }
    if (message.source !== undefined) {
      Source.encode(message.source, writer.uint32(34).fork()).join();
    }
    if (message.sourceProvenance !== undefined) {
      SourceProvenance.encode(message.sourceProvenance, writer.uint32(66).fork()).join();
    }
    if (message.workerPool !== "") {
      writer.uint32(42).string(message.workerPool);
    }
    Object.entries(message.environmentVariables).forEach(([key, value]) => {
      BuildConfig_EnvironmentVariablesEntry.encode({ key: key as any, value }, writer.uint32(50).fork()).join();
    });
    if (message.dockerRegistry !== 0) {
      writer.uint32(80).int32(message.dockerRegistry);
    }
    if (message.dockerRepository !== "") {
      writer.uint32(58).string(message.dockerRepository);
    }
    if (message.serviceAccount !== "") {
      writer.uint32(218).string(message.serviceAccount);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): BuildConfig {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseBuildConfig();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 40:
          if (tag !== 322) {
            break;
          }

          message.automaticUpdatePolicy = AutomaticUpdatePolicy.decode(reader, reader.uint32());
          continue;
        case 41:
          if (tag !== 330) {
            break;
          }

          message.onDeployUpdatePolicy = OnDeployUpdatePolicy.decode(reader, reader.uint32());
          continue;
        case 1:
          if (tag !== 10) {
            break;
          }

          message.build = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.runtime = reader.string();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.entryPoint = reader.string();
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.source = Source.decode(reader, reader.uint32());
          continue;
        case 8:
          if (tag !== 66) {
            break;
          }

          message.sourceProvenance = SourceProvenance.decode(reader, reader.uint32());
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.workerPool = reader.string();
          continue;
        case 6:
          if (tag !== 50) {
            break;
          }

          const entry6 = BuildConfig_EnvironmentVariablesEntry.decode(reader, reader.uint32());
          if (entry6.value !== undefined) {
            message.environmentVariables[entry6.key] = entry6.value;
          }
          continue;
        case 10:
          if (tag !== 80) {
            break;
          }

          message.dockerRegistry = reader.int32() as any;
          continue;
        case 7:
          if (tag !== 58) {
            break;
          }

          message.dockerRepository = reader.string();
          continue;
        case 27:
          if (tag !== 218) {
            break;
          }

          message.serviceAccount = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): BuildConfig {
    return {
      automaticUpdatePolicy: isSet(object.automaticUpdatePolicy)
        ? AutomaticUpdatePolicy.fromJSON(object.automaticUpdatePolicy)
        : undefined,
      onDeployUpdatePolicy: isSet(object.onDeployUpdatePolicy)
        ? OnDeployUpdatePolicy.fromJSON(object.onDeployUpdatePolicy)
        : undefined,
      build: isSet(object.build) ? globalThis.String(object.build) : "",
      runtime: isSet(object.runtime) ? globalThis.String(object.runtime) : "",
      entryPoint: isSet(object.entryPoint) ? globalThis.String(object.entryPoint) : "",
      source: isSet(object.source) ? Source.fromJSON(object.source) : undefined,
      sourceProvenance: isSet(object.sourceProvenance) ? SourceProvenance.fromJSON(object.sourceProvenance) : undefined,
      workerPool: isSet(object.workerPool) ? globalThis.String(object.workerPool) : "",
      environmentVariables: isObject(object.environmentVariables)
        ? Object.entries(object.environmentVariables).reduce<{ [key: string]: string }>((acc, [key, value]) => {
          acc[key] = String(value);
          return acc;
        }, {})
        : {},
      dockerRegistry: isSet(object.dockerRegistry) ? buildConfig_DockerRegistryFromJSON(object.dockerRegistry) : 0,
      dockerRepository: isSet(object.dockerRepository) ? globalThis.String(object.dockerRepository) : "",
      serviceAccount: isSet(object.serviceAccount) ? globalThis.String(object.serviceAccount) : "",
    };
  },

  toJSON(message: BuildConfig): unknown {
    const obj: any = {};
    if (message.automaticUpdatePolicy !== undefined) {
      obj.automaticUpdatePolicy = AutomaticUpdatePolicy.toJSON(message.automaticUpdatePolicy);
    }
    if (message.onDeployUpdatePolicy !== undefined) {
      obj.onDeployUpdatePolicy = OnDeployUpdatePolicy.toJSON(message.onDeployUpdatePolicy);
    }
    if (message.build !== "") {
      obj.build = message.build;
    }
    if (message.runtime !== "") {
      obj.runtime = message.runtime;
    }
    if (message.entryPoint !== "") {
      obj.entryPoint = message.entryPoint;
    }
    if (message.source !== undefined) {
      obj.source = Source.toJSON(message.source);
    }
    if (message.sourceProvenance !== undefined) {
      obj.sourceProvenance = SourceProvenance.toJSON(message.sourceProvenance);
    }
    if (message.workerPool !== "") {
      obj.workerPool = message.workerPool;
    }
    if (message.environmentVariables) {
      const entries = Object.entries(message.environmentVariables);
      if (entries.length > 0) {
        obj.environmentVariables = {};
        entries.forEach(([k, v]) => {
          obj.environmentVariables[k] = v;
        });
      }
    }
    if (message.dockerRegistry !== 0) {
      obj.dockerRegistry = buildConfig_DockerRegistryToJSON(message.dockerRegistry);
    }
    if (message.dockerRepository !== "") {
      obj.dockerRepository = message.dockerRepository;
    }
    if (message.serviceAccount !== "") {
      obj.serviceAccount = message.serviceAccount;
    }
    return obj;
  },

  create(base?: DeepPartial<BuildConfig>): BuildConfig {
    return BuildConfig.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<BuildConfig>): BuildConfig {
    const message = createBaseBuildConfig();
    message.automaticUpdatePolicy =
      (object.automaticUpdatePolicy !== undefined && object.automaticUpdatePolicy !== null)
        ? AutomaticUpdatePolicy.fromPartial(object.automaticUpdatePolicy)
        : undefined;
    message.onDeployUpdatePolicy = (object.onDeployUpdatePolicy !== undefined && object.onDeployUpdatePolicy !== null)
      ? OnDeployUpdatePolicy.fromPartial(object.onDeployUpdatePolicy)
      : undefined;
    message.build = object.build ?? "";
    message.runtime = object.runtime ?? "";
    message.entryPoint = object.entryPoint ?? "";
    message.source = (object.source !== undefined && object.source !== null)
      ? Source.fromPartial(object.source)
      : undefined;
    message.sourceProvenance = (object.sourceProvenance !== undefined && object.sourceProvenance !== null)
      ? SourceProvenance.fromPartial(object.sourceProvenance)
      : undefined;
    message.workerPool = object.workerPool ?? "";
    message.environmentVariables = Object.entries(object.environmentVariables ?? {}).reduce<{ [key: string]: string }>(
      (acc, [key, value]) => {
        if (value !== undefined) {
          acc[key] = globalThis.String(value);
        }
        return acc;
      },
      {},
    );
    message.dockerRegistry = object.dockerRegistry ?? 0;
    message.dockerRepository = object.dockerRepository ?? "";
    message.serviceAccount = object.serviceAccount ?? "";
    return message;
  },
};

function createBaseBuildConfig_EnvironmentVariablesEntry(): BuildConfig_EnvironmentVariablesEntry {
  return { key: "", value: "" };
}

export const BuildConfig_EnvironmentVariablesEntry: MessageFns<BuildConfig_EnvironmentVariablesEntry> = {
  encode(message: BuildConfig_EnvironmentVariablesEntry, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.key !== "") {
      writer.uint32(10).string(message.key);
    }
    if (message.value !== "") {
      writer.uint32(18).string(message.value);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): BuildConfig_EnvironmentVariablesEntry {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseBuildConfig_EnvironmentVariablesEntry();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.key = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.value = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): BuildConfig_EnvironmentVariablesEntry {
    return {
      key: isSet(object.key) ? globalThis.String(object.key) : "",
      value: isSet(object.value) ? globalThis.String(object.value) : "",
    };
  },

  toJSON(message: BuildConfig_EnvironmentVariablesEntry): unknown {
    const obj: any = {};
    if (message.key !== "") {
      obj.key = message.key;
    }
    if (message.value !== "") {
      obj.value = message.value;
    }
    return obj;
  },

  create(base?: DeepPartial<BuildConfig_EnvironmentVariablesEntry>): BuildConfig_EnvironmentVariablesEntry {
    return BuildConfig_EnvironmentVariablesEntry.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<BuildConfig_EnvironmentVariablesEntry>): BuildConfig_EnvironmentVariablesEntry {
    const message = createBaseBuildConfig_EnvironmentVariablesEntry();
    message.key = object.key ?? "";
    message.value = object.value ?? "";
    return message;
  },
};

function createBaseServiceConfig(): ServiceConfig {
  return {
    service: "",
    timeoutSeconds: 0,
    availableMemory: "",
    availableCpu: "",
    environmentVariables: {},
    maxInstanceCount: 0,
    minInstanceCount: 0,
    vpcConnector: "",
    vpcConnectorEgressSettings: 0,
    ingressSettings: 0,
    uri: "",
    serviceAccountEmail: "",
    allTrafficOnLatestRevision: false,
    secretEnvironmentVariables: [],
    secretVolumes: [],
    revision: "",
    maxInstanceRequestConcurrency: 0,
    securityLevel: 0,
    binaryAuthorizationPolicy: "",
  };
}

export const ServiceConfig: MessageFns<ServiceConfig> = {
  encode(message: ServiceConfig, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.service !== "") {
      writer.uint32(10).string(message.service);
    }
    if (message.timeoutSeconds !== 0) {
      writer.uint32(16).int32(message.timeoutSeconds);
    }
    if (message.availableMemory !== "") {
      writer.uint32(106).string(message.availableMemory);
    }
    if (message.availableCpu !== "") {
      writer.uint32(178).string(message.availableCpu);
    }
    Object.entries(message.environmentVariables).forEach(([key, value]) => {
      ServiceConfig_EnvironmentVariablesEntry.encode({ key: key as any, value }, writer.uint32(34).fork()).join();
    });
    if (message.maxInstanceCount !== 0) {
      writer.uint32(40).int32(message.maxInstanceCount);
    }
    if (message.minInstanceCount !== 0) {
      writer.uint32(96).int32(message.minInstanceCount);
    }
    if (message.vpcConnector !== "") {
      writer.uint32(50).string(message.vpcConnector);
    }
    if (message.vpcConnectorEgressSettings !== 0) {
      writer.uint32(56).int32(message.vpcConnectorEgressSettings);
    }
    if (message.ingressSettings !== 0) {
      writer.uint32(64).int32(message.ingressSettings);
    }
    if (message.uri !== "") {
      writer.uint32(74).string(message.uri);
    }
    if (message.serviceAccountEmail !== "") {
      writer.uint32(82).string(message.serviceAccountEmail);
    }
    if (message.allTrafficOnLatestRevision !== false) {
      writer.uint32(128).bool(message.allTrafficOnLatestRevision);
    }
    for (const v of message.secretEnvironmentVariables) {
      SecretEnvVar.encode(v!, writer.uint32(138).fork()).join();
    }
    for (const v of message.secretVolumes) {
      SecretVolume.encode(v!, writer.uint32(154).fork()).join();
    }
    if (message.revision !== "") {
      writer.uint32(146).string(message.revision);
    }
    if (message.maxInstanceRequestConcurrency !== 0) {
      writer.uint32(160).int32(message.maxInstanceRequestConcurrency);
    }
    if (message.securityLevel !== 0) {
      writer.uint32(168).int32(message.securityLevel);
    }
    if (message.binaryAuthorizationPolicy !== "") {
      writer.uint32(186).string(message.binaryAuthorizationPolicy);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ServiceConfig {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseServiceConfig();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.service = reader.string();
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.timeoutSeconds = reader.int32();
          continue;
        case 13:
          if (tag !== 106) {
            break;
          }

          message.availableMemory = reader.string();
          continue;
        case 22:
          if (tag !== 178) {
            break;
          }

          message.availableCpu = reader.string();
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          const entry4 = ServiceConfig_EnvironmentVariablesEntry.decode(reader, reader.uint32());
          if (entry4.value !== undefined) {
            message.environmentVariables[entry4.key] = entry4.value;
          }
          continue;
        case 5:
          if (tag !== 40) {
            break;
          }

          message.maxInstanceCount = reader.int32();
          continue;
        case 12:
          if (tag !== 96) {
            break;
          }

          message.minInstanceCount = reader.int32();
          continue;
        case 6:
          if (tag !== 50) {
            break;
          }

          message.vpcConnector = reader.string();
          continue;
        case 7:
          if (tag !== 56) {
            break;
          }

          message.vpcConnectorEgressSettings = reader.int32() as any;
          continue;
        case 8:
          if (tag !== 64) {
            break;
          }

          message.ingressSettings = reader.int32() as any;
          continue;
        case 9:
          if (tag !== 74) {
            break;
          }

          message.uri = reader.string();
          continue;
        case 10:
          if (tag !== 82) {
            break;
          }

          message.serviceAccountEmail = reader.string();
          continue;
        case 16:
          if (tag !== 128) {
            break;
          }

          message.allTrafficOnLatestRevision = reader.bool();
          continue;
        case 17:
          if (tag !== 138) {
            break;
          }

          message.secretEnvironmentVariables.push(SecretEnvVar.decode(reader, reader.uint32()));
          continue;
        case 19:
          if (tag !== 154) {
            break;
          }

          message.secretVolumes.push(SecretVolume.decode(reader, reader.uint32()));
          continue;
        case 18:
          if (tag !== 146) {
            break;
          }

          message.revision = reader.string();
          continue;
        case 20:
          if (tag !== 160) {
            break;
          }

          message.maxInstanceRequestConcurrency = reader.int32();
          continue;
        case 21:
          if (tag !== 168) {
            break;
          }

          message.securityLevel = reader.int32() as any;
          continue;
        case 23:
          if (tag !== 186) {
            break;
          }

          message.binaryAuthorizationPolicy = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ServiceConfig {
    return {
      service: isSet(object.service) ? globalThis.String(object.service) : "",
      timeoutSeconds: isSet(object.timeoutSeconds) ? globalThis.Number(object.timeoutSeconds) : 0,
      availableMemory: isSet(object.availableMemory) ? globalThis.String(object.availableMemory) : "",
      availableCpu: isSet(object.availableCpu) ? globalThis.String(object.availableCpu) : "",
      environmentVariables: isObject(object.environmentVariables)
        ? Object.entries(object.environmentVariables).reduce<{ [key: string]: string }>((acc, [key, value]) => {
          acc[key] = String(value);
          return acc;
        }, {})
        : {},
      maxInstanceCount: isSet(object.maxInstanceCount) ? globalThis.Number(object.maxInstanceCount) : 0,
      minInstanceCount: isSet(object.minInstanceCount) ? globalThis.Number(object.minInstanceCount) : 0,
      vpcConnector: isSet(object.vpcConnector) ? globalThis.String(object.vpcConnector) : "",
      vpcConnectorEgressSettings: isSet(object.vpcConnectorEgressSettings)
        ? serviceConfig_VpcConnectorEgressSettingsFromJSON(object.vpcConnectorEgressSettings)
        : 0,
      ingressSettings: isSet(object.ingressSettings)
        ? serviceConfig_IngressSettingsFromJSON(object.ingressSettings)
        : 0,
      uri: isSet(object.uri) ? globalThis.String(object.uri) : "",
      serviceAccountEmail: isSet(object.serviceAccountEmail) ? globalThis.String(object.serviceAccountEmail) : "",
      allTrafficOnLatestRevision: isSet(object.allTrafficOnLatestRevision)
        ? globalThis.Boolean(object.allTrafficOnLatestRevision)
        : false,
      secretEnvironmentVariables: globalThis.Array.isArray(object?.secretEnvironmentVariables)
        ? object.secretEnvironmentVariables.map((e: any) => SecretEnvVar.fromJSON(e))
        : [],
      secretVolumes: globalThis.Array.isArray(object?.secretVolumes)
        ? object.secretVolumes.map((e: any) => SecretVolume.fromJSON(e))
        : [],
      revision: isSet(object.revision) ? globalThis.String(object.revision) : "",
      maxInstanceRequestConcurrency: isSet(object.maxInstanceRequestConcurrency)
        ? globalThis.Number(object.maxInstanceRequestConcurrency)
        : 0,
      securityLevel: isSet(object.securityLevel) ? serviceConfig_SecurityLevelFromJSON(object.securityLevel) : 0,
      binaryAuthorizationPolicy: isSet(object.binaryAuthorizationPolicy)
        ? globalThis.String(object.binaryAuthorizationPolicy)
        : "",
    };
  },

  toJSON(message: ServiceConfig): unknown {
    const obj: any = {};
    if (message.service !== "") {
      obj.service = message.service;
    }
    if (message.timeoutSeconds !== 0) {
      obj.timeoutSeconds = Math.round(message.timeoutSeconds);
    }
    if (message.availableMemory !== "") {
      obj.availableMemory = message.availableMemory;
    }
    if (message.availableCpu !== "") {
      obj.availableCpu = message.availableCpu;
    }
    if (message.environmentVariables) {
      const entries = Object.entries(message.environmentVariables);
      if (entries.length > 0) {
        obj.environmentVariables = {};
        entries.forEach(([k, v]) => {
          obj.environmentVariables[k] = v;
        });
      }
    }
    if (message.maxInstanceCount !== 0) {
      obj.maxInstanceCount = Math.round(message.maxInstanceCount);
    }
    if (message.minInstanceCount !== 0) {
      obj.minInstanceCount = Math.round(message.minInstanceCount);
    }
    if (message.vpcConnector !== "") {
      obj.vpcConnector = message.vpcConnector;
    }
    if (message.vpcConnectorEgressSettings !== 0) {
      obj.vpcConnectorEgressSettings = serviceConfig_VpcConnectorEgressSettingsToJSON(
        message.vpcConnectorEgressSettings,
      );
    }
    if (message.ingressSettings !== 0) {
      obj.ingressSettings = serviceConfig_IngressSettingsToJSON(message.ingressSettings);
    }
    if (message.uri !== "") {
      obj.uri = message.uri;
    }
    if (message.serviceAccountEmail !== "") {
      obj.serviceAccountEmail = message.serviceAccountEmail;
    }
    if (message.allTrafficOnLatestRevision !== false) {
      obj.allTrafficOnLatestRevision = message.allTrafficOnLatestRevision;
    }
    if (message.secretEnvironmentVariables?.length) {
      obj.secretEnvironmentVariables = message.secretEnvironmentVariables.map((e) => SecretEnvVar.toJSON(e));
    }
    if (message.secretVolumes?.length) {
      obj.secretVolumes = message.secretVolumes.map((e) => SecretVolume.toJSON(e));
    }
    if (message.revision !== "") {
      obj.revision = message.revision;
    }
    if (message.maxInstanceRequestConcurrency !== 0) {
      obj.maxInstanceRequestConcurrency = Math.round(message.maxInstanceRequestConcurrency);
    }
    if (message.securityLevel !== 0) {
      obj.securityLevel = serviceConfig_SecurityLevelToJSON(message.securityLevel);
    }
    if (message.binaryAuthorizationPolicy !== "") {
      obj.binaryAuthorizationPolicy = message.binaryAuthorizationPolicy;
    }
    return obj;
  },

  create(base?: DeepPartial<ServiceConfig>): ServiceConfig {
    return ServiceConfig.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ServiceConfig>): ServiceConfig {
    const message = createBaseServiceConfig();
    message.service = object.service ?? "";
    message.timeoutSeconds = object.timeoutSeconds ?? 0;
    message.availableMemory = object.availableMemory ?? "";
    message.availableCpu = object.availableCpu ?? "";
    message.environmentVariables = Object.entries(object.environmentVariables ?? {}).reduce<{ [key: string]: string }>(
      (acc, [key, value]) => {
        if (value !== undefined) {
          acc[key] = globalThis.String(value);
        }
        return acc;
      },
      {},
    );
    message.maxInstanceCount = object.maxInstanceCount ?? 0;
    message.minInstanceCount = object.minInstanceCount ?? 0;
    message.vpcConnector = object.vpcConnector ?? "";
    message.vpcConnectorEgressSettings = object.vpcConnectorEgressSettings ?? 0;
    message.ingressSettings = object.ingressSettings ?? 0;
    message.uri = object.uri ?? "";
    message.serviceAccountEmail = object.serviceAccountEmail ?? "";
    message.allTrafficOnLatestRevision = object.allTrafficOnLatestRevision ?? false;
    message.secretEnvironmentVariables = object.secretEnvironmentVariables?.map((e) => SecretEnvVar.fromPartial(e)) ||
      [];
    message.secretVolumes = object.secretVolumes?.map((e) => SecretVolume.fromPartial(e)) || [];
    message.revision = object.revision ?? "";
    message.maxInstanceRequestConcurrency = object.maxInstanceRequestConcurrency ?? 0;
    message.securityLevel = object.securityLevel ?? 0;
    message.binaryAuthorizationPolicy = object.binaryAuthorizationPolicy ?? "";
    return message;
  },
};

function createBaseServiceConfig_EnvironmentVariablesEntry(): ServiceConfig_EnvironmentVariablesEntry {
  return { key: "", value: "" };
}

export const ServiceConfig_EnvironmentVariablesEntry: MessageFns<ServiceConfig_EnvironmentVariablesEntry> = {
  encode(message: ServiceConfig_EnvironmentVariablesEntry, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.key !== "") {
      writer.uint32(10).string(message.key);
    }
    if (message.value !== "") {
      writer.uint32(18).string(message.value);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ServiceConfig_EnvironmentVariablesEntry {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseServiceConfig_EnvironmentVariablesEntry();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.key = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.value = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ServiceConfig_EnvironmentVariablesEntry {
    return {
      key: isSet(object.key) ? globalThis.String(object.key) : "",
      value: isSet(object.value) ? globalThis.String(object.value) : "",
    };
  },

  toJSON(message: ServiceConfig_EnvironmentVariablesEntry): unknown {
    const obj: any = {};
    if (message.key !== "") {
      obj.key = message.key;
    }
    if (message.value !== "") {
      obj.value = message.value;
    }
    return obj;
  },

  create(base?: DeepPartial<ServiceConfig_EnvironmentVariablesEntry>): ServiceConfig_EnvironmentVariablesEntry {
    return ServiceConfig_EnvironmentVariablesEntry.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ServiceConfig_EnvironmentVariablesEntry>): ServiceConfig_EnvironmentVariablesEntry {
    const message = createBaseServiceConfig_EnvironmentVariablesEntry();
    message.key = object.key ?? "";
    message.value = object.value ?? "";
    return message;
  },
};

function createBaseSecretEnvVar(): SecretEnvVar {
  return { key: "", projectId: "", secret: "", version: "" };
}

export const SecretEnvVar: MessageFns<SecretEnvVar> = {
  encode(message: SecretEnvVar, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.key !== "") {
      writer.uint32(10).string(message.key);
    }
    if (message.projectId !== "") {
      writer.uint32(18).string(message.projectId);
    }
    if (message.secret !== "") {
      writer.uint32(26).string(message.secret);
    }
    if (message.version !== "") {
      writer.uint32(34).string(message.version);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): SecretEnvVar {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseSecretEnvVar();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.key = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.projectId = reader.string();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.secret = reader.string();
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.version = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): SecretEnvVar {
    return {
      key: isSet(object.key) ? globalThis.String(object.key) : "",
      projectId: isSet(object.projectId) ? globalThis.String(object.projectId) : "",
      secret: isSet(object.secret) ? globalThis.String(object.secret) : "",
      version: isSet(object.version) ? globalThis.String(object.version) : "",
    };
  },

  toJSON(message: SecretEnvVar): unknown {
    const obj: any = {};
    if (message.key !== "") {
      obj.key = message.key;
    }
    if (message.projectId !== "") {
      obj.projectId = message.projectId;
    }
    if (message.secret !== "") {
      obj.secret = message.secret;
    }
    if (message.version !== "") {
      obj.version = message.version;
    }
    return obj;
  },

  create(base?: DeepPartial<SecretEnvVar>): SecretEnvVar {
    return SecretEnvVar.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<SecretEnvVar>): SecretEnvVar {
    const message = createBaseSecretEnvVar();
    message.key = object.key ?? "";
    message.projectId = object.projectId ?? "";
    message.secret = object.secret ?? "";
    message.version = object.version ?? "";
    return message;
  },
};

function createBaseSecretVolume(): SecretVolume {
  return { mountPath: "", projectId: "", secret: "", versions: [] };
}

export const SecretVolume: MessageFns<SecretVolume> = {
  encode(message: SecretVolume, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.mountPath !== "") {
      writer.uint32(10).string(message.mountPath);
    }
    if (message.projectId !== "") {
      writer.uint32(18).string(message.projectId);
    }
    if (message.secret !== "") {
      writer.uint32(26).string(message.secret);
    }
    for (const v of message.versions) {
      SecretVolume_SecretVersion.encode(v!, writer.uint32(34).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): SecretVolume {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseSecretVolume();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.mountPath = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.projectId = reader.string();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.secret = reader.string();
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.versions.push(SecretVolume_SecretVersion.decode(reader, reader.uint32()));
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): SecretVolume {
    return {
      mountPath: isSet(object.mountPath) ? globalThis.String(object.mountPath) : "",
      projectId: isSet(object.projectId) ? globalThis.String(object.projectId) : "",
      secret: isSet(object.secret) ? globalThis.String(object.secret) : "",
      versions: globalThis.Array.isArray(object?.versions)
        ? object.versions.map((e: any) => SecretVolume_SecretVersion.fromJSON(e))
        : [],
    };
  },

  toJSON(message: SecretVolume): unknown {
    const obj: any = {};
    if (message.mountPath !== "") {
      obj.mountPath = message.mountPath;
    }
    if (message.projectId !== "") {
      obj.projectId = message.projectId;
    }
    if (message.secret !== "") {
      obj.secret = message.secret;
    }
    if (message.versions?.length) {
      obj.versions = message.versions.map((e) => SecretVolume_SecretVersion.toJSON(e));
    }
    return obj;
  },

  create(base?: DeepPartial<SecretVolume>): SecretVolume {
    return SecretVolume.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<SecretVolume>): SecretVolume {
    const message = createBaseSecretVolume();
    message.mountPath = object.mountPath ?? "";
    message.projectId = object.projectId ?? "";
    message.secret = object.secret ?? "";
    message.versions = object.versions?.map((e) => SecretVolume_SecretVersion.fromPartial(e)) || [];
    return message;
  },
};

function createBaseSecretVolume_SecretVersion(): SecretVolume_SecretVersion {
  return { version: "", path: "" };
}

export const SecretVolume_SecretVersion: MessageFns<SecretVolume_SecretVersion> = {
  encode(message: SecretVolume_SecretVersion, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.version !== "") {
      writer.uint32(10).string(message.version);
    }
    if (message.path !== "") {
      writer.uint32(18).string(message.path);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): SecretVolume_SecretVersion {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseSecretVolume_SecretVersion();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.version = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.path = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): SecretVolume_SecretVersion {
    return {
      version: isSet(object.version) ? globalThis.String(object.version) : "",
      path: isSet(object.path) ? globalThis.String(object.path) : "",
    };
  },

  toJSON(message: SecretVolume_SecretVersion): unknown {
    const obj: any = {};
    if (message.version !== "") {
      obj.version = message.version;
    }
    if (message.path !== "") {
      obj.path = message.path;
    }
    return obj;
  },

  create(base?: DeepPartial<SecretVolume_SecretVersion>): SecretVolume_SecretVersion {
    return SecretVolume_SecretVersion.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<SecretVolume_SecretVersion>): SecretVolume_SecretVersion {
    const message = createBaseSecretVolume_SecretVersion();
    message.version = object.version ?? "";
    message.path = object.path ?? "";
    return message;
  },
};

function createBaseEventTrigger(): EventTrigger {
  return {
    trigger: "",
    triggerRegion: "",
    eventType: "",
    eventFilters: [],
    pubsubTopic: "",
    serviceAccountEmail: "",
    retryPolicy: 0,
    channel: "",
    service: "",
  };
}

export const EventTrigger: MessageFns<EventTrigger> = {
  encode(message: EventTrigger, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.trigger !== "") {
      writer.uint32(10).string(message.trigger);
    }
    if (message.triggerRegion !== "") {
      writer.uint32(18).string(message.triggerRegion);
    }
    if (message.eventType !== "") {
      writer.uint32(26).string(message.eventType);
    }
    for (const v of message.eventFilters) {
      EventFilter.encode(v!, writer.uint32(34).fork()).join();
    }
    if (message.pubsubTopic !== "") {
      writer.uint32(42).string(message.pubsubTopic);
    }
    if (message.serviceAccountEmail !== "") {
      writer.uint32(50).string(message.serviceAccountEmail);
    }
    if (message.retryPolicy !== 0) {
      writer.uint32(56).int32(message.retryPolicy);
    }
    if (message.channel !== "") {
      writer.uint32(66).string(message.channel);
    }
    if (message.service !== "") {
      writer.uint32(74).string(message.service);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): EventTrigger {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseEventTrigger();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.trigger = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.triggerRegion = reader.string();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.eventType = reader.string();
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.eventFilters.push(EventFilter.decode(reader, reader.uint32()));
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.pubsubTopic = reader.string();
          continue;
        case 6:
          if (tag !== 50) {
            break;
          }

          message.serviceAccountEmail = reader.string();
          continue;
        case 7:
          if (tag !== 56) {
            break;
          }

          message.retryPolicy = reader.int32() as any;
          continue;
        case 8:
          if (tag !== 66) {
            break;
          }

          message.channel = reader.string();
          continue;
        case 9:
          if (tag !== 74) {
            break;
          }

          message.service = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): EventTrigger {
    return {
      trigger: isSet(object.trigger) ? globalThis.String(object.trigger) : "",
      triggerRegion: isSet(object.triggerRegion) ? globalThis.String(object.triggerRegion) : "",
      eventType: isSet(object.eventType) ? globalThis.String(object.eventType) : "",
      eventFilters: globalThis.Array.isArray(object?.eventFilters)
        ? object.eventFilters.map((e: any) => EventFilter.fromJSON(e))
        : [],
      pubsubTopic: isSet(object.pubsubTopic) ? globalThis.String(object.pubsubTopic) : "",
      serviceAccountEmail: isSet(object.serviceAccountEmail) ? globalThis.String(object.serviceAccountEmail) : "",
      retryPolicy: isSet(object.retryPolicy) ? eventTrigger_RetryPolicyFromJSON(object.retryPolicy) : 0,
      channel: isSet(object.channel) ? globalThis.String(object.channel) : "",
      service: isSet(object.service) ? globalThis.String(object.service) : "",
    };
  },

  toJSON(message: EventTrigger): unknown {
    const obj: any = {};
    if (message.trigger !== "") {
      obj.trigger = message.trigger;
    }
    if (message.triggerRegion !== "") {
      obj.triggerRegion = message.triggerRegion;
    }
    if (message.eventType !== "") {
      obj.eventType = message.eventType;
    }
    if (message.eventFilters?.length) {
      obj.eventFilters = message.eventFilters.map((e) => EventFilter.toJSON(e));
    }
    if (message.pubsubTopic !== "") {
      obj.pubsubTopic = message.pubsubTopic;
    }
    if (message.serviceAccountEmail !== "") {
      obj.serviceAccountEmail = message.serviceAccountEmail;
    }
    if (message.retryPolicy !== 0) {
      obj.retryPolicy = eventTrigger_RetryPolicyToJSON(message.retryPolicy);
    }
    if (message.channel !== "") {
      obj.channel = message.channel;
    }
    if (message.service !== "") {
      obj.service = message.service;
    }
    return obj;
  },

  create(base?: DeepPartial<EventTrigger>): EventTrigger {
    return EventTrigger.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<EventTrigger>): EventTrigger {
    const message = createBaseEventTrigger();
    message.trigger = object.trigger ?? "";
    message.triggerRegion = object.triggerRegion ?? "";
    message.eventType = object.eventType ?? "";
    message.eventFilters = object.eventFilters?.map((e) => EventFilter.fromPartial(e)) || [];
    message.pubsubTopic = object.pubsubTopic ?? "";
    message.serviceAccountEmail = object.serviceAccountEmail ?? "";
    message.retryPolicy = object.retryPolicy ?? 0;
    message.channel = object.channel ?? "";
    message.service = object.service ?? "";
    return message;
  },
};

function createBaseEventFilter(): EventFilter {
  return { attribute: "", value: "", operator: "" };
}

export const EventFilter: MessageFns<EventFilter> = {
  encode(message: EventFilter, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.attribute !== "") {
      writer.uint32(10).string(message.attribute);
    }
    if (message.value !== "") {
      writer.uint32(18).string(message.value);
    }
    if (message.operator !== "") {
      writer.uint32(26).string(message.operator);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): EventFilter {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseEventFilter();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.attribute = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.value = reader.string();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.operator = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): EventFilter {
    return {
      attribute: isSet(object.attribute) ? globalThis.String(object.attribute) : "",
      value: isSet(object.value) ? globalThis.String(object.value) : "",
      operator: isSet(object.operator) ? globalThis.String(object.operator) : "",
    };
  },

  toJSON(message: EventFilter): unknown {
    const obj: any = {};
    if (message.attribute !== "") {
      obj.attribute = message.attribute;
    }
    if (message.value !== "") {
      obj.value = message.value;
    }
    if (message.operator !== "") {
      obj.operator = message.operator;
    }
    return obj;
  },

  create(base?: DeepPartial<EventFilter>): EventFilter {
    return EventFilter.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<EventFilter>): EventFilter {
    const message = createBaseEventFilter();
    message.attribute = object.attribute ?? "";
    message.value = object.value ?? "";
    message.operator = object.operator ?? "";
    return message;
  },
};

function createBaseGetFunctionRequest(): GetFunctionRequest {
  return { name: "", revision: "" };
}

export const GetFunctionRequest: MessageFns<GetFunctionRequest> = {
  encode(message: GetFunctionRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    if (message.revision !== "") {
      writer.uint32(18).string(message.revision);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): GetFunctionRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseGetFunctionRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.revision = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): GetFunctionRequest {
    return {
      name: isSet(object.name) ? globalThis.String(object.name) : "",
      revision: isSet(object.revision) ? globalThis.String(object.revision) : "",
    };
  },

  toJSON(message: GetFunctionRequest): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    if (message.revision !== "") {
      obj.revision = message.revision;
    }
    return obj;
  },

  create(base?: DeepPartial<GetFunctionRequest>): GetFunctionRequest {
    return GetFunctionRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<GetFunctionRequest>): GetFunctionRequest {
    const message = createBaseGetFunctionRequest();
    message.name = object.name ?? "";
    message.revision = object.revision ?? "";
    return message;
  },
};

function createBaseListFunctionsRequest(): ListFunctionsRequest {
  return { parent: "", pageSize: 0, pageToken: "", filter: "", orderBy: "" };
}

export const ListFunctionsRequest: MessageFns<ListFunctionsRequest> = {
  encode(message: ListFunctionsRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.parent !== "") {
      writer.uint32(10).string(message.parent);
    }
    if (message.pageSize !== 0) {
      writer.uint32(16).int32(message.pageSize);
    }
    if (message.pageToken !== "") {
      writer.uint32(26).string(message.pageToken);
    }
    if (message.filter !== "") {
      writer.uint32(34).string(message.filter);
    }
    if (message.orderBy !== "") {
      writer.uint32(42).string(message.orderBy);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ListFunctionsRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseListFunctionsRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.parent = reader.string();
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.pageSize = reader.int32();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.pageToken = reader.string();
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.filter = reader.string();
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.orderBy = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ListFunctionsRequest {
    return {
      parent: isSet(object.parent) ? globalThis.String(object.parent) : "",
      pageSize: isSet(object.pageSize) ? globalThis.Number(object.pageSize) : 0,
      pageToken: isSet(object.pageToken) ? globalThis.String(object.pageToken) : "",
      filter: isSet(object.filter) ? globalThis.String(object.filter) : "",
      orderBy: isSet(object.orderBy) ? globalThis.String(object.orderBy) : "",
    };
  },

  toJSON(message: ListFunctionsRequest): unknown {
    const obj: any = {};
    if (message.parent !== "") {
      obj.parent = message.parent;
    }
    if (message.pageSize !== 0) {
      obj.pageSize = Math.round(message.pageSize);
    }
    if (message.pageToken !== "") {
      obj.pageToken = message.pageToken;
    }
    if (message.filter !== "") {
      obj.filter = message.filter;
    }
    if (message.orderBy !== "") {
      obj.orderBy = message.orderBy;
    }
    return obj;
  },

  create(base?: DeepPartial<ListFunctionsRequest>): ListFunctionsRequest {
    return ListFunctionsRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ListFunctionsRequest>): ListFunctionsRequest {
    const message = createBaseListFunctionsRequest();
    message.parent = object.parent ?? "";
    message.pageSize = object.pageSize ?? 0;
    message.pageToken = object.pageToken ?? "";
    message.filter = object.filter ?? "";
    message.orderBy = object.orderBy ?? "";
    return message;
  },
};

function createBaseListFunctionsResponse(): ListFunctionsResponse {
  return { functions: [], nextPageToken: "", unreachable: [] };
}

export const ListFunctionsResponse: MessageFns<ListFunctionsResponse> = {
  encode(message: ListFunctionsResponse, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.functions) {
      Function.encode(v!, writer.uint32(10).fork()).join();
    }
    if (message.nextPageToken !== "") {
      writer.uint32(18).string(message.nextPageToken);
    }
    for (const v of message.unreachable) {
      writer.uint32(26).string(v!);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ListFunctionsResponse {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseListFunctionsResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.functions.push(Function.decode(reader, reader.uint32()));
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.nextPageToken = reader.string();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.unreachable.push(reader.string());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ListFunctionsResponse {
    return {
      functions: globalThis.Array.isArray(object?.functions)
        ? object.functions.map((e: any) => Function.fromJSON(e))
        : [],
      nextPageToken: isSet(object.nextPageToken) ? globalThis.String(object.nextPageToken) : "",
      unreachable: globalThis.Array.isArray(object?.unreachable)
        ? object.unreachable.map((e: any) => globalThis.String(e))
        : [],
    };
  },

  toJSON(message: ListFunctionsResponse): unknown {
    const obj: any = {};
    if (message.functions?.length) {
      obj.functions = message.functions.map((e) => Function.toJSON(e));
    }
    if (message.nextPageToken !== "") {
      obj.nextPageToken = message.nextPageToken;
    }
    if (message.unreachable?.length) {
      obj.unreachable = message.unreachable;
    }
    return obj;
  },

  create(base?: DeepPartial<ListFunctionsResponse>): ListFunctionsResponse {
    return ListFunctionsResponse.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ListFunctionsResponse>): ListFunctionsResponse {
    const message = createBaseListFunctionsResponse();
    message.functions = object.functions?.map((e) => Function.fromPartial(e)) || [];
    message.nextPageToken = object.nextPageToken ?? "";
    message.unreachable = object.unreachable?.map((e) => e) || [];
    return message;
  },
};

function createBaseCreateFunctionRequest(): CreateFunctionRequest {
  return { parent: "", function: undefined, functionId: "" };
}

export const CreateFunctionRequest: MessageFns<CreateFunctionRequest> = {
  encode(message: CreateFunctionRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.parent !== "") {
      writer.uint32(10).string(message.parent);
    }
    if (message.function !== undefined) {
      Function.encode(message.function, writer.uint32(18).fork()).join();
    }
    if (message.functionId !== "") {
      writer.uint32(26).string(message.functionId);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): CreateFunctionRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseCreateFunctionRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.parent = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.function = Function.decode(reader, reader.uint32());
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.functionId = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): CreateFunctionRequest {
    return {
      parent: isSet(object.parent) ? globalThis.String(object.parent) : "",
      function: isSet(object.function) ? Function.fromJSON(object.function) : undefined,
      functionId: isSet(object.functionId) ? globalThis.String(object.functionId) : "",
    };
  },

  toJSON(message: CreateFunctionRequest): unknown {
    const obj: any = {};
    if (message.parent !== "") {
      obj.parent = message.parent;
    }
    if (message.function !== undefined) {
      obj.function = Function.toJSON(message.function);
    }
    if (message.functionId !== "") {
      obj.functionId = message.functionId;
    }
    return obj;
  },

  create(base?: DeepPartial<CreateFunctionRequest>): CreateFunctionRequest {
    return CreateFunctionRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<CreateFunctionRequest>): CreateFunctionRequest {
    const message = createBaseCreateFunctionRequest();
    message.parent = object.parent ?? "";
    message.function = (object.function !== undefined && object.function !== null)
      ? Function.fromPartial(object.function)
      : undefined;
    message.functionId = object.functionId ?? "";
    return message;
  },
};

function createBaseUpdateFunctionRequest(): UpdateFunctionRequest {
  return { function: undefined, updateMask: undefined };
}

export const UpdateFunctionRequest: MessageFns<UpdateFunctionRequest> = {
  encode(message: UpdateFunctionRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.function !== undefined) {
      Function.encode(message.function, writer.uint32(10).fork()).join();
    }
    if (message.updateMask !== undefined) {
      FieldMask.encode(FieldMask.wrap(message.updateMask), writer.uint32(18).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): UpdateFunctionRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseUpdateFunctionRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.function = Function.decode(reader, reader.uint32());
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.updateMask = FieldMask.unwrap(FieldMask.decode(reader, reader.uint32()));
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): UpdateFunctionRequest {
    return {
      function: isSet(object.function) ? Function.fromJSON(object.function) : undefined,
      updateMask: isSet(object.updateMask) ? FieldMask.unwrap(FieldMask.fromJSON(object.updateMask)) : undefined,
    };
  },

  toJSON(message: UpdateFunctionRequest): unknown {
    const obj: any = {};
    if (message.function !== undefined) {
      obj.function = Function.toJSON(message.function);
    }
    if (message.updateMask !== undefined) {
      obj.updateMask = FieldMask.toJSON(FieldMask.wrap(message.updateMask));
    }
    return obj;
  },

  create(base?: DeepPartial<UpdateFunctionRequest>): UpdateFunctionRequest {
    return UpdateFunctionRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<UpdateFunctionRequest>): UpdateFunctionRequest {
    const message = createBaseUpdateFunctionRequest();
    message.function = (object.function !== undefined && object.function !== null)
      ? Function.fromPartial(object.function)
      : undefined;
    message.updateMask = object.updateMask ?? undefined;
    return message;
  },
};

function createBaseDeleteFunctionRequest(): DeleteFunctionRequest {
  return { name: "" };
}

export const DeleteFunctionRequest: MessageFns<DeleteFunctionRequest> = {
  encode(message: DeleteFunctionRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): DeleteFunctionRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDeleteFunctionRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): DeleteFunctionRequest {
    return { name: isSet(object.name) ? globalThis.String(object.name) : "" };
  },

  toJSON(message: DeleteFunctionRequest): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    return obj;
  },

  create(base?: DeepPartial<DeleteFunctionRequest>): DeleteFunctionRequest {
    return DeleteFunctionRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<DeleteFunctionRequest>): DeleteFunctionRequest {
    const message = createBaseDeleteFunctionRequest();
    message.name = object.name ?? "";
    return message;
  },
};

function createBaseGenerateUploadUrlRequest(): GenerateUploadUrlRequest {
  return { parent: "", kmsKeyName: "", environment: 0 };
}

export const GenerateUploadUrlRequest: MessageFns<GenerateUploadUrlRequest> = {
  encode(message: GenerateUploadUrlRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.parent !== "") {
      writer.uint32(10).string(message.parent);
    }
    if (message.kmsKeyName !== "") {
      writer.uint32(18).string(message.kmsKeyName);
    }
    if (message.environment !== 0) {
      writer.uint32(24).int32(message.environment);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): GenerateUploadUrlRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseGenerateUploadUrlRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.parent = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.kmsKeyName = reader.string();
          continue;
        case 3:
          if (tag !== 24) {
            break;
          }

          message.environment = reader.int32() as any;
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): GenerateUploadUrlRequest {
    return {
      parent: isSet(object.parent) ? globalThis.String(object.parent) : "",
      kmsKeyName: isSet(object.kmsKeyName) ? globalThis.String(object.kmsKeyName) : "",
      environment: isSet(object.environment) ? environmentFromJSON(object.environment) : 0,
    };
  },

  toJSON(message: GenerateUploadUrlRequest): unknown {
    const obj: any = {};
    if (message.parent !== "") {
      obj.parent = message.parent;
    }
    if (message.kmsKeyName !== "") {
      obj.kmsKeyName = message.kmsKeyName;
    }
    if (message.environment !== 0) {
      obj.environment = environmentToJSON(message.environment);
    }
    return obj;
  },

  create(base?: DeepPartial<GenerateUploadUrlRequest>): GenerateUploadUrlRequest {
    return GenerateUploadUrlRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<GenerateUploadUrlRequest>): GenerateUploadUrlRequest {
    const message = createBaseGenerateUploadUrlRequest();
    message.parent = object.parent ?? "";
    message.kmsKeyName = object.kmsKeyName ?? "";
    message.environment = object.environment ?? 0;
    return message;
  },
};

function createBaseGenerateUploadUrlResponse(): GenerateUploadUrlResponse {
  return { uploadUrl: "", storageSource: undefined };
}

export const GenerateUploadUrlResponse: MessageFns<GenerateUploadUrlResponse> = {
  encode(message: GenerateUploadUrlResponse, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.uploadUrl !== "") {
      writer.uint32(10).string(message.uploadUrl);
    }
    if (message.storageSource !== undefined) {
      StorageSource.encode(message.storageSource, writer.uint32(18).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): GenerateUploadUrlResponse {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseGenerateUploadUrlResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.uploadUrl = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.storageSource = StorageSource.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): GenerateUploadUrlResponse {
    return {
      uploadUrl: isSet(object.uploadUrl) ? globalThis.String(object.uploadUrl) : "",
      storageSource: isSet(object.storageSource) ? StorageSource.fromJSON(object.storageSource) : undefined,
    };
  },

  toJSON(message: GenerateUploadUrlResponse): unknown {
    const obj: any = {};
    if (message.uploadUrl !== "") {
      obj.uploadUrl = message.uploadUrl;
    }
    if (message.storageSource !== undefined) {
      obj.storageSource = StorageSource.toJSON(message.storageSource);
    }
    return obj;
  },

  create(base?: DeepPartial<GenerateUploadUrlResponse>): GenerateUploadUrlResponse {
    return GenerateUploadUrlResponse.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<GenerateUploadUrlResponse>): GenerateUploadUrlResponse {
    const message = createBaseGenerateUploadUrlResponse();
    message.uploadUrl = object.uploadUrl ?? "";
    message.storageSource = (object.storageSource !== undefined && object.storageSource !== null)
      ? StorageSource.fromPartial(object.storageSource)
      : undefined;
    return message;
  },
};

function createBaseGenerateDownloadUrlRequest(): GenerateDownloadUrlRequest {
  return { name: "" };
}

export const GenerateDownloadUrlRequest: MessageFns<GenerateDownloadUrlRequest> = {
  encode(message: GenerateDownloadUrlRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): GenerateDownloadUrlRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseGenerateDownloadUrlRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): GenerateDownloadUrlRequest {
    return { name: isSet(object.name) ? globalThis.String(object.name) : "" };
  },

  toJSON(message: GenerateDownloadUrlRequest): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    return obj;
  },

  create(base?: DeepPartial<GenerateDownloadUrlRequest>): GenerateDownloadUrlRequest {
    return GenerateDownloadUrlRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<GenerateDownloadUrlRequest>): GenerateDownloadUrlRequest {
    const message = createBaseGenerateDownloadUrlRequest();
    message.name = object.name ?? "";
    return message;
  },
};

function createBaseGenerateDownloadUrlResponse(): GenerateDownloadUrlResponse {
  return { downloadUrl: "" };
}

export const GenerateDownloadUrlResponse: MessageFns<GenerateDownloadUrlResponse> = {
  encode(message: GenerateDownloadUrlResponse, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.downloadUrl !== "") {
      writer.uint32(10).string(message.downloadUrl);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): GenerateDownloadUrlResponse {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseGenerateDownloadUrlResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.downloadUrl = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): GenerateDownloadUrlResponse {
    return { downloadUrl: isSet(object.downloadUrl) ? globalThis.String(object.downloadUrl) : "" };
  },

  toJSON(message: GenerateDownloadUrlResponse): unknown {
    const obj: any = {};
    if (message.downloadUrl !== "") {
      obj.downloadUrl = message.downloadUrl;
    }
    return obj;
  },

  create(base?: DeepPartial<GenerateDownloadUrlResponse>): GenerateDownloadUrlResponse {
    return GenerateDownloadUrlResponse.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<GenerateDownloadUrlResponse>): GenerateDownloadUrlResponse {
    const message = createBaseGenerateDownloadUrlResponse();
    message.downloadUrl = object.downloadUrl ?? "";
    return message;
  },
};

function createBaseListRuntimesRequest(): ListRuntimesRequest {
  return { parent: "", filter: "" };
}

export const ListRuntimesRequest: MessageFns<ListRuntimesRequest> = {
  encode(message: ListRuntimesRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.parent !== "") {
      writer.uint32(10).string(message.parent);
    }
    if (message.filter !== "") {
      writer.uint32(18).string(message.filter);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ListRuntimesRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseListRuntimesRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.parent = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.filter = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ListRuntimesRequest {
    return {
      parent: isSet(object.parent) ? globalThis.String(object.parent) : "",
      filter: isSet(object.filter) ? globalThis.String(object.filter) : "",
    };
  },

  toJSON(message: ListRuntimesRequest): unknown {
    const obj: any = {};
    if (message.parent !== "") {
      obj.parent = message.parent;
    }
    if (message.filter !== "") {
      obj.filter = message.filter;
    }
    return obj;
  },

  create(base?: DeepPartial<ListRuntimesRequest>): ListRuntimesRequest {
    return ListRuntimesRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ListRuntimesRequest>): ListRuntimesRequest {
    const message = createBaseListRuntimesRequest();
    message.parent = object.parent ?? "";
    message.filter = object.filter ?? "";
    return message;
  },
};

function createBaseListRuntimesResponse(): ListRuntimesResponse {
  return { runtimes: [] };
}

export const ListRuntimesResponse: MessageFns<ListRuntimesResponse> = {
  encode(message: ListRuntimesResponse, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.runtimes) {
      ListRuntimesResponse_Runtime.encode(v!, writer.uint32(10).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ListRuntimesResponse {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseListRuntimesResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.runtimes.push(ListRuntimesResponse_Runtime.decode(reader, reader.uint32()));
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ListRuntimesResponse {
    return {
      runtimes: globalThis.Array.isArray(object?.runtimes)
        ? object.runtimes.map((e: any) => ListRuntimesResponse_Runtime.fromJSON(e))
        : [],
    };
  },

  toJSON(message: ListRuntimesResponse): unknown {
    const obj: any = {};
    if (message.runtimes?.length) {
      obj.runtimes = message.runtimes.map((e) => ListRuntimesResponse_Runtime.toJSON(e));
    }
    return obj;
  },

  create(base?: DeepPartial<ListRuntimesResponse>): ListRuntimesResponse {
    return ListRuntimesResponse.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ListRuntimesResponse>): ListRuntimesResponse {
    const message = createBaseListRuntimesResponse();
    message.runtimes = object.runtimes?.map((e) => ListRuntimesResponse_Runtime.fromPartial(e)) || [];
    return message;
  },
};

function createBaseListRuntimesResponse_Runtime(): ListRuntimesResponse_Runtime {
  return {
    name: "",
    displayName: "",
    stage: 0,
    warnings: [],
    environment: 0,
    deprecationDate: undefined,
    decommissionDate: undefined,
  };
}

export const ListRuntimesResponse_Runtime: MessageFns<ListRuntimesResponse_Runtime> = {
  encode(message: ListRuntimesResponse_Runtime, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    if (message.displayName !== "") {
      writer.uint32(42).string(message.displayName);
    }
    if (message.stage !== 0) {
      writer.uint32(16).int32(message.stage);
    }
    for (const v of message.warnings) {
      writer.uint32(26).string(v!);
    }
    if (message.environment !== 0) {
      writer.uint32(32).int32(message.environment);
    }
    if (message.deprecationDate !== undefined) {
      DateMessage.encode(message.deprecationDate, writer.uint32(50).fork()).join();
    }
    if (message.decommissionDate !== undefined) {
      DateMessage.encode(message.decommissionDate, writer.uint32(58).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ListRuntimesResponse_Runtime {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseListRuntimesResponse_Runtime();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.displayName = reader.string();
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.stage = reader.int32() as any;
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.warnings.push(reader.string());
          continue;
        case 4:
          if (tag !== 32) {
            break;
          }

          message.environment = reader.int32() as any;
          continue;
        case 6:
          if (tag !== 50) {
            break;
          }

          message.deprecationDate = DateMessage.decode(reader, reader.uint32());
          continue;
        case 7:
          if (tag !== 58) {
            break;
          }

          message.decommissionDate = DateMessage.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ListRuntimesResponse_Runtime {
    return {
      name: isSet(object.name) ? globalThis.String(object.name) : "",
      displayName: isSet(object.displayName) ? globalThis.String(object.displayName) : "",
      stage: isSet(object.stage) ? listRuntimesResponse_RuntimeStageFromJSON(object.stage) : 0,
      warnings: globalThis.Array.isArray(object?.warnings) ? object.warnings.map((e: any) => globalThis.String(e)) : [],
      environment: isSet(object.environment) ? environmentFromJSON(object.environment) : 0,
      deprecationDate: isSet(object.deprecationDate) ? DateMessage.fromJSON(object.deprecationDate) : undefined,
      decommissionDate: isSet(object.decommissionDate) ? DateMessage.fromJSON(object.decommissionDate) : undefined,
    };
  },

  toJSON(message: ListRuntimesResponse_Runtime): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    if (message.displayName !== "") {
      obj.displayName = message.displayName;
    }
    if (message.stage !== 0) {
      obj.stage = listRuntimesResponse_RuntimeStageToJSON(message.stage);
    }
    if (message.warnings?.length) {
      obj.warnings = message.warnings;
    }
    if (message.environment !== 0) {
      obj.environment = environmentToJSON(message.environment);
    }
    if (message.deprecationDate !== undefined) {
      obj.deprecationDate = DateMessage.toJSON(message.deprecationDate);
    }
    if (message.decommissionDate !== undefined) {
      obj.decommissionDate = DateMessage.toJSON(message.decommissionDate);
    }
    return obj;
  },

  create(base?: DeepPartial<ListRuntimesResponse_Runtime>): ListRuntimesResponse_Runtime {
    return ListRuntimesResponse_Runtime.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ListRuntimesResponse_Runtime>): ListRuntimesResponse_Runtime {
    const message = createBaseListRuntimesResponse_Runtime();
    message.name = object.name ?? "";
    message.displayName = object.displayName ?? "";
    message.stage = object.stage ?? 0;
    message.warnings = object.warnings?.map((e) => e) || [];
    message.environment = object.environment ?? 0;
    message.deprecationDate = (object.deprecationDate !== undefined && object.deprecationDate !== null)
      ? DateMessage.fromPartial(object.deprecationDate)
      : undefined;
    message.decommissionDate = (object.decommissionDate !== undefined && object.decommissionDate !== null)
      ? DateMessage.fromPartial(object.decommissionDate)
      : undefined;
    return message;
  },
};

function createBaseAutomaticUpdatePolicy(): AutomaticUpdatePolicy {
  return {};
}

export const AutomaticUpdatePolicy: MessageFns<AutomaticUpdatePolicy> = {
  encode(_: AutomaticUpdatePolicy, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): AutomaticUpdatePolicy {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseAutomaticUpdatePolicy();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(_: any): AutomaticUpdatePolicy {
    return {};
  },

  toJSON(_: AutomaticUpdatePolicy): unknown {
    const obj: any = {};
    return obj;
  },

  create(base?: DeepPartial<AutomaticUpdatePolicy>): AutomaticUpdatePolicy {
    return AutomaticUpdatePolicy.fromPartial(base ?? {});
  },
  fromPartial(_: DeepPartial<AutomaticUpdatePolicy>): AutomaticUpdatePolicy {
    const message = createBaseAutomaticUpdatePolicy();
    return message;
  },
};

function createBaseOnDeployUpdatePolicy(): OnDeployUpdatePolicy {
  return { runtimeVersion: "" };
}

export const OnDeployUpdatePolicy: MessageFns<OnDeployUpdatePolicy> = {
  encode(message: OnDeployUpdatePolicy, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.runtimeVersion !== "") {
      writer.uint32(10).string(message.runtimeVersion);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): OnDeployUpdatePolicy {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseOnDeployUpdatePolicy();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.runtimeVersion = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): OnDeployUpdatePolicy {
    return { runtimeVersion: isSet(object.runtimeVersion) ? globalThis.String(object.runtimeVersion) : "" };
  },

  toJSON(message: OnDeployUpdatePolicy): unknown {
    const obj: any = {};
    if (message.runtimeVersion !== "") {
      obj.runtimeVersion = message.runtimeVersion;
    }
    return obj;
  },

  create(base?: DeepPartial<OnDeployUpdatePolicy>): OnDeployUpdatePolicy {
    return OnDeployUpdatePolicy.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<OnDeployUpdatePolicy>): OnDeployUpdatePolicy {
    const message = createBaseOnDeployUpdatePolicy();
    message.runtimeVersion = object.runtimeVersion ?? "";
    return message;
  },
};

function createBaseOperationMetadata(): OperationMetadata {
  return {
    createTime: undefined,
    endTime: undefined,
    target: "",
    verb: "",
    statusDetail: "",
    cancelRequested: false,
    apiVersion: "",
    requestResource: undefined,
    stages: [],
    buildName: "",
    operationType: 0,
  };
}

export const OperationMetadata: MessageFns<OperationMetadata> = {
  encode(message: OperationMetadata, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.createTime !== undefined) {
      Timestamp.encode(toTimestamp(message.createTime), writer.uint32(10).fork()).join();
    }
    if (message.endTime !== undefined) {
      Timestamp.encode(toTimestamp(message.endTime), writer.uint32(18).fork()).join();
    }
    if (message.target !== "") {
      writer.uint32(26).string(message.target);
    }
    if (message.verb !== "") {
      writer.uint32(34).string(message.verb);
    }
    if (message.statusDetail !== "") {
      writer.uint32(42).string(message.statusDetail);
    }
    if (message.cancelRequested !== false) {
      writer.uint32(48).bool(message.cancelRequested);
    }
    if (message.apiVersion !== "") {
      writer.uint32(58).string(message.apiVersion);
    }
    if (message.requestResource !== undefined) {
      Any.encode(message.requestResource, writer.uint32(66).fork()).join();
    }
    for (const v of message.stages) {
      Stage.encode(v!, writer.uint32(74).fork()).join();
    }
    if (message.buildName !== "") {
      writer.uint32(106).string(message.buildName);
    }
    if (message.operationType !== 0) {
      writer.uint32(88).int32(message.operationType);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): OperationMetadata {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseOperationMetadata();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.createTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.endTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.target = reader.string();
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.verb = reader.string();
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.statusDetail = reader.string();
          continue;
        case 6:
          if (tag !== 48) {
            break;
          }

          message.cancelRequested = reader.bool();
          continue;
        case 7:
          if (tag !== 58) {
            break;
          }

          message.apiVersion = reader.string();
          continue;
        case 8:
          if (tag !== 66) {
            break;
          }

          message.requestResource = Any.decode(reader, reader.uint32());
          continue;
        case 9:
          if (tag !== 74) {
            break;
          }

          message.stages.push(Stage.decode(reader, reader.uint32()));
          continue;
        case 13:
          if (tag !== 106) {
            break;
          }

          message.buildName = reader.string();
          continue;
        case 11:
          if (tag !== 88) {
            break;
          }

          message.operationType = reader.int32() as any;
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): OperationMetadata {
    return {
      createTime: isSet(object.createTime) ? fromJsonTimestamp(object.createTime) : undefined,
      endTime: isSet(object.endTime) ? fromJsonTimestamp(object.endTime) : undefined,
      target: isSet(object.target) ? globalThis.String(object.target) : "",
      verb: isSet(object.verb) ? globalThis.String(object.verb) : "",
      statusDetail: isSet(object.statusDetail) ? globalThis.String(object.statusDetail) : "",
      cancelRequested: isSet(object.cancelRequested) ? globalThis.Boolean(object.cancelRequested) : false,
      apiVersion: isSet(object.apiVersion) ? globalThis.String(object.apiVersion) : "",
      requestResource: isSet(object.requestResource) ? Any.fromJSON(object.requestResource) : undefined,
      stages: globalThis.Array.isArray(object?.stages) ? object.stages.map((e: any) => Stage.fromJSON(e)) : [],
      buildName: isSet(object.buildName) ? globalThis.String(object.buildName) : "",
      operationType: isSet(object.operationType) ? operationTypeFromJSON(object.operationType) : 0,
    };
  },

  toJSON(message: OperationMetadata): unknown {
    const obj: any = {};
    if (message.createTime !== undefined) {
      obj.createTime = message.createTime.toISOString();
    }
    if (message.endTime !== undefined) {
      obj.endTime = message.endTime.toISOString();
    }
    if (message.target !== "") {
      obj.target = message.target;
    }
    if (message.verb !== "") {
      obj.verb = message.verb;
    }
    if (message.statusDetail !== "") {
      obj.statusDetail = message.statusDetail;
    }
    if (message.cancelRequested !== false) {
      obj.cancelRequested = message.cancelRequested;
    }
    if (message.apiVersion !== "") {
      obj.apiVersion = message.apiVersion;
    }
    if (message.requestResource !== undefined) {
      obj.requestResource = Any.toJSON(message.requestResource);
    }
    if (message.stages?.length) {
      obj.stages = message.stages.map((e) => Stage.toJSON(e));
    }
    if (message.buildName !== "") {
      obj.buildName = message.buildName;
    }
    if (message.operationType !== 0) {
      obj.operationType = operationTypeToJSON(message.operationType);
    }
    return obj;
  },

  create(base?: DeepPartial<OperationMetadata>): OperationMetadata {
    return OperationMetadata.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<OperationMetadata>): OperationMetadata {
    const message = createBaseOperationMetadata();
    message.createTime = object.createTime ?? undefined;
    message.endTime = object.endTime ?? undefined;
    message.target = object.target ?? "";
    message.verb = object.verb ?? "";
    message.statusDetail = object.statusDetail ?? "";
    message.cancelRequested = object.cancelRequested ?? false;
    message.apiVersion = object.apiVersion ?? "";
    message.requestResource = (object.requestResource !== undefined && object.requestResource !== null)
      ? Any.fromPartial(object.requestResource)
      : undefined;
    message.stages = object.stages?.map((e) => Stage.fromPartial(e)) || [];
    message.buildName = object.buildName ?? "";
    message.operationType = object.operationType ?? 0;
    return message;
  },
};

function createBaseLocationMetadata(): LocationMetadata {
  return { environments: [] };
}

export const LocationMetadata: MessageFns<LocationMetadata> = {
  encode(message: LocationMetadata, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    writer.uint32(10).fork();
    for (const v of message.environments) {
      writer.int32(v);
    }
    writer.join();
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): LocationMetadata {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseLocationMetadata();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag === 8) {
            message.environments.push(reader.int32() as any);

            continue;
          }

          if (tag === 10) {
            const end2 = reader.uint32() + reader.pos;
            while (reader.pos < end2) {
              message.environments.push(reader.int32() as any);
            }

            continue;
          }

          break;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): LocationMetadata {
    return {
      environments: globalThis.Array.isArray(object?.environments)
        ? object.environments.map((e: any) => environmentFromJSON(e))
        : [],
    };
  },

  toJSON(message: LocationMetadata): unknown {
    const obj: any = {};
    if (message.environments?.length) {
      obj.environments = message.environments.map((e) => environmentToJSON(e));
    }
    return obj;
  },

  create(base?: DeepPartial<LocationMetadata>): LocationMetadata {
    return LocationMetadata.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<LocationMetadata>): LocationMetadata {
    const message = createBaseLocationMetadata();
    message.environments = object.environments?.map((e) => e) || [];
    return message;
  },
};

function createBaseStage(): Stage {
  return { name: 0, message: "", state: 0, resource: "", resourceUri: "", stateMessages: [] };
}

export const Stage: MessageFns<Stage> = {
  encode(message: Stage, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== 0) {
      writer.uint32(8).int32(message.name);
    }
    if (message.message !== "") {
      writer.uint32(18).string(message.message);
    }
    if (message.state !== 0) {
      writer.uint32(24).int32(message.state);
    }
    if (message.resource !== "") {
      writer.uint32(34).string(message.resource);
    }
    if (message.resourceUri !== "") {
      writer.uint32(42).string(message.resourceUri);
    }
    for (const v of message.stateMessages) {
      StateMessage.encode(v!, writer.uint32(50).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Stage {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseStage();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 8) {
            break;
          }

          message.name = reader.int32() as any;
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.message = reader.string();
          continue;
        case 3:
          if (tag !== 24) {
            break;
          }

          message.state = reader.int32() as any;
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.resource = reader.string();
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.resourceUri = reader.string();
          continue;
        case 6:
          if (tag !== 50) {
            break;
          }

          message.stateMessages.push(StateMessage.decode(reader, reader.uint32()));
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Stage {
    return {
      name: isSet(object.name) ? stage_NameFromJSON(object.name) : 0,
      message: isSet(object.message) ? globalThis.String(object.message) : "",
      state: isSet(object.state) ? stage_StateFromJSON(object.state) : 0,
      resource: isSet(object.resource) ? globalThis.String(object.resource) : "",
      resourceUri: isSet(object.resourceUri) ? globalThis.String(object.resourceUri) : "",
      stateMessages: globalThis.Array.isArray(object?.stateMessages)
        ? object.stateMessages.map((e: any) => StateMessage.fromJSON(e))
        : [],
    };
  },

  toJSON(message: Stage): unknown {
    const obj: any = {};
    if (message.name !== 0) {
      obj.name = stage_NameToJSON(message.name);
    }
    if (message.message !== "") {
      obj.message = message.message;
    }
    if (message.state !== 0) {
      obj.state = stage_StateToJSON(message.state);
    }
    if (message.resource !== "") {
      obj.resource = message.resource;
    }
    if (message.resourceUri !== "") {
      obj.resourceUri = message.resourceUri;
    }
    if (message.stateMessages?.length) {
      obj.stateMessages = message.stateMessages.map((e) => StateMessage.toJSON(e));
    }
    return obj;
  },

  create(base?: DeepPartial<Stage>): Stage {
    return Stage.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<Stage>): Stage {
    const message = createBaseStage();
    message.name = object.name ?? 0;
    message.message = object.message ?? "";
    message.state = object.state ?? 0;
    message.resource = object.resource ?? "";
    message.resourceUri = object.resourceUri ?? "";
    message.stateMessages = object.stateMessages?.map((e) => StateMessage.fromPartial(e)) || [];
    return message;
  },
};

/**
 * Google Cloud Functions is used to deploy functions that are executed by
 * Google in response to various events. Data connected with that event is
 * passed to a function as the input data.
 *
 * A **function** is a resource which describes a function that should be
 * executed and how it is triggered.
 */
export type FunctionServiceDefinition = typeof FunctionServiceDefinition;
export const FunctionServiceDefinition = {
  name: "FunctionService",
  fullName: "google.cloud.functions.v2alpha.FunctionService",
  methods: {
    /** Returns a function with the given name from the requested project. */
    getFunction: {
      name: "GetFunction",
      requestType: GetFunctionRequest,
      requestStream: false,
      responseType: Function,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [Buffer.from([4, 110, 97, 109, 101])],
          578365826: [
            Buffer.from([
              52,
              18,
              50,
              47,
              118,
              50,
              97,
              108,
              112,
              104,
              97,
              47,
              123,
              110,
              97,
              109,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              102,
              117,
              110,
              99,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              125,
            ]),
          ],
        },
      },
    },
    /** Returns a list of functions that belong to the requested project. */
    listFunctions: {
      name: "ListFunctions",
      requestType: ListFunctionsRequest,
      requestStream: false,
      responseType: ListFunctionsResponse,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [Buffer.from([6, 112, 97, 114, 101, 110, 116])],
          578365826: [
            Buffer.from([
              52,
              18,
              50,
              47,
              118,
              50,
              97,
              108,
              112,
              104,
              97,
              47,
              123,
              112,
              97,
              114,
              101,
              110,
              116,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              125,
              47,
              102,
              117,
              110,
              99,
              116,
              105,
              111,
              110,
              115,
            ]),
          ],
        },
      },
    },
    /**
     * Creates a new function. If a function with the given name already exists in
     * the specified project, the long running operation will return
     * `ALREADY_EXISTS` error.
     */
    createFunction: {
      name: "CreateFunction",
      requestType: CreateFunctionRequest,
      requestStream: false,
      responseType: Operation,
      responseStream: false,
      options: {
        _unknownFields: {
          8394: [
            Buffer.from([
              91,
              10,
              39,
              103,
              111,
              111,
              103,
              108,
              101,
              46,
              99,
              108,
              111,
              117,
              100,
              46,
              102,
              117,
              110,
              99,
              116,
              105,
              111,
              110,
              115,
              46,
              118,
              50,
              97,
              108,
              112,
              104,
              97,
              46,
              70,
              117,
              110,
              99,
              116,
              105,
              111,
              110,
              18,
              48,
              103,
              111,
              111,
              103,
              108,
              101,
              46,
              99,
              108,
              111,
              117,
              100,
              46,
              102,
              117,
              110,
              99,
              116,
              105,
              111,
              110,
              115,
              46,
              118,
              50,
              97,
              108,
              112,
              104,
              97,
              46,
              79,
              112,
              101,
              114,
              97,
              116,
              105,
              111,
              110,
              77,
              101,
              116,
              97,
              100,
              97,
              116,
              97,
            ]),
          ],
          8410: [
            Buffer.from([
              27,
              112,
              97,
              114,
              101,
              110,
              116,
              44,
              102,
              117,
              110,
              99,
              116,
              105,
              111,
              110,
              44,
              102,
              117,
              110,
              99,
              116,
              105,
              111,
              110,
              95,
              105,
              100,
            ]),
          ],
          578365826: [
            Buffer.from([
              62,
              58,
              8,
              102,
              117,
              110,
              99,
              116,
              105,
              111,
              110,
              34,
              50,
              47,
              118,
              50,
              97,
              108,
              112,
              104,
              97,
              47,
              123,
              112,
              97,
              114,
              101,
              110,
              116,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              125,
              47,
              102,
              117,
              110,
              99,
              116,
              105,
              111,
              110,
              115,
            ]),
          ],
        },
      },
    },
    /** Updates existing function. */
    updateFunction: {
      name: "UpdateFunction",
      requestType: UpdateFunctionRequest,
      requestStream: false,
      responseType: Operation,
      responseStream: false,
      options: {
        _unknownFields: {
          8394: [
            Buffer.from([
              91,
              10,
              39,
              103,
              111,
              111,
              103,
              108,
              101,
              46,
              99,
              108,
              111,
              117,
              100,
              46,
              102,
              117,
              110,
              99,
              116,
              105,
              111,
              110,
              115,
              46,
              118,
              50,
              97,
              108,
              112,
              104,
              97,
              46,
              70,
              117,
              110,
              99,
              116,
              105,
              111,
              110,
              18,
              48,
              103,
              111,
              111,
              103,
              108,
              101,
              46,
              99,
              108,
              111,
              117,
              100,
              46,
              102,
              117,
              110,
              99,
              116,
              105,
              111,
              110,
              115,
              46,
              118,
              50,
              97,
              108,
              112,
              104,
              97,
              46,
              79,
              112,
              101,
              114,
              97,
              116,
              105,
              111,
              110,
              77,
              101,
              116,
              97,
              100,
              97,
              116,
              97,
            ]),
          ],
          8410: [
            Buffer.from([
              20,
              102,
              117,
              110,
              99,
              116,
              105,
              111,
              110,
              44,
              117,
              112,
              100,
              97,
              116,
              101,
              95,
              109,
              97,
              115,
              107,
            ]),
          ],
          578365826: [
            Buffer.from([
              71,
              58,
              8,
              102,
              117,
              110,
              99,
              116,
              105,
              111,
              110,
              50,
              59,
              47,
              118,
              50,
              97,
              108,
              112,
              104,
              97,
              47,
              123,
              102,
              117,
              110,
              99,
              116,
              105,
              111,
              110,
              46,
              110,
              97,
              109,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              102,
              117,
              110,
              99,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              125,
            ]),
          ],
        },
      },
    },
    /**
     * Deletes a function with the given name from the specified project. If the
     * given function is used by some trigger, the trigger will be updated to
     * remove this function.
     */
    deleteFunction: {
      name: "DeleteFunction",
      requestType: DeleteFunctionRequest,
      requestStream: false,
      responseType: Operation,
      responseStream: false,
      options: {
        _unknownFields: {
          8394: [
            Buffer.from([
              73,
              10,
              21,
              103,
              111,
              111,
              103,
              108,
              101,
              46,
              112,
              114,
              111,
              116,
              111,
              98,
              117,
              102,
              46,
              69,
              109,
              112,
              116,
              121,
              18,
              48,
              103,
              111,
              111,
              103,
              108,
              101,
              46,
              99,
              108,
              111,
              117,
              100,
              46,
              102,
              117,
              110,
              99,
              116,
              105,
              111,
              110,
              115,
              46,
              118,
              50,
              97,
              108,
              112,
              104,
              97,
              46,
              79,
              112,
              101,
              114,
              97,
              116,
              105,
              111,
              110,
              77,
              101,
              116,
              97,
              100,
              97,
              116,
              97,
            ]),
          ],
          8410: [Buffer.from([4, 110, 97, 109, 101])],
          578365826: [
            Buffer.from([
              52,
              42,
              50,
              47,
              118,
              50,
              97,
              108,
              112,
              104,
              97,
              47,
              123,
              110,
              97,
              109,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              102,
              117,
              110,
              99,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              125,
            ]),
          ],
        },
      },
    },
    /**
     * Returns a signed URL for uploading a function source code.
     * For more information about the signed URL usage see:
     * https://cloud.google.com/storage/docs/access-control/signed-urls.
     * Once the function source code upload is complete, the used signed
     * URL should be provided in CreateFunction or UpdateFunction request
     * as a reference to the function source code.
     *
     * When uploading source code to the generated signed URL, please follow
     * these restrictions:
     *
     * * Source file type should be a zip file.
     * * No credentials should be attached - the signed URLs provide access to the
     *   target bucket using internal service identity; if credentials were
     *   attached, the identity from the credentials would be used, but that
     *   identity does not have permissions to upload files to the URL.
     *
     * When making a HTTP PUT request, specify this header:
     *
     * * `content-type: application/zip`
     *
     * Do not specify this header:
     *
     * * `Authorization: Bearer YOUR_TOKEN`
     */
    generateUploadUrl: {
      name: "GenerateUploadUrl",
      requestType: GenerateUploadUrlRequest,
      requestStream: false,
      responseType: GenerateUploadUrlResponse,
      responseStream: false,
      options: {
        _unknownFields: {
          578365826: [
            Buffer.from([
              73,
              58,
              1,
              42,
              34,
              68,
              47,
              118,
              50,
              97,
              108,
              112,
              104,
              97,
              47,
              123,
              112,
              97,
              114,
              101,
              110,
              116,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              125,
              47,
              102,
              117,
              110,
              99,
              116,
              105,
              111,
              110,
              115,
              58,
              103,
              101,
              110,
              101,
              114,
              97,
              116,
              101,
              85,
              112,
              108,
              111,
              97,
              100,
              85,
              114,
              108,
            ]),
          ],
        },
      },
    },
    /**
     * Returns a signed URL for downloading deployed function source code.
     * The URL is only valid for a limited period and should be used within
     * 30 minutes of generation.
     * For more information about the signed URL usage see:
     * https://cloud.google.com/storage/docs/access-control/signed-urls
     */
    generateDownloadUrl: {
      name: "GenerateDownloadUrl",
      requestType: GenerateDownloadUrlRequest,
      requestStream: false,
      responseType: GenerateDownloadUrlResponse,
      responseStream: false,
      options: {
        _unknownFields: {
          578365826: [
            Buffer.from([
              75,
              58,
              1,
              42,
              34,
              70,
              47,
              118,
              50,
              97,
              108,
              112,
              104,
              97,
              47,
              123,
              110,
              97,
              109,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              102,
              117,
              110,
              99,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              125,
              58,
              103,
              101,
              110,
              101,
              114,
              97,
              116,
              101,
              68,
              111,
              119,
              110,
              108,
              111,
              97,
              100,
              85,
              114,
              108,
            ]),
          ],
        },
      },
    },
    /** Returns a list of runtimes that are supported for the requested project. */
    listRuntimes: {
      name: "ListRuntimes",
      requestType: ListRuntimesRequest,
      requestStream: false,
      responseType: ListRuntimesResponse,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [Buffer.from([6, 112, 97, 114, 101, 110, 116])],
          578365826: [
            Buffer.from([
              51,
              18,
              49,
              47,
              118,
              50,
              97,
              108,
              112,
              104,
              97,
              47,
              123,
              112,
              97,
              114,
              101,
              110,
              116,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              125,
              47,
              114,
              117,
              110,
              116,
              105,
              109,
              101,
              115,
            ]),
          ],
        },
      },
    },
  },
} as const;

export interface FunctionServiceImplementation<CallContextExt = {}> {
  /** Returns a function with the given name from the requested project. */
  getFunction(request: GetFunctionRequest, context: CallContext & CallContextExt): Promise<DeepPartial<Function>>;
  /** Returns a list of functions that belong to the requested project. */
  listFunctions(
    request: ListFunctionsRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<ListFunctionsResponse>>;
  /**
   * Creates a new function. If a function with the given name already exists in
   * the specified project, the long running operation will return
   * `ALREADY_EXISTS` error.
   */
  createFunction(
    request: CreateFunctionRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<Operation>>;
  /** Updates existing function. */
  updateFunction(
    request: UpdateFunctionRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<Operation>>;
  /**
   * Deletes a function with the given name from the specified project. If the
   * given function is used by some trigger, the trigger will be updated to
   * remove this function.
   */
  deleteFunction(
    request: DeleteFunctionRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<Operation>>;
  /**
   * Returns a signed URL for uploading a function source code.
   * For more information about the signed URL usage see:
   * https://cloud.google.com/storage/docs/access-control/signed-urls.
   * Once the function source code upload is complete, the used signed
   * URL should be provided in CreateFunction or UpdateFunction request
   * as a reference to the function source code.
   *
   * When uploading source code to the generated signed URL, please follow
   * these restrictions:
   *
   * * Source file type should be a zip file.
   * * No credentials should be attached - the signed URLs provide access to the
   *   target bucket using internal service identity; if credentials were
   *   attached, the identity from the credentials would be used, but that
   *   identity does not have permissions to upload files to the URL.
   *
   * When making a HTTP PUT request, specify this header:
   *
   * * `content-type: application/zip`
   *
   * Do not specify this header:
   *
   * * `Authorization: Bearer YOUR_TOKEN`
   */
  generateUploadUrl(
    request: GenerateUploadUrlRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<GenerateUploadUrlResponse>>;
  /**
   * Returns a signed URL for downloading deployed function source code.
   * The URL is only valid for a limited period and should be used within
   * 30 minutes of generation.
   * For more information about the signed URL usage see:
   * https://cloud.google.com/storage/docs/access-control/signed-urls
   */
  generateDownloadUrl(
    request: GenerateDownloadUrlRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<GenerateDownloadUrlResponse>>;
  /** Returns a list of runtimes that are supported for the requested project. */
  listRuntimes(
    request: ListRuntimesRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<ListRuntimesResponse>>;
}

export interface FunctionServiceClient<CallOptionsExt = {}> {
  /** Returns a function with the given name from the requested project. */
  getFunction(request: DeepPartial<GetFunctionRequest>, options?: CallOptions & CallOptionsExt): Promise<Function>;
  /** Returns a list of functions that belong to the requested project. */
  listFunctions(
    request: DeepPartial<ListFunctionsRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<ListFunctionsResponse>;
  /**
   * Creates a new function. If a function with the given name already exists in
   * the specified project, the long running operation will return
   * `ALREADY_EXISTS` error.
   */
  createFunction(
    request: DeepPartial<CreateFunctionRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<Operation>;
  /** Updates existing function. */
  updateFunction(
    request: DeepPartial<UpdateFunctionRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<Operation>;
  /**
   * Deletes a function with the given name from the specified project. If the
   * given function is used by some trigger, the trigger will be updated to
   * remove this function.
   */
  deleteFunction(
    request: DeepPartial<DeleteFunctionRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<Operation>;
  /**
   * Returns a signed URL for uploading a function source code.
   * For more information about the signed URL usage see:
   * https://cloud.google.com/storage/docs/access-control/signed-urls.
   * Once the function source code upload is complete, the used signed
   * URL should be provided in CreateFunction or UpdateFunction request
   * as a reference to the function source code.
   *
   * When uploading source code to the generated signed URL, please follow
   * these restrictions:
   *
   * * Source file type should be a zip file.
   * * No credentials should be attached - the signed URLs provide access to the
   *   target bucket using internal service identity; if credentials were
   *   attached, the identity from the credentials would be used, but that
   *   identity does not have permissions to upload files to the URL.
   *
   * When making a HTTP PUT request, specify this header:
   *
   * * `content-type: application/zip`
   *
   * Do not specify this header:
   *
   * * `Authorization: Bearer YOUR_TOKEN`
   */
  generateUploadUrl(
    request: DeepPartial<GenerateUploadUrlRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<GenerateUploadUrlResponse>;
  /**
   * Returns a signed URL for downloading deployed function source code.
   * The URL is only valid for a limited period and should be used within
   * 30 minutes of generation.
   * For more information about the signed URL usage see:
   * https://cloud.google.com/storage/docs/access-control/signed-urls
   */
  generateDownloadUrl(
    request: DeepPartial<GenerateDownloadUrlRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<GenerateDownloadUrlResponse>;
  /** Returns a list of runtimes that are supported for the requested project. */
  listRuntimes(
    request: DeepPartial<ListRuntimesRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<ListRuntimesResponse>;
}

type Builtin = Date | Function | Uint8Array | string | number | boolean | undefined;

export type DeepPartial<T> = T extends Builtin ? T
  : T extends Long ? string | number | Long : T extends globalThis.Array<infer U> ? globalThis.Array<DeepPartial<U>>
  : T extends ReadonlyArray<infer U> ? ReadonlyArray<DeepPartial<U>>
  : T extends {} ? { [K in keyof T]?: DeepPartial<T[K]> }
  : Partial<T>;

function toTimestamp(date: Date): Timestamp {
  const seconds = numberToLong(Math.trunc(date.getTime() / 1_000));
  const nanos = (date.getTime() % 1_000) * 1_000_000;
  return { seconds, nanos };
}

function fromTimestamp(t: Timestamp): Date {
  let millis = (t.seconds.toNumber() || 0) * 1_000;
  millis += (t.nanos || 0) / 1_000_000;
  return new globalThis.Date(millis);
}

function fromJsonTimestamp(o: any): Date {
  if (o instanceof globalThis.Date) {
    return o;
  } else if (typeof o === "string") {
    return new globalThis.Date(o);
  } else {
    return fromTimestamp(Timestamp.fromJSON(o));
  }
}

function numberToLong(number: number) {
  return Long.fromNumber(number);
}

function isObject(value: any): boolean {
  return typeof value === "object" && value !== null;
}

function isSet(value: any): boolean {
  return value !== null && value !== undefined;
}

export interface MessageFns<T> {
  encode(message: T, writer?: BinaryWriter): BinaryWriter;
  decode(input: BinaryReader | Uint8Array, length?: number): T;
  fromJSON(object: any): T;
  toJSON(message: T): unknown;
  create(base?: DeepPartial<T>): T;
  fromPartial(object: DeepPartial<T>): T;
}
