// Code generated by protoc-gen-ts_proto. DO NOT EDIT.
// versions:
//   protoc-gen-ts_proto  v2.2.0
//   protoc               unknown
// source: google/cloud/functions/v1/functions.proto

/* eslint-disable */
import { BinaryReader, BinaryWriter } from "@bufbuild/protobuf/wire";
import Long from "long";
import { type CallContext, type CallOptions } from "nice-grpc-common";
import {
  GetIamPolicyRequest,
  SetIamPolicyRequest,
  TestIamPermissionsRequest,
  TestIamPermissionsResponse,
} from "../../../iam/v1/iam_policy.js";
import { Policy } from "../../../iam/v1/policy.js";
import { Operation } from "../../../longrunning/operations.js";
import { Duration } from "../../../protobuf/duration.js";
import { FieldMask } from "../../../protobuf/field_mask.js";
import { Timestamp } from "../../../protobuf/timestamp.js";

export const protobufPackage = "google.cloud.functions.v1";

/** Describes the current stage of a deployment. */
export enum CloudFunctionStatus {
  /** CLOUD_FUNCTION_STATUS_UNSPECIFIED - Not specified. Invalid state. */
  CLOUD_FUNCTION_STATUS_UNSPECIFIED = 0,
  /** ACTIVE - Function has been successfully deployed and is serving. */
  ACTIVE = 1,
  /** OFFLINE - Function deployment failed and the function isnâ€™t serving. */
  OFFLINE = 2,
  /** DEPLOY_IN_PROGRESS - Function is being created or updated. */
  DEPLOY_IN_PROGRESS = 3,
  /** DELETE_IN_PROGRESS - Function is being deleted. */
  DELETE_IN_PROGRESS = 4,
  /**
   * UNKNOWN - Function deployment failed and the function serving state is undefined.
   * The function should be updated or deleted to move it out of this state.
   */
  UNKNOWN = 5,
  UNRECOGNIZED = -1,
}

export function cloudFunctionStatusFromJSON(object: any): CloudFunctionStatus {
  switch (object) {
    case 0:
    case "CLOUD_FUNCTION_STATUS_UNSPECIFIED":
      return CloudFunctionStatus.CLOUD_FUNCTION_STATUS_UNSPECIFIED;
    case 1:
    case "ACTIVE":
      return CloudFunctionStatus.ACTIVE;
    case 2:
    case "OFFLINE":
      return CloudFunctionStatus.OFFLINE;
    case 3:
    case "DEPLOY_IN_PROGRESS":
      return CloudFunctionStatus.DEPLOY_IN_PROGRESS;
    case 4:
    case "DELETE_IN_PROGRESS":
      return CloudFunctionStatus.DELETE_IN_PROGRESS;
    case 5:
    case "UNKNOWN":
      return CloudFunctionStatus.UNKNOWN;
    case -1:
    case "UNRECOGNIZED":
    default:
      return CloudFunctionStatus.UNRECOGNIZED;
  }
}

export function cloudFunctionStatusToJSON(object: CloudFunctionStatus): string {
  switch (object) {
    case CloudFunctionStatus.CLOUD_FUNCTION_STATUS_UNSPECIFIED:
      return "CLOUD_FUNCTION_STATUS_UNSPECIFIED";
    case CloudFunctionStatus.ACTIVE:
      return "ACTIVE";
    case CloudFunctionStatus.OFFLINE:
      return "OFFLINE";
    case CloudFunctionStatus.DEPLOY_IN_PROGRESS:
      return "DEPLOY_IN_PROGRESS";
    case CloudFunctionStatus.DELETE_IN_PROGRESS:
      return "DELETE_IN_PROGRESS";
    case CloudFunctionStatus.UNKNOWN:
      return "UNKNOWN";
    case CloudFunctionStatus.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/**
 * Describes a Cloud Function that contains user computation executed in
 * response to an event. It encapsulate function and triggers configurations.
 */
export interface CloudFunction {
  /**
   * A user-defined name of the function. Function names must be unique
   * globally and match pattern `projects/* /locations/* /functions/*`
   */
  name: string;
  /** User-provided description of a function. */
  description: string;
  /**
   * The Google Cloud Storage URL, starting with `gs://`, pointing to the zip
   * archive which contains the function.
   */
  sourceArchiveUrl?:
    | string
    | undefined;
  /**
   * *Beta Feature**
   *
   * The source repository where a function is hosted.
   */
  sourceRepository?:
    | SourceRepository
    | undefined;
  /**
   * The Google Cloud Storage signed URL used for source uploading, generated
   * by calling [google.cloud.functions.v1.GenerateUploadUrl].
   *
   * The signature is validated on write methods (Create, Update)
   * The signature is stripped from the Function object on read methods (Get,
   * List)
   */
  sourceUploadUrl?:
    | string
    | undefined;
  /** An HTTPS endpoint type of source that can be triggered via URL. */
  httpsTrigger?:
    | HttpsTrigger
    | undefined;
  /** A source that fires events in response to a condition in another service. */
  eventTrigger?:
    | EventTrigger
    | undefined;
  /** Output only. Status of the function deployment. */
  status: CloudFunctionStatus;
  /**
   * The name of the function (as defined in source code) that will be
   * executed. Defaults to the resource name suffix (ID of the function), if not
   * specified.
   */
  entryPoint: string;
  /**
   * The runtime in which to run the function. Required when deploying a new
   * function, optional when updating an existing function. For a complete
   * list of possible choices, see the
   * [`gcloud` command
   * reference](https://cloud.google.com/sdk/gcloud/reference/functions/deploy#--runtime).
   */
  runtime: string;
  /**
   * The function execution timeout. Execution is considered failed and
   * can be terminated if the function is not completed at the end of the
   * timeout period. Defaults to 60 seconds.
   */
  timeout:
    | Duration
    | undefined;
  /**
   * The amount of memory in MB available for a function.
   * Defaults to 256MB.
   */
  availableMemoryMb: number;
  /**
   * The email of the function's service account. If empty, defaults to
   * `{project_id}@appspot.gserviceaccount.com`.
   */
  serviceAccountEmail: string;
  /** Output only. The last update timestamp of a Cloud Function. */
  updateTime:
    | Date
    | undefined;
  /**
   * Output only. The version identifier of the Cloud Function. Each deployment
   * attempt results in a new version of a function being created.
   */
  versionId: Long;
  /** Labels associated with this Cloud Function. */
  labels: { [key: string]: string };
  /** Environment variables that shall be available during function execution. */
  environmentVariables: { [key: string]: string };
  /** Build environment variables that shall be available during build time. */
  buildEnvironmentVariables: { [key: string]: string };
  /**
   * Deprecated: use vpc_connector
   *
   * @deprecated
   */
  network: string;
  /**
   * The limit on the maximum number of function instances that may coexist at a
   * given time.
   *
   * In some cases, such as rapid traffic surges, Cloud Functions may, for a
   * short period of time, create more instances than the specified max
   * instances limit. If your function cannot tolerate this temporary behavior,
   * you may want to factor in a safety margin and set a lower max instances
   * value than your function can tolerate.
   *
   * See the [Max
   * Instances](https://cloud.google.com/functions/docs/max-instances) Guide for
   * more details.
   */
  maxInstances: number;
  /**
   * A lower bound for the number function instances that may coexist at a
   * given time.
   */
  minInstances: number;
  /**
   * The VPC Network Connector that this cloud function can connect to. It can
   * be either the fully-qualified URI, or the short name of the network
   * connector resource. The format of this field is
   * `projects/* /locations/* /connectors/*`
   *
   * This field is mutually exclusive with `network` field and will eventually
   * replace it.
   *
   * See [the VPC documentation](https://cloud.google.com/compute/docs/vpc) for
   * more information on connecting Cloud projects.
   */
  vpcConnector: string;
  /**
   * The egress settings for the connector, controlling what traffic is diverted
   * through it.
   */
  vpcConnectorEgressSettings: CloudFunction_VpcConnectorEgressSettings;
  /**
   * The ingress settings for the function, controlling what traffic can reach
   * it.
   */
  ingressSettings: CloudFunction_IngressSettings;
  /**
   * Resource name of a KMS crypto key (managed by the user) used to
   * encrypt/decrypt function resources.
   *
   * It must match the pattern
   * `projects/{project}/locations/{location}/keyRings/{key_ring}/cryptoKeys/{crypto_key}`.
   *
   * If specified, you must also provide an artifact registry repository using
   * the `docker_repository` field that was created with the same KMS crypto
   * key.
   *
   * The following service accounts need to be granted the role 'Cloud KMS
   * CryptoKey Encrypter/Decrypter (roles/cloudkms.cryptoKeyEncrypterDecrypter)'
   * on the Key/KeyRing/Project/Organization (least access preferred).
   *
   * 1. Google Cloud Functions service account
   *    (service-{project_number}@gcf-admin-robot.iam.gserviceaccount.com) -
   *    Required to protect the function's image.
   * 2. Google Storage service account
   *    (service-{project_number}@gs-project-accounts.iam.gserviceaccount.com) -
   *    Required to protect the function's source code.
   *    If this service account does not exist, deploying a function without a
   *    KMS key or retrieving the service agent name provisions it. For more
   *    information, see
   *    https://cloud.google.com/storage/docs/projects#service-agents and
   *    https://cloud.google.com/storage/docs/getting-service-agent#gsutil.
   *
   * Google Cloud Functions delegates access to service agents to protect
   * function resources in internal projects that are not accessible by the
   * end user.
   */
  kmsKeyName: string;
  /**
   * Name of the Cloud Build Custom Worker Pool that should be used to build the
   * function. The format of this field is
   * `projects/{project}/locations/{region}/workerPools/{workerPool}` where
   * `{project}` and `{region}` are the project id and region respectively where
   * the worker pool is defined and `{workerPool}` is the short name of the
   * worker pool.
   *
   * If the project id is not the same as the function, then the Cloud
   * Functions Service Agent
   * (`service-<project_number>@gcf-admin-robot.iam.gserviceaccount.com`) must
   * be granted the role Cloud Build Custom Workers Builder
   * (`roles/cloudbuild.customworkers.builder`) in the project.
   */
  buildWorkerPool: string;
  /**
   * Output only. The Cloud Build ID of the latest successful deployment of the
   * function.
   */
  buildId: string;
  /**
   * Output only. The Cloud Build Name of the function deployment.
   * `projects/<project-number>/locations/<region>/builds/<build-id>`.
   */
  buildName: string;
  /** Secret environment variables configuration. */
  secretEnvironmentVariables: SecretEnvVar[];
  /** Secret volumes configuration. */
  secretVolumes: SecretVolume[];
  /**
   * Input only. An identifier for Firebase function sources. Disclaimer: This
   * field is only supported for Firebase function deployments.
   */
  sourceToken: string;
  /**
   * User-managed repository created in Artifact Registry to which the
   * function's Docker image will be pushed after it is built by Cloud Build.
   * May optionally be encrypted with a customer-managed encryption key (CMEK).
   * If unspecified and `docker_registry` is not explicitly set to
   * `CONTAINER_REGISTRY`, GCF will create and use a default Artifact Registry
   * repository named 'gcf-artifacts' in the region.
   *
   * It must match the pattern
   * `projects/{project}/locations/{location}/repositories/{repository}`.
   *
   * Cross-project repositories are not supported.
   * Cross-location repositories are not supported.
   * Repository format must be 'DOCKER'.
   */
  dockerRepository: string;
  /**
   * Docker Registry to use for this deployment.
   *
   * If unspecified, it defaults to `ARTIFACT_REGISTRY`.
   * If `docker_repository` field is specified, this field should either be left
   * unspecified or set to `ARTIFACT_REGISTRY`.
   */
  dockerRegistry: CloudFunction_DockerRegistry;
  automaticUpdatePolicy?: CloudFunction_AutomaticUpdatePolicy | undefined;
  onDeployUpdatePolicy?:
    | CloudFunction_OnDeployUpdatePolicy
    | undefined;
  /**
   * A service account the user provides for use with Cloud Build. The format of
   * this field is
   * `projects/{projectId}/serviceAccounts/{serviceAccountEmail}`.
   */
  buildServiceAccount: string;
}

/**
 * Available egress settings.
 *
 * This controls what traffic is diverted through the VPC Access Connector
 * resource. By default PRIVATE_RANGES_ONLY will be used.
 */
export enum CloudFunction_VpcConnectorEgressSettings {
  /** VPC_CONNECTOR_EGRESS_SETTINGS_UNSPECIFIED - Unspecified. */
  VPC_CONNECTOR_EGRESS_SETTINGS_UNSPECIFIED = 0,
  /** PRIVATE_RANGES_ONLY - Use the VPC Access Connector only for private IP space from RFC1918. */
  PRIVATE_RANGES_ONLY = 1,
  /**
   * ALL_TRAFFIC - Force the use of VPC Access Connector for all egress traffic from the
   * function.
   */
  ALL_TRAFFIC = 2,
  UNRECOGNIZED = -1,
}

export function cloudFunction_VpcConnectorEgressSettingsFromJSON(
  object: any,
): CloudFunction_VpcConnectorEgressSettings {
  switch (object) {
    case 0:
    case "VPC_CONNECTOR_EGRESS_SETTINGS_UNSPECIFIED":
      return CloudFunction_VpcConnectorEgressSettings.VPC_CONNECTOR_EGRESS_SETTINGS_UNSPECIFIED;
    case 1:
    case "PRIVATE_RANGES_ONLY":
      return CloudFunction_VpcConnectorEgressSettings.PRIVATE_RANGES_ONLY;
    case 2:
    case "ALL_TRAFFIC":
      return CloudFunction_VpcConnectorEgressSettings.ALL_TRAFFIC;
    case -1:
    case "UNRECOGNIZED":
    default:
      return CloudFunction_VpcConnectorEgressSettings.UNRECOGNIZED;
  }
}

export function cloudFunction_VpcConnectorEgressSettingsToJSON(
  object: CloudFunction_VpcConnectorEgressSettings,
): string {
  switch (object) {
    case CloudFunction_VpcConnectorEgressSettings.VPC_CONNECTOR_EGRESS_SETTINGS_UNSPECIFIED:
      return "VPC_CONNECTOR_EGRESS_SETTINGS_UNSPECIFIED";
    case CloudFunction_VpcConnectorEgressSettings.PRIVATE_RANGES_ONLY:
      return "PRIVATE_RANGES_ONLY";
    case CloudFunction_VpcConnectorEgressSettings.ALL_TRAFFIC:
      return "ALL_TRAFFIC";
    case CloudFunction_VpcConnectorEgressSettings.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/**
 * Available ingress settings.
 *
 * This controls what traffic can reach the function.
 *
 * If unspecified, ALLOW_ALL will be used.
 */
export enum CloudFunction_IngressSettings {
  /** INGRESS_SETTINGS_UNSPECIFIED - Unspecified. */
  INGRESS_SETTINGS_UNSPECIFIED = 0,
  /** ALLOW_ALL - Allow HTTP traffic from public and private sources. */
  ALLOW_ALL = 1,
  /** ALLOW_INTERNAL_ONLY - Allow HTTP traffic from only private VPC sources. */
  ALLOW_INTERNAL_ONLY = 2,
  /** ALLOW_INTERNAL_AND_GCLB - Allow HTTP traffic from private VPC sources and through GCLB. */
  ALLOW_INTERNAL_AND_GCLB = 3,
  UNRECOGNIZED = -1,
}

export function cloudFunction_IngressSettingsFromJSON(object: any): CloudFunction_IngressSettings {
  switch (object) {
    case 0:
    case "INGRESS_SETTINGS_UNSPECIFIED":
      return CloudFunction_IngressSettings.INGRESS_SETTINGS_UNSPECIFIED;
    case 1:
    case "ALLOW_ALL":
      return CloudFunction_IngressSettings.ALLOW_ALL;
    case 2:
    case "ALLOW_INTERNAL_ONLY":
      return CloudFunction_IngressSettings.ALLOW_INTERNAL_ONLY;
    case 3:
    case "ALLOW_INTERNAL_AND_GCLB":
      return CloudFunction_IngressSettings.ALLOW_INTERNAL_AND_GCLB;
    case -1:
    case "UNRECOGNIZED":
    default:
      return CloudFunction_IngressSettings.UNRECOGNIZED;
  }
}

export function cloudFunction_IngressSettingsToJSON(object: CloudFunction_IngressSettings): string {
  switch (object) {
    case CloudFunction_IngressSettings.INGRESS_SETTINGS_UNSPECIFIED:
      return "INGRESS_SETTINGS_UNSPECIFIED";
    case CloudFunction_IngressSettings.ALLOW_ALL:
      return "ALLOW_ALL";
    case CloudFunction_IngressSettings.ALLOW_INTERNAL_ONLY:
      return "ALLOW_INTERNAL_ONLY";
    case CloudFunction_IngressSettings.ALLOW_INTERNAL_AND_GCLB:
      return "ALLOW_INTERNAL_AND_GCLB";
    case CloudFunction_IngressSettings.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/** Docker Registry to use for storing function Docker images. */
export enum CloudFunction_DockerRegistry {
  /** DOCKER_REGISTRY_UNSPECIFIED - Unspecified. */
  DOCKER_REGISTRY_UNSPECIFIED = 0,
  /**
   * CONTAINER_REGISTRY - Docker images will be stored in multi-regional Container Registry
   * repositories named `gcf`.
   */
  CONTAINER_REGISTRY = 1,
  /**
   * ARTIFACT_REGISTRY - Docker images will be stored in regional Artifact Registry repositories.
   * By default, GCF will create and use repositories named `gcf-artifacts`
   * in every region in which a function is deployed. But the repository to
   * use can also be specified by the user using the `docker_repository`
   * field.
   */
  ARTIFACT_REGISTRY = 2,
  UNRECOGNIZED = -1,
}

export function cloudFunction_DockerRegistryFromJSON(object: any): CloudFunction_DockerRegistry {
  switch (object) {
    case 0:
    case "DOCKER_REGISTRY_UNSPECIFIED":
      return CloudFunction_DockerRegistry.DOCKER_REGISTRY_UNSPECIFIED;
    case 1:
    case "CONTAINER_REGISTRY":
      return CloudFunction_DockerRegistry.CONTAINER_REGISTRY;
    case 2:
    case "ARTIFACT_REGISTRY":
      return CloudFunction_DockerRegistry.ARTIFACT_REGISTRY;
    case -1:
    case "UNRECOGNIZED":
    default:
      return CloudFunction_DockerRegistry.UNRECOGNIZED;
  }
}

export function cloudFunction_DockerRegistryToJSON(object: CloudFunction_DockerRegistry): string {
  switch (object) {
    case CloudFunction_DockerRegistry.DOCKER_REGISTRY_UNSPECIFIED:
      return "DOCKER_REGISTRY_UNSPECIFIED";
    case CloudFunction_DockerRegistry.CONTAINER_REGISTRY:
      return "CONTAINER_REGISTRY";
    case CloudFunction_DockerRegistry.ARTIFACT_REGISTRY:
      return "ARTIFACT_REGISTRY";
    case CloudFunction_DockerRegistry.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/**
 * Security patches are applied automatically to the runtime without requiring
 * the function to be redeployed.
 */
export interface CloudFunction_AutomaticUpdatePolicy {
}

/** Security patches are only applied when a function is redeployed. */
export interface CloudFunction_OnDeployUpdatePolicy {
  /**
   * Output only. Contains the runtime version which was used during latest
   * function deployment.
   */
  runtimeVersion: string;
}

export interface CloudFunction_LabelsEntry {
  key: string;
  value: string;
}

export interface CloudFunction_EnvironmentVariablesEntry {
  key: string;
  value: string;
}

export interface CloudFunction_BuildEnvironmentVariablesEntry {
  key: string;
  value: string;
}

/**
 * Describes SourceRepository, used to represent parameters related to
 * source repository where a function is hosted.
 */
export interface SourceRepository {
  /**
   * The URL pointing to the hosted repository where the function is defined.
   * There are supported Cloud Source Repository URLs in the following
   * formats:
   *
   * To refer to a specific commit:
   * `https://source.developers.google.com/projects/* /repos/* /revisions/* /paths/*`
   * To refer to a moveable alias (branch):
   * `https://source.developers.google.com/projects/* /repos/* /moveable-aliases/* /paths/*`
   * In particular, to refer to HEAD use `master` moveable alias.
   * To refer to a specific fixed alias (tag):
   * `https://source.developers.google.com/projects/* /repos/* /fixed-aliases/* /paths/*`
   *
   * You may omit `paths/*` if you want to use the main directory. The function
   * response may add an empty `/paths/` to the URL.
   */
  url: string;
  /**
   * Output only. The URL pointing to the hosted repository where the function
   * were defined at the time of deployment. It always points to a specific
   * commit in the format described above.
   */
  deployedUrl: string;
}

/** Describes HttpsTrigger, could be used to connect web hooks to function. */
export interface HttpsTrigger {
  /** Output only. The deployed url for the function. */
  url: string;
  /** The security level for the function. */
  securityLevel: HttpsTrigger_SecurityLevel;
}

/**
 * Available security level settings.
 *
 * This controls the methods to enforce security (HTTPS) on a URL.
 *
 * If unspecified, SECURE_OPTIONAL will be used.
 */
export enum HttpsTrigger_SecurityLevel {
  /** SECURITY_LEVEL_UNSPECIFIED - Unspecified. */
  SECURITY_LEVEL_UNSPECIFIED = 0,
  /**
   * SECURE_ALWAYS - Requests for a URL that match this handler that do not use HTTPS are
   * automatically redirected to the HTTPS URL with the same path. Query
   * parameters are reserved for the redirect.
   */
  SECURE_ALWAYS = 1,
  /**
   * SECURE_OPTIONAL - Both HTTP and HTTPS requests with URLs that match the handler succeed
   * without redirects. The application can examine the request to determine
   * which protocol was used and respond accordingly.
   */
  SECURE_OPTIONAL = 2,
  UNRECOGNIZED = -1,
}

export function httpsTrigger_SecurityLevelFromJSON(object: any): HttpsTrigger_SecurityLevel {
  switch (object) {
    case 0:
    case "SECURITY_LEVEL_UNSPECIFIED":
      return HttpsTrigger_SecurityLevel.SECURITY_LEVEL_UNSPECIFIED;
    case 1:
    case "SECURE_ALWAYS":
      return HttpsTrigger_SecurityLevel.SECURE_ALWAYS;
    case 2:
    case "SECURE_OPTIONAL":
      return HttpsTrigger_SecurityLevel.SECURE_OPTIONAL;
    case -1:
    case "UNRECOGNIZED":
    default:
      return HttpsTrigger_SecurityLevel.UNRECOGNIZED;
  }
}

export function httpsTrigger_SecurityLevelToJSON(object: HttpsTrigger_SecurityLevel): string {
  switch (object) {
    case HttpsTrigger_SecurityLevel.SECURITY_LEVEL_UNSPECIFIED:
      return "SECURITY_LEVEL_UNSPECIFIED";
    case HttpsTrigger_SecurityLevel.SECURE_ALWAYS:
      return "SECURE_ALWAYS";
    case HttpsTrigger_SecurityLevel.SECURE_OPTIONAL:
      return "SECURE_OPTIONAL";
    case HttpsTrigger_SecurityLevel.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/**
 * Describes EventTrigger, used to request events be sent from another
 * service.
 */
export interface EventTrigger {
  /**
   * Required. The type of event to observe. For example:
   * `providers/cloud.storage/eventTypes/object.change` and
   * `providers/cloud.pubsub/eventTypes/topic.publish`.
   *
   * Event types match pattern `providers/* /eventTypes/*.*`.
   * The pattern contains:
   *
   * 1. namespace: For example, `cloud.storage` and
   *    `google.firebase.analytics`.
   * 2. resource type: The type of resource on which event occurs. For
   *    example, the Google Cloud Storage API includes the type `object`.
   * 3. action: The action that generates the event. For example, action for
   *    a Google Cloud Storage Object is 'change'.
   * These parts are lower case.
   */
  eventType: string;
  /**
   * Required. The resource(s) from which to observe events, for example,
   * `projects/_/buckets/myBucket`.
   *
   * Not all syntactically correct values are accepted by all services. For
   * example:
   *
   * 1. The authorization model must support it. Google Cloud Functions
   *    only allows EventTriggers to be deployed that observe resources in the
   *    same project as the `CloudFunction`.
   * 2. The resource type must match the pattern expected for an
   *    `event_type`. For example, an `EventTrigger` that has an
   *    `event_type` of "google.pubsub.topic.publish" should have a resource
   *    that matches Google Cloud Pub/Sub topics.
   *
   * Additionally, some services may support short names when creating an
   * `EventTrigger`. These will always be returned in the normalized "long"
   * format.
   *
   * See each *service's* documentation for supported formats.
   */
  resource: string;
  /**
   * The hostname of the service that should be observed.
   *
   * If no string is provided, the default service implementing the API will
   * be used. For example, `storage.googleapis.com` is the default for all
   * event types in the `google.storage` namespace.
   */
  service: string;
  /** Specifies policy for failed executions. */
  failurePolicy: FailurePolicy | undefined;
}

/**
 * Describes the policy in case of function's execution failure.
 * If empty, then defaults to ignoring failures (i.e. not retrying them).
 */
export interface FailurePolicy {
  /** If specified, then the function will be retried in case of a failure. */
  retry?: FailurePolicy_Retry | undefined;
}

/**
 * Describes the retry policy in case of function's execution failure.
 * A function execution will be retried on any failure.
 * A failed execution will be retried up to 7 days with an exponential backoff
 * (capped at 10 seconds).
 * Retried execution is charged as any other execution.
 */
export interface FailurePolicy_Retry {
}

/**
 * Configuration for a secret environment variable. It has the information
 * necessary to fetch the secret value from secret manager and expose it as an
 * environment variable.
 */
export interface SecretEnvVar {
  /** Name of the environment variable. */
  key: string;
  /**
   * Project identifier (preferrably project number but can also be the project
   * ID) of the project that contains the secret. If not set, it will be
   * populated with the function's project assuming that the secret exists in
   * the same project as of the function.
   */
  projectId: string;
  /** Name of the secret in secret manager (not the full resource name). */
  secret: string;
  /**
   * Version of the secret (version number or the string 'latest'). It is
   * recommended to use a numeric version for secret environment variables as
   * any updates to the secret value is not reflected until new instances start.
   */
  version: string;
}

/**
 * Configuration for a secret volume. It has the information necessary to fetch
 * the secret value from secret manager and make it available as files mounted
 * at the requested paths within the application container. Secret value is not
 * a part of the configuration. Every filesystem read operation performs a
 * lookup in secret manager to retrieve the secret value.
 */
export interface SecretVolume {
  /**
   * The path within the container to mount the secret volume. For example,
   * setting the mount_path as `/etc/secrets` would mount the secret value files
   * under the `/etc/secrets` directory. This directory will also be completely
   * shadowed and unavailable to mount any other secrets.
   *
   * Recommended mount paths: /etc/secrets
   * Restricted mount paths: /cloudsql, /dev/log, /pod, /proc, /var/log
   */
  mountPath: string;
  /**
   * Project identifier (preferrably project number but can also be the project
   * ID) of the project that contains the secret. If not set, it will be
   * populated with the function's project assuming that the secret exists in
   * the same project as of the function.
   */
  projectId: string;
  /** Name of the secret in secret manager (not the full resource name). */
  secret: string;
  /**
   * List of secret versions to mount for this secret. If empty, the `latest`
   * version of the secret will be made available in a file named after the
   * secret under the mount point.
   */
  versions: SecretVolume_SecretVersion[];
}

/** Configuration for a single version. */
export interface SecretVolume_SecretVersion {
  /**
   * Version of the secret (version number or the string 'latest'). It is
   * preferable to use `latest` version with secret volumes as secret value
   * changes are reflected immediately.
   */
  version: string;
  /**
   * Relative path of the file under the mount path where the secret value for
   * this version will be fetched and made available. For example, setting the
   * mount_path as '/etc/secrets' and path as `/secret_foo` would mount the
   * secret value file at `/etc/secrets/secret_foo`.
   */
  path: string;
}

/** Request for the `CreateFunction` method. */
export interface CreateFunctionRequest {
  /**
   * Required. The project and location in which the function should be created,
   * specified in the format `projects/* /locations/*`
   */
  location: string;
  /** Required. Function to be created. */
  function: CloudFunction | undefined;
}

/** Request for the `UpdateFunction` method. */
export interface UpdateFunctionRequest {
  /** Required. New version of the function. */
  function:
    | CloudFunction
    | undefined;
  /** Required. The list of fields in `CloudFunction` that have to be updated. */
  updateMask: string[] | undefined;
}

/** Request for the `GetFunction` method. */
export interface GetFunctionRequest {
  /** Required. The name of the function which details should be obtained. */
  name: string;
  /**
   * Optional. The optional version of the function whose details should be
   * obtained. The version of a 1st Gen function is an integer that starts from
   * 1 and gets incremented on redeployments. Each deployment creates a config
   * version of the underlying function. GCF may keep historical configs for old
   * versions. This field can be specified to fetch the historical configs.
   * Leave it blank or set to 0 to get the latest version of the function.
   */
  versionId: Long;
}

/** Request for the `ListFunctions` method. */
export interface ListFunctionsRequest {
  /**
   * The project and location from which the function should be listed,
   * specified in the format `projects/* /locations/*`
   * If you want to list functions in all locations, use "-" in place of a
   * location. When listing functions in all locations, if one or more
   * location(s) are unreachable, the response will contain functions from all
   * reachable locations along with the names of any unreachable locations.
   */
  parent: string;
  /** Maximum number of functions to return per call. */
  pageSize: number;
  /**
   * The value returned by the last
   * `ListFunctionsResponse`; indicates that
   * this is a continuation of a prior `ListFunctions` call, and that the
   * system should return the next page of data.
   */
  pageToken: string;
}

/** Response for the `ListFunctions` method. */
export interface ListFunctionsResponse {
  /** The functions that match the request. */
  functions: CloudFunction[];
  /**
   * If not empty, indicates that there may be more functions that match
   * the request; this value should be passed in a new
   * [google.cloud.functions.v1.ListFunctionsRequest][google.cloud.functions.v1.ListFunctionsRequest]
   * to get more functions.
   */
  nextPageToken: string;
  /**
   * Locations that could not be reached. The response does not include any
   * functions from these locations.
   */
  unreachable: string[];
}

/** Request for the `DeleteFunction` method. */
export interface DeleteFunctionRequest {
  /** Required. The name of the function which should be deleted. */
  name: string;
}

/** Request for the `CallFunction` method. */
export interface CallFunctionRequest {
  /** Required. The name of the function to be called. */
  name: string;
  /** Required. Input to be passed to the function. */
  data: string;
}

/** Response of `CallFunction` method. */
export interface CallFunctionResponse {
  /** Execution id of function invocation. */
  executionId: string;
  /**
   * Result populated for successful execution of synchronous function. Will
   * not be populated if function does not return a result through context.
   */
  result: string;
  /**
   * Either system or user-function generated error. Set if execution
   * was not successful.
   */
  error: string;
}

/** Request of `GenerateSourceUploadUrl` method. */
export interface GenerateUploadUrlRequest {
  /**
   * The project and location in which the Google Cloud Storage signed URL
   * should be generated, specified in the format `projects/* /locations/*`.
   */
  parent: string;
  /**
   * Resource name of a KMS crypto key (managed by the user) used to
   * encrypt/decrypt function source code objects in intermediate Cloud Storage
   * buckets. When you generate an upload url and upload your source code, it
   * gets copied to an intermediate Cloud Storage bucket. The source code is
   * then copied to a versioned directory in the sources bucket in the consumer
   * project during the function deployment.
   *
   * It must match the pattern
   * `projects/{project}/locations/{location}/keyRings/{key_ring}/cryptoKeys/{crypto_key}`.
   *
   * The Google Cloud Functions service account
   * (service-{project_number}@gcf-admin-robot.iam.gserviceaccount.com) must be
   * granted the role 'Cloud KMS CryptoKey Encrypter/Decrypter
   * (roles/cloudkms.cryptoKeyEncrypterDecrypter)' on the
   * Key/KeyRing/Project/Organization (least access preferred). GCF will
   * delegate access to the Google Storage service account in the internal
   * project.
   */
  kmsKeyName: string;
}

/** Response of `GenerateSourceUploadUrl` method. */
export interface GenerateUploadUrlResponse {
  /**
   * The generated Google Cloud Storage signed URL that should be used for a
   * function source code upload. The uploaded file should be a zip archive
   * which contains a function.
   */
  uploadUrl: string;
}

/** Request of `GenerateDownloadUrl` method. */
export interface GenerateDownloadUrlRequest {
  /**
   * The name of function for which source code Google Cloud Storage signed
   * URL should be generated.
   */
  name: string;
  /**
   * The optional version of function. If not set, default, current version
   * is used.
   */
  versionId: Long;
}

/** Response of `GenerateDownloadUrl` method. */
export interface GenerateDownloadUrlResponse {
  /**
   * The generated Google Cloud Storage signed URL that should be used for
   * function source code download.
   */
  downloadUrl: string;
}

function createBaseCloudFunction(): CloudFunction {
  return {
    name: "",
    description: "",
    sourceArchiveUrl: undefined,
    sourceRepository: undefined,
    sourceUploadUrl: undefined,
    httpsTrigger: undefined,
    eventTrigger: undefined,
    status: 0,
    entryPoint: "",
    runtime: "",
    timeout: undefined,
    availableMemoryMb: 0,
    serviceAccountEmail: "",
    updateTime: undefined,
    versionId: Long.ZERO,
    labels: {},
    environmentVariables: {},
    buildEnvironmentVariables: {},
    network: "",
    maxInstances: 0,
    minInstances: 0,
    vpcConnector: "",
    vpcConnectorEgressSettings: 0,
    ingressSettings: 0,
    kmsKeyName: "",
    buildWorkerPool: "",
    buildId: "",
    buildName: "",
    secretEnvironmentVariables: [],
    secretVolumes: [],
    sourceToken: "",
    dockerRepository: "",
    dockerRegistry: 0,
    automaticUpdatePolicy: undefined,
    onDeployUpdatePolicy: undefined,
    buildServiceAccount: "",
  };
}

export const CloudFunction: MessageFns<CloudFunction> = {
  encode(message: CloudFunction, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    if (message.description !== "") {
      writer.uint32(18).string(message.description);
    }
    if (message.sourceArchiveUrl !== undefined) {
      writer.uint32(26).string(message.sourceArchiveUrl);
    }
    if (message.sourceRepository !== undefined) {
      SourceRepository.encode(message.sourceRepository, writer.uint32(34).fork()).join();
    }
    if (message.sourceUploadUrl !== undefined) {
      writer.uint32(130).string(message.sourceUploadUrl);
    }
    if (message.httpsTrigger !== undefined) {
      HttpsTrigger.encode(message.httpsTrigger, writer.uint32(42).fork()).join();
    }
    if (message.eventTrigger !== undefined) {
      EventTrigger.encode(message.eventTrigger, writer.uint32(50).fork()).join();
    }
    if (message.status !== 0) {
      writer.uint32(56).int32(message.status);
    }
    if (message.entryPoint !== "") {
      writer.uint32(66).string(message.entryPoint);
    }
    if (message.runtime !== "") {
      writer.uint32(154).string(message.runtime);
    }
    if (message.timeout !== undefined) {
      Duration.encode(message.timeout, writer.uint32(74).fork()).join();
    }
    if (message.availableMemoryMb !== 0) {
      writer.uint32(80).int32(message.availableMemoryMb);
    }
    if (message.serviceAccountEmail !== "") {
      writer.uint32(90).string(message.serviceAccountEmail);
    }
    if (message.updateTime !== undefined) {
      Timestamp.encode(toTimestamp(message.updateTime), writer.uint32(98).fork()).join();
    }
    if (!message.versionId.equals(Long.ZERO)) {
      writer.uint32(112).int64(message.versionId.toString());
    }
    Object.entries(message.labels).forEach(([key, value]) => {
      CloudFunction_LabelsEntry.encode({ key: key as any, value }, writer.uint32(122).fork()).join();
    });
    Object.entries(message.environmentVariables).forEach(([key, value]) => {
      CloudFunction_EnvironmentVariablesEntry.encode({ key: key as any, value }, writer.uint32(138).fork()).join();
    });
    Object.entries(message.buildEnvironmentVariables).forEach(([key, value]) => {
      CloudFunction_BuildEnvironmentVariablesEntry.encode({ key: key as any, value }, writer.uint32(226).fork()).join();
    });
    if (message.network !== "") {
      writer.uint32(146).string(message.network);
    }
    if (message.maxInstances !== 0) {
      writer.uint32(160).int32(message.maxInstances);
    }
    if (message.minInstances !== 0) {
      writer.uint32(256).int32(message.minInstances);
    }
    if (message.vpcConnector !== "") {
      writer.uint32(178).string(message.vpcConnector);
    }
    if (message.vpcConnectorEgressSettings !== 0) {
      writer.uint32(184).int32(message.vpcConnectorEgressSettings);
    }
    if (message.ingressSettings !== 0) {
      writer.uint32(192).int32(message.ingressSettings);
    }
    if (message.kmsKeyName !== "") {
      writer.uint32(202).string(message.kmsKeyName);
    }
    if (message.buildWorkerPool !== "") {
      writer.uint32(210).string(message.buildWorkerPool);
    }
    if (message.buildId !== "") {
      writer.uint32(218).string(message.buildId);
    }
    if (message.buildName !== "") {
      writer.uint32(266).string(message.buildName);
    }
    for (const v of message.secretEnvironmentVariables) {
      SecretEnvVar.encode(v!, writer.uint32(234).fork()).join();
    }
    for (const v of message.secretVolumes) {
      SecretVolume.encode(v!, writer.uint32(242).fork()).join();
    }
    if (message.sourceToken !== "") {
      writer.uint32(250).string(message.sourceToken);
    }
    if (message.dockerRepository !== "") {
      writer.uint32(274).string(message.dockerRepository);
    }
    if (message.dockerRegistry !== 0) {
      writer.uint32(280).int32(message.dockerRegistry);
    }
    if (message.automaticUpdatePolicy !== undefined) {
      CloudFunction_AutomaticUpdatePolicy.encode(message.automaticUpdatePolicy, writer.uint32(322).fork()).join();
    }
    if (message.onDeployUpdatePolicy !== undefined) {
      CloudFunction_OnDeployUpdatePolicy.encode(message.onDeployUpdatePolicy, writer.uint32(330).fork()).join();
    }
    if (message.buildServiceAccount !== "") {
      writer.uint32(346).string(message.buildServiceAccount);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): CloudFunction {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseCloudFunction();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.description = reader.string();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.sourceArchiveUrl = reader.string();
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.sourceRepository = SourceRepository.decode(reader, reader.uint32());
          continue;
        case 16:
          if (tag !== 130) {
            break;
          }

          message.sourceUploadUrl = reader.string();
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.httpsTrigger = HttpsTrigger.decode(reader, reader.uint32());
          continue;
        case 6:
          if (tag !== 50) {
            break;
          }

          message.eventTrigger = EventTrigger.decode(reader, reader.uint32());
          continue;
        case 7:
          if (tag !== 56) {
            break;
          }

          message.status = reader.int32() as any;
          continue;
        case 8:
          if (tag !== 66) {
            break;
          }

          message.entryPoint = reader.string();
          continue;
        case 19:
          if (tag !== 154) {
            break;
          }

          message.runtime = reader.string();
          continue;
        case 9:
          if (tag !== 74) {
            break;
          }

          message.timeout = Duration.decode(reader, reader.uint32());
          continue;
        case 10:
          if (tag !== 80) {
            break;
          }

          message.availableMemoryMb = reader.int32();
          continue;
        case 11:
          if (tag !== 90) {
            break;
          }

          message.serviceAccountEmail = reader.string();
          continue;
        case 12:
          if (tag !== 98) {
            break;
          }

          message.updateTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        case 14:
          if (tag !== 112) {
            break;
          }

          message.versionId = Long.fromString(reader.int64().toString());
          continue;
        case 15:
          if (tag !== 122) {
            break;
          }

          const entry15 = CloudFunction_LabelsEntry.decode(reader, reader.uint32());
          if (entry15.value !== undefined) {
            message.labels[entry15.key] = entry15.value;
          }
          continue;
        case 17:
          if (tag !== 138) {
            break;
          }

          const entry17 = CloudFunction_EnvironmentVariablesEntry.decode(reader, reader.uint32());
          if (entry17.value !== undefined) {
            message.environmentVariables[entry17.key] = entry17.value;
          }
          continue;
        case 28:
          if (tag !== 226) {
            break;
          }

          const entry28 = CloudFunction_BuildEnvironmentVariablesEntry.decode(reader, reader.uint32());
          if (entry28.value !== undefined) {
            message.buildEnvironmentVariables[entry28.key] = entry28.value;
          }
          continue;
        case 18:
          if (tag !== 146) {
            break;
          }

          message.network = reader.string();
          continue;
        case 20:
          if (tag !== 160) {
            break;
          }

          message.maxInstances = reader.int32();
          continue;
        case 32:
          if (tag !== 256) {
            break;
          }

          message.minInstances = reader.int32();
          continue;
        case 22:
          if (tag !== 178) {
            break;
          }

          message.vpcConnector = reader.string();
          continue;
        case 23:
          if (tag !== 184) {
            break;
          }

          message.vpcConnectorEgressSettings = reader.int32() as any;
          continue;
        case 24:
          if (tag !== 192) {
            break;
          }

          message.ingressSettings = reader.int32() as any;
          continue;
        case 25:
          if (tag !== 202) {
            break;
          }

          message.kmsKeyName = reader.string();
          continue;
        case 26:
          if (tag !== 210) {
            break;
          }

          message.buildWorkerPool = reader.string();
          continue;
        case 27:
          if (tag !== 218) {
            break;
          }

          message.buildId = reader.string();
          continue;
        case 33:
          if (tag !== 266) {
            break;
          }

          message.buildName = reader.string();
          continue;
        case 29:
          if (tag !== 234) {
            break;
          }

          message.secretEnvironmentVariables.push(SecretEnvVar.decode(reader, reader.uint32()));
          continue;
        case 30:
          if (tag !== 242) {
            break;
          }

          message.secretVolumes.push(SecretVolume.decode(reader, reader.uint32()));
          continue;
        case 31:
          if (tag !== 250) {
            break;
          }

          message.sourceToken = reader.string();
          continue;
        case 34:
          if (tag !== 274) {
            break;
          }

          message.dockerRepository = reader.string();
          continue;
        case 35:
          if (tag !== 280) {
            break;
          }

          message.dockerRegistry = reader.int32() as any;
          continue;
        case 40:
          if (tag !== 322) {
            break;
          }

          message.automaticUpdatePolicy = CloudFunction_AutomaticUpdatePolicy.decode(reader, reader.uint32());
          continue;
        case 41:
          if (tag !== 330) {
            break;
          }

          message.onDeployUpdatePolicy = CloudFunction_OnDeployUpdatePolicy.decode(reader, reader.uint32());
          continue;
        case 43:
          if (tag !== 346) {
            break;
          }

          message.buildServiceAccount = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): CloudFunction {
    return {
      name: isSet(object.name) ? globalThis.String(object.name) : "",
      description: isSet(object.description) ? globalThis.String(object.description) : "",
      sourceArchiveUrl: isSet(object.sourceArchiveUrl) ? globalThis.String(object.sourceArchiveUrl) : undefined,
      sourceRepository: isSet(object.sourceRepository) ? SourceRepository.fromJSON(object.sourceRepository) : undefined,
      sourceUploadUrl: isSet(object.sourceUploadUrl) ? globalThis.String(object.sourceUploadUrl) : undefined,
      httpsTrigger: isSet(object.httpsTrigger) ? HttpsTrigger.fromJSON(object.httpsTrigger) : undefined,
      eventTrigger: isSet(object.eventTrigger) ? EventTrigger.fromJSON(object.eventTrigger) : undefined,
      status: isSet(object.status) ? cloudFunctionStatusFromJSON(object.status) : 0,
      entryPoint: isSet(object.entryPoint) ? globalThis.String(object.entryPoint) : "",
      runtime: isSet(object.runtime) ? globalThis.String(object.runtime) : "",
      timeout: isSet(object.timeout) ? Duration.fromJSON(object.timeout) : undefined,
      availableMemoryMb: isSet(object.availableMemoryMb) ? globalThis.Number(object.availableMemoryMb) : 0,
      serviceAccountEmail: isSet(object.serviceAccountEmail) ? globalThis.String(object.serviceAccountEmail) : "",
      updateTime: isSet(object.updateTime) ? fromJsonTimestamp(object.updateTime) : undefined,
      versionId: isSet(object.versionId) ? Long.fromValue(object.versionId) : Long.ZERO,
      labels: isObject(object.labels)
        ? Object.entries(object.labels).reduce<{ [key: string]: string }>((acc, [key, value]) => {
          acc[key] = String(value);
          return acc;
        }, {})
        : {},
      environmentVariables: isObject(object.environmentVariables)
        ? Object.entries(object.environmentVariables).reduce<{ [key: string]: string }>((acc, [key, value]) => {
          acc[key] = String(value);
          return acc;
        }, {})
        : {},
      buildEnvironmentVariables: isObject(object.buildEnvironmentVariables)
        ? Object.entries(object.buildEnvironmentVariables).reduce<{ [key: string]: string }>((acc, [key, value]) => {
          acc[key] = String(value);
          return acc;
        }, {})
        : {},
      network: isSet(object.network) ? globalThis.String(object.network) : "",
      maxInstances: isSet(object.maxInstances) ? globalThis.Number(object.maxInstances) : 0,
      minInstances: isSet(object.minInstances) ? globalThis.Number(object.minInstances) : 0,
      vpcConnector: isSet(object.vpcConnector) ? globalThis.String(object.vpcConnector) : "",
      vpcConnectorEgressSettings: isSet(object.vpcConnectorEgressSettings)
        ? cloudFunction_VpcConnectorEgressSettingsFromJSON(object.vpcConnectorEgressSettings)
        : 0,
      ingressSettings: isSet(object.ingressSettings)
        ? cloudFunction_IngressSettingsFromJSON(object.ingressSettings)
        : 0,
      kmsKeyName: isSet(object.kmsKeyName) ? globalThis.String(object.kmsKeyName) : "",
      buildWorkerPool: isSet(object.buildWorkerPool) ? globalThis.String(object.buildWorkerPool) : "",
      buildId: isSet(object.buildId) ? globalThis.String(object.buildId) : "",
      buildName: isSet(object.buildName) ? globalThis.String(object.buildName) : "",
      secretEnvironmentVariables: globalThis.Array.isArray(object?.secretEnvironmentVariables)
        ? object.secretEnvironmentVariables.map((e: any) => SecretEnvVar.fromJSON(e))
        : [],
      secretVolumes: globalThis.Array.isArray(object?.secretVolumes)
        ? object.secretVolumes.map((e: any) => SecretVolume.fromJSON(e))
        : [],
      sourceToken: isSet(object.sourceToken) ? globalThis.String(object.sourceToken) : "",
      dockerRepository: isSet(object.dockerRepository) ? globalThis.String(object.dockerRepository) : "",
      dockerRegistry: isSet(object.dockerRegistry) ? cloudFunction_DockerRegistryFromJSON(object.dockerRegistry) : 0,
      automaticUpdatePolicy: isSet(object.automaticUpdatePolicy)
        ? CloudFunction_AutomaticUpdatePolicy.fromJSON(object.automaticUpdatePolicy)
        : undefined,
      onDeployUpdatePolicy: isSet(object.onDeployUpdatePolicy)
        ? CloudFunction_OnDeployUpdatePolicy.fromJSON(object.onDeployUpdatePolicy)
        : undefined,
      buildServiceAccount: isSet(object.buildServiceAccount) ? globalThis.String(object.buildServiceAccount) : "",
    };
  },

  toJSON(message: CloudFunction): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    if (message.description !== "") {
      obj.description = message.description;
    }
    if (message.sourceArchiveUrl !== undefined) {
      obj.sourceArchiveUrl = message.sourceArchiveUrl;
    }
    if (message.sourceRepository !== undefined) {
      obj.sourceRepository = SourceRepository.toJSON(message.sourceRepository);
    }
    if (message.sourceUploadUrl !== undefined) {
      obj.sourceUploadUrl = message.sourceUploadUrl;
    }
    if (message.httpsTrigger !== undefined) {
      obj.httpsTrigger = HttpsTrigger.toJSON(message.httpsTrigger);
    }
    if (message.eventTrigger !== undefined) {
      obj.eventTrigger = EventTrigger.toJSON(message.eventTrigger);
    }
    if (message.status !== 0) {
      obj.status = cloudFunctionStatusToJSON(message.status);
    }
    if (message.entryPoint !== "") {
      obj.entryPoint = message.entryPoint;
    }
    if (message.runtime !== "") {
      obj.runtime = message.runtime;
    }
    if (message.timeout !== undefined) {
      obj.timeout = Duration.toJSON(message.timeout);
    }
    if (message.availableMemoryMb !== 0) {
      obj.availableMemoryMb = Math.round(message.availableMemoryMb);
    }
    if (message.serviceAccountEmail !== "") {
      obj.serviceAccountEmail = message.serviceAccountEmail;
    }
    if (message.updateTime !== undefined) {
      obj.updateTime = message.updateTime.toISOString();
    }
    if (!message.versionId.equals(Long.ZERO)) {
      obj.versionId = (message.versionId || Long.ZERO).toString();
    }
    if (message.labels) {
      const entries = Object.entries(message.labels);
      if (entries.length > 0) {
        obj.labels = {};
        entries.forEach(([k, v]) => {
          obj.labels[k] = v;
        });
      }
    }
    if (message.environmentVariables) {
      const entries = Object.entries(message.environmentVariables);
      if (entries.length > 0) {
        obj.environmentVariables = {};
        entries.forEach(([k, v]) => {
          obj.environmentVariables[k] = v;
        });
      }
    }
    if (message.buildEnvironmentVariables) {
      const entries = Object.entries(message.buildEnvironmentVariables);
      if (entries.length > 0) {
        obj.buildEnvironmentVariables = {};
        entries.forEach(([k, v]) => {
          obj.buildEnvironmentVariables[k] = v;
        });
      }
    }
    if (message.network !== "") {
      obj.network = message.network;
    }
    if (message.maxInstances !== 0) {
      obj.maxInstances = Math.round(message.maxInstances);
    }
    if (message.minInstances !== 0) {
      obj.minInstances = Math.round(message.minInstances);
    }
    if (message.vpcConnector !== "") {
      obj.vpcConnector = message.vpcConnector;
    }
    if (message.vpcConnectorEgressSettings !== 0) {
      obj.vpcConnectorEgressSettings = cloudFunction_VpcConnectorEgressSettingsToJSON(
        message.vpcConnectorEgressSettings,
      );
    }
    if (message.ingressSettings !== 0) {
      obj.ingressSettings = cloudFunction_IngressSettingsToJSON(message.ingressSettings);
    }
    if (message.kmsKeyName !== "") {
      obj.kmsKeyName = message.kmsKeyName;
    }
    if (message.buildWorkerPool !== "") {
      obj.buildWorkerPool = message.buildWorkerPool;
    }
    if (message.buildId !== "") {
      obj.buildId = message.buildId;
    }
    if (message.buildName !== "") {
      obj.buildName = message.buildName;
    }
    if (message.secretEnvironmentVariables?.length) {
      obj.secretEnvironmentVariables = message.secretEnvironmentVariables.map((e) => SecretEnvVar.toJSON(e));
    }
    if (message.secretVolumes?.length) {
      obj.secretVolumes = message.secretVolumes.map((e) => SecretVolume.toJSON(e));
    }
    if (message.sourceToken !== "") {
      obj.sourceToken = message.sourceToken;
    }
    if (message.dockerRepository !== "") {
      obj.dockerRepository = message.dockerRepository;
    }
    if (message.dockerRegistry !== 0) {
      obj.dockerRegistry = cloudFunction_DockerRegistryToJSON(message.dockerRegistry);
    }
    if (message.automaticUpdatePolicy !== undefined) {
      obj.automaticUpdatePolicy = CloudFunction_AutomaticUpdatePolicy.toJSON(message.automaticUpdatePolicy);
    }
    if (message.onDeployUpdatePolicy !== undefined) {
      obj.onDeployUpdatePolicy = CloudFunction_OnDeployUpdatePolicy.toJSON(message.onDeployUpdatePolicy);
    }
    if (message.buildServiceAccount !== "") {
      obj.buildServiceAccount = message.buildServiceAccount;
    }
    return obj;
  },

  create(base?: DeepPartial<CloudFunction>): CloudFunction {
    return CloudFunction.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<CloudFunction>): CloudFunction {
    const message = createBaseCloudFunction();
    message.name = object.name ?? "";
    message.description = object.description ?? "";
    message.sourceArchiveUrl = object.sourceArchiveUrl ?? undefined;
    message.sourceRepository = (object.sourceRepository !== undefined && object.sourceRepository !== null)
      ? SourceRepository.fromPartial(object.sourceRepository)
      : undefined;
    message.sourceUploadUrl = object.sourceUploadUrl ?? undefined;
    message.httpsTrigger = (object.httpsTrigger !== undefined && object.httpsTrigger !== null)
      ? HttpsTrigger.fromPartial(object.httpsTrigger)
      : undefined;
    message.eventTrigger = (object.eventTrigger !== undefined && object.eventTrigger !== null)
      ? EventTrigger.fromPartial(object.eventTrigger)
      : undefined;
    message.status = object.status ?? 0;
    message.entryPoint = object.entryPoint ?? "";
    message.runtime = object.runtime ?? "";
    message.timeout = (object.timeout !== undefined && object.timeout !== null)
      ? Duration.fromPartial(object.timeout)
      : undefined;
    message.availableMemoryMb = object.availableMemoryMb ?? 0;
    message.serviceAccountEmail = object.serviceAccountEmail ?? "";
    message.updateTime = object.updateTime ?? undefined;
    message.versionId = (object.versionId !== undefined && object.versionId !== null)
      ? Long.fromValue(object.versionId)
      : Long.ZERO;
    message.labels = Object.entries(object.labels ?? {}).reduce<{ [key: string]: string }>((acc, [key, value]) => {
      if (value !== undefined) {
        acc[key] = globalThis.String(value);
      }
      return acc;
    }, {});
    message.environmentVariables = Object.entries(object.environmentVariables ?? {}).reduce<{ [key: string]: string }>(
      (acc, [key, value]) => {
        if (value !== undefined) {
          acc[key] = globalThis.String(value);
        }
        return acc;
      },
      {},
    );
    message.buildEnvironmentVariables = Object.entries(object.buildEnvironmentVariables ?? {}).reduce<
      { [key: string]: string }
    >((acc, [key, value]) => {
      if (value !== undefined) {
        acc[key] = globalThis.String(value);
      }
      return acc;
    }, {});
    message.network = object.network ?? "";
    message.maxInstances = object.maxInstances ?? 0;
    message.minInstances = object.minInstances ?? 0;
    message.vpcConnector = object.vpcConnector ?? "";
    message.vpcConnectorEgressSettings = object.vpcConnectorEgressSettings ?? 0;
    message.ingressSettings = object.ingressSettings ?? 0;
    message.kmsKeyName = object.kmsKeyName ?? "";
    message.buildWorkerPool = object.buildWorkerPool ?? "";
    message.buildId = object.buildId ?? "";
    message.buildName = object.buildName ?? "";
    message.secretEnvironmentVariables = object.secretEnvironmentVariables?.map((e) => SecretEnvVar.fromPartial(e)) ||
      [];
    message.secretVolumes = object.secretVolumes?.map((e) => SecretVolume.fromPartial(e)) || [];
    message.sourceToken = object.sourceToken ?? "";
    message.dockerRepository = object.dockerRepository ?? "";
    message.dockerRegistry = object.dockerRegistry ?? 0;
    message.automaticUpdatePolicy =
      (object.automaticUpdatePolicy !== undefined && object.automaticUpdatePolicy !== null)
        ? CloudFunction_AutomaticUpdatePolicy.fromPartial(object.automaticUpdatePolicy)
        : undefined;
    message.onDeployUpdatePolicy = (object.onDeployUpdatePolicy !== undefined && object.onDeployUpdatePolicy !== null)
      ? CloudFunction_OnDeployUpdatePolicy.fromPartial(object.onDeployUpdatePolicy)
      : undefined;
    message.buildServiceAccount = object.buildServiceAccount ?? "";
    return message;
  },
};

function createBaseCloudFunction_AutomaticUpdatePolicy(): CloudFunction_AutomaticUpdatePolicy {
  return {};
}

export const CloudFunction_AutomaticUpdatePolicy: MessageFns<CloudFunction_AutomaticUpdatePolicy> = {
  encode(_: CloudFunction_AutomaticUpdatePolicy, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): CloudFunction_AutomaticUpdatePolicy {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseCloudFunction_AutomaticUpdatePolicy();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(_: any): CloudFunction_AutomaticUpdatePolicy {
    return {};
  },

  toJSON(_: CloudFunction_AutomaticUpdatePolicy): unknown {
    const obj: any = {};
    return obj;
  },

  create(base?: DeepPartial<CloudFunction_AutomaticUpdatePolicy>): CloudFunction_AutomaticUpdatePolicy {
    return CloudFunction_AutomaticUpdatePolicy.fromPartial(base ?? {});
  },
  fromPartial(_: DeepPartial<CloudFunction_AutomaticUpdatePolicy>): CloudFunction_AutomaticUpdatePolicy {
    const message = createBaseCloudFunction_AutomaticUpdatePolicy();
    return message;
  },
};

function createBaseCloudFunction_OnDeployUpdatePolicy(): CloudFunction_OnDeployUpdatePolicy {
  return { runtimeVersion: "" };
}

export const CloudFunction_OnDeployUpdatePolicy: MessageFns<CloudFunction_OnDeployUpdatePolicy> = {
  encode(message: CloudFunction_OnDeployUpdatePolicy, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.runtimeVersion !== "") {
      writer.uint32(10).string(message.runtimeVersion);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): CloudFunction_OnDeployUpdatePolicy {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseCloudFunction_OnDeployUpdatePolicy();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.runtimeVersion = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): CloudFunction_OnDeployUpdatePolicy {
    return { runtimeVersion: isSet(object.runtimeVersion) ? globalThis.String(object.runtimeVersion) : "" };
  },

  toJSON(message: CloudFunction_OnDeployUpdatePolicy): unknown {
    const obj: any = {};
    if (message.runtimeVersion !== "") {
      obj.runtimeVersion = message.runtimeVersion;
    }
    return obj;
  },

  create(base?: DeepPartial<CloudFunction_OnDeployUpdatePolicy>): CloudFunction_OnDeployUpdatePolicy {
    return CloudFunction_OnDeployUpdatePolicy.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<CloudFunction_OnDeployUpdatePolicy>): CloudFunction_OnDeployUpdatePolicy {
    const message = createBaseCloudFunction_OnDeployUpdatePolicy();
    message.runtimeVersion = object.runtimeVersion ?? "";
    return message;
  },
};

function createBaseCloudFunction_LabelsEntry(): CloudFunction_LabelsEntry {
  return { key: "", value: "" };
}

export const CloudFunction_LabelsEntry: MessageFns<CloudFunction_LabelsEntry> = {
  encode(message: CloudFunction_LabelsEntry, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.key !== "") {
      writer.uint32(10).string(message.key);
    }
    if (message.value !== "") {
      writer.uint32(18).string(message.value);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): CloudFunction_LabelsEntry {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseCloudFunction_LabelsEntry();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.key = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.value = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): CloudFunction_LabelsEntry {
    return {
      key: isSet(object.key) ? globalThis.String(object.key) : "",
      value: isSet(object.value) ? globalThis.String(object.value) : "",
    };
  },

  toJSON(message: CloudFunction_LabelsEntry): unknown {
    const obj: any = {};
    if (message.key !== "") {
      obj.key = message.key;
    }
    if (message.value !== "") {
      obj.value = message.value;
    }
    return obj;
  },

  create(base?: DeepPartial<CloudFunction_LabelsEntry>): CloudFunction_LabelsEntry {
    return CloudFunction_LabelsEntry.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<CloudFunction_LabelsEntry>): CloudFunction_LabelsEntry {
    const message = createBaseCloudFunction_LabelsEntry();
    message.key = object.key ?? "";
    message.value = object.value ?? "";
    return message;
  },
};

function createBaseCloudFunction_EnvironmentVariablesEntry(): CloudFunction_EnvironmentVariablesEntry {
  return { key: "", value: "" };
}

export const CloudFunction_EnvironmentVariablesEntry: MessageFns<CloudFunction_EnvironmentVariablesEntry> = {
  encode(message: CloudFunction_EnvironmentVariablesEntry, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.key !== "") {
      writer.uint32(10).string(message.key);
    }
    if (message.value !== "") {
      writer.uint32(18).string(message.value);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): CloudFunction_EnvironmentVariablesEntry {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseCloudFunction_EnvironmentVariablesEntry();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.key = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.value = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): CloudFunction_EnvironmentVariablesEntry {
    return {
      key: isSet(object.key) ? globalThis.String(object.key) : "",
      value: isSet(object.value) ? globalThis.String(object.value) : "",
    };
  },

  toJSON(message: CloudFunction_EnvironmentVariablesEntry): unknown {
    const obj: any = {};
    if (message.key !== "") {
      obj.key = message.key;
    }
    if (message.value !== "") {
      obj.value = message.value;
    }
    return obj;
  },

  create(base?: DeepPartial<CloudFunction_EnvironmentVariablesEntry>): CloudFunction_EnvironmentVariablesEntry {
    return CloudFunction_EnvironmentVariablesEntry.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<CloudFunction_EnvironmentVariablesEntry>): CloudFunction_EnvironmentVariablesEntry {
    const message = createBaseCloudFunction_EnvironmentVariablesEntry();
    message.key = object.key ?? "";
    message.value = object.value ?? "";
    return message;
  },
};

function createBaseCloudFunction_BuildEnvironmentVariablesEntry(): CloudFunction_BuildEnvironmentVariablesEntry {
  return { key: "", value: "" };
}

export const CloudFunction_BuildEnvironmentVariablesEntry: MessageFns<CloudFunction_BuildEnvironmentVariablesEntry> = {
  encode(
    message: CloudFunction_BuildEnvironmentVariablesEntry,
    writer: BinaryWriter = new BinaryWriter(),
  ): BinaryWriter {
    if (message.key !== "") {
      writer.uint32(10).string(message.key);
    }
    if (message.value !== "") {
      writer.uint32(18).string(message.value);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): CloudFunction_BuildEnvironmentVariablesEntry {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseCloudFunction_BuildEnvironmentVariablesEntry();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.key = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.value = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): CloudFunction_BuildEnvironmentVariablesEntry {
    return {
      key: isSet(object.key) ? globalThis.String(object.key) : "",
      value: isSet(object.value) ? globalThis.String(object.value) : "",
    };
  },

  toJSON(message: CloudFunction_BuildEnvironmentVariablesEntry): unknown {
    const obj: any = {};
    if (message.key !== "") {
      obj.key = message.key;
    }
    if (message.value !== "") {
      obj.value = message.value;
    }
    return obj;
  },

  create(
    base?: DeepPartial<CloudFunction_BuildEnvironmentVariablesEntry>,
  ): CloudFunction_BuildEnvironmentVariablesEntry {
    return CloudFunction_BuildEnvironmentVariablesEntry.fromPartial(base ?? {});
  },
  fromPartial(
    object: DeepPartial<CloudFunction_BuildEnvironmentVariablesEntry>,
  ): CloudFunction_BuildEnvironmentVariablesEntry {
    const message = createBaseCloudFunction_BuildEnvironmentVariablesEntry();
    message.key = object.key ?? "";
    message.value = object.value ?? "";
    return message;
  },
};

function createBaseSourceRepository(): SourceRepository {
  return { url: "", deployedUrl: "" };
}

export const SourceRepository: MessageFns<SourceRepository> = {
  encode(message: SourceRepository, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.url !== "") {
      writer.uint32(10).string(message.url);
    }
    if (message.deployedUrl !== "") {
      writer.uint32(18).string(message.deployedUrl);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): SourceRepository {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseSourceRepository();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.url = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.deployedUrl = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): SourceRepository {
    return {
      url: isSet(object.url) ? globalThis.String(object.url) : "",
      deployedUrl: isSet(object.deployedUrl) ? globalThis.String(object.deployedUrl) : "",
    };
  },

  toJSON(message: SourceRepository): unknown {
    const obj: any = {};
    if (message.url !== "") {
      obj.url = message.url;
    }
    if (message.deployedUrl !== "") {
      obj.deployedUrl = message.deployedUrl;
    }
    return obj;
  },

  create(base?: DeepPartial<SourceRepository>): SourceRepository {
    return SourceRepository.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<SourceRepository>): SourceRepository {
    const message = createBaseSourceRepository();
    message.url = object.url ?? "";
    message.deployedUrl = object.deployedUrl ?? "";
    return message;
  },
};

function createBaseHttpsTrigger(): HttpsTrigger {
  return { url: "", securityLevel: 0 };
}

export const HttpsTrigger: MessageFns<HttpsTrigger> = {
  encode(message: HttpsTrigger, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.url !== "") {
      writer.uint32(10).string(message.url);
    }
    if (message.securityLevel !== 0) {
      writer.uint32(16).int32(message.securityLevel);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): HttpsTrigger {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseHttpsTrigger();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.url = reader.string();
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.securityLevel = reader.int32() as any;
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): HttpsTrigger {
    return {
      url: isSet(object.url) ? globalThis.String(object.url) : "",
      securityLevel: isSet(object.securityLevel) ? httpsTrigger_SecurityLevelFromJSON(object.securityLevel) : 0,
    };
  },

  toJSON(message: HttpsTrigger): unknown {
    const obj: any = {};
    if (message.url !== "") {
      obj.url = message.url;
    }
    if (message.securityLevel !== 0) {
      obj.securityLevel = httpsTrigger_SecurityLevelToJSON(message.securityLevel);
    }
    return obj;
  },

  create(base?: DeepPartial<HttpsTrigger>): HttpsTrigger {
    return HttpsTrigger.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<HttpsTrigger>): HttpsTrigger {
    const message = createBaseHttpsTrigger();
    message.url = object.url ?? "";
    message.securityLevel = object.securityLevel ?? 0;
    return message;
  },
};

function createBaseEventTrigger(): EventTrigger {
  return { eventType: "", resource: "", service: "", failurePolicy: undefined };
}

export const EventTrigger: MessageFns<EventTrigger> = {
  encode(message: EventTrigger, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.eventType !== "") {
      writer.uint32(10).string(message.eventType);
    }
    if (message.resource !== "") {
      writer.uint32(18).string(message.resource);
    }
    if (message.service !== "") {
      writer.uint32(26).string(message.service);
    }
    if (message.failurePolicy !== undefined) {
      FailurePolicy.encode(message.failurePolicy, writer.uint32(42).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): EventTrigger {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseEventTrigger();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.eventType = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.resource = reader.string();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.service = reader.string();
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.failurePolicy = FailurePolicy.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): EventTrigger {
    return {
      eventType: isSet(object.eventType) ? globalThis.String(object.eventType) : "",
      resource: isSet(object.resource) ? globalThis.String(object.resource) : "",
      service: isSet(object.service) ? globalThis.String(object.service) : "",
      failurePolicy: isSet(object.failurePolicy) ? FailurePolicy.fromJSON(object.failurePolicy) : undefined,
    };
  },

  toJSON(message: EventTrigger): unknown {
    const obj: any = {};
    if (message.eventType !== "") {
      obj.eventType = message.eventType;
    }
    if (message.resource !== "") {
      obj.resource = message.resource;
    }
    if (message.service !== "") {
      obj.service = message.service;
    }
    if (message.failurePolicy !== undefined) {
      obj.failurePolicy = FailurePolicy.toJSON(message.failurePolicy);
    }
    return obj;
  },

  create(base?: DeepPartial<EventTrigger>): EventTrigger {
    return EventTrigger.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<EventTrigger>): EventTrigger {
    const message = createBaseEventTrigger();
    message.eventType = object.eventType ?? "";
    message.resource = object.resource ?? "";
    message.service = object.service ?? "";
    message.failurePolicy = (object.failurePolicy !== undefined && object.failurePolicy !== null)
      ? FailurePolicy.fromPartial(object.failurePolicy)
      : undefined;
    return message;
  },
};

function createBaseFailurePolicy(): FailurePolicy {
  return { retry: undefined };
}

export const FailurePolicy: MessageFns<FailurePolicy> = {
  encode(message: FailurePolicy, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.retry !== undefined) {
      FailurePolicy_Retry.encode(message.retry, writer.uint32(10).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): FailurePolicy {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseFailurePolicy();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.retry = FailurePolicy_Retry.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): FailurePolicy {
    return { retry: isSet(object.retry) ? FailurePolicy_Retry.fromJSON(object.retry) : undefined };
  },

  toJSON(message: FailurePolicy): unknown {
    const obj: any = {};
    if (message.retry !== undefined) {
      obj.retry = FailurePolicy_Retry.toJSON(message.retry);
    }
    return obj;
  },

  create(base?: DeepPartial<FailurePolicy>): FailurePolicy {
    return FailurePolicy.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<FailurePolicy>): FailurePolicy {
    const message = createBaseFailurePolicy();
    message.retry = (object.retry !== undefined && object.retry !== null)
      ? FailurePolicy_Retry.fromPartial(object.retry)
      : undefined;
    return message;
  },
};

function createBaseFailurePolicy_Retry(): FailurePolicy_Retry {
  return {};
}

export const FailurePolicy_Retry: MessageFns<FailurePolicy_Retry> = {
  encode(_: FailurePolicy_Retry, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): FailurePolicy_Retry {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseFailurePolicy_Retry();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(_: any): FailurePolicy_Retry {
    return {};
  },

  toJSON(_: FailurePolicy_Retry): unknown {
    const obj: any = {};
    return obj;
  },

  create(base?: DeepPartial<FailurePolicy_Retry>): FailurePolicy_Retry {
    return FailurePolicy_Retry.fromPartial(base ?? {});
  },
  fromPartial(_: DeepPartial<FailurePolicy_Retry>): FailurePolicy_Retry {
    const message = createBaseFailurePolicy_Retry();
    return message;
  },
};

function createBaseSecretEnvVar(): SecretEnvVar {
  return { key: "", projectId: "", secret: "", version: "" };
}

export const SecretEnvVar: MessageFns<SecretEnvVar> = {
  encode(message: SecretEnvVar, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.key !== "") {
      writer.uint32(10).string(message.key);
    }
    if (message.projectId !== "") {
      writer.uint32(18).string(message.projectId);
    }
    if (message.secret !== "") {
      writer.uint32(26).string(message.secret);
    }
    if (message.version !== "") {
      writer.uint32(34).string(message.version);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): SecretEnvVar {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseSecretEnvVar();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.key = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.projectId = reader.string();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.secret = reader.string();
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.version = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): SecretEnvVar {
    return {
      key: isSet(object.key) ? globalThis.String(object.key) : "",
      projectId: isSet(object.projectId) ? globalThis.String(object.projectId) : "",
      secret: isSet(object.secret) ? globalThis.String(object.secret) : "",
      version: isSet(object.version) ? globalThis.String(object.version) : "",
    };
  },

  toJSON(message: SecretEnvVar): unknown {
    const obj: any = {};
    if (message.key !== "") {
      obj.key = message.key;
    }
    if (message.projectId !== "") {
      obj.projectId = message.projectId;
    }
    if (message.secret !== "") {
      obj.secret = message.secret;
    }
    if (message.version !== "") {
      obj.version = message.version;
    }
    return obj;
  },

  create(base?: DeepPartial<SecretEnvVar>): SecretEnvVar {
    return SecretEnvVar.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<SecretEnvVar>): SecretEnvVar {
    const message = createBaseSecretEnvVar();
    message.key = object.key ?? "";
    message.projectId = object.projectId ?? "";
    message.secret = object.secret ?? "";
    message.version = object.version ?? "";
    return message;
  },
};

function createBaseSecretVolume(): SecretVolume {
  return { mountPath: "", projectId: "", secret: "", versions: [] };
}

export const SecretVolume: MessageFns<SecretVolume> = {
  encode(message: SecretVolume, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.mountPath !== "") {
      writer.uint32(10).string(message.mountPath);
    }
    if (message.projectId !== "") {
      writer.uint32(18).string(message.projectId);
    }
    if (message.secret !== "") {
      writer.uint32(26).string(message.secret);
    }
    for (const v of message.versions) {
      SecretVolume_SecretVersion.encode(v!, writer.uint32(34).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): SecretVolume {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseSecretVolume();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.mountPath = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.projectId = reader.string();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.secret = reader.string();
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.versions.push(SecretVolume_SecretVersion.decode(reader, reader.uint32()));
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): SecretVolume {
    return {
      mountPath: isSet(object.mountPath) ? globalThis.String(object.mountPath) : "",
      projectId: isSet(object.projectId) ? globalThis.String(object.projectId) : "",
      secret: isSet(object.secret) ? globalThis.String(object.secret) : "",
      versions: globalThis.Array.isArray(object?.versions)
        ? object.versions.map((e: any) => SecretVolume_SecretVersion.fromJSON(e))
        : [],
    };
  },

  toJSON(message: SecretVolume): unknown {
    const obj: any = {};
    if (message.mountPath !== "") {
      obj.mountPath = message.mountPath;
    }
    if (message.projectId !== "") {
      obj.projectId = message.projectId;
    }
    if (message.secret !== "") {
      obj.secret = message.secret;
    }
    if (message.versions?.length) {
      obj.versions = message.versions.map((e) => SecretVolume_SecretVersion.toJSON(e));
    }
    return obj;
  },

  create(base?: DeepPartial<SecretVolume>): SecretVolume {
    return SecretVolume.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<SecretVolume>): SecretVolume {
    const message = createBaseSecretVolume();
    message.mountPath = object.mountPath ?? "";
    message.projectId = object.projectId ?? "";
    message.secret = object.secret ?? "";
    message.versions = object.versions?.map((e) => SecretVolume_SecretVersion.fromPartial(e)) || [];
    return message;
  },
};

function createBaseSecretVolume_SecretVersion(): SecretVolume_SecretVersion {
  return { version: "", path: "" };
}

export const SecretVolume_SecretVersion: MessageFns<SecretVolume_SecretVersion> = {
  encode(message: SecretVolume_SecretVersion, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.version !== "") {
      writer.uint32(10).string(message.version);
    }
    if (message.path !== "") {
      writer.uint32(18).string(message.path);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): SecretVolume_SecretVersion {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseSecretVolume_SecretVersion();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.version = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.path = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): SecretVolume_SecretVersion {
    return {
      version: isSet(object.version) ? globalThis.String(object.version) : "",
      path: isSet(object.path) ? globalThis.String(object.path) : "",
    };
  },

  toJSON(message: SecretVolume_SecretVersion): unknown {
    const obj: any = {};
    if (message.version !== "") {
      obj.version = message.version;
    }
    if (message.path !== "") {
      obj.path = message.path;
    }
    return obj;
  },

  create(base?: DeepPartial<SecretVolume_SecretVersion>): SecretVolume_SecretVersion {
    return SecretVolume_SecretVersion.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<SecretVolume_SecretVersion>): SecretVolume_SecretVersion {
    const message = createBaseSecretVolume_SecretVersion();
    message.version = object.version ?? "";
    message.path = object.path ?? "";
    return message;
  },
};

function createBaseCreateFunctionRequest(): CreateFunctionRequest {
  return { location: "", function: undefined };
}

export const CreateFunctionRequest: MessageFns<CreateFunctionRequest> = {
  encode(message: CreateFunctionRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.location !== "") {
      writer.uint32(10).string(message.location);
    }
    if (message.function !== undefined) {
      CloudFunction.encode(message.function, writer.uint32(18).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): CreateFunctionRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseCreateFunctionRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.location = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.function = CloudFunction.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): CreateFunctionRequest {
    return {
      location: isSet(object.location) ? globalThis.String(object.location) : "",
      function: isSet(object.function) ? CloudFunction.fromJSON(object.function) : undefined,
    };
  },

  toJSON(message: CreateFunctionRequest): unknown {
    const obj: any = {};
    if (message.location !== "") {
      obj.location = message.location;
    }
    if (message.function !== undefined) {
      obj.function = CloudFunction.toJSON(message.function);
    }
    return obj;
  },

  create(base?: DeepPartial<CreateFunctionRequest>): CreateFunctionRequest {
    return CreateFunctionRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<CreateFunctionRequest>): CreateFunctionRequest {
    const message = createBaseCreateFunctionRequest();
    message.location = object.location ?? "";
    message.function = (object.function !== undefined && object.function !== null)
      ? CloudFunction.fromPartial(object.function)
      : undefined;
    return message;
  },
};

function createBaseUpdateFunctionRequest(): UpdateFunctionRequest {
  return { function: undefined, updateMask: undefined };
}

export const UpdateFunctionRequest: MessageFns<UpdateFunctionRequest> = {
  encode(message: UpdateFunctionRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.function !== undefined) {
      CloudFunction.encode(message.function, writer.uint32(10).fork()).join();
    }
    if (message.updateMask !== undefined) {
      FieldMask.encode(FieldMask.wrap(message.updateMask), writer.uint32(18).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): UpdateFunctionRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseUpdateFunctionRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.function = CloudFunction.decode(reader, reader.uint32());
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.updateMask = FieldMask.unwrap(FieldMask.decode(reader, reader.uint32()));
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): UpdateFunctionRequest {
    return {
      function: isSet(object.function) ? CloudFunction.fromJSON(object.function) : undefined,
      updateMask: isSet(object.updateMask) ? FieldMask.unwrap(FieldMask.fromJSON(object.updateMask)) : undefined,
    };
  },

  toJSON(message: UpdateFunctionRequest): unknown {
    const obj: any = {};
    if (message.function !== undefined) {
      obj.function = CloudFunction.toJSON(message.function);
    }
    if (message.updateMask !== undefined) {
      obj.updateMask = FieldMask.toJSON(FieldMask.wrap(message.updateMask));
    }
    return obj;
  },

  create(base?: DeepPartial<UpdateFunctionRequest>): UpdateFunctionRequest {
    return UpdateFunctionRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<UpdateFunctionRequest>): UpdateFunctionRequest {
    const message = createBaseUpdateFunctionRequest();
    message.function = (object.function !== undefined && object.function !== null)
      ? CloudFunction.fromPartial(object.function)
      : undefined;
    message.updateMask = object.updateMask ?? undefined;
    return message;
  },
};

function createBaseGetFunctionRequest(): GetFunctionRequest {
  return { name: "", versionId: Long.ZERO };
}

export const GetFunctionRequest: MessageFns<GetFunctionRequest> = {
  encode(message: GetFunctionRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    if (!message.versionId.equals(Long.ZERO)) {
      writer.uint32(16).int64(message.versionId.toString());
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): GetFunctionRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseGetFunctionRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.versionId = Long.fromString(reader.int64().toString());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): GetFunctionRequest {
    return {
      name: isSet(object.name) ? globalThis.String(object.name) : "",
      versionId: isSet(object.versionId) ? Long.fromValue(object.versionId) : Long.ZERO,
    };
  },

  toJSON(message: GetFunctionRequest): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    if (!message.versionId.equals(Long.ZERO)) {
      obj.versionId = (message.versionId || Long.ZERO).toString();
    }
    return obj;
  },

  create(base?: DeepPartial<GetFunctionRequest>): GetFunctionRequest {
    return GetFunctionRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<GetFunctionRequest>): GetFunctionRequest {
    const message = createBaseGetFunctionRequest();
    message.name = object.name ?? "";
    message.versionId = (object.versionId !== undefined && object.versionId !== null)
      ? Long.fromValue(object.versionId)
      : Long.ZERO;
    return message;
  },
};

function createBaseListFunctionsRequest(): ListFunctionsRequest {
  return { parent: "", pageSize: 0, pageToken: "" };
}

export const ListFunctionsRequest: MessageFns<ListFunctionsRequest> = {
  encode(message: ListFunctionsRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.parent !== "") {
      writer.uint32(10).string(message.parent);
    }
    if (message.pageSize !== 0) {
      writer.uint32(16).int32(message.pageSize);
    }
    if (message.pageToken !== "") {
      writer.uint32(26).string(message.pageToken);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ListFunctionsRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseListFunctionsRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.parent = reader.string();
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.pageSize = reader.int32();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.pageToken = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ListFunctionsRequest {
    return {
      parent: isSet(object.parent) ? globalThis.String(object.parent) : "",
      pageSize: isSet(object.pageSize) ? globalThis.Number(object.pageSize) : 0,
      pageToken: isSet(object.pageToken) ? globalThis.String(object.pageToken) : "",
    };
  },

  toJSON(message: ListFunctionsRequest): unknown {
    const obj: any = {};
    if (message.parent !== "") {
      obj.parent = message.parent;
    }
    if (message.pageSize !== 0) {
      obj.pageSize = Math.round(message.pageSize);
    }
    if (message.pageToken !== "") {
      obj.pageToken = message.pageToken;
    }
    return obj;
  },

  create(base?: DeepPartial<ListFunctionsRequest>): ListFunctionsRequest {
    return ListFunctionsRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ListFunctionsRequest>): ListFunctionsRequest {
    const message = createBaseListFunctionsRequest();
    message.parent = object.parent ?? "";
    message.pageSize = object.pageSize ?? 0;
    message.pageToken = object.pageToken ?? "";
    return message;
  },
};

function createBaseListFunctionsResponse(): ListFunctionsResponse {
  return { functions: [], nextPageToken: "", unreachable: [] };
}

export const ListFunctionsResponse: MessageFns<ListFunctionsResponse> = {
  encode(message: ListFunctionsResponse, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.functions) {
      CloudFunction.encode(v!, writer.uint32(10).fork()).join();
    }
    if (message.nextPageToken !== "") {
      writer.uint32(18).string(message.nextPageToken);
    }
    for (const v of message.unreachable) {
      writer.uint32(26).string(v!);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ListFunctionsResponse {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseListFunctionsResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.functions.push(CloudFunction.decode(reader, reader.uint32()));
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.nextPageToken = reader.string();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.unreachable.push(reader.string());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ListFunctionsResponse {
    return {
      functions: globalThis.Array.isArray(object?.functions)
        ? object.functions.map((e: any) => CloudFunction.fromJSON(e))
        : [],
      nextPageToken: isSet(object.nextPageToken) ? globalThis.String(object.nextPageToken) : "",
      unreachable: globalThis.Array.isArray(object?.unreachable)
        ? object.unreachable.map((e: any) => globalThis.String(e))
        : [],
    };
  },

  toJSON(message: ListFunctionsResponse): unknown {
    const obj: any = {};
    if (message.functions?.length) {
      obj.functions = message.functions.map((e) => CloudFunction.toJSON(e));
    }
    if (message.nextPageToken !== "") {
      obj.nextPageToken = message.nextPageToken;
    }
    if (message.unreachable?.length) {
      obj.unreachable = message.unreachable;
    }
    return obj;
  },

  create(base?: DeepPartial<ListFunctionsResponse>): ListFunctionsResponse {
    return ListFunctionsResponse.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ListFunctionsResponse>): ListFunctionsResponse {
    const message = createBaseListFunctionsResponse();
    message.functions = object.functions?.map((e) => CloudFunction.fromPartial(e)) || [];
    message.nextPageToken = object.nextPageToken ?? "";
    message.unreachable = object.unreachable?.map((e) => e) || [];
    return message;
  },
};

function createBaseDeleteFunctionRequest(): DeleteFunctionRequest {
  return { name: "" };
}

export const DeleteFunctionRequest: MessageFns<DeleteFunctionRequest> = {
  encode(message: DeleteFunctionRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): DeleteFunctionRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDeleteFunctionRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): DeleteFunctionRequest {
    return { name: isSet(object.name) ? globalThis.String(object.name) : "" };
  },

  toJSON(message: DeleteFunctionRequest): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    return obj;
  },

  create(base?: DeepPartial<DeleteFunctionRequest>): DeleteFunctionRequest {
    return DeleteFunctionRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<DeleteFunctionRequest>): DeleteFunctionRequest {
    const message = createBaseDeleteFunctionRequest();
    message.name = object.name ?? "";
    return message;
  },
};

function createBaseCallFunctionRequest(): CallFunctionRequest {
  return { name: "", data: "" };
}

export const CallFunctionRequest: MessageFns<CallFunctionRequest> = {
  encode(message: CallFunctionRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    if (message.data !== "") {
      writer.uint32(18).string(message.data);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): CallFunctionRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseCallFunctionRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.data = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): CallFunctionRequest {
    return {
      name: isSet(object.name) ? globalThis.String(object.name) : "",
      data: isSet(object.data) ? globalThis.String(object.data) : "",
    };
  },

  toJSON(message: CallFunctionRequest): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    if (message.data !== "") {
      obj.data = message.data;
    }
    return obj;
  },

  create(base?: DeepPartial<CallFunctionRequest>): CallFunctionRequest {
    return CallFunctionRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<CallFunctionRequest>): CallFunctionRequest {
    const message = createBaseCallFunctionRequest();
    message.name = object.name ?? "";
    message.data = object.data ?? "";
    return message;
  },
};

function createBaseCallFunctionResponse(): CallFunctionResponse {
  return { executionId: "", result: "", error: "" };
}

export const CallFunctionResponse: MessageFns<CallFunctionResponse> = {
  encode(message: CallFunctionResponse, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.executionId !== "") {
      writer.uint32(10).string(message.executionId);
    }
    if (message.result !== "") {
      writer.uint32(18).string(message.result);
    }
    if (message.error !== "") {
      writer.uint32(26).string(message.error);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): CallFunctionResponse {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseCallFunctionResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.executionId = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.result = reader.string();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.error = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): CallFunctionResponse {
    return {
      executionId: isSet(object.executionId) ? globalThis.String(object.executionId) : "",
      result: isSet(object.result) ? globalThis.String(object.result) : "",
      error: isSet(object.error) ? globalThis.String(object.error) : "",
    };
  },

  toJSON(message: CallFunctionResponse): unknown {
    const obj: any = {};
    if (message.executionId !== "") {
      obj.executionId = message.executionId;
    }
    if (message.result !== "") {
      obj.result = message.result;
    }
    if (message.error !== "") {
      obj.error = message.error;
    }
    return obj;
  },

  create(base?: DeepPartial<CallFunctionResponse>): CallFunctionResponse {
    return CallFunctionResponse.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<CallFunctionResponse>): CallFunctionResponse {
    const message = createBaseCallFunctionResponse();
    message.executionId = object.executionId ?? "";
    message.result = object.result ?? "";
    message.error = object.error ?? "";
    return message;
  },
};

function createBaseGenerateUploadUrlRequest(): GenerateUploadUrlRequest {
  return { parent: "", kmsKeyName: "" };
}

export const GenerateUploadUrlRequest: MessageFns<GenerateUploadUrlRequest> = {
  encode(message: GenerateUploadUrlRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.parent !== "") {
      writer.uint32(10).string(message.parent);
    }
    if (message.kmsKeyName !== "") {
      writer.uint32(18).string(message.kmsKeyName);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): GenerateUploadUrlRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseGenerateUploadUrlRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.parent = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.kmsKeyName = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): GenerateUploadUrlRequest {
    return {
      parent: isSet(object.parent) ? globalThis.String(object.parent) : "",
      kmsKeyName: isSet(object.kmsKeyName) ? globalThis.String(object.kmsKeyName) : "",
    };
  },

  toJSON(message: GenerateUploadUrlRequest): unknown {
    const obj: any = {};
    if (message.parent !== "") {
      obj.parent = message.parent;
    }
    if (message.kmsKeyName !== "") {
      obj.kmsKeyName = message.kmsKeyName;
    }
    return obj;
  },

  create(base?: DeepPartial<GenerateUploadUrlRequest>): GenerateUploadUrlRequest {
    return GenerateUploadUrlRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<GenerateUploadUrlRequest>): GenerateUploadUrlRequest {
    const message = createBaseGenerateUploadUrlRequest();
    message.parent = object.parent ?? "";
    message.kmsKeyName = object.kmsKeyName ?? "";
    return message;
  },
};

function createBaseGenerateUploadUrlResponse(): GenerateUploadUrlResponse {
  return { uploadUrl: "" };
}

export const GenerateUploadUrlResponse: MessageFns<GenerateUploadUrlResponse> = {
  encode(message: GenerateUploadUrlResponse, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.uploadUrl !== "") {
      writer.uint32(10).string(message.uploadUrl);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): GenerateUploadUrlResponse {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseGenerateUploadUrlResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.uploadUrl = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): GenerateUploadUrlResponse {
    return { uploadUrl: isSet(object.uploadUrl) ? globalThis.String(object.uploadUrl) : "" };
  },

  toJSON(message: GenerateUploadUrlResponse): unknown {
    const obj: any = {};
    if (message.uploadUrl !== "") {
      obj.uploadUrl = message.uploadUrl;
    }
    return obj;
  },

  create(base?: DeepPartial<GenerateUploadUrlResponse>): GenerateUploadUrlResponse {
    return GenerateUploadUrlResponse.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<GenerateUploadUrlResponse>): GenerateUploadUrlResponse {
    const message = createBaseGenerateUploadUrlResponse();
    message.uploadUrl = object.uploadUrl ?? "";
    return message;
  },
};

function createBaseGenerateDownloadUrlRequest(): GenerateDownloadUrlRequest {
  return { name: "", versionId: Long.UZERO };
}

export const GenerateDownloadUrlRequest: MessageFns<GenerateDownloadUrlRequest> = {
  encode(message: GenerateDownloadUrlRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    if (!message.versionId.equals(Long.UZERO)) {
      writer.uint32(16).uint64(message.versionId.toString());
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): GenerateDownloadUrlRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseGenerateDownloadUrlRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.versionId = Long.fromString(reader.uint64().toString(), true);
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): GenerateDownloadUrlRequest {
    return {
      name: isSet(object.name) ? globalThis.String(object.name) : "",
      versionId: isSet(object.versionId) ? Long.fromValue(object.versionId) : Long.UZERO,
    };
  },

  toJSON(message: GenerateDownloadUrlRequest): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    if (!message.versionId.equals(Long.UZERO)) {
      obj.versionId = (message.versionId || Long.UZERO).toString();
    }
    return obj;
  },

  create(base?: DeepPartial<GenerateDownloadUrlRequest>): GenerateDownloadUrlRequest {
    return GenerateDownloadUrlRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<GenerateDownloadUrlRequest>): GenerateDownloadUrlRequest {
    const message = createBaseGenerateDownloadUrlRequest();
    message.name = object.name ?? "";
    message.versionId = (object.versionId !== undefined && object.versionId !== null)
      ? Long.fromValue(object.versionId)
      : Long.UZERO;
    return message;
  },
};

function createBaseGenerateDownloadUrlResponse(): GenerateDownloadUrlResponse {
  return { downloadUrl: "" };
}

export const GenerateDownloadUrlResponse: MessageFns<GenerateDownloadUrlResponse> = {
  encode(message: GenerateDownloadUrlResponse, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.downloadUrl !== "") {
      writer.uint32(10).string(message.downloadUrl);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): GenerateDownloadUrlResponse {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseGenerateDownloadUrlResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.downloadUrl = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): GenerateDownloadUrlResponse {
    return { downloadUrl: isSet(object.downloadUrl) ? globalThis.String(object.downloadUrl) : "" };
  },

  toJSON(message: GenerateDownloadUrlResponse): unknown {
    const obj: any = {};
    if (message.downloadUrl !== "") {
      obj.downloadUrl = message.downloadUrl;
    }
    return obj;
  },

  create(base?: DeepPartial<GenerateDownloadUrlResponse>): GenerateDownloadUrlResponse {
    return GenerateDownloadUrlResponse.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<GenerateDownloadUrlResponse>): GenerateDownloadUrlResponse {
    const message = createBaseGenerateDownloadUrlResponse();
    message.downloadUrl = object.downloadUrl ?? "";
    return message;
  },
};

/** A service that application uses to manipulate triggers and functions. */
export type CloudFunctionsServiceDefinition = typeof CloudFunctionsServiceDefinition;
export const CloudFunctionsServiceDefinition = {
  name: "CloudFunctionsService",
  fullName: "google.cloud.functions.v1.CloudFunctionsService",
  methods: {
    /** Returns a list of functions that belong to the requested project. */
    listFunctions: {
      name: "ListFunctions",
      requestType: ListFunctionsRequest,
      requestStream: false,
      responseType: ListFunctionsResponse,
      responseStream: false,
      options: {
        _unknownFields: {
          578365826: [
            Buffer.from([
              47,
              18,
              45,
              47,
              118,
              49,
              47,
              123,
              112,
              97,
              114,
              101,
              110,
              116,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              125,
              47,
              102,
              117,
              110,
              99,
              116,
              105,
              111,
              110,
              115,
            ]),
          ],
        },
      },
    },
    /** Returns a function with the given name from the requested project. */
    getFunction: {
      name: "GetFunction",
      requestType: GetFunctionRequest,
      requestStream: false,
      responseType: CloudFunction,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [Buffer.from([4, 110, 97, 109, 101])],
          578365826: [
            Buffer.from([
              47,
              18,
              45,
              47,
              118,
              49,
              47,
              123,
              110,
              97,
              109,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              102,
              117,
              110,
              99,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              125,
            ]),
          ],
        },
      },
    },
    /**
     * Creates a new function. If a function with the given name already exists in
     * the specified project, the long running operation will return
     * `ALREADY_EXISTS` error.
     */
    createFunction: {
      name: "CreateFunction",
      requestType: CreateFunctionRequest,
      requestStream: false,
      responseType: Operation,
      responseStream: false,
      options: {
        _unknownFields: {
          8394: [
            Buffer.from([
              36,
              10,
              13,
              67,
              108,
              111,
              117,
              100,
              70,
              117,
              110,
              99,
              116,
              105,
              111,
              110,
              18,
              19,
              79,
              112,
              101,
              114,
              97,
              116,
              105,
              111,
              110,
              77,
              101,
              116,
              97,
              100,
              97,
              116,
              97,
              86,
              49,
            ]),
          ],
          8410: [Buffer.from([17, 108, 111, 99, 97, 116, 105, 111, 110, 44, 102, 117, 110, 99, 116, 105, 111, 110])],
          578365826: [
            Buffer.from([
              59,
              58,
              8,
              102,
              117,
              110,
              99,
              116,
              105,
              111,
              110,
              34,
              47,
              47,
              118,
              49,
              47,
              123,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              125,
              47,
              102,
              117,
              110,
              99,
              116,
              105,
              111,
              110,
              115,
            ]),
          ],
        },
      },
    },
    /** Updates existing function. */
    updateFunction: {
      name: "UpdateFunction",
      requestType: UpdateFunctionRequest,
      requestStream: false,
      responseType: Operation,
      responseStream: false,
      options: {
        _unknownFields: {
          8394: [
            Buffer.from([
              36,
              10,
              13,
              67,
              108,
              111,
              117,
              100,
              70,
              117,
              110,
              99,
              116,
              105,
              111,
              110,
              18,
              19,
              79,
              112,
              101,
              114,
              97,
              116,
              105,
              111,
              110,
              77,
              101,
              116,
              97,
              100,
              97,
              116,
              97,
              86,
              49,
            ]),
          ],
          8410: [Buffer.from([8, 102, 117, 110, 99, 116, 105, 111, 110])],
          578365826: [
            Buffer.from([
              66,
              58,
              8,
              102,
              117,
              110,
              99,
              116,
              105,
              111,
              110,
              50,
              54,
              47,
              118,
              49,
              47,
              123,
              102,
              117,
              110,
              99,
              116,
              105,
              111,
              110,
              46,
              110,
              97,
              109,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              102,
              117,
              110,
              99,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              125,
            ]),
          ],
        },
      },
    },
    /**
     * Deletes a function with the given name from the specified project. If the
     * given function is used by some trigger, the trigger will be updated to
     * remove this function.
     */
    deleteFunction: {
      name: "DeleteFunction",
      requestType: DeleteFunctionRequest,
      requestStream: false,
      responseType: Operation,
      responseStream: false,
      options: {
        _unknownFields: {
          8394: [
            Buffer.from([
              44,
              10,
              21,
              103,
              111,
              111,
              103,
              108,
              101,
              46,
              112,
              114,
              111,
              116,
              111,
              98,
              117,
              102,
              46,
              69,
              109,
              112,
              116,
              121,
              18,
              19,
              79,
              112,
              101,
              114,
              97,
              116,
              105,
              111,
              110,
              77,
              101,
              116,
              97,
              100,
              97,
              116,
              97,
              86,
              49,
            ]),
          ],
          8410: [Buffer.from([4, 110, 97, 109, 101])],
          578365826: [
            Buffer.from([
              47,
              42,
              45,
              47,
              118,
              49,
              47,
              123,
              110,
              97,
              109,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              102,
              117,
              110,
              99,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              125,
            ]),
          ],
        },
      },
    },
    /**
     * Synchronously invokes a deployed Cloud Function. To be used for testing
     * purposes as very limited traffic is allowed. For more information on
     * the actual limits, refer to
     * [Rate Limits](https://cloud.google.com/functions/quotas#rate_limits).
     */
    callFunction: {
      name: "CallFunction",
      requestType: CallFunctionRequest,
      requestStream: false,
      responseType: CallFunctionResponse,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [Buffer.from([9, 110, 97, 109, 101, 44, 100, 97, 116, 97])],
          578365826: [
            Buffer.from([
              55,
              58,
              1,
              42,
              34,
              50,
              47,
              118,
              49,
              47,
              123,
              110,
              97,
              109,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              102,
              117,
              110,
              99,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              125,
              58,
              99,
              97,
              108,
              108,
            ]),
          ],
        },
      },
    },
    /**
     * Returns a signed URL for uploading a function source code.
     * For more information about the signed URL usage see:
     * https://cloud.google.com/storage/docs/access-control/signed-urls.
     * Once the function source code upload is complete, the used signed
     * URL should be provided in CreateFunction or UpdateFunction request
     * as a reference to the function source code.
     *
     * When uploading source code to the generated signed URL, please follow
     * these restrictions:
     *
     * * Source file type should be a zip file.
     * * Source file size should not exceed 100MB limit.
     * * No credentials should be attached - the signed URLs provide access to the
     *   target bucket using internal service identity; if credentials were
     *   attached, the identity from the credentials would be used, but that
     *   identity does not have permissions to upload files to the URL.
     *
     * When making a HTTP PUT request, these two headers need to be specified:
     *
     * * `content-type: application/zip`
     * * `x-goog-content-length-range: 0,104857600`
     *
     * And this header SHOULD NOT be specified:
     *
     * * `Authorization: Bearer YOUR_TOKEN`
     */
    generateUploadUrl: {
      name: "GenerateUploadUrl",
      requestType: GenerateUploadUrlRequest,
      requestStream: false,
      responseType: GenerateUploadUrlResponse,
      responseStream: false,
      options: {
        _unknownFields: {
          578365826: [
            Buffer.from([
              68,
              58,
              1,
              42,
              34,
              63,
              47,
              118,
              49,
              47,
              123,
              112,
              97,
              114,
              101,
              110,
              116,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              125,
              47,
              102,
              117,
              110,
              99,
              116,
              105,
              111,
              110,
              115,
              58,
              103,
              101,
              110,
              101,
              114,
              97,
              116,
              101,
              85,
              112,
              108,
              111,
              97,
              100,
              85,
              114,
              108,
            ]),
          ],
        },
      },
    },
    /**
     * Returns a signed URL for downloading deployed function source code.
     * The URL is only valid for a limited period and should be used within
     * minutes after generation.
     * For more information about the signed URL usage see:
     * https://cloud.google.com/storage/docs/access-control/signed-urls
     */
    generateDownloadUrl: {
      name: "GenerateDownloadUrl",
      requestType: GenerateDownloadUrlRequest,
      requestStream: false,
      responseType: GenerateDownloadUrlResponse,
      responseStream: false,
      options: {
        _unknownFields: {
          578365826: [
            Buffer.from([
              70,
              58,
              1,
              42,
              34,
              65,
              47,
              118,
              49,
              47,
              123,
              110,
              97,
              109,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              102,
              117,
              110,
              99,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              125,
              58,
              103,
              101,
              110,
              101,
              114,
              97,
              116,
              101,
              68,
              111,
              119,
              110,
              108,
              111,
              97,
              100,
              85,
              114,
              108,
            ]),
          ],
        },
      },
    },
    /**
     * Sets the IAM access control policy on the specified function.
     * Replaces any existing policy.
     */
    setIamPolicy: {
      name: "SetIamPolicy",
      requestType: SetIamPolicyRequest,
      requestStream: false,
      responseType: Policy,
      responseStream: false,
      options: {
        _unknownFields: {
          578365826: [
            Buffer.from([
              67,
              58,
              1,
              42,
              34,
              62,
              47,
              118,
              49,
              47,
              123,
              114,
              101,
              115,
              111,
              117,
              114,
              99,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              102,
              117,
              110,
              99,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              125,
              58,
              115,
              101,
              116,
              73,
              97,
              109,
              80,
              111,
              108,
              105,
              99,
              121,
            ]),
          ],
        },
      },
    },
    /**
     * Gets the IAM access control policy for a function.
     * Returns an empty policy if the function exists and does not have a policy
     * set.
     */
    getIamPolicy: {
      name: "GetIamPolicy",
      requestType: GetIamPolicyRequest,
      requestStream: false,
      responseType: Policy,
      responseStream: false,
      options: {
        _unknownFields: {
          578365826: [
            Buffer.from([
              64,
              18,
              62,
              47,
              118,
              49,
              47,
              123,
              114,
              101,
              115,
              111,
              117,
              114,
              99,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              102,
              117,
              110,
              99,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              125,
              58,
              103,
              101,
              116,
              73,
              97,
              109,
              80,
              111,
              108,
              105,
              99,
              121,
            ]),
          ],
        },
      },
    },
    /**
     * Tests the specified permissions against the IAM access control policy
     * for a function.
     * If the function does not exist, this will return an empty set of
     * permissions, not a NOT_FOUND error.
     */
    testIamPermissions: {
      name: "TestIamPermissions",
      requestType: TestIamPermissionsRequest,
      requestStream: false,
      responseType: TestIamPermissionsResponse,
      responseStream: false,
      options: {
        _unknownFields: {
          578365826: [
            Buffer.from([
              73,
              58,
              1,
              42,
              34,
              68,
              47,
              118,
              49,
              47,
              123,
              114,
              101,
              115,
              111,
              117,
              114,
              99,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              102,
              117,
              110,
              99,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              125,
              58,
              116,
              101,
              115,
              116,
              73,
              97,
              109,
              80,
              101,
              114,
              109,
              105,
              115,
              115,
              105,
              111,
              110,
              115,
            ]),
          ],
        },
      },
    },
  },
} as const;

export interface CloudFunctionsServiceImplementation<CallContextExt = {}> {
  /** Returns a list of functions that belong to the requested project. */
  listFunctions(
    request: ListFunctionsRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<ListFunctionsResponse>>;
  /** Returns a function with the given name from the requested project. */
  getFunction(request: GetFunctionRequest, context: CallContext & CallContextExt): Promise<DeepPartial<CloudFunction>>;
  /**
   * Creates a new function. If a function with the given name already exists in
   * the specified project, the long running operation will return
   * `ALREADY_EXISTS` error.
   */
  createFunction(
    request: CreateFunctionRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<Operation>>;
  /** Updates existing function. */
  updateFunction(
    request: UpdateFunctionRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<Operation>>;
  /**
   * Deletes a function with the given name from the specified project. If the
   * given function is used by some trigger, the trigger will be updated to
   * remove this function.
   */
  deleteFunction(
    request: DeleteFunctionRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<Operation>>;
  /**
   * Synchronously invokes a deployed Cloud Function. To be used for testing
   * purposes as very limited traffic is allowed. For more information on
   * the actual limits, refer to
   * [Rate Limits](https://cloud.google.com/functions/quotas#rate_limits).
   */
  callFunction(
    request: CallFunctionRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<CallFunctionResponse>>;
  /**
   * Returns a signed URL for uploading a function source code.
   * For more information about the signed URL usage see:
   * https://cloud.google.com/storage/docs/access-control/signed-urls.
   * Once the function source code upload is complete, the used signed
   * URL should be provided in CreateFunction or UpdateFunction request
   * as a reference to the function source code.
   *
   * When uploading source code to the generated signed URL, please follow
   * these restrictions:
   *
   * * Source file type should be a zip file.
   * * Source file size should not exceed 100MB limit.
   * * No credentials should be attached - the signed URLs provide access to the
   *   target bucket using internal service identity; if credentials were
   *   attached, the identity from the credentials would be used, but that
   *   identity does not have permissions to upload files to the URL.
   *
   * When making a HTTP PUT request, these two headers need to be specified:
   *
   * * `content-type: application/zip`
   * * `x-goog-content-length-range: 0,104857600`
   *
   * And this header SHOULD NOT be specified:
   *
   * * `Authorization: Bearer YOUR_TOKEN`
   */
  generateUploadUrl(
    request: GenerateUploadUrlRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<GenerateUploadUrlResponse>>;
  /**
   * Returns a signed URL for downloading deployed function source code.
   * The URL is only valid for a limited period and should be used within
   * minutes after generation.
   * For more information about the signed URL usage see:
   * https://cloud.google.com/storage/docs/access-control/signed-urls
   */
  generateDownloadUrl(
    request: GenerateDownloadUrlRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<GenerateDownloadUrlResponse>>;
  /**
   * Sets the IAM access control policy on the specified function.
   * Replaces any existing policy.
   */
  setIamPolicy(request: SetIamPolicyRequest, context: CallContext & CallContextExt): Promise<DeepPartial<Policy>>;
  /**
   * Gets the IAM access control policy for a function.
   * Returns an empty policy if the function exists and does not have a policy
   * set.
   */
  getIamPolicy(request: GetIamPolicyRequest, context: CallContext & CallContextExt): Promise<DeepPartial<Policy>>;
  /**
   * Tests the specified permissions against the IAM access control policy
   * for a function.
   * If the function does not exist, this will return an empty set of
   * permissions, not a NOT_FOUND error.
   */
  testIamPermissions(
    request: TestIamPermissionsRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<TestIamPermissionsResponse>>;
}

export interface CloudFunctionsServiceClient<CallOptionsExt = {}> {
  /** Returns a list of functions that belong to the requested project. */
  listFunctions(
    request: DeepPartial<ListFunctionsRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<ListFunctionsResponse>;
  /** Returns a function with the given name from the requested project. */
  getFunction(request: DeepPartial<GetFunctionRequest>, options?: CallOptions & CallOptionsExt): Promise<CloudFunction>;
  /**
   * Creates a new function. If a function with the given name already exists in
   * the specified project, the long running operation will return
   * `ALREADY_EXISTS` error.
   */
  createFunction(
    request: DeepPartial<CreateFunctionRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<Operation>;
  /** Updates existing function. */
  updateFunction(
    request: DeepPartial<UpdateFunctionRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<Operation>;
  /**
   * Deletes a function with the given name from the specified project. If the
   * given function is used by some trigger, the trigger will be updated to
   * remove this function.
   */
  deleteFunction(
    request: DeepPartial<DeleteFunctionRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<Operation>;
  /**
   * Synchronously invokes a deployed Cloud Function. To be used for testing
   * purposes as very limited traffic is allowed. For more information on
   * the actual limits, refer to
   * [Rate Limits](https://cloud.google.com/functions/quotas#rate_limits).
   */
  callFunction(
    request: DeepPartial<CallFunctionRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<CallFunctionResponse>;
  /**
   * Returns a signed URL for uploading a function source code.
   * For more information about the signed URL usage see:
   * https://cloud.google.com/storage/docs/access-control/signed-urls.
   * Once the function source code upload is complete, the used signed
   * URL should be provided in CreateFunction or UpdateFunction request
   * as a reference to the function source code.
   *
   * When uploading source code to the generated signed URL, please follow
   * these restrictions:
   *
   * * Source file type should be a zip file.
   * * Source file size should not exceed 100MB limit.
   * * No credentials should be attached - the signed URLs provide access to the
   *   target bucket using internal service identity; if credentials were
   *   attached, the identity from the credentials would be used, but that
   *   identity does not have permissions to upload files to the URL.
   *
   * When making a HTTP PUT request, these two headers need to be specified:
   *
   * * `content-type: application/zip`
   * * `x-goog-content-length-range: 0,104857600`
   *
   * And this header SHOULD NOT be specified:
   *
   * * `Authorization: Bearer YOUR_TOKEN`
   */
  generateUploadUrl(
    request: DeepPartial<GenerateUploadUrlRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<GenerateUploadUrlResponse>;
  /**
   * Returns a signed URL for downloading deployed function source code.
   * The URL is only valid for a limited period and should be used within
   * minutes after generation.
   * For more information about the signed URL usage see:
   * https://cloud.google.com/storage/docs/access-control/signed-urls
   */
  generateDownloadUrl(
    request: DeepPartial<GenerateDownloadUrlRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<GenerateDownloadUrlResponse>;
  /**
   * Sets the IAM access control policy on the specified function.
   * Replaces any existing policy.
   */
  setIamPolicy(request: DeepPartial<SetIamPolicyRequest>, options?: CallOptions & CallOptionsExt): Promise<Policy>;
  /**
   * Gets the IAM access control policy for a function.
   * Returns an empty policy if the function exists and does not have a policy
   * set.
   */
  getIamPolicy(request: DeepPartial<GetIamPolicyRequest>, options?: CallOptions & CallOptionsExt): Promise<Policy>;
  /**
   * Tests the specified permissions against the IAM access control policy
   * for a function.
   * If the function does not exist, this will return an empty set of
   * permissions, not a NOT_FOUND error.
   */
  testIamPermissions(
    request: DeepPartial<TestIamPermissionsRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<TestIamPermissionsResponse>;
}

type Builtin = Date | Function | Uint8Array | string | number | boolean | undefined;

export type DeepPartial<T> = T extends Builtin ? T
  : T extends Long ? string | number | Long : T extends globalThis.Array<infer U> ? globalThis.Array<DeepPartial<U>>
  : T extends ReadonlyArray<infer U> ? ReadonlyArray<DeepPartial<U>>
  : T extends {} ? { [K in keyof T]?: DeepPartial<T[K]> }
  : Partial<T>;

function toTimestamp(date: Date): Timestamp {
  const seconds = numberToLong(Math.trunc(date.getTime() / 1_000));
  const nanos = (date.getTime() % 1_000) * 1_000_000;
  return { seconds, nanos };
}

function fromTimestamp(t: Timestamp): Date {
  let millis = (t.seconds.toNumber() || 0) * 1_000;
  millis += (t.nanos || 0) / 1_000_000;
  return new globalThis.Date(millis);
}

function fromJsonTimestamp(o: any): Date {
  if (o instanceof globalThis.Date) {
    return o;
  } else if (typeof o === "string") {
    return new globalThis.Date(o);
  } else {
    return fromTimestamp(Timestamp.fromJSON(o));
  }
}

function numberToLong(number: number) {
  return Long.fromNumber(number);
}

function isObject(value: any): boolean {
  return typeof value === "object" && value !== null;
}

function isSet(value: any): boolean {
  return value !== null && value !== undefined;
}

export interface MessageFns<T> {
  encode(message: T, writer?: BinaryWriter): BinaryWriter;
  decode(input: BinaryReader | Uint8Array, length?: number): T;
  fromJSON(object: any): T;
  toJSON(message: T): unknown;
  create(base?: DeepPartial<T>): T;
  fromPartial(object: DeepPartial<T>): T;
}
