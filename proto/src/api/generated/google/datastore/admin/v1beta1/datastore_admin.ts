// Code generated by protoc-gen-ts_proto. DO NOT EDIT.
// versions:
//   protoc-gen-ts_proto  v2.2.0
//   protoc               unknown
// source: google/datastore/admin/v1beta1/datastore_admin.proto

/* eslint-disable */
import { BinaryReader, BinaryWriter } from "@bufbuild/protobuf/wire";
import Long from "long";
import { type CallContext, type CallOptions } from "nice-grpc-common";
import { Operation } from "../../../longrunning/operations.js";
import { Timestamp } from "../../../protobuf/timestamp.js";

export const protobufPackage = "google.datastore.admin.v1beta1";

/** Operation types. */
export enum OperationType {
  /** OPERATION_TYPE_UNSPECIFIED - Unspecified. */
  OPERATION_TYPE_UNSPECIFIED = 0,
  /** EXPORT_ENTITIES - ExportEntities. */
  EXPORT_ENTITIES = 1,
  /** IMPORT_ENTITIES - ImportEntities. */
  IMPORT_ENTITIES = 2,
  UNRECOGNIZED = -1,
}

export function operationTypeFromJSON(object: any): OperationType {
  switch (object) {
    case 0:
    case "OPERATION_TYPE_UNSPECIFIED":
      return OperationType.OPERATION_TYPE_UNSPECIFIED;
    case 1:
    case "EXPORT_ENTITIES":
      return OperationType.EXPORT_ENTITIES;
    case 2:
    case "IMPORT_ENTITIES":
      return OperationType.IMPORT_ENTITIES;
    case -1:
    case "UNRECOGNIZED":
    default:
      return OperationType.UNRECOGNIZED;
  }
}

export function operationTypeToJSON(object: OperationType): string {
  switch (object) {
    case OperationType.OPERATION_TYPE_UNSPECIFIED:
      return "OPERATION_TYPE_UNSPECIFIED";
    case OperationType.EXPORT_ENTITIES:
      return "EXPORT_ENTITIES";
    case OperationType.IMPORT_ENTITIES:
      return "IMPORT_ENTITIES";
    case OperationType.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/** Metadata common to all Datastore Admin operations. */
export interface CommonMetadata {
  /** The time that work began on the operation. */
  startTime:
    | Date
    | undefined;
  /** The time the operation ended, either successfully or otherwise. */
  endTime:
    | Date
    | undefined;
  /**
   * The type of the operation. Can be used as a filter in
   * ListOperationsRequest.
   */
  operationType: OperationType;
  /**
   * The client-assigned labels which were provided when the operation was
   * created. May also include additional labels.
   */
  labels: { [key: string]: string };
  /** The current state of the Operation. */
  state: CommonMetadata_State;
}

/** The various possible states for an ongoing Operation. */
export enum CommonMetadata_State {
  /** STATE_UNSPECIFIED - Unspecified. */
  STATE_UNSPECIFIED = 0,
  /** INITIALIZING - Request is being prepared for processing. */
  INITIALIZING = 1,
  /** PROCESSING - Request is actively being processed. */
  PROCESSING = 2,
  /**
   * CANCELLING - Request is in the process of being cancelled after user called
   * google.longrunning.Operations.CancelOperation on the operation.
   */
  CANCELLING = 3,
  /** FINALIZING - Request has been processed and is in its finalization stage. */
  FINALIZING = 4,
  /** SUCCESSFUL - Request has completed successfully. */
  SUCCESSFUL = 5,
  /** FAILED - Request has finished being processed, but encountered an error. */
  FAILED = 6,
  /**
   * CANCELLED - Request has finished being cancelled after user called
   * google.longrunning.Operations.CancelOperation.
   */
  CANCELLED = 7,
  UNRECOGNIZED = -1,
}

export function commonMetadata_StateFromJSON(object: any): CommonMetadata_State {
  switch (object) {
    case 0:
    case "STATE_UNSPECIFIED":
      return CommonMetadata_State.STATE_UNSPECIFIED;
    case 1:
    case "INITIALIZING":
      return CommonMetadata_State.INITIALIZING;
    case 2:
    case "PROCESSING":
      return CommonMetadata_State.PROCESSING;
    case 3:
    case "CANCELLING":
      return CommonMetadata_State.CANCELLING;
    case 4:
    case "FINALIZING":
      return CommonMetadata_State.FINALIZING;
    case 5:
    case "SUCCESSFUL":
      return CommonMetadata_State.SUCCESSFUL;
    case 6:
    case "FAILED":
      return CommonMetadata_State.FAILED;
    case 7:
    case "CANCELLED":
      return CommonMetadata_State.CANCELLED;
    case -1:
    case "UNRECOGNIZED":
    default:
      return CommonMetadata_State.UNRECOGNIZED;
  }
}

export function commonMetadata_StateToJSON(object: CommonMetadata_State): string {
  switch (object) {
    case CommonMetadata_State.STATE_UNSPECIFIED:
      return "STATE_UNSPECIFIED";
    case CommonMetadata_State.INITIALIZING:
      return "INITIALIZING";
    case CommonMetadata_State.PROCESSING:
      return "PROCESSING";
    case CommonMetadata_State.CANCELLING:
      return "CANCELLING";
    case CommonMetadata_State.FINALIZING:
      return "FINALIZING";
    case CommonMetadata_State.SUCCESSFUL:
      return "SUCCESSFUL";
    case CommonMetadata_State.FAILED:
      return "FAILED";
    case CommonMetadata_State.CANCELLED:
      return "CANCELLED";
    case CommonMetadata_State.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

export interface CommonMetadata_LabelsEntry {
  key: string;
  value: string;
}

/** Measures the progress of a particular metric. */
export interface Progress {
  /**
   * The amount of work that has been completed. Note that this may be greater
   * than work_estimated.
   */
  workCompleted: Long;
  /**
   * An estimate of how much work needs to be performed. May be zero if the
   * work estimate is unavailable.
   */
  workEstimated: Long;
}

/**
 * The request for
 * [google.datastore.admin.v1beta1.DatastoreAdmin.ExportEntities][google.datastore.admin.v1beta1.DatastoreAdmin.ExportEntities].
 */
export interface ExportEntitiesRequest {
  /** Project ID against which to make the request. */
  projectId: string;
  /** Client-assigned labels. */
  labels: { [key: string]: string };
  /** Description of what data from the project is included in the export. */
  entityFilter:
    | EntityFilter
    | undefined;
  /**
   * Location for the export metadata and data files.
   *
   * The full resource URL of the external storage location. Currently, only
   * Google Cloud Storage is supported. So output_url_prefix should be of the
   * form: `gs://BUCKET_NAME[/NAMESPACE_PATH]`, where `BUCKET_NAME` is the
   * name of the Cloud Storage bucket and `NAMESPACE_PATH` is an optional Cloud
   * Storage namespace path (this is not a Cloud Datastore namespace). For more
   * information about Cloud Storage namespace paths, see
   * [Object name
   * considerations](https://cloud.google.com/storage/docs/naming#object-considerations).
   *
   * The resulting files will be nested deeper than the specified URL prefix.
   * The final output URL will be provided in the
   * [google.datastore.admin.v1beta1.ExportEntitiesResponse.output_url][google.datastore.admin.v1beta1.ExportEntitiesResponse.output_url]
   * field. That value should be used for subsequent ImportEntities operations.
   *
   * By nesting the data files deeper, the same Cloud Storage bucket can be used
   * in multiple ExportEntities operations without conflict.
   */
  outputUrlPrefix: string;
}

export interface ExportEntitiesRequest_LabelsEntry {
  key: string;
  value: string;
}

/**
 * The request for
 * [google.datastore.admin.v1beta1.DatastoreAdmin.ImportEntities][google.datastore.admin.v1beta1.DatastoreAdmin.ImportEntities].
 */
export interface ImportEntitiesRequest {
  /** Project ID against which to make the request. */
  projectId: string;
  /** Client-assigned labels. */
  labels: { [key: string]: string };
  /**
   * The full resource URL of the external storage location. Currently, only
   * Google Cloud Storage is supported. So input_url should be of the form:
   * `gs://BUCKET_NAME[/NAMESPACE_PATH]/OVERALL_EXPORT_METADATA_FILE`, where
   * `BUCKET_NAME` is the name of the Cloud Storage bucket, `NAMESPACE_PATH` is
   * an optional Cloud Storage namespace path (this is not a Cloud Datastore
   * namespace), and `OVERALL_EXPORT_METADATA_FILE` is the metadata file written
   * by the ExportEntities operation. For more information about Cloud Storage
   * namespace paths, see
   * [Object name
   * considerations](https://cloud.google.com/storage/docs/naming#object-considerations).
   *
   * For more information, see
   * [google.datastore.admin.v1beta1.ExportEntitiesResponse.output_url][google.datastore.admin.v1beta1.ExportEntitiesResponse.output_url].
   */
  inputUrl: string;
  /**
   * Optionally specify which kinds/namespaces are to be imported. If provided,
   * the list must be a subset of the EntityFilter used in creating the export,
   * otherwise a FAILED_PRECONDITION error will be returned. If no filter is
   * specified then all entities from the export are imported.
   */
  entityFilter: EntityFilter | undefined;
}

export interface ImportEntitiesRequest_LabelsEntry {
  key: string;
  value: string;
}

/**
 * The response for
 * [google.datastore.admin.v1beta1.DatastoreAdmin.ExportEntities][google.datastore.admin.v1beta1.DatastoreAdmin.ExportEntities].
 */
export interface ExportEntitiesResponse {
  /**
   * Location of the output metadata file. This can be used to begin an import
   * into Cloud Datastore (this project or another project). See
   * [google.datastore.admin.v1beta1.ImportEntitiesRequest.input_url][google.datastore.admin.v1beta1.ImportEntitiesRequest.input_url].
   * Only present if the operation completed successfully.
   */
  outputUrl: string;
}

/** Metadata for ExportEntities operations. */
export interface ExportEntitiesMetadata {
  /** Metadata common to all Datastore Admin operations. */
  common:
    | CommonMetadata
    | undefined;
  /** An estimate of the number of entities processed. */
  progressEntities:
    | Progress
    | undefined;
  /** An estimate of the number of bytes processed. */
  progressBytes:
    | Progress
    | undefined;
  /** Description of which entities are being exported. */
  entityFilter:
    | EntityFilter
    | undefined;
  /**
   * Location for the export metadata and data files. This will be the same
   * value as the
   * [google.datastore.admin.v1beta1.ExportEntitiesRequest.output_url_prefix][google.datastore.admin.v1beta1.ExportEntitiesRequest.output_url_prefix]
   * field. The final output location is provided in
   * [google.datastore.admin.v1beta1.ExportEntitiesResponse.output_url][google.datastore.admin.v1beta1.ExportEntitiesResponse.output_url].
   */
  outputUrlPrefix: string;
}

/** Metadata for ImportEntities operations. */
export interface ImportEntitiesMetadata {
  /** Metadata common to all Datastore Admin operations. */
  common:
    | CommonMetadata
    | undefined;
  /** An estimate of the number of entities processed. */
  progressEntities:
    | Progress
    | undefined;
  /** An estimate of the number of bytes processed. */
  progressBytes:
    | Progress
    | undefined;
  /** Description of which entities are being imported. */
  entityFilter:
    | EntityFilter
    | undefined;
  /**
   * The location of the import metadata file. This will be the same value as
   * the
   * [google.datastore.admin.v1beta1.ExportEntitiesResponse.output_url][google.datastore.admin.v1beta1.ExportEntitiesResponse.output_url]
   * field.
   */
  inputUrl: string;
}

/**
 * Identifies a subset of entities in a project. This is specified as
 * combinations of kinds and namespaces (either or both of which may be all, as
 * described in the following examples).
 * Example usage:
 *
 * Entire project:
 *   kinds=[], namespace_ids=[]
 *
 * Kinds Foo and Bar in all namespaces:
 *   kinds=['Foo', 'Bar'], namespace_ids=[]
 *
 * Kinds Foo and Bar only in the default namespace:
 *   kinds=['Foo', 'Bar'], namespace_ids=['']
 *
 * Kinds Foo and Bar in both the default and Baz namespaces:
 *   kinds=['Foo', 'Bar'], namespace_ids=['', 'Baz']
 *
 * The entire Baz namespace:
 *   kinds=[], namespace_ids=['Baz']
 */
export interface EntityFilter {
  /** If empty, then this represents all kinds. */
  kinds: string[];
  /**
   * An empty list represents all namespaces. This is the preferred
   * usage for projects that don't use namespaces.
   *
   * An empty string element represents the default namespace. This should be
   * used if the project has data in non-default namespaces, but doesn't want to
   * include them.
   * Each namespace in this list must be unique.
   */
  namespaceIds: string[];
}

function createBaseCommonMetadata(): CommonMetadata {
  return { startTime: undefined, endTime: undefined, operationType: 0, labels: {}, state: 0 };
}

export const CommonMetadata: MessageFns<CommonMetadata> = {
  encode(message: CommonMetadata, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.startTime !== undefined) {
      Timestamp.encode(toTimestamp(message.startTime), writer.uint32(10).fork()).join();
    }
    if (message.endTime !== undefined) {
      Timestamp.encode(toTimestamp(message.endTime), writer.uint32(18).fork()).join();
    }
    if (message.operationType !== 0) {
      writer.uint32(24).int32(message.operationType);
    }
    Object.entries(message.labels).forEach(([key, value]) => {
      CommonMetadata_LabelsEntry.encode({ key: key as any, value }, writer.uint32(34).fork()).join();
    });
    if (message.state !== 0) {
      writer.uint32(40).int32(message.state);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): CommonMetadata {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseCommonMetadata();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.startTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.endTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        case 3:
          if (tag !== 24) {
            break;
          }

          message.operationType = reader.int32() as any;
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          const entry4 = CommonMetadata_LabelsEntry.decode(reader, reader.uint32());
          if (entry4.value !== undefined) {
            message.labels[entry4.key] = entry4.value;
          }
          continue;
        case 5:
          if (tag !== 40) {
            break;
          }

          message.state = reader.int32() as any;
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): CommonMetadata {
    return {
      startTime: isSet(object.startTime) ? fromJsonTimestamp(object.startTime) : undefined,
      endTime: isSet(object.endTime) ? fromJsonTimestamp(object.endTime) : undefined,
      operationType: isSet(object.operationType) ? operationTypeFromJSON(object.operationType) : 0,
      labels: isObject(object.labels)
        ? Object.entries(object.labels).reduce<{ [key: string]: string }>((acc, [key, value]) => {
          acc[key] = String(value);
          return acc;
        }, {})
        : {},
      state: isSet(object.state) ? commonMetadata_StateFromJSON(object.state) : 0,
    };
  },

  toJSON(message: CommonMetadata): unknown {
    const obj: any = {};
    if (message.startTime !== undefined) {
      obj.startTime = message.startTime.toISOString();
    }
    if (message.endTime !== undefined) {
      obj.endTime = message.endTime.toISOString();
    }
    if (message.operationType !== 0) {
      obj.operationType = operationTypeToJSON(message.operationType);
    }
    if (message.labels) {
      const entries = Object.entries(message.labels);
      if (entries.length > 0) {
        obj.labels = {};
        entries.forEach(([k, v]) => {
          obj.labels[k] = v;
        });
      }
    }
    if (message.state !== 0) {
      obj.state = commonMetadata_StateToJSON(message.state);
    }
    return obj;
  },

  create(base?: DeepPartial<CommonMetadata>): CommonMetadata {
    return CommonMetadata.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<CommonMetadata>): CommonMetadata {
    const message = createBaseCommonMetadata();
    message.startTime = object.startTime ?? undefined;
    message.endTime = object.endTime ?? undefined;
    message.operationType = object.operationType ?? 0;
    message.labels = Object.entries(object.labels ?? {}).reduce<{ [key: string]: string }>((acc, [key, value]) => {
      if (value !== undefined) {
        acc[key] = globalThis.String(value);
      }
      return acc;
    }, {});
    message.state = object.state ?? 0;
    return message;
  },
};

function createBaseCommonMetadata_LabelsEntry(): CommonMetadata_LabelsEntry {
  return { key: "", value: "" };
}

export const CommonMetadata_LabelsEntry: MessageFns<CommonMetadata_LabelsEntry> = {
  encode(message: CommonMetadata_LabelsEntry, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.key !== "") {
      writer.uint32(10).string(message.key);
    }
    if (message.value !== "") {
      writer.uint32(18).string(message.value);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): CommonMetadata_LabelsEntry {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseCommonMetadata_LabelsEntry();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.key = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.value = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): CommonMetadata_LabelsEntry {
    return {
      key: isSet(object.key) ? globalThis.String(object.key) : "",
      value: isSet(object.value) ? globalThis.String(object.value) : "",
    };
  },

  toJSON(message: CommonMetadata_LabelsEntry): unknown {
    const obj: any = {};
    if (message.key !== "") {
      obj.key = message.key;
    }
    if (message.value !== "") {
      obj.value = message.value;
    }
    return obj;
  },

  create(base?: DeepPartial<CommonMetadata_LabelsEntry>): CommonMetadata_LabelsEntry {
    return CommonMetadata_LabelsEntry.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<CommonMetadata_LabelsEntry>): CommonMetadata_LabelsEntry {
    const message = createBaseCommonMetadata_LabelsEntry();
    message.key = object.key ?? "";
    message.value = object.value ?? "";
    return message;
  },
};

function createBaseProgress(): Progress {
  return { workCompleted: Long.ZERO, workEstimated: Long.ZERO };
}

export const Progress: MessageFns<Progress> = {
  encode(message: Progress, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (!message.workCompleted.equals(Long.ZERO)) {
      writer.uint32(8).int64(message.workCompleted.toString());
    }
    if (!message.workEstimated.equals(Long.ZERO)) {
      writer.uint32(16).int64(message.workEstimated.toString());
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Progress {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseProgress();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 8) {
            break;
          }

          message.workCompleted = Long.fromString(reader.int64().toString());
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.workEstimated = Long.fromString(reader.int64().toString());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Progress {
    return {
      workCompleted: isSet(object.workCompleted) ? Long.fromValue(object.workCompleted) : Long.ZERO,
      workEstimated: isSet(object.workEstimated) ? Long.fromValue(object.workEstimated) : Long.ZERO,
    };
  },

  toJSON(message: Progress): unknown {
    const obj: any = {};
    if (!message.workCompleted.equals(Long.ZERO)) {
      obj.workCompleted = (message.workCompleted || Long.ZERO).toString();
    }
    if (!message.workEstimated.equals(Long.ZERO)) {
      obj.workEstimated = (message.workEstimated || Long.ZERO).toString();
    }
    return obj;
  },

  create(base?: DeepPartial<Progress>): Progress {
    return Progress.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<Progress>): Progress {
    const message = createBaseProgress();
    message.workCompleted = (object.workCompleted !== undefined && object.workCompleted !== null)
      ? Long.fromValue(object.workCompleted)
      : Long.ZERO;
    message.workEstimated = (object.workEstimated !== undefined && object.workEstimated !== null)
      ? Long.fromValue(object.workEstimated)
      : Long.ZERO;
    return message;
  },
};

function createBaseExportEntitiesRequest(): ExportEntitiesRequest {
  return { projectId: "", labels: {}, entityFilter: undefined, outputUrlPrefix: "" };
}

export const ExportEntitiesRequest: MessageFns<ExportEntitiesRequest> = {
  encode(message: ExportEntitiesRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.projectId !== "") {
      writer.uint32(10).string(message.projectId);
    }
    Object.entries(message.labels).forEach(([key, value]) => {
      ExportEntitiesRequest_LabelsEntry.encode({ key: key as any, value }, writer.uint32(18).fork()).join();
    });
    if (message.entityFilter !== undefined) {
      EntityFilter.encode(message.entityFilter, writer.uint32(26).fork()).join();
    }
    if (message.outputUrlPrefix !== "") {
      writer.uint32(34).string(message.outputUrlPrefix);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ExportEntitiesRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseExportEntitiesRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.projectId = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          const entry2 = ExportEntitiesRequest_LabelsEntry.decode(reader, reader.uint32());
          if (entry2.value !== undefined) {
            message.labels[entry2.key] = entry2.value;
          }
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.entityFilter = EntityFilter.decode(reader, reader.uint32());
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.outputUrlPrefix = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ExportEntitiesRequest {
    return {
      projectId: isSet(object.projectId) ? globalThis.String(object.projectId) : "",
      labels: isObject(object.labels)
        ? Object.entries(object.labels).reduce<{ [key: string]: string }>((acc, [key, value]) => {
          acc[key] = String(value);
          return acc;
        }, {})
        : {},
      entityFilter: isSet(object.entityFilter) ? EntityFilter.fromJSON(object.entityFilter) : undefined,
      outputUrlPrefix: isSet(object.outputUrlPrefix) ? globalThis.String(object.outputUrlPrefix) : "",
    };
  },

  toJSON(message: ExportEntitiesRequest): unknown {
    const obj: any = {};
    if (message.projectId !== "") {
      obj.projectId = message.projectId;
    }
    if (message.labels) {
      const entries = Object.entries(message.labels);
      if (entries.length > 0) {
        obj.labels = {};
        entries.forEach(([k, v]) => {
          obj.labels[k] = v;
        });
      }
    }
    if (message.entityFilter !== undefined) {
      obj.entityFilter = EntityFilter.toJSON(message.entityFilter);
    }
    if (message.outputUrlPrefix !== "") {
      obj.outputUrlPrefix = message.outputUrlPrefix;
    }
    return obj;
  },

  create(base?: DeepPartial<ExportEntitiesRequest>): ExportEntitiesRequest {
    return ExportEntitiesRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ExportEntitiesRequest>): ExportEntitiesRequest {
    const message = createBaseExportEntitiesRequest();
    message.projectId = object.projectId ?? "";
    message.labels = Object.entries(object.labels ?? {}).reduce<{ [key: string]: string }>((acc, [key, value]) => {
      if (value !== undefined) {
        acc[key] = globalThis.String(value);
      }
      return acc;
    }, {});
    message.entityFilter = (object.entityFilter !== undefined && object.entityFilter !== null)
      ? EntityFilter.fromPartial(object.entityFilter)
      : undefined;
    message.outputUrlPrefix = object.outputUrlPrefix ?? "";
    return message;
  },
};

function createBaseExportEntitiesRequest_LabelsEntry(): ExportEntitiesRequest_LabelsEntry {
  return { key: "", value: "" };
}

export const ExportEntitiesRequest_LabelsEntry: MessageFns<ExportEntitiesRequest_LabelsEntry> = {
  encode(message: ExportEntitiesRequest_LabelsEntry, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.key !== "") {
      writer.uint32(10).string(message.key);
    }
    if (message.value !== "") {
      writer.uint32(18).string(message.value);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ExportEntitiesRequest_LabelsEntry {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseExportEntitiesRequest_LabelsEntry();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.key = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.value = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ExportEntitiesRequest_LabelsEntry {
    return {
      key: isSet(object.key) ? globalThis.String(object.key) : "",
      value: isSet(object.value) ? globalThis.String(object.value) : "",
    };
  },

  toJSON(message: ExportEntitiesRequest_LabelsEntry): unknown {
    const obj: any = {};
    if (message.key !== "") {
      obj.key = message.key;
    }
    if (message.value !== "") {
      obj.value = message.value;
    }
    return obj;
  },

  create(base?: DeepPartial<ExportEntitiesRequest_LabelsEntry>): ExportEntitiesRequest_LabelsEntry {
    return ExportEntitiesRequest_LabelsEntry.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ExportEntitiesRequest_LabelsEntry>): ExportEntitiesRequest_LabelsEntry {
    const message = createBaseExportEntitiesRequest_LabelsEntry();
    message.key = object.key ?? "";
    message.value = object.value ?? "";
    return message;
  },
};

function createBaseImportEntitiesRequest(): ImportEntitiesRequest {
  return { projectId: "", labels: {}, inputUrl: "", entityFilter: undefined };
}

export const ImportEntitiesRequest: MessageFns<ImportEntitiesRequest> = {
  encode(message: ImportEntitiesRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.projectId !== "") {
      writer.uint32(10).string(message.projectId);
    }
    Object.entries(message.labels).forEach(([key, value]) => {
      ImportEntitiesRequest_LabelsEntry.encode({ key: key as any, value }, writer.uint32(18).fork()).join();
    });
    if (message.inputUrl !== "") {
      writer.uint32(26).string(message.inputUrl);
    }
    if (message.entityFilter !== undefined) {
      EntityFilter.encode(message.entityFilter, writer.uint32(34).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ImportEntitiesRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseImportEntitiesRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.projectId = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          const entry2 = ImportEntitiesRequest_LabelsEntry.decode(reader, reader.uint32());
          if (entry2.value !== undefined) {
            message.labels[entry2.key] = entry2.value;
          }
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.inputUrl = reader.string();
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.entityFilter = EntityFilter.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ImportEntitiesRequest {
    return {
      projectId: isSet(object.projectId) ? globalThis.String(object.projectId) : "",
      labels: isObject(object.labels)
        ? Object.entries(object.labels).reduce<{ [key: string]: string }>((acc, [key, value]) => {
          acc[key] = String(value);
          return acc;
        }, {})
        : {},
      inputUrl: isSet(object.inputUrl) ? globalThis.String(object.inputUrl) : "",
      entityFilter: isSet(object.entityFilter) ? EntityFilter.fromJSON(object.entityFilter) : undefined,
    };
  },

  toJSON(message: ImportEntitiesRequest): unknown {
    const obj: any = {};
    if (message.projectId !== "") {
      obj.projectId = message.projectId;
    }
    if (message.labels) {
      const entries = Object.entries(message.labels);
      if (entries.length > 0) {
        obj.labels = {};
        entries.forEach(([k, v]) => {
          obj.labels[k] = v;
        });
      }
    }
    if (message.inputUrl !== "") {
      obj.inputUrl = message.inputUrl;
    }
    if (message.entityFilter !== undefined) {
      obj.entityFilter = EntityFilter.toJSON(message.entityFilter);
    }
    return obj;
  },

  create(base?: DeepPartial<ImportEntitiesRequest>): ImportEntitiesRequest {
    return ImportEntitiesRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ImportEntitiesRequest>): ImportEntitiesRequest {
    const message = createBaseImportEntitiesRequest();
    message.projectId = object.projectId ?? "";
    message.labels = Object.entries(object.labels ?? {}).reduce<{ [key: string]: string }>((acc, [key, value]) => {
      if (value !== undefined) {
        acc[key] = globalThis.String(value);
      }
      return acc;
    }, {});
    message.inputUrl = object.inputUrl ?? "";
    message.entityFilter = (object.entityFilter !== undefined && object.entityFilter !== null)
      ? EntityFilter.fromPartial(object.entityFilter)
      : undefined;
    return message;
  },
};

function createBaseImportEntitiesRequest_LabelsEntry(): ImportEntitiesRequest_LabelsEntry {
  return { key: "", value: "" };
}

export const ImportEntitiesRequest_LabelsEntry: MessageFns<ImportEntitiesRequest_LabelsEntry> = {
  encode(message: ImportEntitiesRequest_LabelsEntry, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.key !== "") {
      writer.uint32(10).string(message.key);
    }
    if (message.value !== "") {
      writer.uint32(18).string(message.value);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ImportEntitiesRequest_LabelsEntry {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseImportEntitiesRequest_LabelsEntry();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.key = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.value = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ImportEntitiesRequest_LabelsEntry {
    return {
      key: isSet(object.key) ? globalThis.String(object.key) : "",
      value: isSet(object.value) ? globalThis.String(object.value) : "",
    };
  },

  toJSON(message: ImportEntitiesRequest_LabelsEntry): unknown {
    const obj: any = {};
    if (message.key !== "") {
      obj.key = message.key;
    }
    if (message.value !== "") {
      obj.value = message.value;
    }
    return obj;
  },

  create(base?: DeepPartial<ImportEntitiesRequest_LabelsEntry>): ImportEntitiesRequest_LabelsEntry {
    return ImportEntitiesRequest_LabelsEntry.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ImportEntitiesRequest_LabelsEntry>): ImportEntitiesRequest_LabelsEntry {
    const message = createBaseImportEntitiesRequest_LabelsEntry();
    message.key = object.key ?? "";
    message.value = object.value ?? "";
    return message;
  },
};

function createBaseExportEntitiesResponse(): ExportEntitiesResponse {
  return { outputUrl: "" };
}

export const ExportEntitiesResponse: MessageFns<ExportEntitiesResponse> = {
  encode(message: ExportEntitiesResponse, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.outputUrl !== "") {
      writer.uint32(10).string(message.outputUrl);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ExportEntitiesResponse {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseExportEntitiesResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.outputUrl = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ExportEntitiesResponse {
    return { outputUrl: isSet(object.outputUrl) ? globalThis.String(object.outputUrl) : "" };
  },

  toJSON(message: ExportEntitiesResponse): unknown {
    const obj: any = {};
    if (message.outputUrl !== "") {
      obj.outputUrl = message.outputUrl;
    }
    return obj;
  },

  create(base?: DeepPartial<ExportEntitiesResponse>): ExportEntitiesResponse {
    return ExportEntitiesResponse.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ExportEntitiesResponse>): ExportEntitiesResponse {
    const message = createBaseExportEntitiesResponse();
    message.outputUrl = object.outputUrl ?? "";
    return message;
  },
};

function createBaseExportEntitiesMetadata(): ExportEntitiesMetadata {
  return {
    common: undefined,
    progressEntities: undefined,
    progressBytes: undefined,
    entityFilter: undefined,
    outputUrlPrefix: "",
  };
}

export const ExportEntitiesMetadata: MessageFns<ExportEntitiesMetadata> = {
  encode(message: ExportEntitiesMetadata, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.common !== undefined) {
      CommonMetadata.encode(message.common, writer.uint32(10).fork()).join();
    }
    if (message.progressEntities !== undefined) {
      Progress.encode(message.progressEntities, writer.uint32(18).fork()).join();
    }
    if (message.progressBytes !== undefined) {
      Progress.encode(message.progressBytes, writer.uint32(26).fork()).join();
    }
    if (message.entityFilter !== undefined) {
      EntityFilter.encode(message.entityFilter, writer.uint32(34).fork()).join();
    }
    if (message.outputUrlPrefix !== "") {
      writer.uint32(42).string(message.outputUrlPrefix);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ExportEntitiesMetadata {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseExportEntitiesMetadata();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.common = CommonMetadata.decode(reader, reader.uint32());
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.progressEntities = Progress.decode(reader, reader.uint32());
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.progressBytes = Progress.decode(reader, reader.uint32());
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.entityFilter = EntityFilter.decode(reader, reader.uint32());
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.outputUrlPrefix = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ExportEntitiesMetadata {
    return {
      common: isSet(object.common) ? CommonMetadata.fromJSON(object.common) : undefined,
      progressEntities: isSet(object.progressEntities) ? Progress.fromJSON(object.progressEntities) : undefined,
      progressBytes: isSet(object.progressBytes) ? Progress.fromJSON(object.progressBytes) : undefined,
      entityFilter: isSet(object.entityFilter) ? EntityFilter.fromJSON(object.entityFilter) : undefined,
      outputUrlPrefix: isSet(object.outputUrlPrefix) ? globalThis.String(object.outputUrlPrefix) : "",
    };
  },

  toJSON(message: ExportEntitiesMetadata): unknown {
    const obj: any = {};
    if (message.common !== undefined) {
      obj.common = CommonMetadata.toJSON(message.common);
    }
    if (message.progressEntities !== undefined) {
      obj.progressEntities = Progress.toJSON(message.progressEntities);
    }
    if (message.progressBytes !== undefined) {
      obj.progressBytes = Progress.toJSON(message.progressBytes);
    }
    if (message.entityFilter !== undefined) {
      obj.entityFilter = EntityFilter.toJSON(message.entityFilter);
    }
    if (message.outputUrlPrefix !== "") {
      obj.outputUrlPrefix = message.outputUrlPrefix;
    }
    return obj;
  },

  create(base?: DeepPartial<ExportEntitiesMetadata>): ExportEntitiesMetadata {
    return ExportEntitiesMetadata.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ExportEntitiesMetadata>): ExportEntitiesMetadata {
    const message = createBaseExportEntitiesMetadata();
    message.common = (object.common !== undefined && object.common !== null)
      ? CommonMetadata.fromPartial(object.common)
      : undefined;
    message.progressEntities = (object.progressEntities !== undefined && object.progressEntities !== null)
      ? Progress.fromPartial(object.progressEntities)
      : undefined;
    message.progressBytes = (object.progressBytes !== undefined && object.progressBytes !== null)
      ? Progress.fromPartial(object.progressBytes)
      : undefined;
    message.entityFilter = (object.entityFilter !== undefined && object.entityFilter !== null)
      ? EntityFilter.fromPartial(object.entityFilter)
      : undefined;
    message.outputUrlPrefix = object.outputUrlPrefix ?? "";
    return message;
  },
};

function createBaseImportEntitiesMetadata(): ImportEntitiesMetadata {
  return {
    common: undefined,
    progressEntities: undefined,
    progressBytes: undefined,
    entityFilter: undefined,
    inputUrl: "",
  };
}

export const ImportEntitiesMetadata: MessageFns<ImportEntitiesMetadata> = {
  encode(message: ImportEntitiesMetadata, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.common !== undefined) {
      CommonMetadata.encode(message.common, writer.uint32(10).fork()).join();
    }
    if (message.progressEntities !== undefined) {
      Progress.encode(message.progressEntities, writer.uint32(18).fork()).join();
    }
    if (message.progressBytes !== undefined) {
      Progress.encode(message.progressBytes, writer.uint32(26).fork()).join();
    }
    if (message.entityFilter !== undefined) {
      EntityFilter.encode(message.entityFilter, writer.uint32(34).fork()).join();
    }
    if (message.inputUrl !== "") {
      writer.uint32(42).string(message.inputUrl);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ImportEntitiesMetadata {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseImportEntitiesMetadata();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.common = CommonMetadata.decode(reader, reader.uint32());
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.progressEntities = Progress.decode(reader, reader.uint32());
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.progressBytes = Progress.decode(reader, reader.uint32());
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.entityFilter = EntityFilter.decode(reader, reader.uint32());
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.inputUrl = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ImportEntitiesMetadata {
    return {
      common: isSet(object.common) ? CommonMetadata.fromJSON(object.common) : undefined,
      progressEntities: isSet(object.progressEntities) ? Progress.fromJSON(object.progressEntities) : undefined,
      progressBytes: isSet(object.progressBytes) ? Progress.fromJSON(object.progressBytes) : undefined,
      entityFilter: isSet(object.entityFilter) ? EntityFilter.fromJSON(object.entityFilter) : undefined,
      inputUrl: isSet(object.inputUrl) ? globalThis.String(object.inputUrl) : "",
    };
  },

  toJSON(message: ImportEntitiesMetadata): unknown {
    const obj: any = {};
    if (message.common !== undefined) {
      obj.common = CommonMetadata.toJSON(message.common);
    }
    if (message.progressEntities !== undefined) {
      obj.progressEntities = Progress.toJSON(message.progressEntities);
    }
    if (message.progressBytes !== undefined) {
      obj.progressBytes = Progress.toJSON(message.progressBytes);
    }
    if (message.entityFilter !== undefined) {
      obj.entityFilter = EntityFilter.toJSON(message.entityFilter);
    }
    if (message.inputUrl !== "") {
      obj.inputUrl = message.inputUrl;
    }
    return obj;
  },

  create(base?: DeepPartial<ImportEntitiesMetadata>): ImportEntitiesMetadata {
    return ImportEntitiesMetadata.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ImportEntitiesMetadata>): ImportEntitiesMetadata {
    const message = createBaseImportEntitiesMetadata();
    message.common = (object.common !== undefined && object.common !== null)
      ? CommonMetadata.fromPartial(object.common)
      : undefined;
    message.progressEntities = (object.progressEntities !== undefined && object.progressEntities !== null)
      ? Progress.fromPartial(object.progressEntities)
      : undefined;
    message.progressBytes = (object.progressBytes !== undefined && object.progressBytes !== null)
      ? Progress.fromPartial(object.progressBytes)
      : undefined;
    message.entityFilter = (object.entityFilter !== undefined && object.entityFilter !== null)
      ? EntityFilter.fromPartial(object.entityFilter)
      : undefined;
    message.inputUrl = object.inputUrl ?? "";
    return message;
  },
};

function createBaseEntityFilter(): EntityFilter {
  return { kinds: [], namespaceIds: [] };
}

export const EntityFilter: MessageFns<EntityFilter> = {
  encode(message: EntityFilter, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.kinds) {
      writer.uint32(10).string(v!);
    }
    for (const v of message.namespaceIds) {
      writer.uint32(18).string(v!);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): EntityFilter {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseEntityFilter();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.kinds.push(reader.string());
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.namespaceIds.push(reader.string());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): EntityFilter {
    return {
      kinds: globalThis.Array.isArray(object?.kinds) ? object.kinds.map((e: any) => globalThis.String(e)) : [],
      namespaceIds: globalThis.Array.isArray(object?.namespaceIds)
        ? object.namespaceIds.map((e: any) => globalThis.String(e))
        : [],
    };
  },

  toJSON(message: EntityFilter): unknown {
    const obj: any = {};
    if (message.kinds?.length) {
      obj.kinds = message.kinds;
    }
    if (message.namespaceIds?.length) {
      obj.namespaceIds = message.namespaceIds;
    }
    return obj;
  },

  create(base?: DeepPartial<EntityFilter>): EntityFilter {
    return EntityFilter.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<EntityFilter>): EntityFilter {
    const message = createBaseEntityFilter();
    message.kinds = object.kinds?.map((e) => e) || [];
    message.namespaceIds = object.namespaceIds?.map((e) => e) || [];
    return message;
  },
};

/**
 * Google Cloud Datastore Admin API
 *
 * The Datastore Admin API provides several admin services for Cloud Datastore.
 *
 * -----------------------------------------------------------------------------
 * ## Concepts
 *
 * Project, namespace, kind, and entity as defined in the Google Cloud Datastore
 * API.
 *
 * Operation: An Operation represents work being performed in the background.
 *
 * EntityFilter: Allows specifying a subset of entities in a project. This is
 * specified as a combination of kinds and namespaces (either or both of which
 * may be all).
 *
 * -----------------------------------------------------------------------------
 * ## Services
 *
 * # Export/Import
 *
 * The Export/Import service provides the ability to copy all or a subset of
 * entities to/from Google Cloud Storage.
 *
 * Exported data may be imported into Cloud Datastore for any Google Cloud
 * Platform project. It is not restricted to the export source project. It is
 * possible to export from one project and then import into another.
 *
 * Exported data can also be loaded into Google BigQuery for analysis.
 *
 * Exports and imports are performed asynchronously. An Operation resource is
 * created for each export/import. The state (including any errors encountered)
 * of the export/import may be queried via the Operation resource.
 *
 * # Operation
 *
 * The Operations collection provides a record of actions performed for the
 * specified project (including any operations in progress). Operations are not
 * created directly but through calls on other collections or resources.
 *
 * An operation that is not yet done may be cancelled. The request to cancel is
 * asynchronous and the operation may continue to run for some time after the
 * request to cancel is made.
 *
 * An operation that is done may be deleted so that it is no longer listed as
 * part of the Operation collection.
 *
 * ListOperations returns all pending operations, but not completed operations.
 *
 * Operations are created by service DatastoreAdmin,
 * but are accessed via service google.longrunning.Operations.
 */
export type DatastoreAdminDefinition = typeof DatastoreAdminDefinition;
export const DatastoreAdminDefinition = {
  name: "DatastoreAdmin",
  fullName: "google.datastore.admin.v1beta1.DatastoreAdmin",
  methods: {
    /**
     * Exports a copy of all or a subset of entities from Google Cloud Datastore
     * to another storage system, such as Google Cloud Storage. Recent updates to
     * entities may not be reflected in the export. The export occurs in the
     * background and its progress can be monitored and managed via the
     * Operation resource that is created. The output of an export may only be
     * used once the associated operation is done. If an export operation is
     * cancelled before completion it may leave partial data behind in Google
     * Cloud Storage.
     */
    exportEntities: {
      name: "ExportEntities",
      requestType: ExportEntitiesRequest,
      requestStream: false,
      responseType: Operation,
      responseStream: false,
      options: {
        _unknownFields: {
          578365826: [
            Buffer.from([
              42,
              58,
              1,
              42,
              34,
              37,
              47,
              118,
              49,
              98,
              101,
              116,
              97,
              49,
              47,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              123,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              95,
              105,
              100,
              125,
              58,
              101,
              120,
              112,
              111,
              114,
              116,
            ]),
          ],
        },
      },
    },
    /**
     * Imports entities into Google Cloud Datastore. Existing entities with the
     * same key are overwritten. The import occurs in the background and its
     * progress can be monitored and managed via the Operation resource that is
     * created. If an ImportEntities operation is cancelled, it is possible
     * that a subset of the data has already been imported to Cloud Datastore.
     */
    importEntities: {
      name: "ImportEntities",
      requestType: ImportEntitiesRequest,
      requestStream: false,
      responseType: Operation,
      responseStream: false,
      options: {
        _unknownFields: {
          578365826: [
            Buffer.from([
              42,
              58,
              1,
              42,
              34,
              37,
              47,
              118,
              49,
              98,
              101,
              116,
              97,
              49,
              47,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              123,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              95,
              105,
              100,
              125,
              58,
              105,
              109,
              112,
              111,
              114,
              116,
            ]),
          ],
        },
      },
    },
  },
} as const;

export interface DatastoreAdminServiceImplementation<CallContextExt = {}> {
  /**
   * Exports a copy of all or a subset of entities from Google Cloud Datastore
   * to another storage system, such as Google Cloud Storage. Recent updates to
   * entities may not be reflected in the export. The export occurs in the
   * background and its progress can be monitored and managed via the
   * Operation resource that is created. The output of an export may only be
   * used once the associated operation is done. If an export operation is
   * cancelled before completion it may leave partial data behind in Google
   * Cloud Storage.
   */
  exportEntities(
    request: ExportEntitiesRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<Operation>>;
  /**
   * Imports entities into Google Cloud Datastore. Existing entities with the
   * same key are overwritten. The import occurs in the background and its
   * progress can be monitored and managed via the Operation resource that is
   * created. If an ImportEntities operation is cancelled, it is possible
   * that a subset of the data has already been imported to Cloud Datastore.
   */
  importEntities(
    request: ImportEntitiesRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<Operation>>;
}

export interface DatastoreAdminClient<CallOptionsExt = {}> {
  /**
   * Exports a copy of all or a subset of entities from Google Cloud Datastore
   * to another storage system, such as Google Cloud Storage. Recent updates to
   * entities may not be reflected in the export. The export occurs in the
   * background and its progress can be monitored and managed via the
   * Operation resource that is created. The output of an export may only be
   * used once the associated operation is done. If an export operation is
   * cancelled before completion it may leave partial data behind in Google
   * Cloud Storage.
   */
  exportEntities(
    request: DeepPartial<ExportEntitiesRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<Operation>;
  /**
   * Imports entities into Google Cloud Datastore. Existing entities with the
   * same key are overwritten. The import occurs in the background and its
   * progress can be monitored and managed via the Operation resource that is
   * created. If an ImportEntities operation is cancelled, it is possible
   * that a subset of the data has already been imported to Cloud Datastore.
   */
  importEntities(
    request: DeepPartial<ImportEntitiesRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<Operation>;
}

type Builtin = Date | Function | Uint8Array | string | number | boolean | undefined;

export type DeepPartial<T> = T extends Builtin ? T
  : T extends Long ? string | number | Long : T extends globalThis.Array<infer U> ? globalThis.Array<DeepPartial<U>>
  : T extends ReadonlyArray<infer U> ? ReadonlyArray<DeepPartial<U>>
  : T extends {} ? { [K in keyof T]?: DeepPartial<T[K]> }
  : Partial<T>;

function toTimestamp(date: Date): Timestamp {
  const seconds = numberToLong(Math.trunc(date.getTime() / 1_000));
  const nanos = (date.getTime() % 1_000) * 1_000_000;
  return { seconds, nanos };
}

function fromTimestamp(t: Timestamp): Date {
  let millis = (t.seconds.toNumber() || 0) * 1_000;
  millis += (t.nanos || 0) / 1_000_000;
  return new globalThis.Date(millis);
}

function fromJsonTimestamp(o: any): Date {
  if (o instanceof globalThis.Date) {
    return o;
  } else if (typeof o === "string") {
    return new globalThis.Date(o);
  } else {
    return fromTimestamp(Timestamp.fromJSON(o));
  }
}

function numberToLong(number: number) {
  return Long.fromNumber(number);
}

function isObject(value: any): boolean {
  return typeof value === "object" && value !== null;
}

function isSet(value: any): boolean {
  return value !== null && value !== undefined;
}

export interface MessageFns<T> {
  encode(message: T, writer?: BinaryWriter): BinaryWriter;
  decode(input: BinaryReader | Uint8Array, length?: number): T;
  fromJSON(object: any): T;
  toJSON(message: T): unknown;
  create(base?: DeepPartial<T>): T;
  fromPartial(object: DeepPartial<T>): T;
}
