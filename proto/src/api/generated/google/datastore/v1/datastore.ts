// Code generated by protoc-gen-ts_proto. DO NOT EDIT.
// versions:
//   protoc-gen-ts_proto  v2.2.0
//   protoc               unknown
// source: google/datastore/v1/datastore.proto

/* eslint-disable */
import { BinaryReader, BinaryWriter } from "@bufbuild/protobuf/wire";
import Long from "long";
import { type CallContext, type CallOptions } from "nice-grpc-common";
import { Timestamp } from "../../protobuf/timestamp.js";
import { AggregationResultBatch } from "./aggregation_result.js";
import { Entity, Key, PartitionId } from "./entity.js";
import { AggregationQuery, EntityResult, GqlQuery, Query, QueryResultBatch } from "./query.js";
import { ExplainMetrics, ExplainOptions } from "./query_profile.js";

export const protobufPackage = "google.datastore.v1";

/** The request for [Datastore.Lookup][google.datastore.v1.Datastore.Lookup]. */
export interface LookupRequest {
  /** Required. The ID of the project against which to make the request. */
  projectId: string;
  /**
   * The ID of the database against which to make the request.
   *
   * '(default)' is not allowed; please use empty string '' to refer the default
   * database.
   */
  databaseId: string;
  /** The options for this lookup request. */
  readOptions:
    | ReadOptions
    | undefined;
  /** Required. Keys of entities to look up. */
  keys: Key[];
  /**
   * The properties to return. Defaults to returning all properties.
   *
   * If this field is set and an entity has a property not referenced in the
   * mask, it will be absent from [LookupResponse.found.entity.properties][].
   *
   * The entity's key is always returned.
   */
  propertyMask: PropertyMask | undefined;
}

/** The response for [Datastore.Lookup][google.datastore.v1.Datastore.Lookup]. */
export interface LookupResponse {
  /**
   * Entities found as `ResultType.FULL` entities. The order of results in this
   * field is undefined and has no relation to the order of the keys in the
   * input.
   */
  found: EntityResult[];
  /**
   * Entities not found as `ResultType.KEY_ONLY` entities. The order of results
   * in this field is undefined and has no relation to the order of the keys
   * in the input.
   */
  missing: EntityResult[];
  /**
   * A list of keys that were not looked up due to resource constraints. The
   * order of results in this field is undefined and has no relation to the
   * order of the keys in the input.
   */
  deferred: Key[];
  /**
   * The identifier of the transaction that was started as part of this Lookup
   * request.
   *
   * Set only when
   * [ReadOptions.new_transaction][google.datastore.v1.ReadOptions.new_transaction]
   * was set in
   * [LookupRequest.read_options][google.datastore.v1.LookupRequest.read_options].
   */
  transaction: Buffer;
  /** The time at which these entities were read or found missing. */
  readTime: Date | undefined;
}

/** The request for [Datastore.RunQuery][google.datastore.v1.Datastore.RunQuery]. */
export interface RunQueryRequest {
  /** Required. The ID of the project against which to make the request. */
  projectId: string;
  /**
   * The ID of the database against which to make the request.
   *
   * '(default)' is not allowed; please use empty string '' to refer the default
   * database.
   */
  databaseId: string;
  /**
   * Entities are partitioned into subsets, identified by a partition ID.
   * Queries are scoped to a single partition.
   * This partition ID is normalized with the standard default context
   * partition ID.
   */
  partitionId:
    | PartitionId
    | undefined;
  /** The options for this query. */
  readOptions:
    | ReadOptions
    | undefined;
  /** The query to run. */
  query?:
    | Query
    | undefined;
  /** The GQL query to run. This query must be a non-aggregation query. */
  gqlQuery?:
    | GqlQuery
    | undefined;
  /**
   * The properties to return.
   * This field must not be set for a projection query.
   *
   * See
   * [LookupRequest.property_mask][google.datastore.v1.LookupRequest.property_mask].
   */
  propertyMask:
    | PropertyMask
    | undefined;
  /**
   * Optional. Explain options for the query. If set, additional query
   * statistics will be returned. If not, only query results will be returned.
   */
  explainOptions: ExplainOptions | undefined;
}

/**
 * The response for
 * [Datastore.RunQuery][google.datastore.v1.Datastore.RunQuery].
 */
export interface RunQueryResponse {
  /** A batch of query results (always present). */
  batch:
    | QueryResultBatch
    | undefined;
  /** The parsed form of the `GqlQuery` from the request, if it was set. */
  query:
    | Query
    | undefined;
  /**
   * The identifier of the transaction that was started as part of this
   * RunQuery request.
   *
   * Set only when
   * [ReadOptions.new_transaction][google.datastore.v1.ReadOptions.new_transaction]
   * was set in
   * [RunQueryRequest.read_options][google.datastore.v1.RunQueryRequest.read_options].
   */
  transaction: Buffer;
  /**
   * Query explain metrics. This is only present when the
   * [RunQueryRequest.explain_options][google.datastore.v1.RunQueryRequest.explain_options]
   * is provided, and it is sent only once with the last response in the stream.
   */
  explainMetrics: ExplainMetrics | undefined;
}

/**
 * The request for
 * [Datastore.RunAggregationQuery][google.datastore.v1.Datastore.RunAggregationQuery].
 */
export interface RunAggregationQueryRequest {
  /** Required. The ID of the project against which to make the request. */
  projectId: string;
  /**
   * The ID of the database against which to make the request.
   *
   * '(default)' is not allowed; please use empty string '' to refer the default
   * database.
   */
  databaseId: string;
  /**
   * Entities are partitioned into subsets, identified by a partition ID.
   * Queries are scoped to a single partition.
   * This partition ID is normalized with the standard default context
   * partition ID.
   */
  partitionId:
    | PartitionId
    | undefined;
  /** The options for this query. */
  readOptions:
    | ReadOptions
    | undefined;
  /** The query to run. */
  aggregationQuery?:
    | AggregationQuery
    | undefined;
  /** The GQL query to run. This query must be an aggregation query. */
  gqlQuery?:
    | GqlQuery
    | undefined;
  /**
   * Optional. Explain options for the query. If set, additional query
   * statistics will be returned. If not, only query results will be returned.
   */
  explainOptions: ExplainOptions | undefined;
}

/**
 * The response for
 * [Datastore.RunAggregationQuery][google.datastore.v1.Datastore.RunAggregationQuery].
 */
export interface RunAggregationQueryResponse {
  /** A batch of aggregation results. Always present. */
  batch:
    | AggregationResultBatch
    | undefined;
  /** The parsed form of the `GqlQuery` from the request, if it was set. */
  query:
    | AggregationQuery
    | undefined;
  /**
   * The identifier of the transaction that was started as part of this
   * RunAggregationQuery request.
   *
   * Set only when
   * [ReadOptions.new_transaction][google.datastore.v1.ReadOptions.new_transaction]
   * was set in
   * [RunAggregationQueryRequest.read_options][google.datastore.v1.RunAggregationQueryRequest.read_options].
   */
  transaction: Buffer;
  /**
   * Query explain metrics. This is only present when the
   * [RunAggregationQueryRequest.explain_options][google.datastore.v1.RunAggregationQueryRequest.explain_options]
   * is provided, and it is sent only once with the last response in the stream.
   */
  explainMetrics: ExplainMetrics | undefined;
}

/**
 * The request for
 * [Datastore.BeginTransaction][google.datastore.v1.Datastore.BeginTransaction].
 */
export interface BeginTransactionRequest {
  /** Required. The ID of the project against which to make the request. */
  projectId: string;
  /**
   * The ID of the database against which to make the request.
   *
   * '(default)' is not allowed; please use empty string '' to refer the default
   * database.
   */
  databaseId: string;
  /** Options for a new transaction. */
  transactionOptions: TransactionOptions | undefined;
}

/**
 * The response for
 * [Datastore.BeginTransaction][google.datastore.v1.Datastore.BeginTransaction].
 */
export interface BeginTransactionResponse {
  /** The transaction identifier (always present). */
  transaction: Buffer;
}

/** The request for [Datastore.Rollback][google.datastore.v1.Datastore.Rollback]. */
export interface RollbackRequest {
  /** Required. The ID of the project against which to make the request. */
  projectId: string;
  /**
   * The ID of the database against which to make the request.
   *
   * '(default)' is not allowed; please use empty string '' to refer the default
   * database.
   */
  databaseId: string;
  /**
   * Required. The transaction identifier, returned by a call to
   * [Datastore.BeginTransaction][google.datastore.v1.Datastore.BeginTransaction].
   */
  transaction: Buffer;
}

/**
 * The response for
 * [Datastore.Rollback][google.datastore.v1.Datastore.Rollback]. (an empty
 * message).
 */
export interface RollbackResponse {
}

/** The request for [Datastore.Commit][google.datastore.v1.Datastore.Commit]. */
export interface CommitRequest {
  /** Required. The ID of the project against which to make the request. */
  projectId: string;
  /**
   * The ID of the database against which to make the request.
   *
   * '(default)' is not allowed; please use empty string '' to refer the default
   * database.
   */
  databaseId: string;
  /** The type of commit to perform. Defaults to `TRANSACTIONAL`. */
  mode: CommitRequest_Mode;
  /**
   * The identifier of the transaction associated with the commit. A
   * transaction identifier is returned by a call to
   * [Datastore.BeginTransaction][google.datastore.v1.Datastore.BeginTransaction].
   */
  transaction?:
    | Buffer
    | undefined;
  /**
   * Options for beginning a new transaction for this request.
   * The transaction is committed when the request completes. If specified,
   * [TransactionOptions.mode][google.datastore.v1.TransactionOptions] must be
   * [TransactionOptions.ReadWrite][google.datastore.v1.TransactionOptions.ReadWrite].
   */
  singleUseTransaction?:
    | TransactionOptions
    | undefined;
  /**
   * The mutations to perform.
   *
   * When mode is `TRANSACTIONAL`, mutations affecting a single entity are
   * applied in order. The following sequences of mutations affecting a single
   * entity are not permitted in a single `Commit` request:
   *
   * - `insert` followed by `insert`
   * - `update` followed by `insert`
   * - `upsert` followed by `insert`
   * - `delete` followed by `update`
   *
   * When mode is `NON_TRANSACTIONAL`, no two mutations may affect a single
   * entity.
   */
  mutations: Mutation[];
}

/** The modes available for commits. */
export enum CommitRequest_Mode {
  /** MODE_UNSPECIFIED - Unspecified. This value must not be used. */
  MODE_UNSPECIFIED = 0,
  /**
   * TRANSACTIONAL - Transactional: The mutations are either all applied, or none are applied.
   * Learn about transactions
   * [here](https://cloud.google.com/datastore/docs/concepts/transactions).
   */
  TRANSACTIONAL = 1,
  /** NON_TRANSACTIONAL - Non-transactional: The mutations may not apply as all or none. */
  NON_TRANSACTIONAL = 2,
  UNRECOGNIZED = -1,
}

export function commitRequest_ModeFromJSON(object: any): CommitRequest_Mode {
  switch (object) {
    case 0:
    case "MODE_UNSPECIFIED":
      return CommitRequest_Mode.MODE_UNSPECIFIED;
    case 1:
    case "TRANSACTIONAL":
      return CommitRequest_Mode.TRANSACTIONAL;
    case 2:
    case "NON_TRANSACTIONAL":
      return CommitRequest_Mode.NON_TRANSACTIONAL;
    case -1:
    case "UNRECOGNIZED":
    default:
      return CommitRequest_Mode.UNRECOGNIZED;
  }
}

export function commitRequest_ModeToJSON(object: CommitRequest_Mode): string {
  switch (object) {
    case CommitRequest_Mode.MODE_UNSPECIFIED:
      return "MODE_UNSPECIFIED";
    case CommitRequest_Mode.TRANSACTIONAL:
      return "TRANSACTIONAL";
    case CommitRequest_Mode.NON_TRANSACTIONAL:
      return "NON_TRANSACTIONAL";
    case CommitRequest_Mode.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/** The response for [Datastore.Commit][google.datastore.v1.Datastore.Commit]. */
export interface CommitResponse {
  /**
   * The result of performing the mutations.
   * The i-th mutation result corresponds to the i-th mutation in the request.
   */
  mutationResults: MutationResult[];
  /**
   * The number of index entries updated during the commit, or zero if none were
   * updated.
   */
  indexUpdates: number;
  /** The transaction commit timestamp. Not set for non-transactional commits. */
  commitTime: Date | undefined;
}

/**
 * The request for
 * [Datastore.AllocateIds][google.datastore.v1.Datastore.AllocateIds].
 */
export interface AllocateIdsRequest {
  /** Required. The ID of the project against which to make the request. */
  projectId: string;
  /**
   * The ID of the database against which to make the request.
   *
   * '(default)' is not allowed; please use empty string '' to refer the default
   * database.
   */
  databaseId: string;
  /**
   * Required. A list of keys with incomplete key paths for which to allocate
   * IDs. No key may be reserved/read-only.
   */
  keys: Key[];
}

/**
 * The response for
 * [Datastore.AllocateIds][google.datastore.v1.Datastore.AllocateIds].
 */
export interface AllocateIdsResponse {
  /**
   * The keys specified in the request (in the same order), each with
   * its key path completed with a newly allocated ID.
   */
  keys: Key[];
}

/**
 * The request for
 * [Datastore.ReserveIds][google.datastore.v1.Datastore.ReserveIds].
 */
export interface ReserveIdsRequest {
  /** Required. The ID of the project against which to make the request. */
  projectId: string;
  /**
   * The ID of the database against which to make the request.
   *
   * '(default)' is not allowed; please use empty string '' to refer the default
   * database.
   */
  databaseId: string;
  /**
   * Required. A list of keys with complete key paths whose numeric IDs should
   * not be auto-allocated.
   */
  keys: Key[];
}

/**
 * The response for
 * [Datastore.ReserveIds][google.datastore.v1.Datastore.ReserveIds].
 */
export interface ReserveIdsResponse {
}

/** A mutation to apply to an entity. */
export interface Mutation {
  /**
   * The entity to insert. The entity must not already exist.
   * The entity key's final path element may be incomplete.
   */
  insert?:
    | Entity
    | undefined;
  /**
   * The entity to update. The entity must already exist.
   * Must have a complete key path.
   */
  update?:
    | Entity
    | undefined;
  /**
   * The entity to upsert. The entity may or may not already exist.
   * The entity key's final path element may be incomplete.
   */
  upsert?:
    | Entity
    | undefined;
  /**
   * The key of the entity to delete. The entity may or may not already exist.
   * Must have a complete key path and must not be reserved/read-only.
   */
  delete?:
    | Key
    | undefined;
  /**
   * The version of the entity that this mutation is being applied
   * to. If this does not match the current version on the server, the
   * mutation conflicts.
   */
  baseVersion?:
    | Long
    | undefined;
  /**
   * The update time of the entity that this mutation is being applied
   * to. If this does not match the current update time on the server, the
   * mutation conflicts.
   */
  updateTime?:
    | Date
    | undefined;
  /**
   * The properties to write in this mutation.
   * None of the properties in the mask may have a reserved name, except for
   * `__key__`.
   * This field is ignored for `delete`.
   *
   * If the entity already exists, only properties referenced in the mask are
   * updated, others are left untouched.
   * Properties referenced in the mask but not in the entity are deleted.
   */
  propertyMask: PropertyMask | undefined;
}

/** The result of applying a mutation. */
export interface MutationResult {
  /**
   * The automatically allocated key.
   * Set only when the mutation allocated a key.
   */
  key:
    | Key
    | undefined;
  /**
   * The version of the entity on the server after processing the mutation. If
   * the mutation doesn't change anything on the server, then the version will
   * be the version of the current entity or, if no entity is present, a version
   * that is strictly greater than the version of any previous entity and less
   * than the version of any possible future entity.
   */
  version: Long;
  /** The create time of the entity. This field will not be set after a 'delete'. */
  createTime:
    | Date
    | undefined;
  /**
   * The update time of the entity on the server after processing the mutation.
   * If the mutation doesn't change anything on the server, then the timestamp
   * will be the update timestamp of the current entity. This field will not be
   * set after a 'delete'.
   */
  updateTime:
    | Date
    | undefined;
  /**
   * Whether a conflict was detected for this mutation. Always false when a
   * conflict detection strategy field is not set in the mutation.
   */
  conflictDetected: boolean;
}

/**
 * The set of arbitrarily nested property paths used to restrict an operation to
 * only a subset of properties in an entity.
 */
export interface PropertyMask {
  /**
   * The paths to the properties covered by this mask.
   *
   * A path is a list of property names separated by dots (`.`), for example
   * `foo.bar` means the property `bar` inside the entity property `foo` inside
   * the entity associated with this path.
   *
   * If a property name contains a dot `.` or a backslash `\`, then that
   * name must be escaped.
   *
   * A path must not be empty, and may not reference a value inside an
   * [array value][google.datastore.v1.Value.array_value].
   */
  paths: string[];
}

/** The options shared by read requests. */
export interface ReadOptions {
  /** The non-transactional read consistency to use. */
  readConsistency?:
    | ReadOptions_ReadConsistency
    | undefined;
  /**
   * The identifier of the transaction in which to read. A
   * transaction identifier is returned by a call to
   * [Datastore.BeginTransaction][google.datastore.v1.Datastore.BeginTransaction].
   */
  transaction?:
    | Buffer
    | undefined;
  /**
   * Options for beginning a new transaction for this request.
   *
   * The new transaction identifier will be returned in the corresponding
   * response as either
   * [LookupResponse.transaction][google.datastore.v1.LookupResponse.transaction]
   * or
   * [RunQueryResponse.transaction][google.datastore.v1.RunQueryResponse.transaction].
   */
  newTransaction?:
    | TransactionOptions
    | undefined;
  /**
   * Reads entities as they were at the given time. This value is only
   * supported for Cloud Firestore in Datastore mode.
   *
   * This must be a microsecond precision timestamp within the past one hour,
   * or if Point-in-Time Recovery is enabled, can additionally be a whole
   * minute timestamp within the past 7 days.
   */
  readTime?: Date | undefined;
}

/** The possible values for read consistencies. */
export enum ReadOptions_ReadConsistency {
  /** READ_CONSISTENCY_UNSPECIFIED - Unspecified. This value must not be used. */
  READ_CONSISTENCY_UNSPECIFIED = 0,
  /** STRONG - Strong consistency. */
  STRONG = 1,
  /** EVENTUAL - Eventual consistency. */
  EVENTUAL = 2,
  UNRECOGNIZED = -1,
}

export function readOptions_ReadConsistencyFromJSON(object: any): ReadOptions_ReadConsistency {
  switch (object) {
    case 0:
    case "READ_CONSISTENCY_UNSPECIFIED":
      return ReadOptions_ReadConsistency.READ_CONSISTENCY_UNSPECIFIED;
    case 1:
    case "STRONG":
      return ReadOptions_ReadConsistency.STRONG;
    case 2:
    case "EVENTUAL":
      return ReadOptions_ReadConsistency.EVENTUAL;
    case -1:
    case "UNRECOGNIZED":
    default:
      return ReadOptions_ReadConsistency.UNRECOGNIZED;
  }
}

export function readOptions_ReadConsistencyToJSON(object: ReadOptions_ReadConsistency): string {
  switch (object) {
    case ReadOptions_ReadConsistency.READ_CONSISTENCY_UNSPECIFIED:
      return "READ_CONSISTENCY_UNSPECIFIED";
    case ReadOptions_ReadConsistency.STRONG:
      return "STRONG";
    case ReadOptions_ReadConsistency.EVENTUAL:
      return "EVENTUAL";
    case ReadOptions_ReadConsistency.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/**
 * Options for beginning a new transaction.
 *
 * Transactions can be created explicitly with calls to
 * [Datastore.BeginTransaction][google.datastore.v1.Datastore.BeginTransaction]
 * or implicitly by setting
 * [ReadOptions.new_transaction][google.datastore.v1.ReadOptions.new_transaction]
 * in read requests.
 */
export interface TransactionOptions {
  /** The transaction should allow both reads and writes. */
  readWrite?:
    | TransactionOptions_ReadWrite
    | undefined;
  /** The transaction should only allow reads. */
  readOnly?: TransactionOptions_ReadOnly | undefined;
}

/** Options specific to read / write transactions. */
export interface TransactionOptions_ReadWrite {
  /** The transaction identifier of the transaction being retried. */
  previousTransaction: Buffer;
}

/** Options specific to read-only transactions. */
export interface TransactionOptions_ReadOnly {
  /**
   * Reads entities at the given time.
   *
   * This must be a microsecond precision timestamp within the past one hour,
   * or if Point-in-Time Recovery is enabled, can additionally be a whole
   * minute timestamp within the past 7 days.
   */
  readTime: Date | undefined;
}

function createBaseLookupRequest(): LookupRequest {
  return { projectId: "", databaseId: "", readOptions: undefined, keys: [], propertyMask: undefined };
}

export const LookupRequest: MessageFns<LookupRequest> = {
  encode(message: LookupRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.projectId !== "") {
      writer.uint32(66).string(message.projectId);
    }
    if (message.databaseId !== "") {
      writer.uint32(74).string(message.databaseId);
    }
    if (message.readOptions !== undefined) {
      ReadOptions.encode(message.readOptions, writer.uint32(10).fork()).join();
    }
    for (const v of message.keys) {
      Key.encode(v!, writer.uint32(26).fork()).join();
    }
    if (message.propertyMask !== undefined) {
      PropertyMask.encode(message.propertyMask, writer.uint32(42).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): LookupRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseLookupRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 8:
          if (tag !== 66) {
            break;
          }

          message.projectId = reader.string();
          continue;
        case 9:
          if (tag !== 74) {
            break;
          }

          message.databaseId = reader.string();
          continue;
        case 1:
          if (tag !== 10) {
            break;
          }

          message.readOptions = ReadOptions.decode(reader, reader.uint32());
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.keys.push(Key.decode(reader, reader.uint32()));
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.propertyMask = PropertyMask.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): LookupRequest {
    return {
      projectId: isSet(object.projectId) ? globalThis.String(object.projectId) : "",
      databaseId: isSet(object.databaseId) ? globalThis.String(object.databaseId) : "",
      readOptions: isSet(object.readOptions) ? ReadOptions.fromJSON(object.readOptions) : undefined,
      keys: globalThis.Array.isArray(object?.keys) ? object.keys.map((e: any) => Key.fromJSON(e)) : [],
      propertyMask: isSet(object.propertyMask) ? PropertyMask.fromJSON(object.propertyMask) : undefined,
    };
  },

  toJSON(message: LookupRequest): unknown {
    const obj: any = {};
    if (message.projectId !== "") {
      obj.projectId = message.projectId;
    }
    if (message.databaseId !== "") {
      obj.databaseId = message.databaseId;
    }
    if (message.readOptions !== undefined) {
      obj.readOptions = ReadOptions.toJSON(message.readOptions);
    }
    if (message.keys?.length) {
      obj.keys = message.keys.map((e) => Key.toJSON(e));
    }
    if (message.propertyMask !== undefined) {
      obj.propertyMask = PropertyMask.toJSON(message.propertyMask);
    }
    return obj;
  },

  create(base?: DeepPartial<LookupRequest>): LookupRequest {
    return LookupRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<LookupRequest>): LookupRequest {
    const message = createBaseLookupRequest();
    message.projectId = object.projectId ?? "";
    message.databaseId = object.databaseId ?? "";
    message.readOptions = (object.readOptions !== undefined && object.readOptions !== null)
      ? ReadOptions.fromPartial(object.readOptions)
      : undefined;
    message.keys = object.keys?.map((e) => Key.fromPartial(e)) || [];
    message.propertyMask = (object.propertyMask !== undefined && object.propertyMask !== null)
      ? PropertyMask.fromPartial(object.propertyMask)
      : undefined;
    return message;
  },
};

function createBaseLookupResponse(): LookupResponse {
  return { found: [], missing: [], deferred: [], transaction: Buffer.alloc(0), readTime: undefined };
}

export const LookupResponse: MessageFns<LookupResponse> = {
  encode(message: LookupResponse, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.found) {
      EntityResult.encode(v!, writer.uint32(10).fork()).join();
    }
    for (const v of message.missing) {
      EntityResult.encode(v!, writer.uint32(18).fork()).join();
    }
    for (const v of message.deferred) {
      Key.encode(v!, writer.uint32(26).fork()).join();
    }
    if (message.transaction.length !== 0) {
      writer.uint32(42).bytes(message.transaction);
    }
    if (message.readTime !== undefined) {
      Timestamp.encode(toTimestamp(message.readTime), writer.uint32(58).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): LookupResponse {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseLookupResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.found.push(EntityResult.decode(reader, reader.uint32()));
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.missing.push(EntityResult.decode(reader, reader.uint32()));
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.deferred.push(Key.decode(reader, reader.uint32()));
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.transaction = Buffer.from(reader.bytes());
          continue;
        case 7:
          if (tag !== 58) {
            break;
          }

          message.readTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): LookupResponse {
    return {
      found: globalThis.Array.isArray(object?.found) ? object.found.map((e: any) => EntityResult.fromJSON(e)) : [],
      missing: globalThis.Array.isArray(object?.missing)
        ? object.missing.map((e: any) => EntityResult.fromJSON(e))
        : [],
      deferred: globalThis.Array.isArray(object?.deferred) ? object.deferred.map((e: any) => Key.fromJSON(e)) : [],
      transaction: isSet(object.transaction) ? Buffer.from(bytesFromBase64(object.transaction)) : Buffer.alloc(0),
      readTime: isSet(object.readTime) ? fromJsonTimestamp(object.readTime) : undefined,
    };
  },

  toJSON(message: LookupResponse): unknown {
    const obj: any = {};
    if (message.found?.length) {
      obj.found = message.found.map((e) => EntityResult.toJSON(e));
    }
    if (message.missing?.length) {
      obj.missing = message.missing.map((e) => EntityResult.toJSON(e));
    }
    if (message.deferred?.length) {
      obj.deferred = message.deferred.map((e) => Key.toJSON(e));
    }
    if (message.transaction.length !== 0) {
      obj.transaction = base64FromBytes(message.transaction);
    }
    if (message.readTime !== undefined) {
      obj.readTime = message.readTime.toISOString();
    }
    return obj;
  },

  create(base?: DeepPartial<LookupResponse>): LookupResponse {
    return LookupResponse.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<LookupResponse>): LookupResponse {
    const message = createBaseLookupResponse();
    message.found = object.found?.map((e) => EntityResult.fromPartial(e)) || [];
    message.missing = object.missing?.map((e) => EntityResult.fromPartial(e)) || [];
    message.deferred = object.deferred?.map((e) => Key.fromPartial(e)) || [];
    message.transaction = object.transaction ?? Buffer.alloc(0);
    message.readTime = object.readTime ?? undefined;
    return message;
  },
};

function createBaseRunQueryRequest(): RunQueryRequest {
  return {
    projectId: "",
    databaseId: "",
    partitionId: undefined,
    readOptions: undefined,
    query: undefined,
    gqlQuery: undefined,
    propertyMask: undefined,
    explainOptions: undefined,
  };
}

export const RunQueryRequest: MessageFns<RunQueryRequest> = {
  encode(message: RunQueryRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.projectId !== "") {
      writer.uint32(66).string(message.projectId);
    }
    if (message.databaseId !== "") {
      writer.uint32(74).string(message.databaseId);
    }
    if (message.partitionId !== undefined) {
      PartitionId.encode(message.partitionId, writer.uint32(18).fork()).join();
    }
    if (message.readOptions !== undefined) {
      ReadOptions.encode(message.readOptions, writer.uint32(10).fork()).join();
    }
    if (message.query !== undefined) {
      Query.encode(message.query, writer.uint32(26).fork()).join();
    }
    if (message.gqlQuery !== undefined) {
      GqlQuery.encode(message.gqlQuery, writer.uint32(58).fork()).join();
    }
    if (message.propertyMask !== undefined) {
      PropertyMask.encode(message.propertyMask, writer.uint32(82).fork()).join();
    }
    if (message.explainOptions !== undefined) {
      ExplainOptions.encode(message.explainOptions, writer.uint32(98).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): RunQueryRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseRunQueryRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 8:
          if (tag !== 66) {
            break;
          }

          message.projectId = reader.string();
          continue;
        case 9:
          if (tag !== 74) {
            break;
          }

          message.databaseId = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.partitionId = PartitionId.decode(reader, reader.uint32());
          continue;
        case 1:
          if (tag !== 10) {
            break;
          }

          message.readOptions = ReadOptions.decode(reader, reader.uint32());
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.query = Query.decode(reader, reader.uint32());
          continue;
        case 7:
          if (tag !== 58) {
            break;
          }

          message.gqlQuery = GqlQuery.decode(reader, reader.uint32());
          continue;
        case 10:
          if (tag !== 82) {
            break;
          }

          message.propertyMask = PropertyMask.decode(reader, reader.uint32());
          continue;
        case 12:
          if (tag !== 98) {
            break;
          }

          message.explainOptions = ExplainOptions.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): RunQueryRequest {
    return {
      projectId: isSet(object.projectId) ? globalThis.String(object.projectId) : "",
      databaseId: isSet(object.databaseId) ? globalThis.String(object.databaseId) : "",
      partitionId: isSet(object.partitionId) ? PartitionId.fromJSON(object.partitionId) : undefined,
      readOptions: isSet(object.readOptions) ? ReadOptions.fromJSON(object.readOptions) : undefined,
      query: isSet(object.query) ? Query.fromJSON(object.query) : undefined,
      gqlQuery: isSet(object.gqlQuery) ? GqlQuery.fromJSON(object.gqlQuery) : undefined,
      propertyMask: isSet(object.propertyMask) ? PropertyMask.fromJSON(object.propertyMask) : undefined,
      explainOptions: isSet(object.explainOptions) ? ExplainOptions.fromJSON(object.explainOptions) : undefined,
    };
  },

  toJSON(message: RunQueryRequest): unknown {
    const obj: any = {};
    if (message.projectId !== "") {
      obj.projectId = message.projectId;
    }
    if (message.databaseId !== "") {
      obj.databaseId = message.databaseId;
    }
    if (message.partitionId !== undefined) {
      obj.partitionId = PartitionId.toJSON(message.partitionId);
    }
    if (message.readOptions !== undefined) {
      obj.readOptions = ReadOptions.toJSON(message.readOptions);
    }
    if (message.query !== undefined) {
      obj.query = Query.toJSON(message.query);
    }
    if (message.gqlQuery !== undefined) {
      obj.gqlQuery = GqlQuery.toJSON(message.gqlQuery);
    }
    if (message.propertyMask !== undefined) {
      obj.propertyMask = PropertyMask.toJSON(message.propertyMask);
    }
    if (message.explainOptions !== undefined) {
      obj.explainOptions = ExplainOptions.toJSON(message.explainOptions);
    }
    return obj;
  },

  create(base?: DeepPartial<RunQueryRequest>): RunQueryRequest {
    return RunQueryRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<RunQueryRequest>): RunQueryRequest {
    const message = createBaseRunQueryRequest();
    message.projectId = object.projectId ?? "";
    message.databaseId = object.databaseId ?? "";
    message.partitionId = (object.partitionId !== undefined && object.partitionId !== null)
      ? PartitionId.fromPartial(object.partitionId)
      : undefined;
    message.readOptions = (object.readOptions !== undefined && object.readOptions !== null)
      ? ReadOptions.fromPartial(object.readOptions)
      : undefined;
    message.query = (object.query !== undefined && object.query !== null) ? Query.fromPartial(object.query) : undefined;
    message.gqlQuery = (object.gqlQuery !== undefined && object.gqlQuery !== null)
      ? GqlQuery.fromPartial(object.gqlQuery)
      : undefined;
    message.propertyMask = (object.propertyMask !== undefined && object.propertyMask !== null)
      ? PropertyMask.fromPartial(object.propertyMask)
      : undefined;
    message.explainOptions = (object.explainOptions !== undefined && object.explainOptions !== null)
      ? ExplainOptions.fromPartial(object.explainOptions)
      : undefined;
    return message;
  },
};

function createBaseRunQueryResponse(): RunQueryResponse {
  return { batch: undefined, query: undefined, transaction: Buffer.alloc(0), explainMetrics: undefined };
}

export const RunQueryResponse: MessageFns<RunQueryResponse> = {
  encode(message: RunQueryResponse, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.batch !== undefined) {
      QueryResultBatch.encode(message.batch, writer.uint32(10).fork()).join();
    }
    if (message.query !== undefined) {
      Query.encode(message.query, writer.uint32(18).fork()).join();
    }
    if (message.transaction.length !== 0) {
      writer.uint32(42).bytes(message.transaction);
    }
    if (message.explainMetrics !== undefined) {
      ExplainMetrics.encode(message.explainMetrics, writer.uint32(74).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): RunQueryResponse {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseRunQueryResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.batch = QueryResultBatch.decode(reader, reader.uint32());
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.query = Query.decode(reader, reader.uint32());
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.transaction = Buffer.from(reader.bytes());
          continue;
        case 9:
          if (tag !== 74) {
            break;
          }

          message.explainMetrics = ExplainMetrics.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): RunQueryResponse {
    return {
      batch: isSet(object.batch) ? QueryResultBatch.fromJSON(object.batch) : undefined,
      query: isSet(object.query) ? Query.fromJSON(object.query) : undefined,
      transaction: isSet(object.transaction) ? Buffer.from(bytesFromBase64(object.transaction)) : Buffer.alloc(0),
      explainMetrics: isSet(object.explainMetrics) ? ExplainMetrics.fromJSON(object.explainMetrics) : undefined,
    };
  },

  toJSON(message: RunQueryResponse): unknown {
    const obj: any = {};
    if (message.batch !== undefined) {
      obj.batch = QueryResultBatch.toJSON(message.batch);
    }
    if (message.query !== undefined) {
      obj.query = Query.toJSON(message.query);
    }
    if (message.transaction.length !== 0) {
      obj.transaction = base64FromBytes(message.transaction);
    }
    if (message.explainMetrics !== undefined) {
      obj.explainMetrics = ExplainMetrics.toJSON(message.explainMetrics);
    }
    return obj;
  },

  create(base?: DeepPartial<RunQueryResponse>): RunQueryResponse {
    return RunQueryResponse.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<RunQueryResponse>): RunQueryResponse {
    const message = createBaseRunQueryResponse();
    message.batch = (object.batch !== undefined && object.batch !== null)
      ? QueryResultBatch.fromPartial(object.batch)
      : undefined;
    message.query = (object.query !== undefined && object.query !== null) ? Query.fromPartial(object.query) : undefined;
    message.transaction = object.transaction ?? Buffer.alloc(0);
    message.explainMetrics = (object.explainMetrics !== undefined && object.explainMetrics !== null)
      ? ExplainMetrics.fromPartial(object.explainMetrics)
      : undefined;
    return message;
  },
};

function createBaseRunAggregationQueryRequest(): RunAggregationQueryRequest {
  return {
    projectId: "",
    databaseId: "",
    partitionId: undefined,
    readOptions: undefined,
    aggregationQuery: undefined,
    gqlQuery: undefined,
    explainOptions: undefined,
  };
}

export const RunAggregationQueryRequest: MessageFns<RunAggregationQueryRequest> = {
  encode(message: RunAggregationQueryRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.projectId !== "") {
      writer.uint32(66).string(message.projectId);
    }
    if (message.databaseId !== "") {
      writer.uint32(74).string(message.databaseId);
    }
    if (message.partitionId !== undefined) {
      PartitionId.encode(message.partitionId, writer.uint32(18).fork()).join();
    }
    if (message.readOptions !== undefined) {
      ReadOptions.encode(message.readOptions, writer.uint32(10).fork()).join();
    }
    if (message.aggregationQuery !== undefined) {
      AggregationQuery.encode(message.aggregationQuery, writer.uint32(26).fork()).join();
    }
    if (message.gqlQuery !== undefined) {
      GqlQuery.encode(message.gqlQuery, writer.uint32(58).fork()).join();
    }
    if (message.explainOptions !== undefined) {
      ExplainOptions.encode(message.explainOptions, writer.uint32(90).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): RunAggregationQueryRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseRunAggregationQueryRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 8:
          if (tag !== 66) {
            break;
          }

          message.projectId = reader.string();
          continue;
        case 9:
          if (tag !== 74) {
            break;
          }

          message.databaseId = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.partitionId = PartitionId.decode(reader, reader.uint32());
          continue;
        case 1:
          if (tag !== 10) {
            break;
          }

          message.readOptions = ReadOptions.decode(reader, reader.uint32());
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.aggregationQuery = AggregationQuery.decode(reader, reader.uint32());
          continue;
        case 7:
          if (tag !== 58) {
            break;
          }

          message.gqlQuery = GqlQuery.decode(reader, reader.uint32());
          continue;
        case 11:
          if (tag !== 90) {
            break;
          }

          message.explainOptions = ExplainOptions.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): RunAggregationQueryRequest {
    return {
      projectId: isSet(object.projectId) ? globalThis.String(object.projectId) : "",
      databaseId: isSet(object.databaseId) ? globalThis.String(object.databaseId) : "",
      partitionId: isSet(object.partitionId) ? PartitionId.fromJSON(object.partitionId) : undefined,
      readOptions: isSet(object.readOptions) ? ReadOptions.fromJSON(object.readOptions) : undefined,
      aggregationQuery: isSet(object.aggregationQuery) ? AggregationQuery.fromJSON(object.aggregationQuery) : undefined,
      gqlQuery: isSet(object.gqlQuery) ? GqlQuery.fromJSON(object.gqlQuery) : undefined,
      explainOptions: isSet(object.explainOptions) ? ExplainOptions.fromJSON(object.explainOptions) : undefined,
    };
  },

  toJSON(message: RunAggregationQueryRequest): unknown {
    const obj: any = {};
    if (message.projectId !== "") {
      obj.projectId = message.projectId;
    }
    if (message.databaseId !== "") {
      obj.databaseId = message.databaseId;
    }
    if (message.partitionId !== undefined) {
      obj.partitionId = PartitionId.toJSON(message.partitionId);
    }
    if (message.readOptions !== undefined) {
      obj.readOptions = ReadOptions.toJSON(message.readOptions);
    }
    if (message.aggregationQuery !== undefined) {
      obj.aggregationQuery = AggregationQuery.toJSON(message.aggregationQuery);
    }
    if (message.gqlQuery !== undefined) {
      obj.gqlQuery = GqlQuery.toJSON(message.gqlQuery);
    }
    if (message.explainOptions !== undefined) {
      obj.explainOptions = ExplainOptions.toJSON(message.explainOptions);
    }
    return obj;
  },

  create(base?: DeepPartial<RunAggregationQueryRequest>): RunAggregationQueryRequest {
    return RunAggregationQueryRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<RunAggregationQueryRequest>): RunAggregationQueryRequest {
    const message = createBaseRunAggregationQueryRequest();
    message.projectId = object.projectId ?? "";
    message.databaseId = object.databaseId ?? "";
    message.partitionId = (object.partitionId !== undefined && object.partitionId !== null)
      ? PartitionId.fromPartial(object.partitionId)
      : undefined;
    message.readOptions = (object.readOptions !== undefined && object.readOptions !== null)
      ? ReadOptions.fromPartial(object.readOptions)
      : undefined;
    message.aggregationQuery = (object.aggregationQuery !== undefined && object.aggregationQuery !== null)
      ? AggregationQuery.fromPartial(object.aggregationQuery)
      : undefined;
    message.gqlQuery = (object.gqlQuery !== undefined && object.gqlQuery !== null)
      ? GqlQuery.fromPartial(object.gqlQuery)
      : undefined;
    message.explainOptions = (object.explainOptions !== undefined && object.explainOptions !== null)
      ? ExplainOptions.fromPartial(object.explainOptions)
      : undefined;
    return message;
  },
};

function createBaseRunAggregationQueryResponse(): RunAggregationQueryResponse {
  return { batch: undefined, query: undefined, transaction: Buffer.alloc(0), explainMetrics: undefined };
}

export const RunAggregationQueryResponse: MessageFns<RunAggregationQueryResponse> = {
  encode(message: RunAggregationQueryResponse, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.batch !== undefined) {
      AggregationResultBatch.encode(message.batch, writer.uint32(10).fork()).join();
    }
    if (message.query !== undefined) {
      AggregationQuery.encode(message.query, writer.uint32(18).fork()).join();
    }
    if (message.transaction.length !== 0) {
      writer.uint32(42).bytes(message.transaction);
    }
    if (message.explainMetrics !== undefined) {
      ExplainMetrics.encode(message.explainMetrics, writer.uint32(74).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): RunAggregationQueryResponse {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseRunAggregationQueryResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.batch = AggregationResultBatch.decode(reader, reader.uint32());
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.query = AggregationQuery.decode(reader, reader.uint32());
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.transaction = Buffer.from(reader.bytes());
          continue;
        case 9:
          if (tag !== 74) {
            break;
          }

          message.explainMetrics = ExplainMetrics.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): RunAggregationQueryResponse {
    return {
      batch: isSet(object.batch) ? AggregationResultBatch.fromJSON(object.batch) : undefined,
      query: isSet(object.query) ? AggregationQuery.fromJSON(object.query) : undefined,
      transaction: isSet(object.transaction) ? Buffer.from(bytesFromBase64(object.transaction)) : Buffer.alloc(0),
      explainMetrics: isSet(object.explainMetrics) ? ExplainMetrics.fromJSON(object.explainMetrics) : undefined,
    };
  },

  toJSON(message: RunAggregationQueryResponse): unknown {
    const obj: any = {};
    if (message.batch !== undefined) {
      obj.batch = AggregationResultBatch.toJSON(message.batch);
    }
    if (message.query !== undefined) {
      obj.query = AggregationQuery.toJSON(message.query);
    }
    if (message.transaction.length !== 0) {
      obj.transaction = base64FromBytes(message.transaction);
    }
    if (message.explainMetrics !== undefined) {
      obj.explainMetrics = ExplainMetrics.toJSON(message.explainMetrics);
    }
    return obj;
  },

  create(base?: DeepPartial<RunAggregationQueryResponse>): RunAggregationQueryResponse {
    return RunAggregationQueryResponse.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<RunAggregationQueryResponse>): RunAggregationQueryResponse {
    const message = createBaseRunAggregationQueryResponse();
    message.batch = (object.batch !== undefined && object.batch !== null)
      ? AggregationResultBatch.fromPartial(object.batch)
      : undefined;
    message.query = (object.query !== undefined && object.query !== null)
      ? AggregationQuery.fromPartial(object.query)
      : undefined;
    message.transaction = object.transaction ?? Buffer.alloc(0);
    message.explainMetrics = (object.explainMetrics !== undefined && object.explainMetrics !== null)
      ? ExplainMetrics.fromPartial(object.explainMetrics)
      : undefined;
    return message;
  },
};

function createBaseBeginTransactionRequest(): BeginTransactionRequest {
  return { projectId: "", databaseId: "", transactionOptions: undefined };
}

export const BeginTransactionRequest: MessageFns<BeginTransactionRequest> = {
  encode(message: BeginTransactionRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.projectId !== "") {
      writer.uint32(66).string(message.projectId);
    }
    if (message.databaseId !== "") {
      writer.uint32(74).string(message.databaseId);
    }
    if (message.transactionOptions !== undefined) {
      TransactionOptions.encode(message.transactionOptions, writer.uint32(82).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): BeginTransactionRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseBeginTransactionRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 8:
          if (tag !== 66) {
            break;
          }

          message.projectId = reader.string();
          continue;
        case 9:
          if (tag !== 74) {
            break;
          }

          message.databaseId = reader.string();
          continue;
        case 10:
          if (tag !== 82) {
            break;
          }

          message.transactionOptions = TransactionOptions.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): BeginTransactionRequest {
    return {
      projectId: isSet(object.projectId) ? globalThis.String(object.projectId) : "",
      databaseId: isSet(object.databaseId) ? globalThis.String(object.databaseId) : "",
      transactionOptions: isSet(object.transactionOptions)
        ? TransactionOptions.fromJSON(object.transactionOptions)
        : undefined,
    };
  },

  toJSON(message: BeginTransactionRequest): unknown {
    const obj: any = {};
    if (message.projectId !== "") {
      obj.projectId = message.projectId;
    }
    if (message.databaseId !== "") {
      obj.databaseId = message.databaseId;
    }
    if (message.transactionOptions !== undefined) {
      obj.transactionOptions = TransactionOptions.toJSON(message.transactionOptions);
    }
    return obj;
  },

  create(base?: DeepPartial<BeginTransactionRequest>): BeginTransactionRequest {
    return BeginTransactionRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<BeginTransactionRequest>): BeginTransactionRequest {
    const message = createBaseBeginTransactionRequest();
    message.projectId = object.projectId ?? "";
    message.databaseId = object.databaseId ?? "";
    message.transactionOptions = (object.transactionOptions !== undefined && object.transactionOptions !== null)
      ? TransactionOptions.fromPartial(object.transactionOptions)
      : undefined;
    return message;
  },
};

function createBaseBeginTransactionResponse(): BeginTransactionResponse {
  return { transaction: Buffer.alloc(0) };
}

export const BeginTransactionResponse: MessageFns<BeginTransactionResponse> = {
  encode(message: BeginTransactionResponse, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.transaction.length !== 0) {
      writer.uint32(10).bytes(message.transaction);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): BeginTransactionResponse {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseBeginTransactionResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.transaction = Buffer.from(reader.bytes());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): BeginTransactionResponse {
    return {
      transaction: isSet(object.transaction) ? Buffer.from(bytesFromBase64(object.transaction)) : Buffer.alloc(0),
    };
  },

  toJSON(message: BeginTransactionResponse): unknown {
    const obj: any = {};
    if (message.transaction.length !== 0) {
      obj.transaction = base64FromBytes(message.transaction);
    }
    return obj;
  },

  create(base?: DeepPartial<BeginTransactionResponse>): BeginTransactionResponse {
    return BeginTransactionResponse.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<BeginTransactionResponse>): BeginTransactionResponse {
    const message = createBaseBeginTransactionResponse();
    message.transaction = object.transaction ?? Buffer.alloc(0);
    return message;
  },
};

function createBaseRollbackRequest(): RollbackRequest {
  return { projectId: "", databaseId: "", transaction: Buffer.alloc(0) };
}

export const RollbackRequest: MessageFns<RollbackRequest> = {
  encode(message: RollbackRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.projectId !== "") {
      writer.uint32(66).string(message.projectId);
    }
    if (message.databaseId !== "") {
      writer.uint32(74).string(message.databaseId);
    }
    if (message.transaction.length !== 0) {
      writer.uint32(10).bytes(message.transaction);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): RollbackRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseRollbackRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 8:
          if (tag !== 66) {
            break;
          }

          message.projectId = reader.string();
          continue;
        case 9:
          if (tag !== 74) {
            break;
          }

          message.databaseId = reader.string();
          continue;
        case 1:
          if (tag !== 10) {
            break;
          }

          message.transaction = Buffer.from(reader.bytes());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): RollbackRequest {
    return {
      projectId: isSet(object.projectId) ? globalThis.String(object.projectId) : "",
      databaseId: isSet(object.databaseId) ? globalThis.String(object.databaseId) : "",
      transaction: isSet(object.transaction) ? Buffer.from(bytesFromBase64(object.transaction)) : Buffer.alloc(0),
    };
  },

  toJSON(message: RollbackRequest): unknown {
    const obj: any = {};
    if (message.projectId !== "") {
      obj.projectId = message.projectId;
    }
    if (message.databaseId !== "") {
      obj.databaseId = message.databaseId;
    }
    if (message.transaction.length !== 0) {
      obj.transaction = base64FromBytes(message.transaction);
    }
    return obj;
  },

  create(base?: DeepPartial<RollbackRequest>): RollbackRequest {
    return RollbackRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<RollbackRequest>): RollbackRequest {
    const message = createBaseRollbackRequest();
    message.projectId = object.projectId ?? "";
    message.databaseId = object.databaseId ?? "";
    message.transaction = object.transaction ?? Buffer.alloc(0);
    return message;
  },
};

function createBaseRollbackResponse(): RollbackResponse {
  return {};
}

export const RollbackResponse: MessageFns<RollbackResponse> = {
  encode(_: RollbackResponse, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): RollbackResponse {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseRollbackResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(_: any): RollbackResponse {
    return {};
  },

  toJSON(_: RollbackResponse): unknown {
    const obj: any = {};
    return obj;
  },

  create(base?: DeepPartial<RollbackResponse>): RollbackResponse {
    return RollbackResponse.fromPartial(base ?? {});
  },
  fromPartial(_: DeepPartial<RollbackResponse>): RollbackResponse {
    const message = createBaseRollbackResponse();
    return message;
  },
};

function createBaseCommitRequest(): CommitRequest {
  return {
    projectId: "",
    databaseId: "",
    mode: 0,
    transaction: undefined,
    singleUseTransaction: undefined,
    mutations: [],
  };
}

export const CommitRequest: MessageFns<CommitRequest> = {
  encode(message: CommitRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.projectId !== "") {
      writer.uint32(66).string(message.projectId);
    }
    if (message.databaseId !== "") {
      writer.uint32(74).string(message.databaseId);
    }
    if (message.mode !== 0) {
      writer.uint32(40).int32(message.mode);
    }
    if (message.transaction !== undefined) {
      writer.uint32(10).bytes(message.transaction);
    }
    if (message.singleUseTransaction !== undefined) {
      TransactionOptions.encode(message.singleUseTransaction, writer.uint32(82).fork()).join();
    }
    for (const v of message.mutations) {
      Mutation.encode(v!, writer.uint32(50).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): CommitRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseCommitRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 8:
          if (tag !== 66) {
            break;
          }

          message.projectId = reader.string();
          continue;
        case 9:
          if (tag !== 74) {
            break;
          }

          message.databaseId = reader.string();
          continue;
        case 5:
          if (tag !== 40) {
            break;
          }

          message.mode = reader.int32() as any;
          continue;
        case 1:
          if (tag !== 10) {
            break;
          }

          message.transaction = Buffer.from(reader.bytes());
          continue;
        case 10:
          if (tag !== 82) {
            break;
          }

          message.singleUseTransaction = TransactionOptions.decode(reader, reader.uint32());
          continue;
        case 6:
          if (tag !== 50) {
            break;
          }

          message.mutations.push(Mutation.decode(reader, reader.uint32()));
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): CommitRequest {
    return {
      projectId: isSet(object.projectId) ? globalThis.String(object.projectId) : "",
      databaseId: isSet(object.databaseId) ? globalThis.String(object.databaseId) : "",
      mode: isSet(object.mode) ? commitRequest_ModeFromJSON(object.mode) : 0,
      transaction: isSet(object.transaction) ? Buffer.from(bytesFromBase64(object.transaction)) : undefined,
      singleUseTransaction: isSet(object.singleUseTransaction)
        ? TransactionOptions.fromJSON(object.singleUseTransaction)
        : undefined,
      mutations: globalThis.Array.isArray(object?.mutations)
        ? object.mutations.map((e: any) => Mutation.fromJSON(e))
        : [],
    };
  },

  toJSON(message: CommitRequest): unknown {
    const obj: any = {};
    if (message.projectId !== "") {
      obj.projectId = message.projectId;
    }
    if (message.databaseId !== "") {
      obj.databaseId = message.databaseId;
    }
    if (message.mode !== 0) {
      obj.mode = commitRequest_ModeToJSON(message.mode);
    }
    if (message.transaction !== undefined) {
      obj.transaction = base64FromBytes(message.transaction);
    }
    if (message.singleUseTransaction !== undefined) {
      obj.singleUseTransaction = TransactionOptions.toJSON(message.singleUseTransaction);
    }
    if (message.mutations?.length) {
      obj.mutations = message.mutations.map((e) => Mutation.toJSON(e));
    }
    return obj;
  },

  create(base?: DeepPartial<CommitRequest>): CommitRequest {
    return CommitRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<CommitRequest>): CommitRequest {
    const message = createBaseCommitRequest();
    message.projectId = object.projectId ?? "";
    message.databaseId = object.databaseId ?? "";
    message.mode = object.mode ?? 0;
    message.transaction = object.transaction ?? undefined;
    message.singleUseTransaction = (object.singleUseTransaction !== undefined && object.singleUseTransaction !== null)
      ? TransactionOptions.fromPartial(object.singleUseTransaction)
      : undefined;
    message.mutations = object.mutations?.map((e) => Mutation.fromPartial(e)) || [];
    return message;
  },
};

function createBaseCommitResponse(): CommitResponse {
  return { mutationResults: [], indexUpdates: 0, commitTime: undefined };
}

export const CommitResponse: MessageFns<CommitResponse> = {
  encode(message: CommitResponse, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.mutationResults) {
      MutationResult.encode(v!, writer.uint32(26).fork()).join();
    }
    if (message.indexUpdates !== 0) {
      writer.uint32(32).int32(message.indexUpdates);
    }
    if (message.commitTime !== undefined) {
      Timestamp.encode(toTimestamp(message.commitTime), writer.uint32(66).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): CommitResponse {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseCommitResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 3:
          if (tag !== 26) {
            break;
          }

          message.mutationResults.push(MutationResult.decode(reader, reader.uint32()));
          continue;
        case 4:
          if (tag !== 32) {
            break;
          }

          message.indexUpdates = reader.int32();
          continue;
        case 8:
          if (tag !== 66) {
            break;
          }

          message.commitTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): CommitResponse {
    return {
      mutationResults: globalThis.Array.isArray(object?.mutationResults)
        ? object.mutationResults.map((e: any) => MutationResult.fromJSON(e))
        : [],
      indexUpdates: isSet(object.indexUpdates) ? globalThis.Number(object.indexUpdates) : 0,
      commitTime: isSet(object.commitTime) ? fromJsonTimestamp(object.commitTime) : undefined,
    };
  },

  toJSON(message: CommitResponse): unknown {
    const obj: any = {};
    if (message.mutationResults?.length) {
      obj.mutationResults = message.mutationResults.map((e) => MutationResult.toJSON(e));
    }
    if (message.indexUpdates !== 0) {
      obj.indexUpdates = Math.round(message.indexUpdates);
    }
    if (message.commitTime !== undefined) {
      obj.commitTime = message.commitTime.toISOString();
    }
    return obj;
  },

  create(base?: DeepPartial<CommitResponse>): CommitResponse {
    return CommitResponse.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<CommitResponse>): CommitResponse {
    const message = createBaseCommitResponse();
    message.mutationResults = object.mutationResults?.map((e) => MutationResult.fromPartial(e)) || [];
    message.indexUpdates = object.indexUpdates ?? 0;
    message.commitTime = object.commitTime ?? undefined;
    return message;
  },
};

function createBaseAllocateIdsRequest(): AllocateIdsRequest {
  return { projectId: "", databaseId: "", keys: [] };
}

export const AllocateIdsRequest: MessageFns<AllocateIdsRequest> = {
  encode(message: AllocateIdsRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.projectId !== "") {
      writer.uint32(66).string(message.projectId);
    }
    if (message.databaseId !== "") {
      writer.uint32(74).string(message.databaseId);
    }
    for (const v of message.keys) {
      Key.encode(v!, writer.uint32(10).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): AllocateIdsRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseAllocateIdsRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 8:
          if (tag !== 66) {
            break;
          }

          message.projectId = reader.string();
          continue;
        case 9:
          if (tag !== 74) {
            break;
          }

          message.databaseId = reader.string();
          continue;
        case 1:
          if (tag !== 10) {
            break;
          }

          message.keys.push(Key.decode(reader, reader.uint32()));
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): AllocateIdsRequest {
    return {
      projectId: isSet(object.projectId) ? globalThis.String(object.projectId) : "",
      databaseId: isSet(object.databaseId) ? globalThis.String(object.databaseId) : "",
      keys: globalThis.Array.isArray(object?.keys) ? object.keys.map((e: any) => Key.fromJSON(e)) : [],
    };
  },

  toJSON(message: AllocateIdsRequest): unknown {
    const obj: any = {};
    if (message.projectId !== "") {
      obj.projectId = message.projectId;
    }
    if (message.databaseId !== "") {
      obj.databaseId = message.databaseId;
    }
    if (message.keys?.length) {
      obj.keys = message.keys.map((e) => Key.toJSON(e));
    }
    return obj;
  },

  create(base?: DeepPartial<AllocateIdsRequest>): AllocateIdsRequest {
    return AllocateIdsRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<AllocateIdsRequest>): AllocateIdsRequest {
    const message = createBaseAllocateIdsRequest();
    message.projectId = object.projectId ?? "";
    message.databaseId = object.databaseId ?? "";
    message.keys = object.keys?.map((e) => Key.fromPartial(e)) || [];
    return message;
  },
};

function createBaseAllocateIdsResponse(): AllocateIdsResponse {
  return { keys: [] };
}

export const AllocateIdsResponse: MessageFns<AllocateIdsResponse> = {
  encode(message: AllocateIdsResponse, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.keys) {
      Key.encode(v!, writer.uint32(10).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): AllocateIdsResponse {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseAllocateIdsResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.keys.push(Key.decode(reader, reader.uint32()));
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): AllocateIdsResponse {
    return { keys: globalThis.Array.isArray(object?.keys) ? object.keys.map((e: any) => Key.fromJSON(e)) : [] };
  },

  toJSON(message: AllocateIdsResponse): unknown {
    const obj: any = {};
    if (message.keys?.length) {
      obj.keys = message.keys.map((e) => Key.toJSON(e));
    }
    return obj;
  },

  create(base?: DeepPartial<AllocateIdsResponse>): AllocateIdsResponse {
    return AllocateIdsResponse.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<AllocateIdsResponse>): AllocateIdsResponse {
    const message = createBaseAllocateIdsResponse();
    message.keys = object.keys?.map((e) => Key.fromPartial(e)) || [];
    return message;
  },
};

function createBaseReserveIdsRequest(): ReserveIdsRequest {
  return { projectId: "", databaseId: "", keys: [] };
}

export const ReserveIdsRequest: MessageFns<ReserveIdsRequest> = {
  encode(message: ReserveIdsRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.projectId !== "") {
      writer.uint32(66).string(message.projectId);
    }
    if (message.databaseId !== "") {
      writer.uint32(74).string(message.databaseId);
    }
    for (const v of message.keys) {
      Key.encode(v!, writer.uint32(10).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ReserveIdsRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseReserveIdsRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 8:
          if (tag !== 66) {
            break;
          }

          message.projectId = reader.string();
          continue;
        case 9:
          if (tag !== 74) {
            break;
          }

          message.databaseId = reader.string();
          continue;
        case 1:
          if (tag !== 10) {
            break;
          }

          message.keys.push(Key.decode(reader, reader.uint32()));
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ReserveIdsRequest {
    return {
      projectId: isSet(object.projectId) ? globalThis.String(object.projectId) : "",
      databaseId: isSet(object.databaseId) ? globalThis.String(object.databaseId) : "",
      keys: globalThis.Array.isArray(object?.keys) ? object.keys.map((e: any) => Key.fromJSON(e)) : [],
    };
  },

  toJSON(message: ReserveIdsRequest): unknown {
    const obj: any = {};
    if (message.projectId !== "") {
      obj.projectId = message.projectId;
    }
    if (message.databaseId !== "") {
      obj.databaseId = message.databaseId;
    }
    if (message.keys?.length) {
      obj.keys = message.keys.map((e) => Key.toJSON(e));
    }
    return obj;
  },

  create(base?: DeepPartial<ReserveIdsRequest>): ReserveIdsRequest {
    return ReserveIdsRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ReserveIdsRequest>): ReserveIdsRequest {
    const message = createBaseReserveIdsRequest();
    message.projectId = object.projectId ?? "";
    message.databaseId = object.databaseId ?? "";
    message.keys = object.keys?.map((e) => Key.fromPartial(e)) || [];
    return message;
  },
};

function createBaseReserveIdsResponse(): ReserveIdsResponse {
  return {};
}

export const ReserveIdsResponse: MessageFns<ReserveIdsResponse> = {
  encode(_: ReserveIdsResponse, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ReserveIdsResponse {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseReserveIdsResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(_: any): ReserveIdsResponse {
    return {};
  },

  toJSON(_: ReserveIdsResponse): unknown {
    const obj: any = {};
    return obj;
  },

  create(base?: DeepPartial<ReserveIdsResponse>): ReserveIdsResponse {
    return ReserveIdsResponse.fromPartial(base ?? {});
  },
  fromPartial(_: DeepPartial<ReserveIdsResponse>): ReserveIdsResponse {
    const message = createBaseReserveIdsResponse();
    return message;
  },
};

function createBaseMutation(): Mutation {
  return {
    insert: undefined,
    update: undefined,
    upsert: undefined,
    delete: undefined,
    baseVersion: undefined,
    updateTime: undefined,
    propertyMask: undefined,
  };
}

export const Mutation: MessageFns<Mutation> = {
  encode(message: Mutation, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.insert !== undefined) {
      Entity.encode(message.insert, writer.uint32(34).fork()).join();
    }
    if (message.update !== undefined) {
      Entity.encode(message.update, writer.uint32(42).fork()).join();
    }
    if (message.upsert !== undefined) {
      Entity.encode(message.upsert, writer.uint32(50).fork()).join();
    }
    if (message.delete !== undefined) {
      Key.encode(message.delete, writer.uint32(58).fork()).join();
    }
    if (message.baseVersion !== undefined) {
      writer.uint32(64).int64(message.baseVersion.toString());
    }
    if (message.updateTime !== undefined) {
      Timestamp.encode(toTimestamp(message.updateTime), writer.uint32(90).fork()).join();
    }
    if (message.propertyMask !== undefined) {
      PropertyMask.encode(message.propertyMask, writer.uint32(74).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Mutation {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseMutation();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 4:
          if (tag !== 34) {
            break;
          }

          message.insert = Entity.decode(reader, reader.uint32());
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.update = Entity.decode(reader, reader.uint32());
          continue;
        case 6:
          if (tag !== 50) {
            break;
          }

          message.upsert = Entity.decode(reader, reader.uint32());
          continue;
        case 7:
          if (tag !== 58) {
            break;
          }

          message.delete = Key.decode(reader, reader.uint32());
          continue;
        case 8:
          if (tag !== 64) {
            break;
          }

          message.baseVersion = Long.fromString(reader.int64().toString());
          continue;
        case 11:
          if (tag !== 90) {
            break;
          }

          message.updateTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        case 9:
          if (tag !== 74) {
            break;
          }

          message.propertyMask = PropertyMask.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Mutation {
    return {
      insert: isSet(object.insert) ? Entity.fromJSON(object.insert) : undefined,
      update: isSet(object.update) ? Entity.fromJSON(object.update) : undefined,
      upsert: isSet(object.upsert) ? Entity.fromJSON(object.upsert) : undefined,
      delete: isSet(object.delete) ? Key.fromJSON(object.delete) : undefined,
      baseVersion: isSet(object.baseVersion) ? Long.fromValue(object.baseVersion) : undefined,
      updateTime: isSet(object.updateTime) ? fromJsonTimestamp(object.updateTime) : undefined,
      propertyMask: isSet(object.propertyMask) ? PropertyMask.fromJSON(object.propertyMask) : undefined,
    };
  },

  toJSON(message: Mutation): unknown {
    const obj: any = {};
    if (message.insert !== undefined) {
      obj.insert = Entity.toJSON(message.insert);
    }
    if (message.update !== undefined) {
      obj.update = Entity.toJSON(message.update);
    }
    if (message.upsert !== undefined) {
      obj.upsert = Entity.toJSON(message.upsert);
    }
    if (message.delete !== undefined) {
      obj.delete = Key.toJSON(message.delete);
    }
    if (message.baseVersion !== undefined) {
      obj.baseVersion = (message.baseVersion || Long.ZERO).toString();
    }
    if (message.updateTime !== undefined) {
      obj.updateTime = message.updateTime.toISOString();
    }
    if (message.propertyMask !== undefined) {
      obj.propertyMask = PropertyMask.toJSON(message.propertyMask);
    }
    return obj;
  },

  create(base?: DeepPartial<Mutation>): Mutation {
    return Mutation.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<Mutation>): Mutation {
    const message = createBaseMutation();
    message.insert = (object.insert !== undefined && object.insert !== null)
      ? Entity.fromPartial(object.insert)
      : undefined;
    message.update = (object.update !== undefined && object.update !== null)
      ? Entity.fromPartial(object.update)
      : undefined;
    message.upsert = (object.upsert !== undefined && object.upsert !== null)
      ? Entity.fromPartial(object.upsert)
      : undefined;
    message.delete = (object.delete !== undefined && object.delete !== null)
      ? Key.fromPartial(object.delete)
      : undefined;
    message.baseVersion = (object.baseVersion !== undefined && object.baseVersion !== null)
      ? Long.fromValue(object.baseVersion)
      : undefined;
    message.updateTime = object.updateTime ?? undefined;
    message.propertyMask = (object.propertyMask !== undefined && object.propertyMask !== null)
      ? PropertyMask.fromPartial(object.propertyMask)
      : undefined;
    return message;
  },
};

function createBaseMutationResult(): MutationResult {
  return { key: undefined, version: Long.ZERO, createTime: undefined, updateTime: undefined, conflictDetected: false };
}

export const MutationResult: MessageFns<MutationResult> = {
  encode(message: MutationResult, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.key !== undefined) {
      Key.encode(message.key, writer.uint32(26).fork()).join();
    }
    if (!message.version.equals(Long.ZERO)) {
      writer.uint32(32).int64(message.version.toString());
    }
    if (message.createTime !== undefined) {
      Timestamp.encode(toTimestamp(message.createTime), writer.uint32(58).fork()).join();
    }
    if (message.updateTime !== undefined) {
      Timestamp.encode(toTimestamp(message.updateTime), writer.uint32(50).fork()).join();
    }
    if (message.conflictDetected !== false) {
      writer.uint32(40).bool(message.conflictDetected);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): MutationResult {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseMutationResult();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 3:
          if (tag !== 26) {
            break;
          }

          message.key = Key.decode(reader, reader.uint32());
          continue;
        case 4:
          if (tag !== 32) {
            break;
          }

          message.version = Long.fromString(reader.int64().toString());
          continue;
        case 7:
          if (tag !== 58) {
            break;
          }

          message.createTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        case 6:
          if (tag !== 50) {
            break;
          }

          message.updateTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        case 5:
          if (tag !== 40) {
            break;
          }

          message.conflictDetected = reader.bool();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): MutationResult {
    return {
      key: isSet(object.key) ? Key.fromJSON(object.key) : undefined,
      version: isSet(object.version) ? Long.fromValue(object.version) : Long.ZERO,
      createTime: isSet(object.createTime) ? fromJsonTimestamp(object.createTime) : undefined,
      updateTime: isSet(object.updateTime) ? fromJsonTimestamp(object.updateTime) : undefined,
      conflictDetected: isSet(object.conflictDetected) ? globalThis.Boolean(object.conflictDetected) : false,
    };
  },

  toJSON(message: MutationResult): unknown {
    const obj: any = {};
    if (message.key !== undefined) {
      obj.key = Key.toJSON(message.key);
    }
    if (!message.version.equals(Long.ZERO)) {
      obj.version = (message.version || Long.ZERO).toString();
    }
    if (message.createTime !== undefined) {
      obj.createTime = message.createTime.toISOString();
    }
    if (message.updateTime !== undefined) {
      obj.updateTime = message.updateTime.toISOString();
    }
    if (message.conflictDetected !== false) {
      obj.conflictDetected = message.conflictDetected;
    }
    return obj;
  },

  create(base?: DeepPartial<MutationResult>): MutationResult {
    return MutationResult.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<MutationResult>): MutationResult {
    const message = createBaseMutationResult();
    message.key = (object.key !== undefined && object.key !== null) ? Key.fromPartial(object.key) : undefined;
    message.version = (object.version !== undefined && object.version !== null)
      ? Long.fromValue(object.version)
      : Long.ZERO;
    message.createTime = object.createTime ?? undefined;
    message.updateTime = object.updateTime ?? undefined;
    message.conflictDetected = object.conflictDetected ?? false;
    return message;
  },
};

function createBasePropertyMask(): PropertyMask {
  return { paths: [] };
}

export const PropertyMask: MessageFns<PropertyMask> = {
  encode(message: PropertyMask, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.paths) {
      writer.uint32(10).string(v!);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): PropertyMask {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBasePropertyMask();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.paths.push(reader.string());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): PropertyMask {
    return { paths: globalThis.Array.isArray(object?.paths) ? object.paths.map((e: any) => globalThis.String(e)) : [] };
  },

  toJSON(message: PropertyMask): unknown {
    const obj: any = {};
    if (message.paths?.length) {
      obj.paths = message.paths;
    }
    return obj;
  },

  create(base?: DeepPartial<PropertyMask>): PropertyMask {
    return PropertyMask.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<PropertyMask>): PropertyMask {
    const message = createBasePropertyMask();
    message.paths = object.paths?.map((e) => e) || [];
    return message;
  },
};

function createBaseReadOptions(): ReadOptions {
  return { readConsistency: undefined, transaction: undefined, newTransaction: undefined, readTime: undefined };
}

export const ReadOptions: MessageFns<ReadOptions> = {
  encode(message: ReadOptions, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.readConsistency !== undefined) {
      writer.uint32(8).int32(message.readConsistency);
    }
    if (message.transaction !== undefined) {
      writer.uint32(18).bytes(message.transaction);
    }
    if (message.newTransaction !== undefined) {
      TransactionOptions.encode(message.newTransaction, writer.uint32(26).fork()).join();
    }
    if (message.readTime !== undefined) {
      Timestamp.encode(toTimestamp(message.readTime), writer.uint32(34).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ReadOptions {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseReadOptions();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 8) {
            break;
          }

          message.readConsistency = reader.int32() as any;
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.transaction = Buffer.from(reader.bytes());
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.newTransaction = TransactionOptions.decode(reader, reader.uint32());
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.readTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ReadOptions {
    return {
      readConsistency: isSet(object.readConsistency)
        ? readOptions_ReadConsistencyFromJSON(object.readConsistency)
        : undefined,
      transaction: isSet(object.transaction) ? Buffer.from(bytesFromBase64(object.transaction)) : undefined,
      newTransaction: isSet(object.newTransaction) ? TransactionOptions.fromJSON(object.newTransaction) : undefined,
      readTime: isSet(object.readTime) ? fromJsonTimestamp(object.readTime) : undefined,
    };
  },

  toJSON(message: ReadOptions): unknown {
    const obj: any = {};
    if (message.readConsistency !== undefined) {
      obj.readConsistency = readOptions_ReadConsistencyToJSON(message.readConsistency);
    }
    if (message.transaction !== undefined) {
      obj.transaction = base64FromBytes(message.transaction);
    }
    if (message.newTransaction !== undefined) {
      obj.newTransaction = TransactionOptions.toJSON(message.newTransaction);
    }
    if (message.readTime !== undefined) {
      obj.readTime = message.readTime.toISOString();
    }
    return obj;
  },

  create(base?: DeepPartial<ReadOptions>): ReadOptions {
    return ReadOptions.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ReadOptions>): ReadOptions {
    const message = createBaseReadOptions();
    message.readConsistency = object.readConsistency ?? undefined;
    message.transaction = object.transaction ?? undefined;
    message.newTransaction = (object.newTransaction !== undefined && object.newTransaction !== null)
      ? TransactionOptions.fromPartial(object.newTransaction)
      : undefined;
    message.readTime = object.readTime ?? undefined;
    return message;
  },
};

function createBaseTransactionOptions(): TransactionOptions {
  return { readWrite: undefined, readOnly: undefined };
}

export const TransactionOptions: MessageFns<TransactionOptions> = {
  encode(message: TransactionOptions, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.readWrite !== undefined) {
      TransactionOptions_ReadWrite.encode(message.readWrite, writer.uint32(10).fork()).join();
    }
    if (message.readOnly !== undefined) {
      TransactionOptions_ReadOnly.encode(message.readOnly, writer.uint32(18).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): TransactionOptions {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseTransactionOptions();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.readWrite = TransactionOptions_ReadWrite.decode(reader, reader.uint32());
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.readOnly = TransactionOptions_ReadOnly.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): TransactionOptions {
    return {
      readWrite: isSet(object.readWrite) ? TransactionOptions_ReadWrite.fromJSON(object.readWrite) : undefined,
      readOnly: isSet(object.readOnly) ? TransactionOptions_ReadOnly.fromJSON(object.readOnly) : undefined,
    };
  },

  toJSON(message: TransactionOptions): unknown {
    const obj: any = {};
    if (message.readWrite !== undefined) {
      obj.readWrite = TransactionOptions_ReadWrite.toJSON(message.readWrite);
    }
    if (message.readOnly !== undefined) {
      obj.readOnly = TransactionOptions_ReadOnly.toJSON(message.readOnly);
    }
    return obj;
  },

  create(base?: DeepPartial<TransactionOptions>): TransactionOptions {
    return TransactionOptions.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<TransactionOptions>): TransactionOptions {
    const message = createBaseTransactionOptions();
    message.readWrite = (object.readWrite !== undefined && object.readWrite !== null)
      ? TransactionOptions_ReadWrite.fromPartial(object.readWrite)
      : undefined;
    message.readOnly = (object.readOnly !== undefined && object.readOnly !== null)
      ? TransactionOptions_ReadOnly.fromPartial(object.readOnly)
      : undefined;
    return message;
  },
};

function createBaseTransactionOptions_ReadWrite(): TransactionOptions_ReadWrite {
  return { previousTransaction: Buffer.alloc(0) };
}

export const TransactionOptions_ReadWrite: MessageFns<TransactionOptions_ReadWrite> = {
  encode(message: TransactionOptions_ReadWrite, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.previousTransaction.length !== 0) {
      writer.uint32(10).bytes(message.previousTransaction);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): TransactionOptions_ReadWrite {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseTransactionOptions_ReadWrite();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.previousTransaction = Buffer.from(reader.bytes());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): TransactionOptions_ReadWrite {
    return {
      previousTransaction: isSet(object.previousTransaction)
        ? Buffer.from(bytesFromBase64(object.previousTransaction))
        : Buffer.alloc(0),
    };
  },

  toJSON(message: TransactionOptions_ReadWrite): unknown {
    const obj: any = {};
    if (message.previousTransaction.length !== 0) {
      obj.previousTransaction = base64FromBytes(message.previousTransaction);
    }
    return obj;
  },

  create(base?: DeepPartial<TransactionOptions_ReadWrite>): TransactionOptions_ReadWrite {
    return TransactionOptions_ReadWrite.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<TransactionOptions_ReadWrite>): TransactionOptions_ReadWrite {
    const message = createBaseTransactionOptions_ReadWrite();
    message.previousTransaction = object.previousTransaction ?? Buffer.alloc(0);
    return message;
  },
};

function createBaseTransactionOptions_ReadOnly(): TransactionOptions_ReadOnly {
  return { readTime: undefined };
}

export const TransactionOptions_ReadOnly: MessageFns<TransactionOptions_ReadOnly> = {
  encode(message: TransactionOptions_ReadOnly, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.readTime !== undefined) {
      Timestamp.encode(toTimestamp(message.readTime), writer.uint32(10).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): TransactionOptions_ReadOnly {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseTransactionOptions_ReadOnly();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.readTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): TransactionOptions_ReadOnly {
    return { readTime: isSet(object.readTime) ? fromJsonTimestamp(object.readTime) : undefined };
  },

  toJSON(message: TransactionOptions_ReadOnly): unknown {
    const obj: any = {};
    if (message.readTime !== undefined) {
      obj.readTime = message.readTime.toISOString();
    }
    return obj;
  },

  create(base?: DeepPartial<TransactionOptions_ReadOnly>): TransactionOptions_ReadOnly {
    return TransactionOptions_ReadOnly.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<TransactionOptions_ReadOnly>): TransactionOptions_ReadOnly {
    const message = createBaseTransactionOptions_ReadOnly();
    message.readTime = object.readTime ?? undefined;
    return message;
  },
};

/**
 * Each RPC normalizes the partition IDs of the keys in its input entities,
 * and always returns entities with keys with normalized partition IDs.
 * This applies to all keys and entities, including those in values, except keys
 * with both an empty path and an empty or unset partition ID. Normalization of
 * input keys sets the project ID (if not already set) to the project ID from
 * the request.
 */
export type DatastoreDefinition = typeof DatastoreDefinition;
export const DatastoreDefinition = {
  name: "Datastore",
  fullName: "google.datastore.v1.Datastore",
  methods: {
    /** Looks up entities by key. */
    lookup: {
      name: "Lookup",
      requestType: LookupRequest,
      requestStream: false,
      responseType: LookupResponse,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [
            Buffer.from([
              28,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              95,
              105,
              100,
              44,
              114,
              101,
              97,
              100,
              95,
              111,
              112,
              116,
              105,
              111,
              110,
              115,
              44,
              107,
              101,
              121,
              115,
            ]),
          ],
          578365826: [
            Buffer.from([
              37,
              58,
              1,
              42,
              34,
              32,
              47,
              118,
              49,
              47,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              123,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              95,
              105,
              100,
              125,
              58,
              108,
              111,
              111,
              107,
              117,
              112,
            ]),
          ],
          578365834: [
            Buffer.from([
              29,
              18,
              12,
              10,
              10,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              95,
              105,
              100,
              18,
              13,
              10,
              11,
              100,
              97,
              116,
              97,
              98,
              97,
              115,
              101,
              95,
              105,
              100,
            ]),
          ],
        },
      },
    },
    /** Queries for entities. */
    runQuery: {
      name: "RunQuery",
      requestType: RunQueryRequest,
      requestStream: false,
      responseType: RunQueryResponse,
      responseStream: false,
      options: {
        _unknownFields: {
          578365826: [
            Buffer.from([
              39,
              58,
              1,
              42,
              34,
              34,
              47,
              118,
              49,
              47,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              123,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              95,
              105,
              100,
              125,
              58,
              114,
              117,
              110,
              81,
              117,
              101,
              114,
              121,
            ]),
          ],
          578365834: [
            Buffer.from([
              29,
              18,
              12,
              10,
              10,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              95,
              105,
              100,
              18,
              13,
              10,
              11,
              100,
              97,
              116,
              97,
              98,
              97,
              115,
              101,
              95,
              105,
              100,
            ]),
          ],
        },
      },
    },
    /** Runs an aggregation query. */
    runAggregationQuery: {
      name: "RunAggregationQuery",
      requestType: RunAggregationQueryRequest,
      requestStream: false,
      responseType: RunAggregationQueryResponse,
      responseStream: false,
      options: {
        _unknownFields: {
          578365826: [
            Buffer.from([
              50,
              58,
              1,
              42,
              34,
              45,
              47,
              118,
              49,
              47,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              123,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              95,
              105,
              100,
              125,
              58,
              114,
              117,
              110,
              65,
              103,
              103,
              114,
              101,
              103,
              97,
              116,
              105,
              111,
              110,
              81,
              117,
              101,
              114,
              121,
            ]),
          ],
          578365834: [
            Buffer.from([
              29,
              18,
              12,
              10,
              10,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              95,
              105,
              100,
              18,
              13,
              10,
              11,
              100,
              97,
              116,
              97,
              98,
              97,
              115,
              101,
              95,
              105,
              100,
            ]),
          ],
        },
      },
    },
    /** Begins a new transaction. */
    beginTransaction: {
      name: "BeginTransaction",
      requestType: BeginTransactionRequest,
      requestStream: false,
      responseType: BeginTransactionResponse,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [Buffer.from([10, 112, 114, 111, 106, 101, 99, 116, 95, 105, 100])],
          578365826: [
            Buffer.from([
              47,
              58,
              1,
              42,
              34,
              42,
              47,
              118,
              49,
              47,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              123,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              95,
              105,
              100,
              125,
              58,
              98,
              101,
              103,
              105,
              110,
              84,
              114,
              97,
              110,
              115,
              97,
              99,
              116,
              105,
              111,
              110,
            ]),
          ],
          578365834: [
            Buffer.from([
              29,
              18,
              12,
              10,
              10,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              95,
              105,
              100,
              18,
              13,
              10,
              11,
              100,
              97,
              116,
              97,
              98,
              97,
              115,
              101,
              95,
              105,
              100,
            ]),
          ],
        },
      },
    },
    /**
     * Commits a transaction, optionally creating, deleting or modifying some
     * entities.
     */
    commit: {
      name: "Commit",
      requestType: CommitRequest,
      requestStream: false,
      responseType: CommitResponse,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [
            Buffer.from([
              37,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              95,
              105,
              100,
              44,
              109,
              111,
              100,
              101,
              44,
              116,
              114,
              97,
              110,
              115,
              97,
              99,
              116,
              105,
              111,
              110,
              44,
              109,
              117,
              116,
              97,
              116,
              105,
              111,
              110,
              115,
            ]),
            Buffer.from([
              25,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              95,
              105,
              100,
              44,
              109,
              111,
              100,
              101,
              44,
              109,
              117,
              116,
              97,
              116,
              105,
              111,
              110,
              115,
            ]),
          ],
          578365826: [
            Buffer.from([
              37,
              58,
              1,
              42,
              34,
              32,
              47,
              118,
              49,
              47,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              123,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              95,
              105,
              100,
              125,
              58,
              99,
              111,
              109,
              109,
              105,
              116,
            ]),
          ],
          578365834: [
            Buffer.from([
              29,
              18,
              12,
              10,
              10,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              95,
              105,
              100,
              18,
              13,
              10,
              11,
              100,
              97,
              116,
              97,
              98,
              97,
              115,
              101,
              95,
              105,
              100,
            ]),
          ],
        },
      },
    },
    /** Rolls back a transaction. */
    rollback: {
      name: "Rollback",
      requestType: RollbackRequest,
      requestStream: false,
      responseType: RollbackResponse,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [
            Buffer.from([
              22,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              95,
              105,
              100,
              44,
              116,
              114,
              97,
              110,
              115,
              97,
              99,
              116,
              105,
              111,
              110,
            ]),
          ],
          578365826: [
            Buffer.from([
              39,
              58,
              1,
              42,
              34,
              34,
              47,
              118,
              49,
              47,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              123,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              95,
              105,
              100,
              125,
              58,
              114,
              111,
              108,
              108,
              98,
              97,
              99,
              107,
            ]),
          ],
          578365834: [
            Buffer.from([
              29,
              18,
              12,
              10,
              10,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              95,
              105,
              100,
              18,
              13,
              10,
              11,
              100,
              97,
              116,
              97,
              98,
              97,
              115,
              101,
              95,
              105,
              100,
            ]),
          ],
        },
      },
    },
    /**
     * Allocates IDs for the given keys, which is useful for referencing an entity
     * before it is inserted.
     */
    allocateIds: {
      name: "AllocateIds",
      requestType: AllocateIdsRequest,
      requestStream: false,
      responseType: AllocateIdsResponse,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [Buffer.from([15, 112, 114, 111, 106, 101, 99, 116, 95, 105, 100, 44, 107, 101, 121, 115])],
          578365826: [
            Buffer.from([
              42,
              58,
              1,
              42,
              34,
              37,
              47,
              118,
              49,
              47,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              123,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              95,
              105,
              100,
              125,
              58,
              97,
              108,
              108,
              111,
              99,
              97,
              116,
              101,
              73,
              100,
              115,
            ]),
          ],
          578365834: [
            Buffer.from([
              29,
              18,
              12,
              10,
              10,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              95,
              105,
              100,
              18,
              13,
              10,
              11,
              100,
              97,
              116,
              97,
              98,
              97,
              115,
              101,
              95,
              105,
              100,
            ]),
          ],
        },
      },
    },
    /**
     * Prevents the supplied keys' IDs from being auto-allocated by Cloud
     * Datastore.
     */
    reserveIds: {
      name: "ReserveIds",
      requestType: ReserveIdsRequest,
      requestStream: false,
      responseType: ReserveIdsResponse,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [Buffer.from([15, 112, 114, 111, 106, 101, 99, 116, 95, 105, 100, 44, 107, 101, 121, 115])],
          578365826: [
            Buffer.from([
              41,
              58,
              1,
              42,
              34,
              36,
              47,
              118,
              49,
              47,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              123,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              95,
              105,
              100,
              125,
              58,
              114,
              101,
              115,
              101,
              114,
              118,
              101,
              73,
              100,
              115,
            ]),
          ],
          578365834: [
            Buffer.from([
              29,
              18,
              12,
              10,
              10,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              95,
              105,
              100,
              18,
              13,
              10,
              11,
              100,
              97,
              116,
              97,
              98,
              97,
              115,
              101,
              95,
              105,
              100,
            ]),
          ],
        },
      },
    },
  },
} as const;

export interface DatastoreServiceImplementation<CallContextExt = {}> {
  /** Looks up entities by key. */
  lookup(request: LookupRequest, context: CallContext & CallContextExt): Promise<DeepPartial<LookupResponse>>;
  /** Queries for entities. */
  runQuery(request: RunQueryRequest, context: CallContext & CallContextExt): Promise<DeepPartial<RunQueryResponse>>;
  /** Runs an aggregation query. */
  runAggregationQuery(
    request: RunAggregationQueryRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<RunAggregationQueryResponse>>;
  /** Begins a new transaction. */
  beginTransaction(
    request: BeginTransactionRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<BeginTransactionResponse>>;
  /**
   * Commits a transaction, optionally creating, deleting or modifying some
   * entities.
   */
  commit(request: CommitRequest, context: CallContext & CallContextExt): Promise<DeepPartial<CommitResponse>>;
  /** Rolls back a transaction. */
  rollback(request: RollbackRequest, context: CallContext & CallContextExt): Promise<DeepPartial<RollbackResponse>>;
  /**
   * Allocates IDs for the given keys, which is useful for referencing an entity
   * before it is inserted.
   */
  allocateIds(
    request: AllocateIdsRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<AllocateIdsResponse>>;
  /**
   * Prevents the supplied keys' IDs from being auto-allocated by Cloud
   * Datastore.
   */
  reserveIds(
    request: ReserveIdsRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<ReserveIdsResponse>>;
}

export interface DatastoreClient<CallOptionsExt = {}> {
  /** Looks up entities by key. */
  lookup(request: DeepPartial<LookupRequest>, options?: CallOptions & CallOptionsExt): Promise<LookupResponse>;
  /** Queries for entities. */
  runQuery(request: DeepPartial<RunQueryRequest>, options?: CallOptions & CallOptionsExt): Promise<RunQueryResponse>;
  /** Runs an aggregation query. */
  runAggregationQuery(
    request: DeepPartial<RunAggregationQueryRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<RunAggregationQueryResponse>;
  /** Begins a new transaction. */
  beginTransaction(
    request: DeepPartial<BeginTransactionRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<BeginTransactionResponse>;
  /**
   * Commits a transaction, optionally creating, deleting or modifying some
   * entities.
   */
  commit(request: DeepPartial<CommitRequest>, options?: CallOptions & CallOptionsExt): Promise<CommitResponse>;
  /** Rolls back a transaction. */
  rollback(request: DeepPartial<RollbackRequest>, options?: CallOptions & CallOptionsExt): Promise<RollbackResponse>;
  /**
   * Allocates IDs for the given keys, which is useful for referencing an entity
   * before it is inserted.
   */
  allocateIds(
    request: DeepPartial<AllocateIdsRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<AllocateIdsResponse>;
  /**
   * Prevents the supplied keys' IDs from being auto-allocated by Cloud
   * Datastore.
   */
  reserveIds(
    request: DeepPartial<ReserveIdsRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<ReserveIdsResponse>;
}

function bytesFromBase64(b64: string): Uint8Array {
  return Uint8Array.from(globalThis.Buffer.from(b64, "base64"));
}

function base64FromBytes(arr: Uint8Array): string {
  return globalThis.Buffer.from(arr).toString("base64");
}

type Builtin = Date | Function | Uint8Array | string | number | boolean | undefined;

export type DeepPartial<T> = T extends Builtin ? T
  : T extends Long ? string | number | Long : T extends globalThis.Array<infer U> ? globalThis.Array<DeepPartial<U>>
  : T extends ReadonlyArray<infer U> ? ReadonlyArray<DeepPartial<U>>
  : T extends {} ? { [K in keyof T]?: DeepPartial<T[K]> }
  : Partial<T>;

function toTimestamp(date: Date): Timestamp {
  const seconds = numberToLong(Math.trunc(date.getTime() / 1_000));
  const nanos = (date.getTime() % 1_000) * 1_000_000;
  return { seconds, nanos };
}

function fromTimestamp(t: Timestamp): Date {
  let millis = (t.seconds.toNumber() || 0) * 1_000;
  millis += (t.nanos || 0) / 1_000_000;
  return new globalThis.Date(millis);
}

function fromJsonTimestamp(o: any): Date {
  if (o instanceof globalThis.Date) {
    return o;
  } else if (typeof o === "string") {
    return new globalThis.Date(o);
  } else {
    return fromTimestamp(Timestamp.fromJSON(o));
  }
}

function numberToLong(number: number) {
  return Long.fromNumber(number);
}

function isSet(value: any): boolean {
  return value !== null && value !== undefined;
}

export interface MessageFns<T> {
  encode(message: T, writer?: BinaryWriter): BinaryWriter;
  decode(input: BinaryReader | Uint8Array, length?: number): T;
  fromJSON(object: any): T;
  toJSON(message: T): unknown;
  create(base?: DeepPartial<T>): T;
  fromPartial(object: DeepPartial<T>): T;
}
