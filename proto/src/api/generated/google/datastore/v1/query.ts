// Code generated by protoc-gen-ts_proto. DO NOT EDIT.
// versions:
//   protoc-gen-ts_proto  v2.2.0
//   protoc               unknown
// source: google/datastore/v1/query.proto

/* eslint-disable */
import { BinaryReader, BinaryWriter } from "@bufbuild/protobuf/wire";
import Long from "long";
import { Timestamp } from "../../protobuf/timestamp.js";
import { Int32Value, Int64Value } from "../../protobuf/wrappers.js";
import { Entity, Value } from "./entity.js";

export const protobufPackage = "google.datastore.v1";

/** The result of fetching an entity from Datastore. */
export interface EntityResult {
  /** The resulting entity. */
  entity:
    | Entity
    | undefined;
  /**
   * The version of the entity, a strictly positive number that monotonically
   * increases with changes to the entity.
   *
   * This field is set for
   * [`FULL`][google.datastore.v1.EntityResult.ResultType.FULL] entity results.
   *
   * For [missing][google.datastore.v1.LookupResponse.missing] entities in
   * `LookupResponse`, this is the version of the snapshot that was used to look
   * up the entity, and it is always set except for eventually consistent reads.
   */
  version: Long;
  /**
   * The time at which the entity was created.
   * This field is set for
   * [`FULL`][google.datastore.v1.EntityResult.ResultType.FULL] entity results.
   * If this entity is missing, this field will not be set.
   */
  createTime:
    | Date
    | undefined;
  /**
   * The time at which the entity was last changed.
   * This field is set for
   * [`FULL`][google.datastore.v1.EntityResult.ResultType.FULL] entity results.
   * If this entity is missing, this field will not be set.
   */
  updateTime:
    | Date
    | undefined;
  /**
   * A cursor that points to the position after the result entity.
   * Set only when the `EntityResult` is part of a `QueryResultBatch` message.
   */
  cursor: Buffer;
}

/**
 * Specifies what data the 'entity' field contains.
 * A `ResultType` is either implied (for example, in `LookupResponse.missing`
 * from `datastore.proto`, it is always `KEY_ONLY`) or specified by context
 * (for example, in message `QueryResultBatch`, field `entity_result_type`
 * specifies a `ResultType` for all the values in field `entity_results`).
 */
export enum EntityResult_ResultType {
  /** RESULT_TYPE_UNSPECIFIED - Unspecified. This value is never used. */
  RESULT_TYPE_UNSPECIFIED = 0,
  /** FULL - The key and properties. */
  FULL = 1,
  /** PROJECTION - A projected subset of properties. The entity may have no key. */
  PROJECTION = 2,
  /** KEY_ONLY - Only the key. */
  KEY_ONLY = 3,
  UNRECOGNIZED = -1,
}

export function entityResult_ResultTypeFromJSON(object: any): EntityResult_ResultType {
  switch (object) {
    case 0:
    case "RESULT_TYPE_UNSPECIFIED":
      return EntityResult_ResultType.RESULT_TYPE_UNSPECIFIED;
    case 1:
    case "FULL":
      return EntityResult_ResultType.FULL;
    case 2:
    case "PROJECTION":
      return EntityResult_ResultType.PROJECTION;
    case 3:
    case "KEY_ONLY":
      return EntityResult_ResultType.KEY_ONLY;
    case -1:
    case "UNRECOGNIZED":
    default:
      return EntityResult_ResultType.UNRECOGNIZED;
  }
}

export function entityResult_ResultTypeToJSON(object: EntityResult_ResultType): string {
  switch (object) {
    case EntityResult_ResultType.RESULT_TYPE_UNSPECIFIED:
      return "RESULT_TYPE_UNSPECIFIED";
    case EntityResult_ResultType.FULL:
      return "FULL";
    case EntityResult_ResultType.PROJECTION:
      return "PROJECTION";
    case EntityResult_ResultType.KEY_ONLY:
      return "KEY_ONLY";
    case EntityResult_ResultType.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/** A query for entities. */
export interface Query {
  /** The projection to return. Defaults to returning all properties. */
  projection: Projection[];
  /**
   * The kinds to query (if empty, returns entities of all kinds).
   * Currently at most 1 kind may be specified.
   */
  kind: KindExpression[];
  /** The filter to apply. */
  filter:
    | Filter
    | undefined;
  /** The order to apply to the query results (if empty, order is unspecified). */
  order: PropertyOrder[];
  /**
   * The properties to make distinct. The query results will contain the first
   * result for each distinct combination of values for the given properties
   * (if empty, all results are returned).
   *
   * Requires:
   *
   * * If `order` is specified, the set of distinct on properties must appear
   * before the non-distinct on properties in `order`.
   */
  distinctOn: PropertyReference[];
  /**
   * A starting point for the query results. Query cursors are
   * returned in query result batches and
   * [can only be used to continue the same
   * query](https://cloud.google.com/datastore/docs/concepts/queries#cursors_limits_and_offsets).
   */
  startCursor: Buffer;
  /**
   * An ending point for the query results. Query cursors are
   * returned in query result batches and
   * [can only be used to limit the same
   * query](https://cloud.google.com/datastore/docs/concepts/queries#cursors_limits_and_offsets).
   */
  endCursor: Buffer;
  /**
   * The number of results to skip. Applies before limit, but after all other
   * constraints. Optional. Must be >= 0 if specified.
   */
  offset: number;
  /**
   * The maximum number of results to return. Applies after all other
   * constraints. Optional.
   * Unspecified is interpreted as no limit.
   * Must be >= 0 if specified.
   */
  limit: number | undefined;
}

/**
 * Datastore query for running an aggregation over a
 * [Query][google.datastore.v1.Query].
 */
export interface AggregationQuery {
  /** Nested query for aggregation */
  nestedQuery?:
    | Query
    | undefined;
  /**
   * Optional. Series of aggregations to apply over the results of the
   * `nested_query`.
   *
   * Requires:
   *
   * * A minimum of one and maximum of five aggregations per query.
   */
  aggregations: AggregationQuery_Aggregation[];
}

/** Defines an aggregation that produces a single result. */
export interface AggregationQuery_Aggregation {
  /** Count aggregator. */
  count?:
    | AggregationQuery_Aggregation_Count
    | undefined;
  /** Sum aggregator. */
  sum?:
    | AggregationQuery_Aggregation_Sum
    | undefined;
  /** Average aggregator. */
  avg?:
    | AggregationQuery_Aggregation_Avg
    | undefined;
  /**
   * Optional. Optional name of the property to store the result of the
   * aggregation.
   *
   * If not provided, Datastore will pick a default name following the format
   * `property_<incremental_id++>`. For example:
   *
   * ```
   * AGGREGATE
   *   COUNT_UP_TO(1) AS count_up_to_1,
   *   COUNT_UP_TO(2),
   *   COUNT_UP_TO(3) AS count_up_to_3,
   *   COUNT(*)
   * OVER (
   *   ...
   * );
   * ```
   *
   * becomes:
   *
   * ```
   * AGGREGATE
   *   COUNT_UP_TO(1) AS count_up_to_1,
   *   COUNT_UP_TO(2) AS property_1,
   *   COUNT_UP_TO(3) AS count_up_to_3,
   *   COUNT(*) AS property_2
   * OVER (
   *   ...
   * );
   * ```
   *
   * Requires:
   *
   * * Must be unique across all aggregation aliases.
   * * Conform to [entity property
   * name][google.datastore.v1.Entity.properties] limitations.
   */
  alias: string;
}

/**
 * Count of entities that match the query.
 *
 * The `COUNT(*)` aggregation function operates on the entire entity
 * so it does not require a field reference.
 */
export interface AggregationQuery_Aggregation_Count {
  /**
   * Optional. Optional constraint on the maximum number of entities to
   * count.
   *
   * This provides a way to set an upper bound on the number of entities
   * to scan, limiting latency, and cost.
   *
   * Unspecified is interpreted as no bound.
   *
   * If a zero value is provided, a count result of zero should always be
   * expected.
   *
   * High-Level Example:
   *
   * ```
   * AGGREGATE COUNT_UP_TO(1000) OVER ( SELECT * FROM k );
   * ```
   *
   * Requires:
   *
   * * Must be non-negative when present.
   */
  upTo: Long | undefined;
}

/**
 * Sum of the values of the requested property.
 *
 * * Only numeric values will be aggregated. All non-numeric values
 * including `NULL` are skipped.
 *
 * * If the aggregated values contain `NaN`, returns `NaN`. Infinity math
 * follows IEEE-754 standards.
 *
 * * If the aggregated value set is empty, returns 0.
 *
 * * Returns a 64-bit integer if all aggregated numbers are integers and the
 * sum result does not overflow. Otherwise, the result is returned as a
 * double. Note that even if all the aggregated values are integers, the
 * result is returned as a double if it cannot fit within a 64-bit signed
 * integer. When this occurs, the returned value will lose precision.
 *
 * * When underflow occurs, floating-point aggregation is non-deterministic.
 * This means that running the same query repeatedly without any changes to
 * the underlying values could produce slightly different results each
 * time. In those cases, values should be stored as integers over
 * floating-point numbers.
 */
export interface AggregationQuery_Aggregation_Sum {
  /** The property to aggregate on. */
  property: PropertyReference | undefined;
}

/**
 * Average of the values of the requested property.
 *
 * * Only numeric values will be aggregated. All non-numeric values
 * including `NULL` are skipped.
 *
 * * If the aggregated values contain `NaN`, returns `NaN`. Infinity math
 * follows IEEE-754 standards.
 *
 * * If the aggregated value set is empty, returns `NULL`.
 *
 * * Always returns the result as a double.
 */
export interface AggregationQuery_Aggregation_Avg {
  /** The property to aggregate on. */
  property: PropertyReference | undefined;
}

/** A representation of a kind. */
export interface KindExpression {
  /** The name of the kind. */
  name: string;
}

/** A reference to a property relative to the kind expressions. */
export interface PropertyReference {
  /**
   * A reference to a property.
   *
   * Requires:
   *
   * * MUST be a dot-delimited (`.`) string of segments, where each segment
   * conforms to [entity property name][google.datastore.v1.Entity.properties]
   * limitations.
   */
  name: string;
}

/** A representation of a property in a projection. */
export interface Projection {
  /** The property to project. */
  property: PropertyReference | undefined;
}

/** The desired order for a specific property. */
export interface PropertyOrder {
  /** The property to order by. */
  property:
    | PropertyReference
    | undefined;
  /** The direction to order by. Defaults to `ASCENDING`. */
  direction: PropertyOrder_Direction;
}

/** The sort direction. */
export enum PropertyOrder_Direction {
  /** DIRECTION_UNSPECIFIED - Unspecified. This value must not be used. */
  DIRECTION_UNSPECIFIED = 0,
  /** ASCENDING - Ascending. */
  ASCENDING = 1,
  /** DESCENDING - Descending. */
  DESCENDING = 2,
  UNRECOGNIZED = -1,
}

export function propertyOrder_DirectionFromJSON(object: any): PropertyOrder_Direction {
  switch (object) {
    case 0:
    case "DIRECTION_UNSPECIFIED":
      return PropertyOrder_Direction.DIRECTION_UNSPECIFIED;
    case 1:
    case "ASCENDING":
      return PropertyOrder_Direction.ASCENDING;
    case 2:
    case "DESCENDING":
      return PropertyOrder_Direction.DESCENDING;
    case -1:
    case "UNRECOGNIZED":
    default:
      return PropertyOrder_Direction.UNRECOGNIZED;
  }
}

export function propertyOrder_DirectionToJSON(object: PropertyOrder_Direction): string {
  switch (object) {
    case PropertyOrder_Direction.DIRECTION_UNSPECIFIED:
      return "DIRECTION_UNSPECIFIED";
    case PropertyOrder_Direction.ASCENDING:
      return "ASCENDING";
    case PropertyOrder_Direction.DESCENDING:
      return "DESCENDING";
    case PropertyOrder_Direction.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/** A holder for any type of filter. */
export interface Filter {
  /** A composite filter. */
  compositeFilter?:
    | CompositeFilter
    | undefined;
  /** A filter on a property. */
  propertyFilter?: PropertyFilter | undefined;
}

/** A filter that merges multiple other filters using the given operator. */
export interface CompositeFilter {
  /** The operator for combining multiple filters. */
  op: CompositeFilter_Operator;
  /**
   * The list of filters to combine.
   *
   * Requires:
   *
   * * At least one filter is present.
   */
  filters: Filter[];
}

/** A composite filter operator. */
export enum CompositeFilter_Operator {
  /** OPERATOR_UNSPECIFIED - Unspecified. This value must not be used. */
  OPERATOR_UNSPECIFIED = 0,
  /** AND - The results are required to satisfy each of the combined filters. */
  AND = 1,
  /** OR - Documents are required to satisfy at least one of the combined filters. */
  OR = 2,
  UNRECOGNIZED = -1,
}

export function compositeFilter_OperatorFromJSON(object: any): CompositeFilter_Operator {
  switch (object) {
    case 0:
    case "OPERATOR_UNSPECIFIED":
      return CompositeFilter_Operator.OPERATOR_UNSPECIFIED;
    case 1:
    case "AND":
      return CompositeFilter_Operator.AND;
    case 2:
    case "OR":
      return CompositeFilter_Operator.OR;
    case -1:
    case "UNRECOGNIZED":
    default:
      return CompositeFilter_Operator.UNRECOGNIZED;
  }
}

export function compositeFilter_OperatorToJSON(object: CompositeFilter_Operator): string {
  switch (object) {
    case CompositeFilter_Operator.OPERATOR_UNSPECIFIED:
      return "OPERATOR_UNSPECIFIED";
    case CompositeFilter_Operator.AND:
      return "AND";
    case CompositeFilter_Operator.OR:
      return "OR";
    case CompositeFilter_Operator.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/** A filter on a specific property. */
export interface PropertyFilter {
  /** The property to filter by. */
  property:
    | PropertyReference
    | undefined;
  /** The operator to filter by. */
  op: PropertyFilter_Operator;
  /** The value to compare the property to. */
  value: Value | undefined;
}

/** A property filter operator. */
export enum PropertyFilter_Operator {
  /** OPERATOR_UNSPECIFIED - Unspecified. This value must not be used. */
  OPERATOR_UNSPECIFIED = 0,
  /**
   * LESS_THAN - The given `property` is less than the given `value`.
   *
   * Requires:
   *
   * * That `property` comes first in `order_by`.
   */
  LESS_THAN = 1,
  /**
   * LESS_THAN_OR_EQUAL - The given `property` is less than or equal to the given `value`.
   *
   * Requires:
   *
   * * That `property` comes first in `order_by`.
   */
  LESS_THAN_OR_EQUAL = 2,
  /**
   * GREATER_THAN - The given `property` is greater than the given `value`.
   *
   * Requires:
   *
   * * That `property` comes first in `order_by`.
   */
  GREATER_THAN = 3,
  /**
   * GREATER_THAN_OR_EQUAL - The given `property` is greater than or equal to the given `value`.
   *
   * Requires:
   *
   * * That `property` comes first in `order_by`.
   */
  GREATER_THAN_OR_EQUAL = 4,
  /** EQUAL - The given `property` is equal to the given `value`. */
  EQUAL = 5,
  /**
   * IN - The given `property` is equal to at least one value in the given array.
   *
   * Requires:
   *
   * * That `value` is a non-empty `ArrayValue`, subject to disjunction
   *   limits.
   * * No `NOT_IN` is in the same query.
   */
  IN = 6,
  /**
   * NOT_EQUAL - The given `property` is not equal to the given `value`.
   *
   * Requires:
   *
   * * No other `NOT_EQUAL` or `NOT_IN` is in the same query.
   * * That `property` comes first in the `order_by`.
   */
  NOT_EQUAL = 9,
  /**
   * HAS_ANCESTOR - Limit the result set to the given entity and its descendants.
   *
   * Requires:
   *
   * * That `value` is an entity key.
   * * All evaluated disjunctions must have the same `HAS_ANCESTOR` filter.
   */
  HAS_ANCESTOR = 11,
  /**
   * NOT_IN - The value of the `property` is not in the given array.
   *
   * Requires:
   *
   * * That `value` is a non-empty `ArrayValue` with at most 10 values.
   * * No other `OR`, `IN`, `NOT_IN`, `NOT_EQUAL` is in the same query.
   * * That `field` comes first in the `order_by`.
   */
  NOT_IN = 13,
  UNRECOGNIZED = -1,
}

export function propertyFilter_OperatorFromJSON(object: any): PropertyFilter_Operator {
  switch (object) {
    case 0:
    case "OPERATOR_UNSPECIFIED":
      return PropertyFilter_Operator.OPERATOR_UNSPECIFIED;
    case 1:
    case "LESS_THAN":
      return PropertyFilter_Operator.LESS_THAN;
    case 2:
    case "LESS_THAN_OR_EQUAL":
      return PropertyFilter_Operator.LESS_THAN_OR_EQUAL;
    case 3:
    case "GREATER_THAN":
      return PropertyFilter_Operator.GREATER_THAN;
    case 4:
    case "GREATER_THAN_OR_EQUAL":
      return PropertyFilter_Operator.GREATER_THAN_OR_EQUAL;
    case 5:
    case "EQUAL":
      return PropertyFilter_Operator.EQUAL;
    case 6:
    case "IN":
      return PropertyFilter_Operator.IN;
    case 9:
    case "NOT_EQUAL":
      return PropertyFilter_Operator.NOT_EQUAL;
    case 11:
    case "HAS_ANCESTOR":
      return PropertyFilter_Operator.HAS_ANCESTOR;
    case 13:
    case "NOT_IN":
      return PropertyFilter_Operator.NOT_IN;
    case -1:
    case "UNRECOGNIZED":
    default:
      return PropertyFilter_Operator.UNRECOGNIZED;
  }
}

export function propertyFilter_OperatorToJSON(object: PropertyFilter_Operator): string {
  switch (object) {
    case PropertyFilter_Operator.OPERATOR_UNSPECIFIED:
      return "OPERATOR_UNSPECIFIED";
    case PropertyFilter_Operator.LESS_THAN:
      return "LESS_THAN";
    case PropertyFilter_Operator.LESS_THAN_OR_EQUAL:
      return "LESS_THAN_OR_EQUAL";
    case PropertyFilter_Operator.GREATER_THAN:
      return "GREATER_THAN";
    case PropertyFilter_Operator.GREATER_THAN_OR_EQUAL:
      return "GREATER_THAN_OR_EQUAL";
    case PropertyFilter_Operator.EQUAL:
      return "EQUAL";
    case PropertyFilter_Operator.IN:
      return "IN";
    case PropertyFilter_Operator.NOT_EQUAL:
      return "NOT_EQUAL";
    case PropertyFilter_Operator.HAS_ANCESTOR:
      return "HAS_ANCESTOR";
    case PropertyFilter_Operator.NOT_IN:
      return "NOT_IN";
    case PropertyFilter_Operator.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/**
 * A [GQL
 * query](https://cloud.google.com/datastore/docs/apis/gql/gql_reference).
 */
export interface GqlQuery {
  /**
   * A string of the format described
   * [here](https://cloud.google.com/datastore/docs/apis/gql/gql_reference).
   */
  queryString: string;
  /**
   * When false, the query string must not contain any literals and instead must
   * bind all values. For example,
   * `SELECT * FROM Kind WHERE a = 'string literal'` is not allowed, while
   * `SELECT * FROM Kind WHERE a = @value` is.
   */
  allowLiterals: boolean;
  /**
   * For each non-reserved named binding site in the query string, there must be
   * a named parameter with that name, but not necessarily the inverse.
   *
   * Key must match regex `[A-Za-z_$][A-Za-z_$0-9]*`, must not match regex
   * `__.*__`, and must not be `""`.
   */
  namedBindings: { [key: string]: GqlQueryParameter };
  /**
   * Numbered binding site @1 references the first numbered parameter,
   * effectively using 1-based indexing, rather than the usual 0.
   *
   * For each binding site numbered i in `query_string`, there must be an i-th
   * numbered parameter. The inverse must also be true.
   */
  positionalBindings: GqlQueryParameter[];
}

export interface GqlQuery_NamedBindingsEntry {
  key: string;
  value: GqlQueryParameter | undefined;
}

/** A binding parameter for a GQL query. */
export interface GqlQueryParameter {
  /** A value parameter. */
  value?:
    | Value
    | undefined;
  /**
   * A query cursor. Query cursors are returned in query
   * result batches.
   */
  cursor?: Buffer | undefined;
}

/** A batch of results produced by a query. */
export interface QueryResultBatch {
  /** The number of results skipped, typically because of an offset. */
  skippedResults: number;
  /**
   * A cursor that points to the position after the last skipped result.
   * Will be set when `skipped_results` != 0.
   */
  skippedCursor: Buffer;
  /** The result type for every entity in `entity_results`. */
  entityResultType: EntityResult_ResultType;
  /** The results for this batch. */
  entityResults: EntityResult[];
  /** A cursor that points to the position after the last result in the batch. */
  endCursor: Buffer;
  /** The state of the query after the current batch. */
  moreResults: QueryResultBatch_MoreResultsType;
  /**
   * The version number of the snapshot this batch was returned from.
   * This applies to the range of results from the query's `start_cursor` (or
   * the beginning of the query if no cursor was given) to this batch's
   * `end_cursor` (not the query's `end_cursor`).
   *
   * In a single transaction, subsequent query result batches for the same query
   * can have a greater snapshot version number. Each batch's snapshot version
   * is valid for all preceding batches.
   * The value will be zero for eventually consistent queries.
   */
  snapshotVersion: Long;
  /**
   * Read timestamp this batch was returned from.
   * This applies to the range of results from the query's `start_cursor` (or
   * the beginning of the query if no cursor was given) to this batch's
   * `end_cursor` (not the query's `end_cursor`).
   *
   * In a single transaction, subsequent query result batches for the same query
   * can have a greater timestamp. Each batch's read timestamp
   * is valid for all preceding batches.
   * This value will not be set for eventually consistent queries in Cloud
   * Datastore.
   */
  readTime: Date | undefined;
}

/** The possible values for the `more_results` field. */
export enum QueryResultBatch_MoreResultsType {
  /** MORE_RESULTS_TYPE_UNSPECIFIED - Unspecified. This value is never used. */
  MORE_RESULTS_TYPE_UNSPECIFIED = 0,
  /** NOT_FINISHED - There may be additional batches to fetch from this query. */
  NOT_FINISHED = 1,
  /** MORE_RESULTS_AFTER_LIMIT - The query is finished, but there may be more results after the limit. */
  MORE_RESULTS_AFTER_LIMIT = 2,
  /**
   * MORE_RESULTS_AFTER_CURSOR - The query is finished, but there may be more results after the end
   * cursor.
   */
  MORE_RESULTS_AFTER_CURSOR = 4,
  /** NO_MORE_RESULTS - The query is finished, and there are no more results. */
  NO_MORE_RESULTS = 3,
  UNRECOGNIZED = -1,
}

export function queryResultBatch_MoreResultsTypeFromJSON(object: any): QueryResultBatch_MoreResultsType {
  switch (object) {
    case 0:
    case "MORE_RESULTS_TYPE_UNSPECIFIED":
      return QueryResultBatch_MoreResultsType.MORE_RESULTS_TYPE_UNSPECIFIED;
    case 1:
    case "NOT_FINISHED":
      return QueryResultBatch_MoreResultsType.NOT_FINISHED;
    case 2:
    case "MORE_RESULTS_AFTER_LIMIT":
      return QueryResultBatch_MoreResultsType.MORE_RESULTS_AFTER_LIMIT;
    case 4:
    case "MORE_RESULTS_AFTER_CURSOR":
      return QueryResultBatch_MoreResultsType.MORE_RESULTS_AFTER_CURSOR;
    case 3:
    case "NO_MORE_RESULTS":
      return QueryResultBatch_MoreResultsType.NO_MORE_RESULTS;
    case -1:
    case "UNRECOGNIZED":
    default:
      return QueryResultBatch_MoreResultsType.UNRECOGNIZED;
  }
}

export function queryResultBatch_MoreResultsTypeToJSON(object: QueryResultBatch_MoreResultsType): string {
  switch (object) {
    case QueryResultBatch_MoreResultsType.MORE_RESULTS_TYPE_UNSPECIFIED:
      return "MORE_RESULTS_TYPE_UNSPECIFIED";
    case QueryResultBatch_MoreResultsType.NOT_FINISHED:
      return "NOT_FINISHED";
    case QueryResultBatch_MoreResultsType.MORE_RESULTS_AFTER_LIMIT:
      return "MORE_RESULTS_AFTER_LIMIT";
    case QueryResultBatch_MoreResultsType.MORE_RESULTS_AFTER_CURSOR:
      return "MORE_RESULTS_AFTER_CURSOR";
    case QueryResultBatch_MoreResultsType.NO_MORE_RESULTS:
      return "NO_MORE_RESULTS";
    case QueryResultBatch_MoreResultsType.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

function createBaseEntityResult(): EntityResult {
  return {
    entity: undefined,
    version: Long.ZERO,
    createTime: undefined,
    updateTime: undefined,
    cursor: Buffer.alloc(0),
  };
}

export const EntityResult: MessageFns<EntityResult> = {
  encode(message: EntityResult, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.entity !== undefined) {
      Entity.encode(message.entity, writer.uint32(10).fork()).join();
    }
    if (!message.version.equals(Long.ZERO)) {
      writer.uint32(32).int64(message.version.toString());
    }
    if (message.createTime !== undefined) {
      Timestamp.encode(toTimestamp(message.createTime), writer.uint32(50).fork()).join();
    }
    if (message.updateTime !== undefined) {
      Timestamp.encode(toTimestamp(message.updateTime), writer.uint32(42).fork()).join();
    }
    if (message.cursor.length !== 0) {
      writer.uint32(26).bytes(message.cursor);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): EntityResult {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseEntityResult();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.entity = Entity.decode(reader, reader.uint32());
          continue;
        case 4:
          if (tag !== 32) {
            break;
          }

          message.version = Long.fromString(reader.int64().toString());
          continue;
        case 6:
          if (tag !== 50) {
            break;
          }

          message.createTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.updateTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.cursor = Buffer.from(reader.bytes());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): EntityResult {
    return {
      entity: isSet(object.entity) ? Entity.fromJSON(object.entity) : undefined,
      version: isSet(object.version) ? Long.fromValue(object.version) : Long.ZERO,
      createTime: isSet(object.createTime) ? fromJsonTimestamp(object.createTime) : undefined,
      updateTime: isSet(object.updateTime) ? fromJsonTimestamp(object.updateTime) : undefined,
      cursor: isSet(object.cursor) ? Buffer.from(bytesFromBase64(object.cursor)) : Buffer.alloc(0),
    };
  },

  toJSON(message: EntityResult): unknown {
    const obj: any = {};
    if (message.entity !== undefined) {
      obj.entity = Entity.toJSON(message.entity);
    }
    if (!message.version.equals(Long.ZERO)) {
      obj.version = (message.version || Long.ZERO).toString();
    }
    if (message.createTime !== undefined) {
      obj.createTime = message.createTime.toISOString();
    }
    if (message.updateTime !== undefined) {
      obj.updateTime = message.updateTime.toISOString();
    }
    if (message.cursor.length !== 0) {
      obj.cursor = base64FromBytes(message.cursor);
    }
    return obj;
  },

  create(base?: DeepPartial<EntityResult>): EntityResult {
    return EntityResult.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<EntityResult>): EntityResult {
    const message = createBaseEntityResult();
    message.entity = (object.entity !== undefined && object.entity !== null)
      ? Entity.fromPartial(object.entity)
      : undefined;
    message.version = (object.version !== undefined && object.version !== null)
      ? Long.fromValue(object.version)
      : Long.ZERO;
    message.createTime = object.createTime ?? undefined;
    message.updateTime = object.updateTime ?? undefined;
    message.cursor = object.cursor ?? Buffer.alloc(0);
    return message;
  },
};

function createBaseQuery(): Query {
  return {
    projection: [],
    kind: [],
    filter: undefined,
    order: [],
    distinctOn: [],
    startCursor: Buffer.alloc(0),
    endCursor: Buffer.alloc(0),
    offset: 0,
    limit: undefined,
  };
}

export const Query: MessageFns<Query> = {
  encode(message: Query, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.projection) {
      Projection.encode(v!, writer.uint32(18).fork()).join();
    }
    for (const v of message.kind) {
      KindExpression.encode(v!, writer.uint32(26).fork()).join();
    }
    if (message.filter !== undefined) {
      Filter.encode(message.filter, writer.uint32(34).fork()).join();
    }
    for (const v of message.order) {
      PropertyOrder.encode(v!, writer.uint32(42).fork()).join();
    }
    for (const v of message.distinctOn) {
      PropertyReference.encode(v!, writer.uint32(50).fork()).join();
    }
    if (message.startCursor.length !== 0) {
      writer.uint32(58).bytes(message.startCursor);
    }
    if (message.endCursor.length !== 0) {
      writer.uint32(66).bytes(message.endCursor);
    }
    if (message.offset !== 0) {
      writer.uint32(80).int32(message.offset);
    }
    if (message.limit !== undefined) {
      Int32Value.encode({ value: message.limit! }, writer.uint32(98).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Query {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseQuery();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 2:
          if (tag !== 18) {
            break;
          }

          message.projection.push(Projection.decode(reader, reader.uint32()));
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.kind.push(KindExpression.decode(reader, reader.uint32()));
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.filter = Filter.decode(reader, reader.uint32());
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.order.push(PropertyOrder.decode(reader, reader.uint32()));
          continue;
        case 6:
          if (tag !== 50) {
            break;
          }

          message.distinctOn.push(PropertyReference.decode(reader, reader.uint32()));
          continue;
        case 7:
          if (tag !== 58) {
            break;
          }

          message.startCursor = Buffer.from(reader.bytes());
          continue;
        case 8:
          if (tag !== 66) {
            break;
          }

          message.endCursor = Buffer.from(reader.bytes());
          continue;
        case 10:
          if (tag !== 80) {
            break;
          }

          message.offset = reader.int32();
          continue;
        case 12:
          if (tag !== 98) {
            break;
          }

          message.limit = Int32Value.decode(reader, reader.uint32()).value;
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Query {
    return {
      projection: globalThis.Array.isArray(object?.projection)
        ? object.projection.map((e: any) => Projection.fromJSON(e))
        : [],
      kind: globalThis.Array.isArray(object?.kind) ? object.kind.map((e: any) => KindExpression.fromJSON(e)) : [],
      filter: isSet(object.filter) ? Filter.fromJSON(object.filter) : undefined,
      order: globalThis.Array.isArray(object?.order) ? object.order.map((e: any) => PropertyOrder.fromJSON(e)) : [],
      distinctOn: globalThis.Array.isArray(object?.distinctOn)
        ? object.distinctOn.map((e: any) => PropertyReference.fromJSON(e))
        : [],
      startCursor: isSet(object.startCursor) ? Buffer.from(bytesFromBase64(object.startCursor)) : Buffer.alloc(0),
      endCursor: isSet(object.endCursor) ? Buffer.from(bytesFromBase64(object.endCursor)) : Buffer.alloc(0),
      offset: isSet(object.offset) ? globalThis.Number(object.offset) : 0,
      limit: isSet(object.limit) ? Number(object.limit) : undefined,
    };
  },

  toJSON(message: Query): unknown {
    const obj: any = {};
    if (message.projection?.length) {
      obj.projection = message.projection.map((e) => Projection.toJSON(e));
    }
    if (message.kind?.length) {
      obj.kind = message.kind.map((e) => KindExpression.toJSON(e));
    }
    if (message.filter !== undefined) {
      obj.filter = Filter.toJSON(message.filter);
    }
    if (message.order?.length) {
      obj.order = message.order.map((e) => PropertyOrder.toJSON(e));
    }
    if (message.distinctOn?.length) {
      obj.distinctOn = message.distinctOn.map((e) => PropertyReference.toJSON(e));
    }
    if (message.startCursor.length !== 0) {
      obj.startCursor = base64FromBytes(message.startCursor);
    }
    if (message.endCursor.length !== 0) {
      obj.endCursor = base64FromBytes(message.endCursor);
    }
    if (message.offset !== 0) {
      obj.offset = Math.round(message.offset);
    }
    if (message.limit !== undefined) {
      obj.limit = message.limit;
    }
    return obj;
  },

  create(base?: DeepPartial<Query>): Query {
    return Query.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<Query>): Query {
    const message = createBaseQuery();
    message.projection = object.projection?.map((e) => Projection.fromPartial(e)) || [];
    message.kind = object.kind?.map((e) => KindExpression.fromPartial(e)) || [];
    message.filter = (object.filter !== undefined && object.filter !== null)
      ? Filter.fromPartial(object.filter)
      : undefined;
    message.order = object.order?.map((e) => PropertyOrder.fromPartial(e)) || [];
    message.distinctOn = object.distinctOn?.map((e) => PropertyReference.fromPartial(e)) || [];
    message.startCursor = object.startCursor ?? Buffer.alloc(0);
    message.endCursor = object.endCursor ?? Buffer.alloc(0);
    message.offset = object.offset ?? 0;
    message.limit = object.limit ?? undefined;
    return message;
  },
};

function createBaseAggregationQuery(): AggregationQuery {
  return { nestedQuery: undefined, aggregations: [] };
}

export const AggregationQuery: MessageFns<AggregationQuery> = {
  encode(message: AggregationQuery, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.nestedQuery !== undefined) {
      Query.encode(message.nestedQuery, writer.uint32(10).fork()).join();
    }
    for (const v of message.aggregations) {
      AggregationQuery_Aggregation.encode(v!, writer.uint32(26).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): AggregationQuery {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseAggregationQuery();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.nestedQuery = Query.decode(reader, reader.uint32());
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.aggregations.push(AggregationQuery_Aggregation.decode(reader, reader.uint32()));
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): AggregationQuery {
    return {
      nestedQuery: isSet(object.nestedQuery) ? Query.fromJSON(object.nestedQuery) : undefined,
      aggregations: globalThis.Array.isArray(object?.aggregations)
        ? object.aggregations.map((e: any) => AggregationQuery_Aggregation.fromJSON(e))
        : [],
    };
  },

  toJSON(message: AggregationQuery): unknown {
    const obj: any = {};
    if (message.nestedQuery !== undefined) {
      obj.nestedQuery = Query.toJSON(message.nestedQuery);
    }
    if (message.aggregations?.length) {
      obj.aggregations = message.aggregations.map((e) => AggregationQuery_Aggregation.toJSON(e));
    }
    return obj;
  },

  create(base?: DeepPartial<AggregationQuery>): AggregationQuery {
    return AggregationQuery.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<AggregationQuery>): AggregationQuery {
    const message = createBaseAggregationQuery();
    message.nestedQuery = (object.nestedQuery !== undefined && object.nestedQuery !== null)
      ? Query.fromPartial(object.nestedQuery)
      : undefined;
    message.aggregations = object.aggregations?.map((e) => AggregationQuery_Aggregation.fromPartial(e)) || [];
    return message;
  },
};

function createBaseAggregationQuery_Aggregation(): AggregationQuery_Aggregation {
  return { count: undefined, sum: undefined, avg: undefined, alias: "" };
}

export const AggregationQuery_Aggregation: MessageFns<AggregationQuery_Aggregation> = {
  encode(message: AggregationQuery_Aggregation, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.count !== undefined) {
      AggregationQuery_Aggregation_Count.encode(message.count, writer.uint32(10).fork()).join();
    }
    if (message.sum !== undefined) {
      AggregationQuery_Aggregation_Sum.encode(message.sum, writer.uint32(18).fork()).join();
    }
    if (message.avg !== undefined) {
      AggregationQuery_Aggregation_Avg.encode(message.avg, writer.uint32(26).fork()).join();
    }
    if (message.alias !== "") {
      writer.uint32(58).string(message.alias);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): AggregationQuery_Aggregation {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseAggregationQuery_Aggregation();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.count = AggregationQuery_Aggregation_Count.decode(reader, reader.uint32());
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.sum = AggregationQuery_Aggregation_Sum.decode(reader, reader.uint32());
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.avg = AggregationQuery_Aggregation_Avg.decode(reader, reader.uint32());
          continue;
        case 7:
          if (tag !== 58) {
            break;
          }

          message.alias = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): AggregationQuery_Aggregation {
    return {
      count: isSet(object.count) ? AggregationQuery_Aggregation_Count.fromJSON(object.count) : undefined,
      sum: isSet(object.sum) ? AggregationQuery_Aggregation_Sum.fromJSON(object.sum) : undefined,
      avg: isSet(object.avg) ? AggregationQuery_Aggregation_Avg.fromJSON(object.avg) : undefined,
      alias: isSet(object.alias) ? globalThis.String(object.alias) : "",
    };
  },

  toJSON(message: AggregationQuery_Aggregation): unknown {
    const obj: any = {};
    if (message.count !== undefined) {
      obj.count = AggregationQuery_Aggregation_Count.toJSON(message.count);
    }
    if (message.sum !== undefined) {
      obj.sum = AggregationQuery_Aggregation_Sum.toJSON(message.sum);
    }
    if (message.avg !== undefined) {
      obj.avg = AggregationQuery_Aggregation_Avg.toJSON(message.avg);
    }
    if (message.alias !== "") {
      obj.alias = message.alias;
    }
    return obj;
  },

  create(base?: DeepPartial<AggregationQuery_Aggregation>): AggregationQuery_Aggregation {
    return AggregationQuery_Aggregation.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<AggregationQuery_Aggregation>): AggregationQuery_Aggregation {
    const message = createBaseAggregationQuery_Aggregation();
    message.count = (object.count !== undefined && object.count !== null)
      ? AggregationQuery_Aggregation_Count.fromPartial(object.count)
      : undefined;
    message.sum = (object.sum !== undefined && object.sum !== null)
      ? AggregationQuery_Aggregation_Sum.fromPartial(object.sum)
      : undefined;
    message.avg = (object.avg !== undefined && object.avg !== null)
      ? AggregationQuery_Aggregation_Avg.fromPartial(object.avg)
      : undefined;
    message.alias = object.alias ?? "";
    return message;
  },
};

function createBaseAggregationQuery_Aggregation_Count(): AggregationQuery_Aggregation_Count {
  return { upTo: undefined };
}

export const AggregationQuery_Aggregation_Count: MessageFns<AggregationQuery_Aggregation_Count> = {
  encode(message: AggregationQuery_Aggregation_Count, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.upTo !== undefined) {
      Int64Value.encode({ value: message.upTo! }, writer.uint32(10).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): AggregationQuery_Aggregation_Count {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseAggregationQuery_Aggregation_Count();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.upTo = Int64Value.decode(reader, reader.uint32()).value;
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): AggregationQuery_Aggregation_Count {
    return { upTo: isSet(object.upTo) ? Long.fromValue(object.upTo) : undefined };
  },

  toJSON(message: AggregationQuery_Aggregation_Count): unknown {
    const obj: any = {};
    if (message.upTo !== undefined) {
      obj.upTo = message.upTo;
    }
    return obj;
  },

  create(base?: DeepPartial<AggregationQuery_Aggregation_Count>): AggregationQuery_Aggregation_Count {
    return AggregationQuery_Aggregation_Count.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<AggregationQuery_Aggregation_Count>): AggregationQuery_Aggregation_Count {
    const message = createBaseAggregationQuery_Aggregation_Count();
    message.upTo = (object.upTo !== undefined && object.upTo !== null) ? Long.fromValue(object.upTo) : undefined;
    return message;
  },
};

function createBaseAggregationQuery_Aggregation_Sum(): AggregationQuery_Aggregation_Sum {
  return { property: undefined };
}

export const AggregationQuery_Aggregation_Sum: MessageFns<AggregationQuery_Aggregation_Sum> = {
  encode(message: AggregationQuery_Aggregation_Sum, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.property !== undefined) {
      PropertyReference.encode(message.property, writer.uint32(10).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): AggregationQuery_Aggregation_Sum {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseAggregationQuery_Aggregation_Sum();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.property = PropertyReference.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): AggregationQuery_Aggregation_Sum {
    return { property: isSet(object.property) ? PropertyReference.fromJSON(object.property) : undefined };
  },

  toJSON(message: AggregationQuery_Aggregation_Sum): unknown {
    const obj: any = {};
    if (message.property !== undefined) {
      obj.property = PropertyReference.toJSON(message.property);
    }
    return obj;
  },

  create(base?: DeepPartial<AggregationQuery_Aggregation_Sum>): AggregationQuery_Aggregation_Sum {
    return AggregationQuery_Aggregation_Sum.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<AggregationQuery_Aggregation_Sum>): AggregationQuery_Aggregation_Sum {
    const message = createBaseAggregationQuery_Aggregation_Sum();
    message.property = (object.property !== undefined && object.property !== null)
      ? PropertyReference.fromPartial(object.property)
      : undefined;
    return message;
  },
};

function createBaseAggregationQuery_Aggregation_Avg(): AggregationQuery_Aggregation_Avg {
  return { property: undefined };
}

export const AggregationQuery_Aggregation_Avg: MessageFns<AggregationQuery_Aggregation_Avg> = {
  encode(message: AggregationQuery_Aggregation_Avg, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.property !== undefined) {
      PropertyReference.encode(message.property, writer.uint32(10).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): AggregationQuery_Aggregation_Avg {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseAggregationQuery_Aggregation_Avg();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.property = PropertyReference.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): AggregationQuery_Aggregation_Avg {
    return { property: isSet(object.property) ? PropertyReference.fromJSON(object.property) : undefined };
  },

  toJSON(message: AggregationQuery_Aggregation_Avg): unknown {
    const obj: any = {};
    if (message.property !== undefined) {
      obj.property = PropertyReference.toJSON(message.property);
    }
    return obj;
  },

  create(base?: DeepPartial<AggregationQuery_Aggregation_Avg>): AggregationQuery_Aggregation_Avg {
    return AggregationQuery_Aggregation_Avg.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<AggregationQuery_Aggregation_Avg>): AggregationQuery_Aggregation_Avg {
    const message = createBaseAggregationQuery_Aggregation_Avg();
    message.property = (object.property !== undefined && object.property !== null)
      ? PropertyReference.fromPartial(object.property)
      : undefined;
    return message;
  },
};

function createBaseKindExpression(): KindExpression {
  return { name: "" };
}

export const KindExpression: MessageFns<KindExpression> = {
  encode(message: KindExpression, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): KindExpression {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseKindExpression();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): KindExpression {
    return { name: isSet(object.name) ? globalThis.String(object.name) : "" };
  },

  toJSON(message: KindExpression): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    return obj;
  },

  create(base?: DeepPartial<KindExpression>): KindExpression {
    return KindExpression.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<KindExpression>): KindExpression {
    const message = createBaseKindExpression();
    message.name = object.name ?? "";
    return message;
  },
};

function createBasePropertyReference(): PropertyReference {
  return { name: "" };
}

export const PropertyReference: MessageFns<PropertyReference> = {
  encode(message: PropertyReference, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(18).string(message.name);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): PropertyReference {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBasePropertyReference();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 2:
          if (tag !== 18) {
            break;
          }

          message.name = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): PropertyReference {
    return { name: isSet(object.name) ? globalThis.String(object.name) : "" };
  },

  toJSON(message: PropertyReference): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    return obj;
  },

  create(base?: DeepPartial<PropertyReference>): PropertyReference {
    return PropertyReference.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<PropertyReference>): PropertyReference {
    const message = createBasePropertyReference();
    message.name = object.name ?? "";
    return message;
  },
};

function createBaseProjection(): Projection {
  return { property: undefined };
}

export const Projection: MessageFns<Projection> = {
  encode(message: Projection, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.property !== undefined) {
      PropertyReference.encode(message.property, writer.uint32(10).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Projection {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseProjection();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.property = PropertyReference.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Projection {
    return { property: isSet(object.property) ? PropertyReference.fromJSON(object.property) : undefined };
  },

  toJSON(message: Projection): unknown {
    const obj: any = {};
    if (message.property !== undefined) {
      obj.property = PropertyReference.toJSON(message.property);
    }
    return obj;
  },

  create(base?: DeepPartial<Projection>): Projection {
    return Projection.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<Projection>): Projection {
    const message = createBaseProjection();
    message.property = (object.property !== undefined && object.property !== null)
      ? PropertyReference.fromPartial(object.property)
      : undefined;
    return message;
  },
};

function createBasePropertyOrder(): PropertyOrder {
  return { property: undefined, direction: 0 };
}

export const PropertyOrder: MessageFns<PropertyOrder> = {
  encode(message: PropertyOrder, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.property !== undefined) {
      PropertyReference.encode(message.property, writer.uint32(10).fork()).join();
    }
    if (message.direction !== 0) {
      writer.uint32(16).int32(message.direction);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): PropertyOrder {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBasePropertyOrder();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.property = PropertyReference.decode(reader, reader.uint32());
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.direction = reader.int32() as any;
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): PropertyOrder {
    return {
      property: isSet(object.property) ? PropertyReference.fromJSON(object.property) : undefined,
      direction: isSet(object.direction) ? propertyOrder_DirectionFromJSON(object.direction) : 0,
    };
  },

  toJSON(message: PropertyOrder): unknown {
    const obj: any = {};
    if (message.property !== undefined) {
      obj.property = PropertyReference.toJSON(message.property);
    }
    if (message.direction !== 0) {
      obj.direction = propertyOrder_DirectionToJSON(message.direction);
    }
    return obj;
  },

  create(base?: DeepPartial<PropertyOrder>): PropertyOrder {
    return PropertyOrder.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<PropertyOrder>): PropertyOrder {
    const message = createBasePropertyOrder();
    message.property = (object.property !== undefined && object.property !== null)
      ? PropertyReference.fromPartial(object.property)
      : undefined;
    message.direction = object.direction ?? 0;
    return message;
  },
};

function createBaseFilter(): Filter {
  return { compositeFilter: undefined, propertyFilter: undefined };
}

export const Filter: MessageFns<Filter> = {
  encode(message: Filter, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.compositeFilter !== undefined) {
      CompositeFilter.encode(message.compositeFilter, writer.uint32(10).fork()).join();
    }
    if (message.propertyFilter !== undefined) {
      PropertyFilter.encode(message.propertyFilter, writer.uint32(18).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Filter {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseFilter();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.compositeFilter = CompositeFilter.decode(reader, reader.uint32());
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.propertyFilter = PropertyFilter.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Filter {
    return {
      compositeFilter: isSet(object.compositeFilter) ? CompositeFilter.fromJSON(object.compositeFilter) : undefined,
      propertyFilter: isSet(object.propertyFilter) ? PropertyFilter.fromJSON(object.propertyFilter) : undefined,
    };
  },

  toJSON(message: Filter): unknown {
    const obj: any = {};
    if (message.compositeFilter !== undefined) {
      obj.compositeFilter = CompositeFilter.toJSON(message.compositeFilter);
    }
    if (message.propertyFilter !== undefined) {
      obj.propertyFilter = PropertyFilter.toJSON(message.propertyFilter);
    }
    return obj;
  },

  create(base?: DeepPartial<Filter>): Filter {
    return Filter.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<Filter>): Filter {
    const message = createBaseFilter();
    message.compositeFilter = (object.compositeFilter !== undefined && object.compositeFilter !== null)
      ? CompositeFilter.fromPartial(object.compositeFilter)
      : undefined;
    message.propertyFilter = (object.propertyFilter !== undefined && object.propertyFilter !== null)
      ? PropertyFilter.fromPartial(object.propertyFilter)
      : undefined;
    return message;
  },
};

function createBaseCompositeFilter(): CompositeFilter {
  return { op: 0, filters: [] };
}

export const CompositeFilter: MessageFns<CompositeFilter> = {
  encode(message: CompositeFilter, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.op !== 0) {
      writer.uint32(8).int32(message.op);
    }
    for (const v of message.filters) {
      Filter.encode(v!, writer.uint32(18).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): CompositeFilter {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseCompositeFilter();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 8) {
            break;
          }

          message.op = reader.int32() as any;
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.filters.push(Filter.decode(reader, reader.uint32()));
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): CompositeFilter {
    return {
      op: isSet(object.op) ? compositeFilter_OperatorFromJSON(object.op) : 0,
      filters: globalThis.Array.isArray(object?.filters) ? object.filters.map((e: any) => Filter.fromJSON(e)) : [],
    };
  },

  toJSON(message: CompositeFilter): unknown {
    const obj: any = {};
    if (message.op !== 0) {
      obj.op = compositeFilter_OperatorToJSON(message.op);
    }
    if (message.filters?.length) {
      obj.filters = message.filters.map((e) => Filter.toJSON(e));
    }
    return obj;
  },

  create(base?: DeepPartial<CompositeFilter>): CompositeFilter {
    return CompositeFilter.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<CompositeFilter>): CompositeFilter {
    const message = createBaseCompositeFilter();
    message.op = object.op ?? 0;
    message.filters = object.filters?.map((e) => Filter.fromPartial(e)) || [];
    return message;
  },
};

function createBasePropertyFilter(): PropertyFilter {
  return { property: undefined, op: 0, value: undefined };
}

export const PropertyFilter: MessageFns<PropertyFilter> = {
  encode(message: PropertyFilter, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.property !== undefined) {
      PropertyReference.encode(message.property, writer.uint32(10).fork()).join();
    }
    if (message.op !== 0) {
      writer.uint32(16).int32(message.op);
    }
    if (message.value !== undefined) {
      Value.encode(message.value, writer.uint32(26).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): PropertyFilter {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBasePropertyFilter();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.property = PropertyReference.decode(reader, reader.uint32());
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.op = reader.int32() as any;
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.value = Value.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): PropertyFilter {
    return {
      property: isSet(object.property) ? PropertyReference.fromJSON(object.property) : undefined,
      op: isSet(object.op) ? propertyFilter_OperatorFromJSON(object.op) : 0,
      value: isSet(object.value) ? Value.fromJSON(object.value) : undefined,
    };
  },

  toJSON(message: PropertyFilter): unknown {
    const obj: any = {};
    if (message.property !== undefined) {
      obj.property = PropertyReference.toJSON(message.property);
    }
    if (message.op !== 0) {
      obj.op = propertyFilter_OperatorToJSON(message.op);
    }
    if (message.value !== undefined) {
      obj.value = Value.toJSON(message.value);
    }
    return obj;
  },

  create(base?: DeepPartial<PropertyFilter>): PropertyFilter {
    return PropertyFilter.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<PropertyFilter>): PropertyFilter {
    const message = createBasePropertyFilter();
    message.property = (object.property !== undefined && object.property !== null)
      ? PropertyReference.fromPartial(object.property)
      : undefined;
    message.op = object.op ?? 0;
    message.value = (object.value !== undefined && object.value !== null) ? Value.fromPartial(object.value) : undefined;
    return message;
  },
};

function createBaseGqlQuery(): GqlQuery {
  return { queryString: "", allowLiterals: false, namedBindings: {}, positionalBindings: [] };
}

export const GqlQuery: MessageFns<GqlQuery> = {
  encode(message: GqlQuery, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.queryString !== "") {
      writer.uint32(10).string(message.queryString);
    }
    if (message.allowLiterals !== false) {
      writer.uint32(16).bool(message.allowLiterals);
    }
    Object.entries(message.namedBindings).forEach(([key, value]) => {
      GqlQuery_NamedBindingsEntry.encode({ key: key as any, value }, writer.uint32(42).fork()).join();
    });
    for (const v of message.positionalBindings) {
      GqlQueryParameter.encode(v!, writer.uint32(34).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): GqlQuery {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseGqlQuery();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.queryString = reader.string();
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.allowLiterals = reader.bool();
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          const entry5 = GqlQuery_NamedBindingsEntry.decode(reader, reader.uint32());
          if (entry5.value !== undefined) {
            message.namedBindings[entry5.key] = entry5.value;
          }
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.positionalBindings.push(GqlQueryParameter.decode(reader, reader.uint32()));
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): GqlQuery {
    return {
      queryString: isSet(object.queryString) ? globalThis.String(object.queryString) : "",
      allowLiterals: isSet(object.allowLiterals) ? globalThis.Boolean(object.allowLiterals) : false,
      namedBindings: isObject(object.namedBindings)
        ? Object.entries(object.namedBindings).reduce<{ [key: string]: GqlQueryParameter }>((acc, [key, value]) => {
          acc[key] = GqlQueryParameter.fromJSON(value);
          return acc;
        }, {})
        : {},
      positionalBindings: globalThis.Array.isArray(object?.positionalBindings)
        ? object.positionalBindings.map((e: any) => GqlQueryParameter.fromJSON(e))
        : [],
    };
  },

  toJSON(message: GqlQuery): unknown {
    const obj: any = {};
    if (message.queryString !== "") {
      obj.queryString = message.queryString;
    }
    if (message.allowLiterals !== false) {
      obj.allowLiterals = message.allowLiterals;
    }
    if (message.namedBindings) {
      const entries = Object.entries(message.namedBindings);
      if (entries.length > 0) {
        obj.namedBindings = {};
        entries.forEach(([k, v]) => {
          obj.namedBindings[k] = GqlQueryParameter.toJSON(v);
        });
      }
    }
    if (message.positionalBindings?.length) {
      obj.positionalBindings = message.positionalBindings.map((e) => GqlQueryParameter.toJSON(e));
    }
    return obj;
  },

  create(base?: DeepPartial<GqlQuery>): GqlQuery {
    return GqlQuery.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<GqlQuery>): GqlQuery {
    const message = createBaseGqlQuery();
    message.queryString = object.queryString ?? "";
    message.allowLiterals = object.allowLiterals ?? false;
    message.namedBindings = Object.entries(object.namedBindings ?? {}).reduce<{ [key: string]: GqlQueryParameter }>(
      (acc, [key, value]) => {
        if (value !== undefined) {
          acc[key] = GqlQueryParameter.fromPartial(value);
        }
        return acc;
      },
      {},
    );
    message.positionalBindings = object.positionalBindings?.map((e) => GqlQueryParameter.fromPartial(e)) || [];
    return message;
  },
};

function createBaseGqlQuery_NamedBindingsEntry(): GqlQuery_NamedBindingsEntry {
  return { key: "", value: undefined };
}

export const GqlQuery_NamedBindingsEntry: MessageFns<GqlQuery_NamedBindingsEntry> = {
  encode(message: GqlQuery_NamedBindingsEntry, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.key !== "") {
      writer.uint32(10).string(message.key);
    }
    if (message.value !== undefined) {
      GqlQueryParameter.encode(message.value, writer.uint32(18).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): GqlQuery_NamedBindingsEntry {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseGqlQuery_NamedBindingsEntry();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.key = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.value = GqlQueryParameter.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): GqlQuery_NamedBindingsEntry {
    return {
      key: isSet(object.key) ? globalThis.String(object.key) : "",
      value: isSet(object.value) ? GqlQueryParameter.fromJSON(object.value) : undefined,
    };
  },

  toJSON(message: GqlQuery_NamedBindingsEntry): unknown {
    const obj: any = {};
    if (message.key !== "") {
      obj.key = message.key;
    }
    if (message.value !== undefined) {
      obj.value = GqlQueryParameter.toJSON(message.value);
    }
    return obj;
  },

  create(base?: DeepPartial<GqlQuery_NamedBindingsEntry>): GqlQuery_NamedBindingsEntry {
    return GqlQuery_NamedBindingsEntry.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<GqlQuery_NamedBindingsEntry>): GqlQuery_NamedBindingsEntry {
    const message = createBaseGqlQuery_NamedBindingsEntry();
    message.key = object.key ?? "";
    message.value = (object.value !== undefined && object.value !== null)
      ? GqlQueryParameter.fromPartial(object.value)
      : undefined;
    return message;
  },
};

function createBaseGqlQueryParameter(): GqlQueryParameter {
  return { value: undefined, cursor: undefined };
}

export const GqlQueryParameter: MessageFns<GqlQueryParameter> = {
  encode(message: GqlQueryParameter, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.value !== undefined) {
      Value.encode(message.value, writer.uint32(18).fork()).join();
    }
    if (message.cursor !== undefined) {
      writer.uint32(26).bytes(message.cursor);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): GqlQueryParameter {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseGqlQueryParameter();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 2:
          if (tag !== 18) {
            break;
          }

          message.value = Value.decode(reader, reader.uint32());
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.cursor = Buffer.from(reader.bytes());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): GqlQueryParameter {
    return {
      value: isSet(object.value) ? Value.fromJSON(object.value) : undefined,
      cursor: isSet(object.cursor) ? Buffer.from(bytesFromBase64(object.cursor)) : undefined,
    };
  },

  toJSON(message: GqlQueryParameter): unknown {
    const obj: any = {};
    if (message.value !== undefined) {
      obj.value = Value.toJSON(message.value);
    }
    if (message.cursor !== undefined) {
      obj.cursor = base64FromBytes(message.cursor);
    }
    return obj;
  },

  create(base?: DeepPartial<GqlQueryParameter>): GqlQueryParameter {
    return GqlQueryParameter.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<GqlQueryParameter>): GqlQueryParameter {
    const message = createBaseGqlQueryParameter();
    message.value = (object.value !== undefined && object.value !== null) ? Value.fromPartial(object.value) : undefined;
    message.cursor = object.cursor ?? undefined;
    return message;
  },
};

function createBaseQueryResultBatch(): QueryResultBatch {
  return {
    skippedResults: 0,
    skippedCursor: Buffer.alloc(0),
    entityResultType: 0,
    entityResults: [],
    endCursor: Buffer.alloc(0),
    moreResults: 0,
    snapshotVersion: Long.ZERO,
    readTime: undefined,
  };
}

export const QueryResultBatch: MessageFns<QueryResultBatch> = {
  encode(message: QueryResultBatch, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.skippedResults !== 0) {
      writer.uint32(48).int32(message.skippedResults);
    }
    if (message.skippedCursor.length !== 0) {
      writer.uint32(26).bytes(message.skippedCursor);
    }
    if (message.entityResultType !== 0) {
      writer.uint32(8).int32(message.entityResultType);
    }
    for (const v of message.entityResults) {
      EntityResult.encode(v!, writer.uint32(18).fork()).join();
    }
    if (message.endCursor.length !== 0) {
      writer.uint32(34).bytes(message.endCursor);
    }
    if (message.moreResults !== 0) {
      writer.uint32(40).int32(message.moreResults);
    }
    if (!message.snapshotVersion.equals(Long.ZERO)) {
      writer.uint32(56).int64(message.snapshotVersion.toString());
    }
    if (message.readTime !== undefined) {
      Timestamp.encode(toTimestamp(message.readTime), writer.uint32(66).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): QueryResultBatch {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseQueryResultBatch();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 6:
          if (tag !== 48) {
            break;
          }

          message.skippedResults = reader.int32();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.skippedCursor = Buffer.from(reader.bytes());
          continue;
        case 1:
          if (tag !== 8) {
            break;
          }

          message.entityResultType = reader.int32() as any;
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.entityResults.push(EntityResult.decode(reader, reader.uint32()));
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.endCursor = Buffer.from(reader.bytes());
          continue;
        case 5:
          if (tag !== 40) {
            break;
          }

          message.moreResults = reader.int32() as any;
          continue;
        case 7:
          if (tag !== 56) {
            break;
          }

          message.snapshotVersion = Long.fromString(reader.int64().toString());
          continue;
        case 8:
          if (tag !== 66) {
            break;
          }

          message.readTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): QueryResultBatch {
    return {
      skippedResults: isSet(object.skippedResults) ? globalThis.Number(object.skippedResults) : 0,
      skippedCursor: isSet(object.skippedCursor) ? Buffer.from(bytesFromBase64(object.skippedCursor)) : Buffer.alloc(0),
      entityResultType: isSet(object.entityResultType) ? entityResult_ResultTypeFromJSON(object.entityResultType) : 0,
      entityResults: globalThis.Array.isArray(object?.entityResults)
        ? object.entityResults.map((e: any) => EntityResult.fromJSON(e))
        : [],
      endCursor: isSet(object.endCursor) ? Buffer.from(bytesFromBase64(object.endCursor)) : Buffer.alloc(0),
      moreResults: isSet(object.moreResults) ? queryResultBatch_MoreResultsTypeFromJSON(object.moreResults) : 0,
      snapshotVersion: isSet(object.snapshotVersion) ? Long.fromValue(object.snapshotVersion) : Long.ZERO,
      readTime: isSet(object.readTime) ? fromJsonTimestamp(object.readTime) : undefined,
    };
  },

  toJSON(message: QueryResultBatch): unknown {
    const obj: any = {};
    if (message.skippedResults !== 0) {
      obj.skippedResults = Math.round(message.skippedResults);
    }
    if (message.skippedCursor.length !== 0) {
      obj.skippedCursor = base64FromBytes(message.skippedCursor);
    }
    if (message.entityResultType !== 0) {
      obj.entityResultType = entityResult_ResultTypeToJSON(message.entityResultType);
    }
    if (message.entityResults?.length) {
      obj.entityResults = message.entityResults.map((e) => EntityResult.toJSON(e));
    }
    if (message.endCursor.length !== 0) {
      obj.endCursor = base64FromBytes(message.endCursor);
    }
    if (message.moreResults !== 0) {
      obj.moreResults = queryResultBatch_MoreResultsTypeToJSON(message.moreResults);
    }
    if (!message.snapshotVersion.equals(Long.ZERO)) {
      obj.snapshotVersion = (message.snapshotVersion || Long.ZERO).toString();
    }
    if (message.readTime !== undefined) {
      obj.readTime = message.readTime.toISOString();
    }
    return obj;
  },

  create(base?: DeepPartial<QueryResultBatch>): QueryResultBatch {
    return QueryResultBatch.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<QueryResultBatch>): QueryResultBatch {
    const message = createBaseQueryResultBatch();
    message.skippedResults = object.skippedResults ?? 0;
    message.skippedCursor = object.skippedCursor ?? Buffer.alloc(0);
    message.entityResultType = object.entityResultType ?? 0;
    message.entityResults = object.entityResults?.map((e) => EntityResult.fromPartial(e)) || [];
    message.endCursor = object.endCursor ?? Buffer.alloc(0);
    message.moreResults = object.moreResults ?? 0;
    message.snapshotVersion = (object.snapshotVersion !== undefined && object.snapshotVersion !== null)
      ? Long.fromValue(object.snapshotVersion)
      : Long.ZERO;
    message.readTime = object.readTime ?? undefined;
    return message;
  },
};

function bytesFromBase64(b64: string): Uint8Array {
  return Uint8Array.from(globalThis.Buffer.from(b64, "base64"));
}

function base64FromBytes(arr: Uint8Array): string {
  return globalThis.Buffer.from(arr).toString("base64");
}

type Builtin = Date | Function | Uint8Array | string | number | boolean | undefined;

export type DeepPartial<T> = T extends Builtin ? T
  : T extends Long ? string | number | Long : T extends globalThis.Array<infer U> ? globalThis.Array<DeepPartial<U>>
  : T extends ReadonlyArray<infer U> ? ReadonlyArray<DeepPartial<U>>
  : T extends {} ? { [K in keyof T]?: DeepPartial<T[K]> }
  : Partial<T>;

function toTimestamp(date: Date): Timestamp {
  const seconds = numberToLong(Math.trunc(date.getTime() / 1_000));
  const nanos = (date.getTime() % 1_000) * 1_000_000;
  return { seconds, nanos };
}

function fromTimestamp(t: Timestamp): Date {
  let millis = (t.seconds.toNumber() || 0) * 1_000;
  millis += (t.nanos || 0) / 1_000_000;
  return new globalThis.Date(millis);
}

function fromJsonTimestamp(o: any): Date {
  if (o instanceof globalThis.Date) {
    return o;
  } else if (typeof o === "string") {
    return new globalThis.Date(o);
  } else {
    return fromTimestamp(Timestamp.fromJSON(o));
  }
}

function numberToLong(number: number) {
  return Long.fromNumber(number);
}

function isObject(value: any): boolean {
  return typeof value === "object" && value !== null;
}

function isSet(value: any): boolean {
  return value !== null && value !== undefined;
}

export interface MessageFns<T> {
  encode(message: T, writer?: BinaryWriter): BinaryWriter;
  decode(input: BinaryReader | Uint8Array, length?: number): T;
  fromJSON(object: any): T;
  toJSON(message: T): unknown;
  create(base?: DeepPartial<T>): T;
  fromPartial(object: DeepPartial<T>): T;
}
